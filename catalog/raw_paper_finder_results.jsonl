{"search_index": 1, "query": "multiagent tool science", "title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Yubo Ma", "Zhibin Gou", "Junheng Hao", "Ruochen Xu", "Shuohang Wang", "Liangming Pan", "Yujiu Yang", "Yixin Cao", "Aixin Sun"], "affinity_score": 0.8108, "link": "https://aclanthology.org/2024.emnlp-main.880/", "abstract": "Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and shifts the focus from pursuing an omniscient problem solver to a proficient tool-user. To facilitate the research of such setting, we construct a tool-augmented training corpus named MathFunc which encompasses over 30,000 samples and roughly 6,000 tools. Building on MathFunc, we develop SciAgent to retrieve, understand and, if necessary, tool scientific problem solving. Additionally, we craft a benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs’ abilities with tool assistance. Extensive experiments on SciToolBench confirm the effectiveness of SciAgent. Notably, SciAgent-Llama3-8B surpasses other LLMs with the comparable size by more than 8.0% in absolute accuracy. Furthermore, SciAgent-DeepMath-7B shows much superior performance than ChatGPT.", "bibtex": "@inproceedings{ma-etal-2024-sciagent,\n    title = \"{S}ci{A}gent: Tool-augmented Language Models for Scientific Reasoning\",\n    author = \"Ma, Yubo  and\n      Gou, Zhibin  and\n      Hao, Junheng  and\n      Xu, Ruochen  and\n      Wang, Shuohang  and\n      Pan, Liangming  and\n      Yang, Yujiu  and\n      Cao, Yixin  and\n      Sun, Aixin\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.880/\",\n    doi = \"10.18653/v1/2024.emnlp-main.880\",\n    pages = \"15701--15736\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main SciAgent_ Tool-augmented Language Models for Scientific Reasoning.pdf", "retrieved_at": "2025-11-12T03:14:13.168681Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Haoyang Su", "Renqi Chen", "Shixiang Tang", "Zhenfei Yin", "Xinzhe Zheng", "Jinzhe Li", "Biqing Qi", "Qi Wu", "Hui Li", "Wanli Ouyang", "Philip Torr", "Bowen Zhou", "Nanqing Dong"], "affinity_score": 0.7877, "link": "https://aclanthology.org/2025.acl-long.1368/", "abstract": "The rapid advancement of scientific progress requires innovative tools that can accelerate knowledge discovery. Although recent AI methods, particularly large language models (LLMs), have shown promise in tasks such as hypothesis generation and experimental design, they fall short of replicating the collaborative nature of real-world scientific practices, where diverse experts work together in teams to tackle complex problems. To address the limitations, we propose an LLM-based multi-agent system, i.e., Virtual Scientists (VIRSCI), designed to mimic the teamwork inherent in scientific research. VIRSCI organizes a team of agents to collaboratively generate, evaluate, and refine research ideas. Through comprehensive experiments, we demonstrate that this multi-agent approach outperforms the state-of-the-art method in producing novel scientific ideas. We further investigate the collaboration mechanisms that contribute to its tendency to produce ideas with higher novelty, offering valuable insights to guide future research and illuminating pathways toward building a robust system for autonomous scientific discovery. The code is available at https://github.com/open-sciencelab/Virtual-Scientists.", "bibtex": "@inproceedings{su-etal-2025-many,\n    title = \"Many Heads Are Better Than One: Improved Scientific Idea Generation by A {LLM}-Based Multi-Agent System\",\n    author = \"Su, Haoyang  and\n      Chen, Renqi  and\n      Tang, Shixiang  and\n      Yin, Zhenfei  and\n      Zheng, Xinzhe  and\n      Li, Jinzhe  and\n      Qi, Biqing  and\n      Wu, Qi  and\n      Li, Hui  and\n      Ouyang, Wanli  and\n      Torr, Philip  and\n      Zhou, Bowen  and\n      Dong, Nanqing\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1368/\",\n    doi = \"10.18653/v1/2025.acl-long.1368\",\n    pages = \"28201--28240\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Many Heads Are Better Than One_ Improved Scientific Idea Generation by A LLM-Based Multi-Agent System.pdf", "retrieved_at": "2025-11-12T03:14:13.426072Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "LLM Agents Making Agent Tools", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Georg Wölflein", "Dyke Ferber", "Daniel Truhn", "Ognjen Arandjelovic", "Jakob Nikolas Kather"], "affinity_score": 0.7693, "link": "https://aclanthology.org/2025.acl-long.1266/", "abstract": "Tool use has turned large language models (LLMs) into powerful agents that can perform complex multi-step tasks by dynamically utilising external software components. However, these tools must be implemented in advance by human developers, hindering the applicability of LLM agents in domains demanding large numbers of highly specialised tools, like in life sciences and medicine. Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose ToolMaker, an agentic framework that autonomously transforms papers with code into LLM-compatible tools. Given a GitHub URL and short task description, ToolMaker autonomously installs dependencies and generates code to perform the task, using a closed-loop self-correction mechanism for debugging. To evaluate our approach, we introduce a benchmark comprising 15 complex computational tasks spanning various domains with over 100 unit tests to assess correctness and robustness. Our method correctly implements 80% of the tasks, substantially outperforming current state-of-the-art software engineering agents. ToolMaker therefore is a step towards fully autonomous agent-based scientific workflows.", "bibtex": "@inproceedings{wolflein-etal-2025-llm,\n    title = \"{LLM} Agents Making Agent Tools\",\n    author = {W{\\\"o}lflein, Georg  and\n      Ferber, Dyke  and\n      Truhn, Daniel  and\n      Arandjelovic, Ognjen  and\n      Kather, Jakob Nikolas},\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1266/\",\n    doi = \"10.18653/v1/2025.acl-long.1266\",\n    pages = \"26092--26130\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long LLM Agents Making Agent Tools.pdf", "retrieved_at": "2025-11-12T03:14:13.694052Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool Usage", "venue": "ICLR 2025 Spotlight", "year": "2025", "authors": ["Zhi Gao", "Bofei Zhang", "Pengxiang Li", "Xiaojian Ma", "Tao Yuan", "Yue Fan", "Yuwei Wu", "Yunde Jia", "Song-Chun Zhu", "Qing Li"], "affinity_score": 0.7625, "link": "https://openreview.net/pdf/5023fe68ab67d9e72385045030a9d62d49bf747d.pdf", "abstract": "The advancement of large language models (LLMs) prompts the development of multi-modal agents, which are used as a controller to call external tools, providing a feasible way to solve practical tasks. In this paper, we propose a multi-modal agent tuning method that automatically generates multi-modal tool-usage data and tunes a vision-language model (VLM) as the controller for powerful tool-usage reasoning. To preserve the data quality, we prompt the GPT-4o mini model to generate queries, files, and trajectories, followed by query-file and trajectory verifiers. Based on the data synthesis pipeline, we collect the MM-Traj dataset that contains 20K tasks with trajectories of tool usage. Then, we develop the T3-Agent via Trajectory Tuning on VLMs for Tool usage using MM-Traj. Evaluations on the GTA and GAIA benchmarks show that the T3-Agent consistently achieves improvements on two popular VLMs: MiniCPM-V-8.5B and Qwen2-VL-7B, which outperforms untrained VLMs by 20%, showing the effectiveness of the proposed data synthesis pipeline, leading to high-quality data for tool-usage capabilities.", "bibtex": "@inproceedings{\ngao2025multimodal,\ntitle={Multi-modal Agent Tuning: Building a {VLM}-Driven Agent for Efficient Tool Usage},\nauthor={Zhi Gao and Bofei Zhang and Pengxiang Li and Xiaojian Ma and Tao Yuan and Yue Fan and Yuwei Wu and Yunde Jia and Song-Chun Zhu and Qing Li},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=0bmGL4q7vJ}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Spotlight Multi-modal Agent Tuning_ Building a VLM-Driven Agent for Efficient Tool Usage.pdf", "retrieved_at": "2025-11-12T03:14:14.625045Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Jinheon Baek", "Sujay Kumar Jauhar", "Silviu Cucerzan", "Sung Ju Hwang"], "affinity_score": 0.76, "link": "https://aclanthology.org/2025.naacl-long.342/", "abstract": "The pace of scientific research, vital for improving human life, is complex, slow, and needs specialized expertise. Meanwhile, novel, impactful research often stems from both a deep understanding of prior work, and a cross-pollination of ideas across domains and fields. To enhance the productivity of researchers, we propose ResearchAgent, which leverages the encyclopedic knowledge and linguistic reasoning capabilities of Large Language Models (LLMs) to assist them in their work. This system automatically defines novel problems, proposes methods and designs experiments, while iteratively refining them based on the feedback from collaborative LLM-powered reviewing agents. Specifically, starting with a core scientific paper, ResearchAgent is augmented not only with relevant publications by connecting information over an academic graph but also entities retrieved from a knowledge store derived from shared underlying concepts mined across numerous papers. Then, mimicking a scientific approach to improving ideas with peer discussions, we leverage multiple LLM-based ReviewingAgents that provide reviews and feedback via iterative revision processes. These reviewing agents are instantiated with human preference-aligned LLMs whose criteria for evaluation are elicited from actual human judgments via LLM prompting. We experimentally validate our ResearchAgent on scientific publications across multiple disciplines, showing its effectiveness in generating novel, clear, and valid ideas based on both human and model-based evaluation results. Our initial foray into AI-mediated scientific research has important implications for the development of future systems aimed at supporting researchers in their ideation and operationalization of novel work.", "bibtex": "@inproceedings{baek-etal-2025-researchagent,\n    title = \"{R}esearch{A}gent: Iterative Research Idea Generation over Scientific Literature with Large Language Models\",\n    author = \"Baek, Jinheon  and\n      Jauhar, Sujay Kumar  and\n      Cucerzan, Silviu  and\n      Hwang, Sung Ju\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.342/\",\n    doi = \"10.18653/v1/2025.naacl-long.342\",\n    pages = \"6709--6738\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long ResearchAgent_ Iterative Research Idea Generation over Scientific Literature with Large Language Models.pdf", "retrieved_at": "2025-11-12T03:14:14.845806Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Ziru Chen", "Shijie Chen", "Yuting Ning", "Qianheng Zhang", "Boshi Wang", "Botao Yu", "Yifei Li", "Zeyi Liao", "Chen Wei", "Zitong Lu", "Vishal Dey", "Mingyi Xue", "Frazier N. Baker", "Benjamin Burns", "Daniel Adu-Ampratwum", "Xuhui Huang", "Xia Ning", "Song Gao", "Yu Su", "Huan Sun"], "affinity_score": 0.7594, "link": "https://openreview.net/pdf/01bb45041a6c8c75021cdf0e1835d645398f660d.pdf", "abstract": "The advancements of language language models (LLMs) have piqued growing interest in developing LLM-based language agents to automate scientific discovery end-to-end, which has sparked both excitement and skepticism about the true capabilities of such agents. In this work, we argue that for an agent to fully automate scientific discovery, it must be able to complete all essential tasks in the workflow. Thus, we call for rigorous assessment of agents on individual tasks in a scientific workflow before making bold claims on end-to-end automation. To this end, we present ScienceAgentBench, a new benchmark for evaluating language agents for data-driven scientific discovery. To ensure the scientific authenticity and real-world relevance of our benchmark, we extract 102 tasks from 44 peer-reviewed publications in four disciplines and engage nine subject matter experts to validate them. We unify the target output for every task to a self-contained Python program file and employ an array of evaluation metrics to examine the generated programs, execution results, and costs. Each task goes through multiple rounds of manual validation by annotators and subject matter experts to ensure its annotation quality and scientific plausibility. We also propose two effective strategies to mitigate data contamination concerns. Using our benchmark, we evaluate five open-weight and proprietary LLMs, each with three frameworks: direct prompting, OpenHands, and self-debug. Given three attempts for each task, the best-performing agent can only solve 32.4% of the tasks independently and 34.3% with expert-provided knowledge. These results underscore the limited capacities of current language agents in generating code for data-driven discovery, let alone end-to-end automation for scientific research.", "bibtex": "@inproceedings{\nchen2025scienceagentbench,\ntitle={ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery},\nauthor={Ziru Chen and Shijie Chen and Yuting Ning and Qianheng Zhang and Boshi Wang and Botao Yu and Yifei Li and Zeyi Liao and Chen Wei and Zitong Lu and Vishal Dey and Mingyi Xue and Frazier N. Baker and Benjamin Burns and Daniel Adu-Ampratwum and Xuhui Huang and Xia Ning and Song Gao and Yu Su and Huan Sun},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=6z4YKr0GK6}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster ScienceAgentBench_ Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery.pdf", "retrieved_at": "2025-11-12T03:14:15.511926Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Learning to Use Tools via Cooperative and Interactive Agents", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Zhengliang Shi", "Shen Gao", "Xiuyi Chen", "Yue Feng", "Lingyong Yan", "Haibo Shi", "Dawei Yin", "Pengjie Ren", "Suzan Verberne", "Zhaochun Ren"], "affinity_score": 0.7576, "link": "https://aclanthology.org/2024.findings-emnlp.624/", "abstract": "Tool learning empowers large language models (LLMs) as agents to use external tools and extend their utility. Existing methods employ one single LLM-based agent to iteratively select and execute tools, thereafter incorporating execution results into the next action prediction. Despite their progress, these methods suffer from performance degradation when addressing practical tasks due to: (1) the pre-defined pipeline with restricted flexibility to calibrate incorrect actions, and (2) the struggle to adapt a general LLM-based agent to perform a variety of specialized actions. To mitigate these problems, we propose ConAgents, a Cooperative and interactive Agents framework, which coordinates three specialized agents for tool selection, tool execution, and action calibration separately. ConAgents introduces two communication protocols to enable the flexible cooperation of agents. To effectively generalize the ConAgents into open-source models, we also propose specialized action distillation, enhancing their ability to perform specialized actions in our framework. Our extensive experiments on three datasets show that the LLMs, when equipped with the ConAgents, outperform baselines with substantial improvement (i.e., up to 14% higher success rate).", "bibtex": "@inproceedings{shi-etal-2024-learning,\n    title = \"Learning to Use Tools via Cooperative and Interactive Agents\",\n    author = \"Shi, Zhengliang  and\n      Gao, Shen  and\n      Chen, Xiuyi  and\n      Feng, Yue  and\n      Yan, Lingyong  and\n      Shi, Haibo  and\n      Yin, Dawei  and\n      Ren, Pengjie  and\n      Verberne, Suzan  and\n      Ren, Zhaochun\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.624/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.624\",\n    pages = \"10642--10657\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings Learning to Use Tools via Cooperative and Interactive Agents.pdf", "retrieved_at": "2025-11-12T03:14:15.747789Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Multi-agent Architecture Search via Agentic Supernet", "venue": "ICML 2025 Oral", "year": "2025", "authors": ["Guibin Zhang", "Luyang Niu", "Junfeng Fang", "Kun Wang", "LEI BAI", "Xiang Wang"], "affinity_score": 0.7571, "link": "https://openreview.net/pdf/46a781e93da44fdacc085588e4eeb8edc5f20439.pdf", "abstract": "Large Language Model (LLM)-empowered multi-agent systems extend the cognitive boundaries of individual agents through disciplined collaboration and interaction, while constructing these systems often requires labor-intensive manual designs. Despite the availability of methods to automate the design of agentic workflows, they typically seek to identify a static, complex, one-size-fits-all system, which, however, fails to dynamically allocate inference resources based on the difficulty and domain of each query. To address this challenge, we shift away from the pursuit of a monolithic agentic system, instead optimizing the \\textbf{agentic supernet}, a probabilistic and continuous distribution of agentic architectures. We introduce \\textbf{MaAS}, an automated framework that samples query-dependent agentic systems from the supernet, delivering high-quality solutions and tailored resource allocation (\\textit{e.g.}, LLM calls, tool calls, token cost). Comprehensive evaluation across six benchmarks demonstrates that MaAS \\textbf{(I)} requires only $6\\sim45\\%$ of the inference costs of existing handcrafted or automated multi-agent systems, \\textbf{(II)} surpasses them by $0.54\\%\\sim11.82\\%$, and \\textbf{(III)} enjoys superior cross-dataset and cross-LLM-backbone transferability.", "bibtex": "@inproceedings{\nzhang2025multiagent,\ntitle={Multi-agent Architecture Search via Agentic Supernet},\nauthor={Guibin Zhang and Luyang Niu and Junfeng Fang and Kun Wang and LEI BAI and Xiang Wang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=imcyVlzpXh}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Oral Multi-agent Architecture Search via Agentic Supernet.pdf", "retrieved_at": "2025-11-12T03:14:16.841549Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "From Awareness to Adaptability: Enhancing Tool Utilization for Scientific Reasoning", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Wenjing Xie", "Xiaobo Liang", "Juntao Li", "Wanfu Wang", "Kehai Chen (陈科海)", "Qiaoming Zhu (朱巧明)", "Min Zhang (张民)"], "affinity_score": 0.7531, "link": "https://aclanthology.org/2025.findings-acl.461/", "abstract": "As large language models (LLMs) are increasingly applied to complex scientific problem-solving, their effectiveness is often limited by unconscious or failed tool usage. To address this issue, we introduce the Tool-Awareness Training (TAT) method, designed to enhance scientific reasoning. This approach leverages both forward and backward data generation strategies to strengthen the model’s conscious and selective tool utilization in multi-step reasoning tasks. Our method unfolds in three stages: (1) developing tool-knowledge through backward tooluse data generation (2) enhancing tool-awareness in multi-step reasoning by utilizing forward reasoning data, and (3) improving domain adaptability through large-scale domain-specific data for multi-task learning. These three stages progressively establish the foundation for tool learning and scientific reasoning, effectively integrating both, enabling the model to tackle multi-domain scientific tasks while optimizing tool usage. Our experimental results demonstrate that TAT significantly enhances LLM performance in mathematical and scientific reasoning tasks, particularly by improving the model’s tool utilization capabilities, including proactivity and execution success rates.", "bibtex": "@inproceedings{xie-etal-2025-awareness,\n    title = \"From Awareness to Adaptability: Enhancing Tool Utilization for Scientific Reasoning\",\n    author = \"Xie, Wenjing  and\n      Liang, Xiaobo  and\n      Li, Juntao  and\n      Wang, Wanfu  and\n      Chen, Kehai  and\n      Zhu, Qiaoming  and\n      Zhang, Min\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.461/\",\n    doi = \"10.18653/v1/2025.findings-acl.461\",\n    pages = \"8811--8831\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings From Awareness to Adaptability_ Enhancing Tool Utilization for Scientific Reasoning.pdf", "retrieved_at": "2025-11-12T03:14:17.086285Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MultiAgentBench : Evaluating the Collaboration and Competition of LLM agents", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Kunlun Zhu", "Hongyi Du", "Zhaochen Hong", "Xiaocheng Yang", "Shuyi Guo", "Daisy Zhe Wang", "Zhenhailong Wang", "Cheng Qian", "Robert Tang", "Heng Ji", "Jiaxuan You"], "affinity_score": 0.7523, "link": "https://aclanthology.org/2025.acl-long.421/", "abstract": "Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents; yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition. In this paper, we introduce MultiAgentBench, a comprehensive benchmark designed to evaluate LLM-based multi-agent systems across diverse, interactive scenarios. Our framework measures not only task completion but also the quality of collaboration and competition using novel, milestone-based key performance indicators. Moreover, we evaluate various coordination protocols (including star, chain, tree, and graph topologies) and innovative strategies such as group discussion and cognitive planning. Notably, cognitive planning improves milestone achievement rates by 3%. Code and dataset will be made publicly available. Code and datasets are publicavailable at https://github.com/ulab-uiuc/MARBLE", "bibtex": "@inproceedings{zhu-etal-2025-multiagentbench,\n    title = \"{M}ulti{A}gent{B}ench : Evaluating the Collaboration and Competition of {LLM} agents\",\n    author = \"Zhu, Kunlun  and\n      Du, Hongyi  and\n      Hong, Zhaochen  and\n      Yang, Xiaocheng  and\n      Guo, Shuyi  and\n      Wang, Zhe  and\n      Wang, Zhenhailong  and\n      Qian, Cheng  and\n      Tang, Robert  and\n      Ji, Heng  and\n      You, Jiaxuan\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.421/\",\n    doi = \"10.18653/v1/2025.acl-long.421\",\n    pages = \"8580--8622\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long MultiAgentBench _ Evaluating the Collaboration and Competition of LLM agents.pdf", "retrieved_at": "2025-11-12T03:14:17.358295Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ACT: Knowledgeable Agents to Design and Perform Complex Tasks", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Makoto Nakatsuji", "Shuhei Tateishi", "Yasuhiro Fujiwara", "Ayaka Matsumoto", "Narichika Nomoto", "Yoshihide Kato"], "affinity_score": 0.7513, "link": "https://aclanthology.org/2025.acl-long.823/", "abstract": "Large language models enhance collaborative task execution in multi-agent systems. Current studies break complex task into manageable tasks, but agents lack understanding of the overall task and how others approach their tasks, hindering synergy and integration.We propose a method called knowledgeable A gents to design and perform C omplex T asks (ACT), where: (1) Agents independently manage their knowledge and tasks while collaboratively design the complex task into a more comprehensible form. In parallel, each agent also acquires knowledge of others, defined as a structured description of how other agents approach their tasks based on the agent’s own task resolution. (2) Each agent updates its knowledge and refines its task through interactions with others. By referencing structured knowledge, they effectively integrate their tasks to collaboratively solve the complex task.Three evaluations including creative writing and tool utilization, show that ACT accurately outperforms existing methods in solving complex tasks.", "bibtex": "@inproceedings{nakatsuji-etal-2025-act,\n    title = \"{ACT}: Knowledgeable Agents to Design and Perform Complex Tasks\",\n    author = \"Nakatsuji, Makoto  and\n      Tateishi, Shuhei  and\n      Fujiwara, Yasuhiro  and\n      Matsumoto, Ayaka  and\n      Nomoto, Narichika  and\n      Sato, Yoshihide\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.823/\",\n    doi = \"10.18653/v1/2025.acl-long.823\",\n    pages = \"16831--16861\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long ACT_ Knowledgeable Agents to Design and Perform Complex Tasks.pdf", "retrieved_at": "2025-11-12T03:18:12.451811Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Yaolun Zhang", "Xiaogeng Liu", "Chaowei Xiao"], "affinity_score": 0.7472, "link": "https://openreview.net/pdf/34ab3426aaf31798b2df911672d4e1e4643a631d.pdf", "abstract": "Large Language Models (LLMs) have demonstrated the ability to solve a wide range of practical tasks within multi-agent systems. However, existing human-designed multi-agent frameworks are typically limited to a small set of pre-defined scenarios, while current automated design methods suffer from several limitations, such as the lack of tool integration, dependence on external training data, and rigid communication structures. In this paper, we propose \\textbf{MetaAgent}, a  \\textbf{finite state machine} based framework that can automatically generate a multi-agent system. Given a task description, MetaAgent will design a multi-agent system and polish it through an optimization algorithm. When the multi-agent system is deployed, the finite state machine will control the agent's actions and the state transitions. To evaluate our framework, we conduct experiments on both text-based tasks and practical tasks. The results indicate that the generated multi-agent system surpasses other auto-designed methods and can achieve a comparable performance with the human-designed multi-agent system, which is optimized for those specific tasks.", "bibtex": "@inproceedings{\nzhang2025metaagent,\ntitle={MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines},\nauthor={Yaolun Zhang and Xiaogeng Liu and Chaowei Xiao},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=vOxaD3hhPt}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster MetaAgent_ Automatically Constructing Multi-Agent Systems Based on Finite State Machines.pdf", "retrieved_at": "2025-11-12T03:18:13.398069Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Iterative Tool Usage Exploration for Multimodal Agents via Step-wise Preference Tuning", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Pengxiang Li", "Zhi Gao", "Bofei Zhang", "Yapeng Mi", "Xiaojian Ma", "Chenrui Shi", "Tao Yuan", "Yuwei Wu", "Yunde Jia", "Song-Chun Zhu", "Qing Li"], "affinity_score": 0.7454, "link": "https://openreview.net/pdf/a3ae43bcdfe712b2361e4ab5254bbce2bcc0dd95.pdf", "abstract": "Multimodal agents, which integrate a controller (e.g., a vision language model) with external tools, have demonstrated remarkable capabilities in tackling complex multimodal tasks.\nExisting approaches for training these agents, both supervised fine-tuning and reinforcement learning, depend on extensive human-annotated task-answer pairs and tool trajectories.\nHowever, for complex multimodal tasks, such annotations are prohibitively expensive or impractical to obtain.\nIn this paper, we propose an iterative tool usage exploration method for multimodal agents without any pre-collected data, namely SPORT, via step-wise preference optimization to refine the trajectories of tool usage. Our method enables multimodal agents to autonomously discover effective tool usage strategies through self-exploration and optimization, eliminating the bottleneck of human annotation.\nSPORT has four iterative components: task synthesis, step sampling, step verification, and preference tuning.\nWe first synthesize multimodal tasks using language models. \nThen, we introduce a novel trajectory exploration scheme, where step sampling and step verification are executed alternately to solve synthesized tasks.\nIn step sampling, the agent tries different tools and obtains corresponding results. \nIn step verification, we employ a verifier to provide AI feedback to construct step-wise preference data. \nThe data is subsequently used to update the controller for tool usage through preference tuning, producing a SPORT agent.\nBy interacting with real environments, the SPORT agent gradually evolves into a more refined and capable system.\nEvaluation in the GTA and GAIA benchmarks shows that the SPORT agent achieves 6.41% and  3.64% improvements, underscoring the generalization and effectiveness introduced by our method.", "bibtex": "@inproceedings{\nli2025iterative,\ntitle={Iterative Tool Usage Exploration for Multimodal Agents via Step-wise Preference Tuning},\nauthor={Pengxiang Li and Zhi Gao and Bofei Zhang and Yapeng Mi and Xiaojian Ma and Chenrui Shi and Tao Yuan and Yuwei Wu and Yunde Jia and Song-Chun Zhu and Qing Li},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=yKUwkihcsi}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Iterative Tool Usage Exploration for Multimodal Agents via Step-wise Preference Tuning.pdf", "retrieved_at": "2025-11-12T03:18:14.424206Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Voting or Consensus? Decision-Making in Multi-Agent Debate", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Lars Benedikt Kaesberg", "Jonas Becker", "Jan Philip Wahle", "Terry Ruas", "Bela Gipp"], "affinity_score": 0.7446, "link": "https://aclanthology.org/2025.findings-acl.606/", "abstract": "Much of the success of multi-agent debates depends on carefully choosing the right parameters. The decision-making protocol stands out as it can highly impact final model answers, depending on how decisions are reached. Systematic comparison of decision protocols is difficult because many studies alter multiple discussion parameters beyond the protocol. So far, it has been largely unknown how decision-making influences different tasks. This work systematically evaluates the impact of seven decision protocols (e.g., majority voting, unanimity consensus). We change only one variable at a time - the decision protocol - to analyze how different methods affect the collaboration between agents and measure differences in knowledge and reasoning tasks. Our results show that voting protocols improve performance by 13.2% in reasoning tasks and consensus protocols by 2.8% in knowledge tasks compared to other decision protocols. Increasing the number of agents improves performance, while more discussion rounds before voting reduce it. To improve decision-making by increasing answer diversity, we propose two new methods, All-Agents Drafting (AAD) and Collective Improvement (CI). Our methods improve task performance by up to 3.3% with AAD and up to 7.4% with CI. This work demonstrates the importance of decision-making in multi-agent debates beyond scaling.", "bibtex": "@inproceedings{kaesberg-etal-2025-voting,\n    title = \"Voting or Consensus? Decision-Making in Multi-Agent Debate\",\n    author = \"Kaesberg, Lars Benedikt  and\n      Becker, Jonas  and\n      Wahle, Jan Philip  and\n      Ruas, Terry  and\n      Gipp, Bela\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.606/\",\n    doi = \"10.18653/v1/2025.findings-acl.606\",\n    pages = \"11640--11671\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings Voting or Consensus_ Decision-Making in Multi-Agent Debate.pdf", "retrieved_at": "2025-11-12T03:18:14.693342Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Haochun Wang", "Sendong Zhao", "Jingbo Wang", "Zewen Qiang", "Bing Qin (秦兵)", "Ting Liu (刘挺)"], "affinity_score": 0.7444, "link": "https://aclanthology.org/2025.acl-long.1037/", "abstract": "Multi-agent collaboration has emerged as a pivotal paradigm for addressing complex, distributed tasks in large language model (LLM)-driven applications. While prior research has focused on high-level architectural frameworks, the granular mechanisms governing agents—critical to performance and scalability—remain underexplored. This study systematically investigates four dimensions of collaboration strategies: (1) agent governance, (2) participation control, (3) interaction dynamics, and (4) dialogue history management. Through rigorous experimentation under two context-dependent scenarios—Distributed Evidence Integration (DEI) and Structured Evidence Synthesis (SES)—we quantify the impact of these strategies on both task accuracy and computational efficiency. Our findings reveal that centralized governance, instructor-led participation, ordered interaction patterns, and instructor-curated context summarization collectively optimize the trade-off between decision quality and resource utilization with the support of the proposed Token-Accuracy Ratio (TAR). This work establishes a foundation for designing adaptive, scalable multi-agent systems, shifting the focus from structural novelty to strategic interaction mechanics.", "bibtex": "@inproceedings{wang-etal-2025-beyond,\n    title = \"Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems\",\n    author = \"Wang, Haochun  and\n      Zhao, Sendong  and\n      Wang, Jingbo  and\n      Qiang, Zewen  and\n      Qin, Bing  and\n      Liu, Ting\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1037/\",\n    doi = \"10.18653/v1/2025.acl-long.1037\",\n    pages = \"21361--21375\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Beyond Frameworks_ Unpacking Collaboration Strategies in Multi-Agent Systems.pdf", "retrieved_at": "2025-11-12T03:18:14.935177Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "BLADE: Benchmarking Language Model Agents for Data-Driven Science", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Ken Gu", "Ruoxi Shang", "Ruien Jiang", "Keying Kuang", "Richard-John Lin", "Donghe Lyu", "Yue Mao", "Youran Pan", "Teng Wu", "Jiaqian Yu", "Yikun Zhang", "Tianmai M. Zhang", "Lanyi Zhu", "Mike A Merrill", "Jeffrey Heer", "Tim Althoff"], "affinity_score": 0.7394, "link": "https://aclanthology.org/2024.findings-emnlp.815/", "abstract": "Data-driven scientific discovery requires the iterative integration of scientific domain knowledge, statistical expertise, and an understanding of data semantics to make nuanced analytical decisions, e.g., about which variables, transformations, and statistical models to consider. LM-based agents equipped with planning, memory, and code execution capabilities have the potential to support data-driven science. However, evaluating agents on such open-ended tasks is challenging due to multiple valid approaches, partially correct steps, and different ways to express the same decisions. To address these challenges, we present BLADE, a benchmark to automatically evaluate agents’ multifaceted approaches to open-ended research questions. BLADE consists of 12 datasets and research questions drawn from existing scientific literature, with ground truth collected from independent analyses by expert data scientists and researchers. To automatically evaluate agent responses, we developed corresponding computational methods to match different representations of analyses to this ground truth. Though language models possess considerable world knowledge, our evaluation shows that they are often limited to basic analyses. However, agents capable of interacting with the underlying data demonstrate improved, but still non-optimal, diversity in their analytical decision making. Our work enables the evaluation of agents for data-driven science and provides researchers deeper insights into agents’ analysis approaches.", "bibtex": "@inproceedings{gu-etal-2024-blade,\n    title = \"{BLADE}: Benchmarking Language Model Agents for Data-Driven Science\",\n    author = \"Gu, Ken  and\n      Shang, Ruoxi  and\n      Jiang, Ruien  and\n      Kuang, Keying  and\n      Lin, Richard-John  and\n      Lyu, Donghe  and\n      Mao, Yue  and\n      Pan, Youran  and\n      Wu, Teng  and\n      Yu, Jiaqian  and\n      Zhang, Yikun  and\n      Zhang, Tianmai M.  and\n      Zhu, Lanyi  and\n      Merrill, Mike A  and\n      Heer, Jeffrey  and\n      Althoff, Tim\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.815/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.815\",\n    pages = \"13936--13971\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings BLADE_ Benchmarking Language Model Agents for Data-Driven Science.pdf", "retrieved_at": "2025-11-12T03:18:15.564130Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence", "venue": "ICLR 2025 Spotlight", "year": "2025", "authors": ["Weize Chen", "Ziming You", "Ran Li", "yitong guan", "Chen Qian", "Chenyang Zhao", "Cheng Yang", "Ruobing Xie", "Zhiyuan Liu", "Maosong Sun"], "affinity_score": 0.7392, "link": "https://openreview.net/pdf/1006483e763807a740f78d0096898fc8d8a8424b.pdf", "abstract": "The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents. However, existing multi-agent frameworks often struggle with integrating diverse capable third-party agents due to reliance on agents defined within their own ecosystems. They also face challenges in simulating distributed environments, as most frameworks are limited to single-device setups. Furthermore, these frameworks often rely on hard-coded communication pipelines, limiting their adaptability to dynamic task requirements. Inspired by the concept of the Internet, we propose the Internet of Agents (IoA), a novel framework that addresses these limitations by providing a flexible and scalable platform for LLM-based multi-agent collaboration. IoA introduces an agent integration protocol, an instant-messaging-like architecture design, and dynamic mechanisms for agent teaming and conversation flow control. Through extensive experiments on general assistant tasks, embodied AI tasks, and retrieval-augmented generation benchmarks, we demonstrate that IoA consistently outperforms state-of-the-art baselines, showcasing its ability to facilitate effective collaboration among heterogeneous agents. IoA represents a step towards linking diverse agents in an Internet-like environment, where agents can seamlessly collaborate to achieve greater intelligence and capabilities. We will release our code to facilitate further research.", "bibtex": "@inproceedings{\nchen2025internet,\ntitle={Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence},\nauthor={Weize Chen and Ziming You and Ran Li and yitong guan and Chen Qian and Chenyang Zhao and Cheng Yang and Ruobing Xie and Zhiyuan Liu and Maosong Sun},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=o1Et3MogPw}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Spotlight Internet of Agents_ Weaving a Web of Heterogeneous Agents for Collaborative Intelligence.pdf", "retrieved_at": "2025-11-12T03:18:16.478776Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "EvoAgent: Towards Automatic Multi-Agent Generation via Evolutionary Algorithms", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Siyu Yuan", "Kaitao Song", "Jiangjie Chen", "Xu Tan", "Dongsheng Li", "Deqing Yang"], "affinity_score": 0.7354, "link": "https://aclanthology.org/2025.naacl-long.315/", "abstract": "The rise of powerful large language models (LLMs) has spurred a new trend in building LLM-based autonomous agents for solving complex tasks, especially multi-agent systems. Despite the remarkable progress, we notice that existing works are heavily dependent on human-designed frameworks, which greatly limits the functional scope and scalability of agent systems. How to automatically extend the specialized agent to multi-agent systems to improve task-solving capability still remains a significant challenge. In this paper, we introduce EVOAGENT, a generic method to automatically extend specialized agents to multi-agent systems via the evolutionary algorithm, thereby improving the effectiveness of LLM-based agents in solving tasks. Specifically, we consider the existing agent frameworks as the initial individual and then apply a series of evolutionary operators (e.g., mutation, crossover, selection, etc.) to generate multiple agents with diverse settings. Experimental results across various tasks show that EVOAGENT can significantly enhance the tasksolving capability of LLM-based agents, and can be generalized to any LLM-based agent framework to extend them into multi-agent systems. Resources are available at https://evo-agent.github.io/.", "bibtex": "@inproceedings{yuan-etal-2025-evoagent,\n    title = \"{E}vo{A}gent: Towards Automatic Multi-Agent Generation via Evolutionary Algorithms\",\n    author = \"Yuan, Siyu  and\n      Song, Kaitao  and\n      Chen, Jiangjie  and\n      Tan, Xu  and\n      Li, Dongsheng  and\n      Yang, Deqing\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.315/\",\n    doi = \"10.18653/v1/2025.naacl-long.315\",\n    pages = \"6192--6217\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long EvoAgent_ Towards Automatic Multi-Agent Generation via Evolutionary Algorithms.pdf", "retrieved_at": "2025-11-12T03:18:16.867550Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "An Evaluation Mechanism of LLM-based Agents on Manipulating APIs", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Bing Liu", "Zhou Jianxiang", "Dan Meng", "Haonan Lu"], "affinity_score": 0.7351, "link": "https://aclanthology.org/2024.findings-emnlp.267/", "abstract": "LLM-based agents can greatly extend the abilities of LLMs and thus attract sharply increased studies. An ambitious vision – serving users by manipulating massive API-based tools – has been proposed and explored. However, we find a widely accepted evaluation mechanism for generic agents is still missing. This work aims to fill this gap. We decompose tool use capability into seven aspects and form a thorough evaluation schema. In addition, we design and release an instruction dataset and a toolset – the two sides that the agents bridge between – following the principle of reflecting real-world challenges. Furthermore, we evaluate multiple generic agents. Our findings can inspire future research in improving LLM-based agents and rethink the philosophy of API design.", "bibtex": "@inproceedings{liu-etal-2024-evaluation-mechanism,\n    title = \"An Evaluation Mechanism of {LLM}-based Agents on Manipulating {API}s\",\n    author = \"Liu, Bing  and\n      Jianxiang, Zhou  and\n      Meng, Dan  and\n      Lu, Haonan\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.267/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.267\",\n    pages = \"4649--4662\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings An Evaluation Mechanism of LLM-based Agents on Manipulating APIs.pdf", "retrieved_at": "2025-11-12T03:18:17.137557Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AgentStudio: A Toolkit for Building General Virtual Agents", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Longtao Zheng", "Zhiyuan Huang", "Zhenghai Xue", "Xinrun Wang", "Bo An", "Shuicheng YAN"], "affinity_score": 0.7325, "link": "https://openreview.net/pdf/474fb13c084ca1d640c138556e983c3c43addabb.pdf", "abstract": "General virtual agents need to handle multimodal observations, master complex action spaces, and self-improve in dynamic, open-domain environments. However, existing environments are often domain-specific and require complex setups, which limits agent development and evaluation in real-world settings. As a result, current evaluations lack in-depth analyses that decompose fundamental agent capabilities. We introduce AgentStudio, a trinity of environments, tools, and benchmarks to address these issues. AgentStudio provides a lightweight, interactive environment with highly generic observation and action spaces, e.g., video observations and GUI/API actions. It integrates tools for creating online benchmark tasks, annotating GUI elements, and labeling actions in videos. Based on our environment and tools, we curate an online task suite that benchmarks both GUI interactions and function calling with efficient auto-evaluation. We also reorganize existing datasets and collect new ones using our tools to establish three datasets: GroundUI, IDMBench, and CriticBench. These datasets evaluate fundamental agent abilities, including GUI grounding, learning from videos, and success detection, pointing to the desiderata for robust, general, and open-ended virtual agents.", "bibtex": "@inproceedings{\nzheng2025agentstudio,\ntitle={AgentStudio: A Toolkit for Building General Virtual Agents},\nauthor={Longtao Zheng and Zhiyuan Huang and Zhenghai Xue and Xinrun Wang and Bo An and Shuicheng YAN},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=axUf8BOjnH}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster AgentStudio_ A Toolkit for Building General Virtual Agents.pdf", "retrieved_at": "2025-11-12T03:18:18.215306Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AI-Researcher: Autonomous Scientific Innovation", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Jiabin Tang", "Lianghao Xia", "Zhonghang Li", "Chao Huang"], "affinity_score": 0.731, "link": "https://openreview.net/pdf/a1c63cdd0495de94664b1513f7d95a3aedcb483a.pdf", "abstract": "The powerful reasoning capabilities of Large Language Models (LLMs) in mathematics and coding, combined with their ability to automate complex tasks through agentic frameworks, present unprecedented opportunities for accelerating scientific innovation. In this paper, we introduce AI-Researcher, a fully autonomous research system that transforms how AI-driven scientific discovery is conducted and evaluated. Our framework seamlessly orchestrates the complete research pipeline--from literature review and hypothesis generation to algorithm implementation and publication-ready manuscript preparation--with minimal human intervention. To rigorously assess autonomous research capabilities, we develop Scientist-Bench, a comprehensive benchmark comprising state-of-the-art papers across diverse AI research domains, featuring both guided innovation and open-ended exploration tasks. Through extensive experiments, we demonstrate that AI-Researcher achieves remarkable implementation success rates and produces research papers that approach human-level quality. This work establishes new foundations for autonomous scientific innovation that can complement human researchers by systematically exploring solution spaces beyond cognitive limitations.", "bibtex": "@inproceedings{\ntang2025airesearcher,\ntitle={{AI}-Researcher: Autonomous Scientific Innovation},\nauthor={Jiabin Tang and Lianghao Xia and Zhonghang Li and Chao Huang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=kQWyOYUAC4}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Spotlight AI-Researcher_ Autonomous Scientific Innovation.pdf", "retrieved_at": "2025-11-12T03:18:20.170712Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Improving Multi-Agent Debate with Sparse Communication Topology", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Yunxuan Li", "Yibing Du", "Jiageng Zhang", "Le Hou", "Peter Grabowski", "Yeqing Li", "Eugene Ie"], "affinity_score": 0.7294, "link": "https://aclanthology.org/2024.findings-emnlp.427/", "abstract": "Multi-agent debate has proven effective in improving large language models quality for reasoning and factuality tasks. While various role-playing strategies in multi-agent debates have been explored, in terms of the communication among agents, existing approaches adopt a brute force algorithm – each agent can communicate with all other agents. In this paper, we systematically investigate the effect of communication connectivity in multi-agent systems. Our experiments on GPT and Mistral models reveal that multi-agent debates leveraging sparse communication topology can achieve comparable or superior performance while significantly reducing computational costs. Furthermore, we extend the multi-agent debate framework to multi-modal reasoning and alignment labeling tasks, showcasing its broad applicability and effectiveness. Our findings underscore the importance of communication connectivity on enhancing the efficiency and effectiveness of the “society of minds” approach.", "bibtex": "@inproceedings{li-etal-2024-improving-multi,\n    title = \"Improving Multi-Agent Debate with Sparse Communication Topology\",\n    author = \"Li, Yunxuan  and\n      Du, Yibing  and\n      Zhang, Jiageng  and\n      Hou, Le  and\n      Grabowski, Peter  and\n      Li, Yeqing  and\n      Ie, Eugene\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.427/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.427\",\n    pages = \"7281--7294\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings Improving Multi-Agent Debate with Sparse Communication Topology.pdf", "retrieved_at": "2025-11-12T03:18:20.420074Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "LLM-Based Explicit Models of Opponents for Multi-Agent Games", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["XiaoPeng Yu", "Wanpeng Zhang", "Zongqing Lu"], "affinity_score": 0.729, "link": "https://aclanthology.org/2025.naacl-long.41/", "abstract": "In multi-agent scenarios, the ability to anticipate and respond to opponents is essential, particularly in environments involving adversarial and collaborative interactions. In this paper, we introduce Explicit Models of Opponents (EMO) based on Large Language Models (LLMs), enabling agents to better predict and adapt to diverse, dynamic multi-agent interactions. Unlike traditional methods that often simplify multi-agent interactions using a single opponent model, EMO constructs an individual model for each opponent and aligns these models working in synergy through a bi-level feedback-refinement framework. We test EMO alongside several reasoning methods in multi-player deduction games, where agents must infer hidden information about their opponents. The results show that EMO significantly enhances agents’ decision-making, outperforming traditional single-model approaches. Our findings demonstrate that EMO can be a powerful tool for enhancing LLM-based agents in complex multi-agent systems.", "bibtex": "@inproceedings{yu-etal-2025-llm,\n    title = \"{LLM}-Based Explicit Models of Opponents for Multi-Agent Games\",\n    author = \"Yu, XiaoPeng  and\n      Zhang, Wanpeng  and\n      Lu, Zongqing\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.41/\",\n    doi = \"10.18653/v1/2025.naacl-long.41\",\n    pages = \"892--911\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long LLM-Based Explicit Models of Opponents for Multi-Agent Games.pdf", "retrieved_at": "2025-11-12T03:18:20.672378Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Weizhou Shen", "Chenliang Li", "Hongzhan Chen", "Ming Yan", "Xiaojun Quan", "Hehong Chen", "Ji Zhang", "Fei Huang"], "affinity_score": 0.7274, "link": "https://aclanthology.org/2024.emnlp-main.929/", "abstract": "Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete various tasks in a self-directed fashion. The challenge of tool use demands that LLMs not only understand user queries and generate answers accurately but also excel in task planning, tool invocation, and result summarization. While traditional works focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models. To overcome these challenges, we propose a novel approach that decomposes the aforementioned capabilities into a planner, caller, and summarizer. Each component is implemented by a single LLM that focuses on a specific capability and collaborates with others to accomplish the task. This modular framework facilitates individual updates and the potential use of smaller LLMs for building each capability. To effectively train this framework, we introduce a two-stage training paradigm. First, we fine-tune a backbone LLM on the entire dataset without discriminating sub-tasks, providing the model with a comprehensive understanding of the task. Second, the fine-tuned LLM is used to instantiate the planner, caller, and summarizer respectively, which are continually fine-tuned on respective sub-tasks. Evaluation across various tool-use benchmarks illustrates that our proposed multi-LLM framework surpasses the traditional single-LLM approach, highlighting its efficacy and advantages in tool learning.", "bibtex": "@inproceedings{shen-etal-2024-small,\n    title = \"Small {LLM}s Are Weak Tool Learners: A Multi-{LLM} Agent\",\n    author = \"Shen, Weizhou  and\n      Li, Chenliang  and\n      Chen, Hongzhan  and\n      Yan, Ming  and\n      Quan, Xiaojun  and\n      Chen, Hehong  and\n      Zhang, Ji  and\n      Huang, Fei\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.929/\",\n    doi = \"10.18653/v1/2024.emnlp-main.929\",\n    pages = \"16658--16680\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main Small LLMs Are Weak Tool Learners_ A Multi-LLM Agent.pdf", "retrieved_at": "2025-11-12T03:18:20.927899Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MMedAgent: Learning to Use Medical Tools with Multi-modal Agent", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Binxu Li", "Tiankai Yan", "Yuanting Pan", "Jie Luo", "Ruiyang Ji", "Jiayuan Ding", "Zhe Xu", "Shilong Liu", "Haoyu Dong", "Zihao Lin", "Yixin Wang"], "affinity_score": 0.7265, "link": "https://aclanthology.org/2024.findings-emnlp.510/", "abstract": "Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit limited generality and often fall short when compared to specialized models. Recently, LLM-based agents have been developed to address these challenges by selecting appropriate specialized models as tools based on user inputs. However, such advancements have not been extensively explored within the medical domain. To bridge this gap, this paper introduces the first agent explicitly designed for the medical field, named M ulti-modal Med ical Agent (MMedAgent). We curate an instruction-tuning dataset comprising six medical tools solving seven tasks across five modalities, enabling the agent to choose the most suitable tools for a given task. Comprehensive experiments demonstrate that MMedAgent achieves superior performance across a variety of medical tasks compared to state-of-the-art open-source methods and even the closed-source model, GPT-4o. Furthermore, MMedAgent exhibits efficiency in updating and integrating new medical tools.", "bibtex": "@inproceedings{li-etal-2024-mmedagent,\n    title = \"{MM}ed{A}gent: Learning to Use Medical Tools with Multi-modal Agent\",\n    author = \"Li, Binxu  and\n      Yan, Tiankai  and\n      Pan, Yuanting  and\n      Luo, Jie  and\n      Ji, Ruiyang  and\n      Ding, Jiayuan  and\n      Xu, Zhe  and\n      Liu, Shilong  and\n      Dong, Haoyu  and\n      Lin, Zihao  and\n      Wang, Yixin\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.510/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.510\",\n    pages = \"8745--8760\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings MMedAgent_ Learning to Use Medical Tools with Multi-modal Agent.pdf", "retrieved_at": "2025-11-12T03:18:21.262214Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MMInA: Benchmarking Multihop Multimodal Internet Agents", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Shulin Tian", "Ziniu Zhang", "Liang-Yu Chen", "Ziwei Liu"], "affinity_score": 0.7248, "link": "https://aclanthology.org/2025.findings-acl.703/", "abstract": "Autonomous embodied agents live on an Internet of multimedia websites. Can they hop around multimodal websites to complete complex user tasks? Existing benchmarks fail to assess them in a realistic, evolving environment for their embodiment across websites. To answer this question, we present MMInA, a multihop and multimodal benchmark to evaluate the embodied agents for compositional Internet tasks, with several appealing properties:\n1) Evolving real-world multimodal websites.\nOur benchmark uniquely operates on evolving real-world websites, ensuring a high degree of realism and applicability to natural user tasks. Our data includes 1,050 human-written tasks covering various domains such as shopping and travel, with each task requiring the agent to extract multimodal information from web pages as observations autonomously.\n2) Multihop web browsing.\nOur dataset features naturally compositional tasks that require information from or actions on multiple websites to solve, to assess long-range reasoning capabilities on web tasks.\n3) Holistic evaluation.\nWe propose a novel protocol for evaluating an agent’s progress in completing multihop tasks. We experiment with both standalone (multimodal) language models and heuristic-based web agents. Extensive experiments demonstrate that while long-chain multihop web tasks are easy for humans, they remain challenging for state-of-the-art web agents. We identify that agents are more likely to fail on the early hops when solving tasks of more hops, which results in lower task success rates. To address this issue, we propose a simple memory augmentation approach replaying past action trajectories to reflect. Our method significantly improves the performance of both the single-hop and multihop web browsing abilities.", "bibtex": "@inproceedings{tian-etal-2025-mmina,\n    title = \"{MMI}n{A}: Benchmarking Multihop Multimodal {I}nternet Agents\",\n    author = \"Tian, Shulin  and\n      Zhang, Ziniu  and\n      Chen, Liangyu  and\n      Liu, Ziwei\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.703/\",\n    doi = \"10.18653/v1/2025.findings-acl.703\",\n    pages = \"13682--13697\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings MMInA_ Benchmarking Multihop Multimodal Internet Agents.pdf", "retrieved_at": "2025-11-12T03:18:22.477381Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "CONSENSAGENT: Towards Efficient and Effective Consensus in Multi-Agent LLM Interactions Through Sycophancy Mitigation", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Priya Pitre", "Naren Ramakrishnan", "Xuan Wang"], "affinity_score": 0.7243, "link": "https://aclanthology.org/2025.findings-acl.1141/", "abstract": "Multi-agent large language model (LLM) systems have shown remarkable performance in tasks such as reasoning, planning, and decision-making. However, their applicability is limited by challenges such as high computational costs and robustness issues. In this work, we identify and systematically evaluate a critical yet overlooked challenge: sycophancy, where agents reinforce each other’s responses instead of critically engaging with the debate. This behavior inflates computational costs by requiring additional debate rounds to reach consensus, limiting the efficiency of multi-agent LLM systems. Through experiments on six benchmark reasoning datasets across three models, we analyze the impact of sycophancy and its role in reducing the reliability of multi-agent debate. Motivated by our findings, we propose CONSENSAGENT, a novel framework that dynamically refines prompts based on agent interactions to mitigate sycophancy. CONSENSAGENT improves accuracy of the debate while maintaining efficiency. It significantly outperforms both single-agent and multi-agent baselines, achieving state-of-the-art results across all benchmark datasets. Our findings highlight the crucial role of structured prompt optimization in multi-agent setups and establish a foundation for more reliable, efficient multi-agent LLM systems in real-world applications.", "bibtex": "@inproceedings{pitre-etal-2025-consensagent,\n    title = \"{CONSENSAGENT}: Towards Efficient and Effective Consensus in Multi-Agent {LLM} Interactions Through Sycophancy Mitigation\",\n    author = \"Pitre, Priya  and\n      Ramakrishnan, Naren  and\n      Wang, Xuan\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1141/\",\n    doi = \"10.18653/v1/2025.findings-acl.1141\",\n    pages = \"22112--22133\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings CONSENSAGENT_ Towards Efficient and Effective Consensus in Multi-Agent LLM Interactions Through Sycophancy Mitigation.pdf", "retrieved_at": "2025-11-12T03:18:22.742403Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "SMART: Self-Aware Agent for Tool Overuse Mitigation", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Cheng Qian", "Emre Can Acikgoz", "Hongru Wang", "Xiusi Chen", "Avirup Sil", "Dilek Hakkani-Tur", "Gokhan Tur", "Heng Ji"], "affinity_score": 0.7238, "link": "https://aclanthology.org/2025.findings-acl.239/", "abstract": "Current Large Language Model (LLM) agents demonstrate strong reasoning and tool use capabilities, but often lack self-awareness, failing to balance these approaches effectively. This imbalance leads to\nTool Overuse\n, where models unnecessarily rely on external tools for tasks solvable with parametric knowledge, increasing computational overhead. Inspired by human metacognition, we introduce\nSMART\n(Strategic Model-Aware Reasoning with Tools), a paradigm that enhances an agent’s self-awareness to optimize task handling and reduce tool overuse. To support this paradigm, we introduce\nSMART-ER\n, a dataset spanning three domains, where reasoning alternates between parametric knowledge and tool-dependent steps, with each step enriched by rationales explaining when tools are necessary. Through supervised training, we develop\nSMARTAgent\n, a family of models that dynamically balance parametric knowledge and tool use. Evaluations show that SMARTAgent reduces tool use by 24% while improving performance by over 37%, enabling 7B-scale models to match its 70B counterpart and GPT-4. Additionally, SMARTAgent generalizes to out-of-distribution test data like GSM8K and MINTQA, maintaining accuracy with just one-fifth the tool calls. These highlight the potential of strategic tool use to enhance reasoning, mitigate overuse, and bridge the gap between model size and performance, advancing intelligent and resource-efficient agent designs.", "bibtex": "@inproceedings{qian-etal-2025-smart,\n    title = \"{SMART}: Self-Aware Agent for Tool Overuse Mitigation\",\n    author = {Qian, Cheng  and\n      Acikgoz, Emre Can  and\n      Wang, Hongru  and\n      Chen, Xiusi  and\n      Sil, Avirup  and\n      Hakkani-T{\\\"u}r, Dilek  and\n      Tur, Gokhan  and\n      Ji, Heng},\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.239/\",\n    doi = \"10.18653/v1/2025.findings-acl.239\",\n    pages = \"4604--4621\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings SMART_ Self-Aware Agent for Tool Overuse Mitigation.pdf", "retrieved_at": "2025-11-12T03:18:23.161002Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AgentStore: Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Chengyou Jia", "Minnan Luo (罗敏楠)", "Zhuohang Dang", "Qiushi Sun", "Fangzhi Xu", "Junlin Hu", "Tianbao Xie", "Zhiyong Wu"], "affinity_score": 0.7233, "link": "https://aclanthology.org/2025.findings-acl.466/", "abstract": "Digital agents capable of automating complex computer tasks have attracted considerable attention. However, existing agent methods exhibit deficiencies in their generalization and specialization capabilities, especially in handling open-ended computer tasks in real-world environments. Inspired by the rich functionality of the App store, we present AgentStore, a scalable platform designed to dynamically integrate heterogeneous agents for automating computer tasks. AgentStore allows the system to continuously enrich its capabilities and adapt to rapidly evolving operating systems. Additionally, we propose a novel core MetaAgent with the AgentToken strategy to efficiently manage diverse agents and utilize their specialized and generalist abilities for both domain-specific and system-wide tasks. Extensive experiments on three interactive real-world benchmarks demonstrate that AgentStore significantly expands the capability boundaries of agent systems in both generalization and specialization, underscoring its potential for developing the specialized generalist computer assistant.", "bibtex": "@inproceedings{jia-etal-2025-agentstore,\n    title = \"{A}gent{S}tore: Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant\",\n    author = \"Jia, Chengyou  and\n      Luo, Minnan  and\n      Dang, Zhuohang  and\n      Sun, Qiushi  and\n      Xu, Fangzhi  and\n      Hu, Junlin  and\n      Xie, Tianbao  and\n      Wu, Zhiyong\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.466/\",\n    doi = \"10.18653/v1/2025.findings-acl.466\",\n    pages = \"8908--8934\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings AgentStore_ Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant.pdf", "retrieved_at": "2025-11-12T03:18:24.967486Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Risk-Sensitive Theory of Mind: Coordinating with Agents of Unknown Bias using Cumulative Prospect Theory", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Mason O. Smith", "Wenlong Zhang"], "affinity_score": 0.7229, "link": "https://openreview.net/pdf/b60eb4dcfb1bb3b33c5165fac746c57c165ca3b4.pdf", "abstract": "Humans are often modeled as rational actors by interactive agents when they are in fact frequently observed to make biased decisions. This erroneous assumption may cause an agent’s model of the human to fail, especially when interaction occurs in bias-inducing settings that prompt risky decisions. To address this, this paper formulates a risk-sensitive multi-agent coordination problem and presents the novel Risk-Sensitive Theory of Mind (RS-ToM) framework that allows an autonomous agent to reason about and adapt to a partner of unknown risk-sensitivity. In simulated studies, we show that an agent with an RS-ToM is able to better coordinate with such a partner when compared to an agent that assumes their partner is rational. Thus, we observe significant improvements to team performance, coordination fluency, compliance with partner risk-preferences, and predictability. The presented results suggest that an RS-ToM will be able to model and plan with partners that exhibit these risk-sensitive biases in the real world.", "bibtex": "@inproceedings{\nsmith2025risksensitive,\ntitle={Risk-Sensitive Theory of Mind: Coordinating with Agents of Unknown Bias using Cumulative Prospect Theory},\nauthor={Mason O. Smith and Wenlong Zhang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=MRD19y4Zjm}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Risk-Sensitive Theory of Mind_ Coordinating with Agents of Unknown Bias using Cumulative Prospect Theory.pdf", "retrieved_at": "2025-11-12T03:18:25.668478Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Inverse Attention Agents for Multi-Agent Systems", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Qian Long", "Ruoyan Li", "Minglu Zhao", "Tao Gao", "Demetri Terzopoulos"], "affinity_score": 0.7227, "link": "https://openreview.net/pdf/3a5cba611f316d02e2767025a0b698800b6c4e75.pdf", "abstract": "A major challenge for Multi-Agent Systems (MAS) is enabling agents to adapt dynamically to diverse environments in which opponents and teammates may continually change. Agents trained using conventional methods tend to excel only within the confines of their training cohorts; their performance drops significantly when confronting unfamiliar agents. To address this shortcoming, we introduce Inverse Attention Agents that adopt concepts from the Theory of Mind (ToM) implemented algorithmically using an attention mechanism trained in an end-to-end manner. Crucial to determining the final actions of these agents, the weights in their attention model explicitly represent attention to different goals. We furthermore propose an inverse attention network that deduces the ToM of agents based on observations and prior actions. The network infers the attentional states of other agents, thereby refining the attention weights to adjust the agent's final action. We conduct experiments in a continuous environment, tackling demanding tasks encompassing cooperation, competition, and a blend of both. They demonstrate that the inverse attention network successfully infers the attention of other agents, and that this information improves agent performance. Additional human experiments show that, compared to baseline agent models, our inverse attention agents exhibit superior cooperation with humans and better emulate human behaviors.", "bibtex": "@inproceedings{\nlong2025inverse,\ntitle={Inverse Attention Agents for Multi-Agent Systems},\nauthor={Qian Long and Ruoyan Li and Minglu Zhao and Tao Gao and Demetri Terzopoulos},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=OaoDVZntGe}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Inverse Attention Agents for Multi-Agent Systems.pdf", "retrieved_at": "2025-11-12T03:18:27.289544Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "SCALE: Towards Collaborative Content Analysis in Social Science with Large Language Model Agents and Human Intervention", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Chengshuai Zhao", "Zhen Tan", "Chau-Wai Wong", "Xinyan Zhao", "Tianlong Chen", "Huan Liu (刘欢)"], "affinity_score": 0.7164, "link": "https://aclanthology.org/2025.acl-long.416/", "abstract": "Content analysis breaks down complex and unstructured texts into theory-informed numerical categories. Particularly, in social science, this process usually relies on multiple rounds of manual annotation, domain expert discussion, and rule-based refinement. In this paper, we introduce SCALE, a novel multi-agent framework that effectively ̲ S imulates ̲ C ontent ̲ A nalysis via ̲ L arge language model (LLM) ag ̲ E nts. SCALE imitates key phases of content analysis, including text coding, collaborative discussion, and dynamic codebook evolution, capturing the reflective depth and adaptive discussions of human researchers. Furthermore, by integrating diverse modes of human intervention, SCALE is augmented with expert input to further enhance its performance. Extensive evaluations on real-world datasets demonstrate that SCALE achieves human-approximated performance across various complex content analysis tasks, offering an innovative potential for future social science research.", "bibtex": "@inproceedings{zhao-etal-2025-scale,\n    title = \"{SCALE}: Towards Collaborative Content Analysis in Social Science with Large Language Model Agents and Human Intervention\",\n    author = \"Zhao, Chengshuai  and\n      Tan, Zhen  and\n      Wong, Chau-Wai  and\n      Zhao, Xinyan  and\n      Chen, Tianlong  and\n      Liu, Huan\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.416/\",\n    doi = \"10.18653/v1/2025.acl-long.416\",\n    pages = \"8473--8503\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long SCALE_ Towards Collaborative Content Analysis in Social Science with Large Language Model Agents and Human Intervention.pdf", "retrieved_at": "2025-11-12T03:18:27.547746Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Tianyi Men", "Zhuoran Jin", "Pengfei Cao", "Yubo Chen (陈玉博)", "Kang Liu (刘康)", "Jun Zhao (军 赵)"], "affinity_score": 0.7163, "link": "https://aclanthology.org/2025.acl-long.857/", "abstract": "As Multimodal Large Language Models (MLLMs) advance, multimodal agents show promise in real-world tasks like web navigation and embodied intelligence. However, due to limitations in a lack of external feedback, these agents struggle with self-correction and generalization. A promising approach is to use reward models as external feedback, but there is no clear on how to select reward models for agents. Thus, there is an urgent need to build a reward bench targeted at agents. To address these challenges, we propose Agent-RewardBench, a benchmark designed to evaluate reward modeling ability in MLLMs. The benchmark is characterized by three key features: (1) Multiple dimensions and real-world agent scenarios evaluation. It covers perception, planning, and safety with 7 scenarios; (2) Step-level reward evaluation. It allows for the assessment of agent capabilities at the individual steps of a task, providing a more granular view of performance during the planning process; and (3) Appropriately difficulty and high-quality. We carefully sample from 10 diverse models, difficulty control to maintain task challenges, and manual verification to ensure the integrity of the data. Experiments demonstrate that even state-of-the-art multimodal models show limited performance, highlighting the need for specialized training in agent reward modeling. Code is available at github.", "bibtex": "@inproceedings{men-etal-2025-agent,\n    title = \"Agent-{R}eward{B}ench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents\",\n    author = \"Men, Tianyi  and\n      Jin, Zhuoran  and\n      Cao, Pengfei  and\n      Chen, Yubo  and\n      Liu, Kang  and\n      Zhao, Jun\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.857/\",\n    doi = \"10.18653/v1/2025.acl-long.857\",\n    pages = \"17521--17541\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Agent-RewardBench_ Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents.pdf", "retrieved_at": "2025-11-12T03:18:27.907367Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Edan Toledo", "Karen Hambardzumyan", "Martin Josifoski", "RISHI HAZRA", "Nicolas Baldwin", "Alexis Audran-Reiss", "Michael Kuchnik", "Despoina Magka", "Minqi Jiang", "Alisia Maria Lupidi", "Andrei Lupu", "Roberta Raileanu", "Tatiana Shavrina", "Kelvin Niu", "Jean-Christophe Gagnon-Audet", "Michael Shvartsman", "Shagun Sodhani", "Alexander H Miller", "Abhishek Charnalia", "Derek Dunfield", "Carole-Jean Wu", "Pontus Stenetorp", "Nicola Cancedda", "Jakob Nicolaus Foerster", "Yoram Bachrach"], "affinity_score": 0.7155, "link": "https://openreview.net/pdf/a22e34894b1de174131d79168e9a32bf5fefd3a5.pdf", "abstract": "AI research agents are demonstrating great potential to accelerate scientific progress by automating the design, implementation, and training of machine learning models. We focus on methods for improving agents' performance on MLE-bench, a challenging benchmark where agents compete in Kaggle competitions to solve real-world machine learning problems. We formalize AI research agents as search policies that navigate a space of candidate solutions, iteratively modifying them using operators. By designing and systematically varying different operator sets and search policies (Greedy, MCTS, Evolutionary), we show that their interplay is critical for achieving high performance. Our best pairing of search strategy and operator set achieves a state-of-the-art result on MLE-bench lite, increasing the success rate of achieving a Kaggle medal from 39.6% to 47.7%. Our investigation underscores the importance of jointly considering the search strategy, operator design, and evaluation methodology in advancing automated machine learning.", "bibtex": "@inproceedings{\ntoledo2025ai,\ntitle={{AI} Research Agents for Machine Learning: Search, Exploration, and Generalization in {MLE}-bench},\nauthor={Edan Toledo and Karen Hambardzumyan and Martin Josifoski and RISHI HAZRA and Nicolas Baldwin and Alexis Audran-Reiss and Michael Kuchnik and Despoina Magka and Minqi Jiang and Alisia Maria Lupidi and Andrei Lupu and Roberta Raileanu and Tatiana Shavrina and Kelvin Niu and Jean-Christophe Gagnon-Audet and Michael Shvartsman and Shagun Sodhani and Alexander H Miller and Abhishek Charnalia and Derek Dunfield and Carole-Jean Wu and Pontus Stenetorp and Nicola Cancedda and Jakob Nicolaus Foerster and Yoram Bachrach},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=RwfrdKSgCE}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Spotlight AI Research Agents for Machine Learning_ Search, Exploration, and Generalization in MLE-bench.pdf", "retrieved_at": "2025-11-12T03:18:28.498314Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Improving Parallel Program Performance with LLM Optimizers via Agent-System Interfaces", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Anjiang Wei", "Allen Nie", "Thiago S. F. X. Teixeira", "Rohan Yadav", "Wonchan Lee", "Ke Wang", "Alex Aiken"], "affinity_score": 0.715, "link": "https://openreview.net/pdf/1c09d7f36ca58adc31509f59aac3eede212bee62.pdf", "abstract": "Modern scientific discovery increasingly relies on high-performance computing for complex modeling and simulation. A key challenge in improving parallel program performance is efficiently mapping tasks to processors and data to memory, a process dictated by intricate, low-level system code known as\nmappers\n. Developing high-performance mappers demands days of manual tuning, posing a significant barrier for domain scientists without systems expertise. We introduce a framework that automates mapper development with generative optimization, leveraging richer feedback beyond scalar performance metrics. Our approach features the Agent-System Interface, which includes a Domain-Specific Language (DSL) to abstract away the low-level complexity of system code and define a structured search space, as well as AutoGuide, a mechanism that interprets raw execution output into actionable feedback. Unlike traditional reinforcement learning methods such as OpenTuner, which rely solely on scalar feedback, our method finds superior mappers in far fewer iterations. With just 10 iterations, it outperforms OpenTuner even after 1000 iterations, achieving $3.8\\times$ faster performance. Our approach finds mappers that surpass expert-written mappers by up to $1.34\\times$ speedup across nine benchmarks while reducing tuning time from days to minutes.", "bibtex": "@inproceedings{\nwei2025improving,\ntitle={Improving Parallel Program Performance with {LLM} Optimizers via Agent-System Interfaces},\nauthor={Anjiang Wei and Allen Nie and Thiago S. F. X. Teixeira and Rohan Yadav and Wonchan Lee and Ke Wang and Alex Aiken},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=3h80HyStMH}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Improving Parallel Program Performance with LLM Optimizers via Agent-System Interfaces.pdf", "retrieved_at": "2025-11-12T03:18:29.178250Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Wanjia Zhao", "Mert Yuksekgonul", "Shirley Wu", "James Zou"], "affinity_score": 0.7147, "link": "https://openreview.net/pdf/856c35f60eccff17ac8726de9ca5f7fbf9bcf3ee.pdf", "abstract": "Multi-agent AI systems powered by large language models (LLMs) are increasingly applied to solve complex tasks. However, these systems often rely on fragile, manually designed prompts and heuristics, making optimization difficult. A key challenge in optimizing multi-agent systems is acquiring suitable training data for specialized agents. We introduce SiriuS, a self-improving, reasoning-driven optimization framework for multi-agent systems. Central to our approach is the construction of an experience library: a repository of high-quality reasoning trajectories. The library is built by retaining reasoning steps that lead to successful outcomes, providing a robust training set for optimizing multi-agent system. Additionally, we introduce a library augmentation procedure that refines unsuccessful trajectories, further enriching the library. SiriuS boosts performance by 2.86% to 21.88% on reasoning and biomedical QA and enhances agent negotiation in competitive settings. Our results show that SiriuS enhances multi-agent performance while generating reusable data for self-correction and self-play enhancement in the future.", "bibtex": "@inproceedings{\nzhao2025sirius,\ntitle={SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning},\nauthor={Wanjia Zhao and Mert Yuksekgonul and Shirley Wu and James Zou},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=IDSTtDw4Cs}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster SiriuS_ Self-improving Multi-agent Systems via Bootstrapped Reasoning.pdf", "retrieved_at": "2025-11-12T03:18:29.735916Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Agent S: An Open Agentic Framework that Uses Computers Like a Human", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Saaket Agashe", "Jiuzhou Han", "Shuyu Gan", "Jiachen Yang", "Ang Li", "Xin Eric Wang"], "affinity_score": 0.7146, "link": "https://openreview.net/pdf/5c0a5b17c744fe619f72841610ad18eb2216c723.pdf", "abstract": "We present Agent S, an open agentic framework that enables autonomous interaction with computers through Graphical User Interface (GUI), aimed at transforming human-computer interaction by automating complex, multi-step tasks. Agent S addresses three key challenges in automating computer tasks: acquiring domain-specific knowledge, planning over long task horizons, and handling dynamic, non-uniform interfaces. To this end, Agent S introduces experience-augmented hierarchical planning, which learns from external knowledge search and internal experience retrieval at multiple levels, facilitating efficient task planning and subtask execution. \nIn addition, it employs an Agent-Computer Interface (ACI) to better elicit the reasoning and control capabilities of GUI agents based on Multimodal Large Language Models (MLLMs). Evaluation on the OSWorld benchmark shows that Agent S outperforms the baseline by 9.37\\% on success rate (an 83.6\\% relative improvement) and achieves a new state-of-the-art. Comprehensive analysis highlights the effectiveness of individual components and provides insights for future improvements. Furthermore, Agent S demonstrates broad generalizability to different operating systems on a newly-released WindowsAgentArena benchmark. Code available at https://github.com/simular-ai/Agent-S.", "bibtex": "@inproceedings{\nagashe2025agent,\ntitle={Agent S: An Open Agentic Framework that Uses Computers Like a Human},\nauthor={Saaket Agashe and Jiuzhou Han and Shuyu Gan and Jiachen Yang and Ang Li and Xin Eric Wang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=lIVRgt4nLv}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Agent S_ An Open Agentic Framework that Uses Computers Like a Human.pdf", "retrieved_at": "2025-11-12T03:18:31.429023Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Anjie Liu", "Jianhong Wang", "Samuel Kaski", "Jun Wang", "Mengyue Yang"], "affinity_score": 0.7145, "link": "https://openreview.net/pdf/4ab60f7a43857f9b872256c8f6144e3b46d65ab2.pdf", "abstract": "Steering cooperative multi-agent reinforcement learning (MARL) towards desired outcomes is challenging, particularly when the global guidance from a human on the whole multi-agent system is impractical in a large-scale MARL. On the other hand, designing external mechanisms (e.g., intrinsic rewards and human feedback) to coordinate agents mostly relies on empirical studies, lacking a easy-to-use research tool. In this work, we employ multi-agent influence diagrams (MAIDs) as a graphical framework to address the above issues. First, we introduce the concept of MARL interaction paradigms (orthogonal to MARL learning paradigms), using MAIDs to analyze and visualize both unguided self-organization and global guidance mechanisms in MARL. Then, we design a new MARL interaction paradigm, referred to as the targeted intervention paradigm that is applied to only a single targeted agent, so the problem of global guidance can be mitigated. In implementation, we introduce a causal inference technique—referred to as Pre-Strategy Intervention (PSI)—to realize the targeted intervention paradigm. Since MAIDs can be regarded as a special class of causal diagrams, a composite desired outcome that integrates the primary task goal and an additional desired outcome can be achieved by maximizing the corresponding causal effect through the PSI. Moreover, the bundled relevance graph analysis of MAIDs provides a tool to identify whether an MARL learning paradigm is workable under the design of an MARL interaction paradigm. In experiments, we demonstrate the effectiveness of our proposed targeted intervention, and verify the result of relevance graph analysis.", "bibtex": "@inproceedings{\nliu2025a,\ntitle={A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning},\nauthor={Anjie Liu and Jianhong Wang and Samuel Kaski and Jun Wang and Mengyue Yang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=Vejx32FeWt}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning.pdf", "retrieved_at": "2025-11-12T03:18:32.422347Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Flow: Modularized Agentic Workflow Automation", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Boye Niu", "Yiliao Song", "Kai Lian", "Yifan Shen", "Yu Yao", "Kun Zhang", "Tongliang Liu"], "affinity_score": 0.714, "link": "https://openreview.net/pdf/883b7c240d2be5b635b144abc546885546d7fa50.pdf", "abstract": "Multi-agent frameworks powered by large language models (LLMs) have demonstrated great success in automated planning and task execution. However, the effective adjustment of agentic workflows during execution has not been well studied. An effective workflow adjustment is crucial in real-world scenarios, as the initial plan must adjust to unforeseen challenges and changing conditions in real time to ensure the efficient execution of complex tasks. In this paper, we define workflows as an activity-on-vertex (AOV) graph, which allows continuous workflow refinement by LLM agents through dynamic subtask allocation adjustment based on historical performance and previous AOVs. To further enhance framework performance, we emphasize modularity in workflow design based on evaluating parallelism and dependency complexity. With this design, our proposed multi-agent framework achieves efficient concurrent execution of subtasks, effective goal achievement, and enhanced error tolerance. Empirical results across various practical tasks demonstrate significant improvements in the efficiency of multi-agent frameworks through dynamic workflow refinement and modularization.", "bibtex": "@inproceedings{\nniu2025flow,\ntitle={Flow: Modularized Agentic Workflow Automation},\nauthor={Boye Niu and Yiliao Song and Kai Lian and Yifan Shen and Yu Yao and Kun Zhang and Tongliang Liu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=sLKDbuyq99}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Flow_ Modularized Agentic Workflow Automation.pdf", "retrieved_at": "2025-11-12T03:18:33.177698Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Efficient Multi-Agent Collaboration with Tool Use for Online Planning in Complex Table Question Answering", "venue": "NAACL 2025 Findings", "year": "2025", "authors": ["Wei Zhou", "Mohsen Mesgar", "Annemarie Friedrich", "Heike Adel"], "affinity_score": 0.7139, "link": "https://aclanthology.org/2025.findings-naacl.54/", "abstract": "Complex table question answering (TQA) aims to answer questions that require complex reasoning, such as multi-step or multi-category reasoning, over data represented in tabular form. Previous approaches demonstrate notable performance by leveraging either closed-source large language models (LLMs) or fine-tuned open-weight LLMs. However, fine-tuning LLMs requires high-quality training data, which is costly to obtain. The use of closed-source LLMs poses accessibility challenges and leads to reproducibility issues. In this paper, we propose Multi Agent Collaboration with Tool use (MACT), a framework that requires neither fine-tuning nor closed-source models. In MACT, a planning agent and a coding agent that also make use of tools collaborate for TQA. MACT outperforms previous SoTA systems on three out of four benchmarks and performs comparably to the larger and more expensive closed-source model GPT-4 on two benchmarks, even when using only open-weight models without any fine-tuning. Our extensive analyses prove the effectiveness of MACT’s multi-agent collaboration in TQA. We release our code publicly.", "bibtex": "@inproceedings{zhou-etal-2025-efficient,\n    title = \"Efficient Multi-Agent Collaboration with Tool Use for Online Planning in Complex Table Question Answering\",\n    author = \"Zhou, Wei  and\n      Mesgar, Mohsen  and\n      Friedrich, Annemarie  and\n      Adel, Heike\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Findings of the Association for Computational Linguistics: NAACL 2025\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-naacl.54/\",\n    doi = \"10.18653/v1/2025.findings-naacl.54\",\n    pages = \"945--968\",\n    ISBN = \"979-8-89176-195-7\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Findings Efficient Multi-Agent Collaboration with Tool Use for Online Planning in Complex Table Question Answering.pdf", "retrieved_at": "2025-11-12T03:18:33.479791Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Agent-Oriented Planning in Multi-Agent Systems", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Ao Li", "Yuexiang Xie", "Songze Li", "Fugee Tsung", "Bolin Ding", "Yaliang Li"], "affinity_score": 0.7135, "link": "https://openreview.net/pdf/82bac503b8ff6352c48f82986a318160a941b2a4.pdf", "abstract": "Through the collaboration of multiple LLM-empowered agents possessing diverse expertise and tools, multi-agent systems achieve impressive progress in solving real-world problems. Given the user queries, the meta-agents, serving as the brain within multi-agent systems, are required to decompose the queries into multiple sub-tasks that can be allocated to suitable agents capable of solving them, so-called agent-oriented planning. In this study, we identify three critical design principles of agent-oriented planning, including solvability, completeness, and non-redundancy, to ensure that each sub-task can be effectively resolved, resulting in satisfactory responses to user queries. These principles further inspire us to propose AOP, a novel framework for agent-oriented planning in multi-agent systems, leveraging a fast task decomposition and allocation process followed by an effective and efficient evaluation via a reward model. According to the evaluation results, the meta-agent is also responsible for promptly making necessary adjustments to sub-tasks and scheduling. Besides, we integrate a feedback loop into AOP to further enhance the effectiveness and robustness of such a problem-solving process. Extensive experiments demonstrate the advancement of AOP in solving real-world problems compared to both single-agent systems and existing planning strategies for multi-agent systems. The source code is available at https://github.com/lalaliat/Agent-Oriented-Planning", "bibtex": "@inproceedings{\nli2025agentoriented,\ntitle={Agent-Oriented Planning in Multi-Agent Systems},\nauthor={Ao Li and Yuexiang Xie and Songze Li and Fugee Tsung and Bolin Ding and Yaliang Li},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=EqcLAU6gyU}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Agent-Oriented Planning in Multi-Agent Systems.pdf", "retrieved_at": "2025-11-12T03:18:34.917068Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks", "venue": "ICML 2025 Spotlightposter", "year": "2025", "authors": ["Guibin Zhang", "Yanwei Yue", "Xiangguo Sun", "Guancheng Wan", "Miao Yu", "Junfeng Fang", "Kun Wang", "Tianlong Chen", "Dawei Cheng"], "affinity_score": 0.712, "link": "https://openreview.net/pdf/ac2d69ee4852bf5e47910fa3e4da09a7322def18.pdf", "abstract": "Recent advancements in large language model (LLM)-based agents have demonstrated that collective intelligence can significantly surpass the capabilities of individual agents, primarily due to well-crafted inter-agent communication topologies. Despite the diverse and high-performing designs available, practitioners often face confusion when selecting the most effective pipeline for their specific task: \\textit{Which topology is the best choice for my task, avoiding unnecessary communication token overhead while ensuring high-quality solution?} In response to this dilemma, we introduce G-Designer, an adaptive, efficient, and robust solution for multi-agent deployment, which dynamically designs task-aware, customized communication topologies. Specifically, G-Designer models the multi-agent system as a multi-agent network, leveraging a variational graph auto-encoder to encode both the nodes (agents) and a task-specific virtual node, and decodes a task-adaptive and high-performing communication topology. Extensive experiments on six benchmarks showcase that G-Designer is: \\textbf{(1) high-performing}, achieving superior results on MMLU with accuracy at $84.50\\%$ and on HumanEval with pass@1 at $89.90\\%$; \\textbf{(2) task-adaptive}, architecting communication protocols tailored to task difficulty, reducing token consumption by up to $95.33\\%$ on HumanEval; and \\textbf{(3) adversarially robust}, defending against agent adversarial attacks with merely $0.3\\%$ accuracy drop.", "bibtex": "@inproceedings{\nzhang2025gdesigner,\ntitle={G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks},\nauthor={Guibin Zhang and Yanwei Yue and Xiangguo Sun and Guancheng Wan and Miao Yu and Junfeng Fang and Kun Wang and Tianlong Chen and Dawei Cheng},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=LpE54NUnmO}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Spotlightposter G-Designer_ Architecting Multi-agent Communication Topologies via Graph Neural Networks.pdf", "retrieved_at": "2025-11-12T03:18:35.641520Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ResearchTown: Simulator of Human Research Community", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Haofei Yu", "Zhaochen Hong", "Zirui Cheng", "Kunlun Zhu", "Keyang Xuan", "Jinwei Yao", "Tao Feng", "Jiaxuan You"], "affinity_score": 0.7119, "link": "https://openreview.net/pdf/17f00ca8bf036f1be17d8f405f4e63cc025c1f64.pdf", "abstract": "Large Language Models (LLMs) have demonstrated remarkable potential in scientific domains, yet a fundamental question remains unanswered: Can we simulate human research communities with LLMs? Addressing this question can deepen our understanding of the processes behind idea brainstorming and inspire the automatic discovery of novel scientific insights. In this work, we propose ResearchTown, a multi-agent framework for research community simulation. Within this framework, the human research community is simplified as an agent-data graph, where researchers and papers are represented as agent-type and data-type nodes, respectively, and connected based on their collaboration relationships. We also introduce TextGNN, a text-based inference framework that models various research activities (e.g., paper reading, paper writing, and review writing) as special forms of a unified message-passing process on the agent-data graph. To evaluate the quality of the research community simulation, we present ResearchBench, a benchmark that uses a node-masking prediction task for scalable and objective assessment based on similarity. Our experiments reveal three key findings: (1) ResearchTown can provide a realistic simulation of collaborative research activities, including paper writing and review writing; (2) ResearchTown can maintain robust simulation with multiple researchers and diverse papers; (3) ResearchTown can generate interdisciplinary research ideas that potentially inspire pioneering research directions.", "bibtex": "@inproceedings{\nyu2025researchtown,\ntitle={ResearchTown: Simulator of Human Research Community},\nauthor={Haofei Yu and Zhaochen Hong and Zirui Cheng and Kunlun Zhu and Keyang Xuan and Jinwei Yao and Tao Feng and Jiaxuan You},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=CZPOIZqWwd}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster ResearchTown_ Simulator of Human Research Community.pdf", "retrieved_at": "2025-11-12T03:18:36.129515Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Xinyi Mou (牟馨忆)", "Jingcong Liang", "Jiayu Lin", "Xinnong Zhang", "Xiawei Liu", "Shiyue Yang", "Rong Ye", "Lei Chen", "Haoyu Kuang", "Xuan-Jing Huang (黄萱菁)", "Zhongyu Wei (魏忠钰)"], "affinity_score": 0.7114, "link": "https://aclanthology.org/2025.naacl-long.257/", "abstract": "Large language models (LLMs) are increasingly leveraged to empower autonomous agents to simulate human beings in various fields of behavioral research. However, evaluating their capacity to navigate complex social interactions remains a challenge. Previous studies face limitations due to insufficient scenario diversity, complexity, and a single-perspective focus. To this end, we introduce AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios. Drawing on Dramaturgical Theory, AgentSense employs a bottom-up approach to create 1,225 diverse social scenarios constructed from extensive scripts. We evaluate LLM-driven agents through multi-turn interactions, emphasizing both goal completion and implicit reasoning. We analyze goals using ERG theory and conduct comprehensive experiments. Our findings highlight that LLMs struggle with goals in complex social scenarios, especially high-level growth needs, and even GPT-4o requires improvement in private information reasoning.", "bibtex": "@inproceedings{mou-etal-2025-agentsense,\n    title = \"{A}gent{S}ense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios\",\n    author = \"Mou, Xinyi  and\n      Liang, Jingcong  and\n      Lin, Jiayu  and\n      Zhang, Xinnong  and\n      Liu, Xiawei  and\n      Yang, Shiyue  and\n      Ye, Rong  and\n      Chen, Lei  and\n      Kuang, Haoyu  and\n      Huang, Xuanjing  and\n      Wei, Zhongyu\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.257/\",\n    doi = \"10.18653/v1/2025.naacl-long.257\",\n    pages = \"4975--5001\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long AgentSense_ Benchmarking Social Intelligence of Language Agents through Interactive Scenarios.pdf", "retrieved_at": "2025-11-12T03:18:36.383710Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Tools Fail: Detecting Silent Errors in Faulty Tools", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Jimin Sun", "So Yeon Min", "Yingshan Chang", "Yonatan Bisk"], "affinity_score": 0.7088, "link": "https://aclanthology.org/2024.emnlp-main.790/", "abstract": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not in their weights, to perform tasks on the web, and even to control robots. However, most ontologies and surveys of tool-use have assumed the core challenge for LLMs is choosing the tool. Instead, we introduce a framework for tools more broadly which guides us to explore a model’s ability to detect “silent” tool errors, and reflect on how to plan. This more directly aligns with the increasingly popular use of models as tools. We provide an initial approach to failure recovery with promising results both on a controlled calculator setting and embodied agent planning.", "bibtex": "@inproceedings{sun-etal-2024-tools,\n    title = \"Tools Fail: Detecting Silent Errors in Faulty Tools\",\n    author = \"Sun, Jimin  and\n      Min, So Yeon  and\n      Chang, Yingshan  and\n      Bisk, Yonatan\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.790/\",\n    doi = \"10.18653/v1/2024.emnlp-main.790\",\n    pages = \"14272--14289\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main Tools Fail_ Detecting Silent Errors in Faulty Tools.pdf", "retrieved_at": "2025-11-12T03:18:36.629893Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "InfantAgent-Next: A Multimodal Generalist Agent for Automated Computer Interaction", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Bin Lei", "Weitai Kang", "Zijian Zhang", "Winson Chen", "Xi Xie", "Shan Zuo", "Mimi Xie", "Ali Payani", "Mingyi Hong", "Yan Yan", "Caiwen Ding"], "affinity_score": 0.7084, "link": "https://openreview.net/pdf/ae7bb751a0d72057590b5907d9d4fa86c412be50.pdf", "abstract": "This paper introduces \\textsc{InfantAgent-Next}, a generalist agent capable of interacting with computers in a multimodal manner, encompassing text, images, audio, and video.\nUnlike existing approaches that either build intricate workflows around a single large model or only provide workflow modularity, our agent integrates tool-based and pure vision agents within a highly modular architecture, enabling different models to collaboratively solve decoupled tasks in a step-by-step manner. \nOur generality is demonstrated by our ability to evaluate not only pure vision-based real-world benchmarks (i.e., OSWorld), but also more general or tool-intensive benchmarks (e.g., GAIA and SWE-Bench).\nSpecifically,\nwe\nachieve a $\\mathbf{7.27\\%}$ accuracy gain over Claude-Computer-Use on OSWorld.\nCodes and evaluation scripts are included in the supplementary material and will be released as open-source.", "bibtex": "@inproceedings{\nlei2025infantagentnext,\ntitle={InfantAgent-Next: A Multimodal Generalist Agent for Automated Computer Interaction},\nauthor={Bin Lei and Weitai Kang and Zijian Zhang and Winson Chen and Xi Xie and Shan Zuo and Mimi Xie and Ali Payani and Mingyi Hong and Yan Yan and Caiwen Ding},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=NKcwN347H7}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster InfantAgent-Next_ A Multimodal Generalist Agent for Automated Computer Interaction.pdf", "retrieved_at": "2025-11-12T03:18:37.727536Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Chanwoo Park", "Seungju Han", "Xingzhi Guo", "Asuman E. Ozdaglar", "Kaiqing Zhang", "Joo-Kyung Kim"], "affinity_score": 0.7066, "link": "https://aclanthology.org/2025.acl-long.1459/", "abstract": "Leveraging multi-agentic frameworks to enhance large language models (LLMs) has demonstrated significant potential recently, with most existing studies focusing on prompting and developing workflows with frozen LLMs. In this paper, we aim to further unleash the power of such multi-agentic frameworks for post-training LLMs for better collaboration. Specifically, we develop a new paradigm of Multi-Agent Post-co-training for collaborative LLMs with Reinforcement Learning (MAPoRL). In MAPoRL, multiple LLMs first generate their own responses and engage in discussions to collaboratively enhance the final response output; the final output is then scored by a verifier, where the scores serve as the reward and is maximized through multi-agent RL. Additionally, MAPoRL also reshapes the reward above with additional incentives to encourage corrective and persuasive outputs in the discussions. A key novelty from most existing LLM post-training paradigms is the advocacy of co-training multiple LLMs together, and the use of RL for better generalization. Accompanied by a few analytical insights, our experiments show that training single LLMs solely is insufficient for encouraging collaboration, while multi-agent co-training can significantly enhance the collaboration performance across multiple datasets, with generalization to unseen domains, compared to that of multiple LLMs before post-training.", "bibtex": "@inproceedings{park-etal-2025-maporl,\n    title = \"{MAP}o{RL}: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning\",\n    author = \"Park, Chanwoo  and\n      Han, Seungju  and\n      Guo, Xingzhi  and\n      Ozdaglar, Asuman E.  and\n      Zhang, Kaiqing  and\n      Kim, Joo-Kyung\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1459/\",\n    doi = \"10.18653/v1/2025.acl-long.1459\",\n    pages = \"30215--30248\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long MAPoRL_ Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning.pdf", "retrieved_at": "2025-11-12T03:18:38.027925Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Priyanka Kargupta", "Ishika Agarwal", "Tal August", "Jiawei Han"], "affinity_score": 0.7052, "link": "https://aclanthology.org/2025.acl-long.1422/", "abstract": "With the exponential growth of research facilitated by modern technology and improved accessibility, scientific discoveries have become increasingly fragmented within and across fields. This makes it challenging to assess the significance, novelty, incremental findings, and equivalent ideas between related works, particularly those from different research communities. Large language models (LLMs) have recently demonstrated strong quantitative and qualitative reasoning abilities, and multi-agent LLM debates have shown promise in handling complex reasoning tasks by exploring diverse perspectives and reasoning paths. Inspired by this, we introduce Tree-of-Debate (ToD), a framework which converts scientific papers into LLM personas that debate their respective novelties. To emphasize structured, critical reasoning rather than focusing solely on outcomes, ToD dynamically constructs a debate tree, enabling fine-grained analysis of independent novelty arguments within scholarly articles. Through experiments on scientific literature across various domains, evaluated by expert researchers, we demonstrate that ToD generates informative arguments, effectively contrasts papers, and supports researchers in their literature review.", "bibtex": "@inproceedings{kargupta-etal-2025-tree,\n    title = \"Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis\",\n    author = \"Kargupta, Priyanka  and\n      Agarwal, Ishika  and\n      August, Tal  and\n      Han, Jiawei\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1422/\",\n    doi = \"10.18653/v1/2025.acl-long.1422\",\n    pages = \"29378--29403\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Tree-of-Debate_ Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis.pdf", "retrieved_at": "2025-11-12T03:18:38.243052Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Siyu Yuan", "Kaitao Song", "Jiangjie Chen", "Xu Tan", "Yongliang Shen", "Kan Ren", "Dongsheng Li", "Deqing Yang"], "affinity_score": 0.7048, "link": "https://aclanthology.org/2025.naacl-long.44/", "abstract": "There has been a rising interest in utilizing tools in applications of autonomous agents based on large language models (LLMs) to address intricate real-world tasks. To develop LLMbased agents, it usually requires LLMs to understand many tool functions from different tool documentations. However, these documentations could be diverse, redundant, or incomplete, which immensely affects the capability of LLMs in using tools. Current LLMs exhibit satisfactory instruction-following capabilities based on instruction-following fine-tuning process. Motivated by this, in this paper, we introduce EASYTOOL, a framework transforming diverse and lengthy tool documentation into a unified and concise tool instruction to fully leverage instruction-following capabilities of LLMs for easier tool usage. EASYTOOL purifies essential information from extensive tool documentation of different sources, and elaborates a unified interface (i.e., tool instruction) to offer standardized tool descriptions and functionalities for LLM-based agents. Extensive experiments on multiple different tasks demonstrate that EASYTOOL can significantly reduce token consumption and improve the performance of LLM-based agents on tool utilization in real-world scenarios. Our code is available in supplemental materials. Our code is available at https://github.com/microsoft/JARVIS/tree/main/easytool.", "bibtex": "@inproceedings{yuan-etal-2025-easytool,\n    title = \"{EASYTOOL}: Enhancing {LLM}-based Agents with Concise Tool Instruction\",\n    author = \"Yuan, Siyu  and\n      Song, Kaitao  and\n      Chen, Jiangjie  and\n      Tan, Xu  and\n      Shen, Yongliang  and\n      Ren, Kan  and\n      Li, Dongsheng  and\n      Yang, Deqing\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.44/\",\n    doi = \"10.18653/v1/2025.naacl-long.44\",\n    pages = \"951--972\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long EASYTOOL_ Enhancing LLM-based Agents with Concise Tool Instruction.pdf", "retrieved_at": "2025-11-12T03:18:38.498270Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Smurfs: Multi-Agent System using Context-Efficient DFSDT for Tool Planning", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Junzhi Chen", "Juhao Liang", "Benyou Wang"], "affinity_score": 0.7048, "link": "https://aclanthology.org/2025.naacl-long.169/", "abstract": "Teaching large language models (LLMs) to tool solving complex problems can grant them human-like reasoning abilities. ReAct and its variants are popular frameworks for tool use in both single-agent and multi-agent systems. To address issues like error propagation and limited exploration in ReAct, the Deep First Search Decision Tree (DFSDT) was proposed, but it faces challenges such as rollback instability, redundant context, and premature termination in single-agent settings. We introduce “Smurfs,” a novel multi-agent system (MAS) that enhances DFSDT with a modular, context-efficient, and training-free design. Smurfs surpasses baseline methods in both the open-ended StableToolBench and the closed-ended HotpotQA tasks, reducing token usage by 60.9% compared to DFSDT and enabling Mistral-7b to perform on par with GPT-4-DFSDT. Extensive ablation studies confirm the effectiveness of Smurfs’ core components, offering valuable insights for the construction and interpretation of MAS, and paving the way for future exploration. We release the code at https://github.com/FreedomIntelligence/Smurfs.", "bibtex": "@inproceedings{chen-etal-2025-smurfs,\n    title = \"Smurfs: Multi-Agent System using Context-Efficient {DFSDT} for Tool Planning\",\n    author = \"Chen, Junzhi  and\n      Liang, Juhao  and\n      Wang, Benyou\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.169/\",\n    doi = \"10.18653/v1/2025.naacl-long.169\",\n    pages = \"3281--3298\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long Smurfs_ Multi-Agent System using Context-Efficient DFSDT for Tool Planning.pdf", "retrieved_at": "2025-11-12T03:18:38.801234Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Automated Design of Agentic Systems", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Shengran Hu", "Cong Lu", "Jeff Clune"], "affinity_score": 0.7048, "link": "https://openreview.net/pdf/116ed45ae3d0873b16f5fdcab7f1fa4f12253e6d.pdf", "abstract": "Researchers are investing substantial effort in developing powerful general-purpose agents, wherein Foundation Models are used as modules within agentic systems (e.g. Chain-of-Thought, Self-Reflection, Toolformer). However, the history of machine learning teaches us that hand-designed solutions are eventually replaced by learned solutions. We describe a newly forming research area, Automated Design of Agentic Systems (ADAS), which aims to automatically create powerful agentic system designs, including inventing novel building blocks and/or combining them in new ways. We further demonstrate that there is an unexplored yet promising approach within ADAS where agents can be defined in code and new agents can be automatically discovered by a meta agent programming ever better ones in code. Given that programming languages are Turing Complete, this approach theoretically enables the learning of any possible agentic system: including novel prompts, tool use, workflows, and combinations thereof. We present a simple yet effective algorithm named Meta Agent Search to demonstrate this idea, where a meta agent iteratively programs interesting new agents based on an ever-growing archive of previous discoveries. Through extensive experiments across multiple domains including coding, science, and math, we show that our algorithm can progressively invent agents with novel designs that greatly outperform state-of-the-art hand-designed agents. Importantly, we consistently observe the surprising result that agents invented by Meta Agent Search maintain superior performance even when transferred across domains and models, demonstrating their robustness and generality. Provided we develop it safely, our work illustrates the potential of an exciting new research direction toward automatically designing ever-more powerful agentic systems to benefit humanity.", "bibtex": "@inproceedings{\nhu2025automated,\ntitle={Automated Design of Agentic Systems},\nauthor={Shengran Hu and Cong Lu and Jeff Clune},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=t9U3LW7JVX}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Automated Design of Agentic Systems.pdf", "retrieved_at": "2025-11-12T03:18:40.280607Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ToolExpNet: Optimizing Multi-Tool Selection in LLMs with Similarity and Dependency-Aware Experience Networks", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Zijing Zhang", "Zhanpeng Chen", "He Zhu", "Ziyang Chen", "Nan Du", "Xiaolong Li (李小龙)"], "affinity_score": 0.7047, "link": "https://aclanthology.org/2025.findings-acl.811/", "abstract": "Tool learning enhances Large Language Models’ (LLMs) dynamic interaction with external tools, improving their ability to solve complex problems. However, current empirical methods, which primarily focus on isolated tools learning, still struggle with accurate multi-tool selection due to issues like confusing similar tools and neglecting dependencies. To address these challenges, we propose the Tool Experience Network (ToolExpNet), which integrates tools and trial-and-error experiences into a network characterized by semantic similarity and dependency relationships. ToolExpNet iteratively conducts simulated experiments using adaptive sampling to explore subtle differences and connections between tools, and summarizes these experiences to provide insightful guidance for LLM tool selection. Our experiments demonstrate that learning the relationships between tools helps achieve more comprehensive tool learning. Evaluations on multiple real-world API datasets show that ToolExpNet effectively addresses common challenges in multi-tool selection, significantly outperforming existing baselines across different foundation LLMs.", "bibtex": "@inproceedings{zhang-etal-2025-toolexpnet,\n    title = \"{T}ool{E}xp{N}et: Optimizing Multi-Tool Selection in {LLM}s with Similarity and Dependency-Aware Experience Networks\",\n    author = \"Zhang, Zijing  and\n      Chen, Zhanpeng  and\n      Zhu, He  and\n      Chen, Ziyang  and\n      Du, Nan  and\n      Li, Xiaolong\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.811/\",\n    doi = \"10.18653/v1/2025.findings-acl.811\",\n    pages = \"15706--15722\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings ToolExpNet_ Optimizing Multi-Tool Selection in LLMs with Similarity and Dependency-Aware Experience Networks.pdf", "retrieved_at": "2025-11-12T03:18:40.508901Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Plasticity as the Mirror of Empowerment", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["David Abel", "Michael Bowling", "Andre Barreto", "Will Dabney", "Shi Dong", "Steven Stenberg Hansen", "Anna Harutyunyan", "Khimya Khetarpal", "Clare Lyle", "Razvan Pascanu", "Georgios Piliouras", "Doina Precup", "Jonathan Richens", "Mark Rowland", "Tom Schaul", "Satinder Singh"], "affinity_score": 0.704, "link": "https://openreview.net/pdf/1da0f949b4feb28e9cc758652d9baf74687e823a.pdf", "abstract": "Agents are minimally entities that are influenced by their past observations and act to influence future observations. This latter capacity is captured by empowerment, which has served as a vital framing concept across artificial intelligence and cognitive science. This former capacity, however, is equally foundational: In what ways, and to what extent, can an agent be influenced by what it observes? In this paper, we ground this concept in a universal agent-centric measure that we refer to as plasticity, and reveal a fundamental connection to empowerment. Following a set of desiderata on a suitable definition, we define plasticity using a new information-theoretic quantity we call the generalized directed information. We show that this new quantity strictly generalizes the directed information introduced by Massey (1990) while preserving all of its desirable properties. Under this definition, we find that plasticity is well thought of as the mirror of empowerment: The two concepts are defined using the same measure, with only the direction of influence reversed. Our main result establishes a tension between the plasticity and empowerment of an agent, suggesting that agent design needs to be mindful of both characteristics. We explore the implications of these findings, and suggest that plasticity, empowerment, and their relationship are essential to understanding agency.", "bibtex": "@inproceedings{\nabel2025plasticity,\ntitle={Plasticity as the Mirror of Empowerment},\nauthor={David Abel and Michael Bowling and Andre Barreto and Will Dabney and Shi Dong and Steven Stenberg Hansen and Anna Harutyunyan and Khimya Khetarpal and Clare Lyle and Razvan Pascanu and Georgios Piliouras and Doina Precup and Jonathan Richens and Mark Rowland and Tom Schaul and Satinder Singh},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=eOZFqyE9Ok}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Spotlight Plasticity as the Mirror of Empowerment.pdf", "retrieved_at": "2025-11-12T03:18:41.075615Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AgentSquare: Automatic LLM Agent Search in Modular Design Space", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Yu Shang", "Yu Li", "Keyu Zhao", "Likai Ma", "Jiahe Liu", "Fengli Xu", "Yong Li"], "affinity_score": 0.7032, "link": "https://openreview.net/pdf/c06588c16619cd2e27dd12043d72f687442e36c5.pdf", "abstract": "Recent advancements in Large Language Models (LLMs) have led to a rapid growth of agentic systems capable of handling a wide range of complex tasks. However, current research largely relies on manual, task-specific design, limiting their adaptability to novel tasks. In this paper, we introduce a new research problem: Modularized LLM Agent Search (MoLAS). We propose a modular design space that abstracts existing LLM agent designs into four fundamental modules with uniform IO interface: Planning, Reasoning, Tool Use, and Memory. Building on this design space, we present a novel LLM agent search framework called AgentSquare, which introduces two core mechanisms, i.e., module evolution and recombination, to efficiently search for optimized LLM agents. To further accelerate the process, we design a performance predictor that uses in-context surrogate models to skip unpromising agent designs. Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Moreover, AgentSquare can generate interpretable design insights, enabling a deeper understanding of agentic architecture and its impact on task performance. We believe that the modular design space and AgentSquare search framework offer a platform for fully exploiting the potential of prior successful designs and consolidate the collective efforts of research community. Code repo is available at https://github.com/tsinghua-fib-lab/AgentSquare.", "bibtex": "@inproceedings{\nshang2025agentsquare,\ntitle={AgentSquare: Automatic {LLM} Agent Search in Modular Design Space},\nauthor={Yu Shang and Yu Li and Keyu Zhao and Likai Ma and Jiahe Liu and Fengli Xu and Yong Li},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=mPdmDYIQ7f}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster AgentSquare_ Automatic LLM Agent Search in Modular Design Space.pdf", "retrieved_at": "2025-11-12T03:18:41.779293Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Caution for the Environment: Multimodal LLM Agents are Susceptible to Environmental Distractions", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Xinbei Ma", "Yiting Wang", "Yao Yao", "Tongxin Yuan", "Aston Zhang", "Zhuosheng Zhang", "Hai Zhao"], "affinity_score": 0.7031, "link": "https://aclanthology.org/2025.acl-long.1087/", "abstract": "This paper investigates the faithfulness of multimodal large language model (MLLM) agents in a graphical user interface (GUI) environment, aiming to address the research question of whether multimodal GUI agents can be distracted by environmental context. A general scenario is proposed where both the user and the agent are benign, and the environment, while not malicious, contains unrelated content. A wide range of MLLMs are evaluated as GUI agents using a simulated dataset, following three working patterns with different levels of perception. Experimental results reveal that even the most powerful models, whether generalist agents or specialist GUI agents, are susceptible to distractions. While recent studies predominantly focus on the helpfulness of agents, our findings first indicate that these agents are prone to environmental distractions. Furthermore, we implement an adversarial environment injection and analyze the approach to improve faithfulness, calling for a collective focus on this important topic.", "bibtex": "@inproceedings{ma-etal-2025-caution,\n    title = \"Caution for the Environment: Multimodal {LLM} Agents are Susceptible to Environmental Distractions\",\n    author = \"Ma, Xinbei  and\n      Wang, Yiting  and\n      Yao, Yao  and\n      Yuan, Tongxin  and\n      Zhang, Aston  and\n      Zhang, Zhuosheng  and\n      Zhao, Hai\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1087/\",\n    doi = \"10.18653/v1/2025.acl-long.1087\",\n    pages = \"22324--22339\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Caution for the Environment_ Multimodal LLM Agents are Susceptible to Environmental Distractions.pdf", "retrieved_at": "2025-11-12T03:18:42.228505Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Enhancing Open-Domain Task-Solving Capability of LLMs via Autonomous Tool Integration from GitHub", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Bohan Lyu", "Xin Cong", "Heyang Yu", "Pan Yang", "Cheng Qian", "Zihe Wang", "Yujia Qin", "Yining Ye", "Yaxi Lu", "Chen Qian", "Zhong Zhang", "Yukun Yan (闫宇坤)", "Yankai Lin (林衍凯)", "Zhiyuan Liu", "Maosong Sun (孙茂松)"], "affinity_score": 0.7031, "link": "https://aclanthology.org/2025.acl-long.845/", "abstract": "Large Language Models (LLMs) excel in traditional natural language processing tasks but struggle with problems that require complex domain-specific calculations or simulations. While equipping LLMs with external tools to build LLM-based agents can enhance their capabilities, existing approaches lack the flexibility to address diverse and ever-evolving user queries in open domains. Currently, there is also no existing dataset that evaluates LLMs on open-domain knowledge that requires tools to solve. To this end, we introduce OpenAct benchmark to evaluate the open-domain task-solving capability, which is built on human expert consultation and repositories in GitHub. It comprises 339 questions spanning 7 diverse domains that need to be solved with domain-specific methods. In our experiments, even state-of-the-art LLMs and LLM-based agents demonstrate unsatisfactory success rates, underscoring the need for a novel approach.Furthermore, we present OpenAgent, a novel LLM-based agent system that can tackle evolving queries in open domains through autonomously integrating specialized tools from GitHub. OpenAgent employs 1) a hierarchical framework where specialized agents handle specific tasks and can assign tasks to inferior agents, 2) a bi-level experience learning mechanism to learn from both humans’ and its own experiences to tackle tool flaws. Experiments demonstrate its superior effectiveness and efficiency, which significantly outperforms baselines. Our data and code are open-source at https://github.com/OpenBMB/OpenAct.", "bibtex": "@inproceedings{lyu-etal-2025-enhancing,\n    title = \"Enhancing Open-Domain Task-Solving Capability of {LLM}s via Autonomous Tool Integration from {G}it{H}ub\",\n    author = \"Lyu, Bohan  and\n      Cong, Xin  and\n      Yu, Heyang  and\n      Yang, Pan  and\n      Qian, Cheng  and\n      Wang, Zihe  and\n      Qin, Yujia  and\n      Ye, Yining  and\n      Lu, Yaxi  and\n      Qian, Chen  and\n      Zhang, Zhong  and\n      Yan, Yukun  and\n      Lin, Yankai  and\n      Liu, Zhiyuan  and\n      Sun, Maosong\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.845/\",\n    doi = \"10.18653/v1/2025.acl-long.845\",\n    pages = \"17257--17277\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Enhancing Open-Domain Task-Solving Capability of LLMs via Autonomous Tool Integration from GitHub.pdf", "retrieved_at": "2025-11-12T03:18:42.586529Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "LAM SIMULATOR: Advancing Data Generation for Large Action Model Training via Online Exploration and Trajectory Feedback", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Thai Quoc Hoang", "Kung-Hsiang Huang", "Shirley Kokane", "Jianguo Zhang", "Zuxin Liu", "Ming Zhu", "Jake Grigsby", "Tian Lan (兰天)", "Michael S Ryoo", "Chien-Sheng Wu", "Shelby Heinecke", "Huan Wang", "Silvio Savarese", "Caiming Xiong", "Juan Carlos Niebles"], "affinity_score": 0.7022, "link": "https://aclanthology.org/2025.findings-acl.670/", "abstract": "Large Action Models (LAMs) for AI Agents offer incredible potential but face challenges due to the need for high-quality training data, especially for multi-steps tasks that involve planning, executing tool calls, and responding to feedback. To address these issues, we present LAM SIMULATOR, a comprehensive framework designed for online exploration of agentic tasks with high-quality feedback. Our framework features a dynamic task query generator, an extensive collection of tools, and an interactive environment where Large Language Model (LLM) Agents can call tools and receive real-time feedback. This setup enables LLM Agents to explore and solve tasks autonomously, facilitating the discovery of multiple approaches to tackle any given task. The resulting action trajectory data are then used to create high-quality training datasets for LAMs. Our experiments on popular agentic benchmarks, ToolBench and CRMArena, highlight the effectiveness of LAM SIMULATOR: models trained with self-generated datasets using our framework achieve significant performance gains, up to a 49.3% improvement over their original baselines. LAM SIMULATOR requires minimal human input during dataset creation, highlighting LAM SIMULATOR’s efficiency and effectiveness in speeding up development of AI agents.", "bibtex": "@inproceedings{hoang-etal-2025-lam,\n    title = \"{LAM} {SIMULATOR}: Advancing Data Generation for Large Action Model Training via Online Exploration and Trajectory Feedback\",\n    author = \"Hoang, Thai Quoc  and\n      Huang, Kung-Hsiang  and\n      Kokane, Shirley  and\n      Zhang, Jianguo  and\n      Liu, Zuxin  and\n      Zhu, Ming  and\n      Grigsby, Jake  and\n      Lan, Tian  and\n      Ryoo, Michael S  and\n      Wu, Chien-Sheng  and\n      Heinecke, Shelby  and\n      Wang, Huan  and\n      Savarese, Silvio  and\n      Xiong, Caiming  and\n      Niebles, Juan Carlos\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.670/\",\n    doi = \"10.18653/v1/2025.findings-acl.670\",\n    pages = \"12921--12934\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings LAM SIMULATOR_ Advancing Data Generation for Large Action Model Training via Online Exploration and Trajectory Feedback.pdf", "retrieved_at": "2025-11-12T03:18:42.827599Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AgentDropout: Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Zhexuan Wang", "Yutong Wang", "Xuebo Liu", "Liang Ding", "Miao Zhang", "Jie Liu (刘杰)", "Min Zhang (张民)"], "affinity_score": 0.7021, "link": "https://aclanthology.org/2025.acl-long.1170/", "abstract": "Multi-agent systems (MAS) based on large language models (LLMs) have demonstrated significant potential in collaborative problem-solving. However, they still face substantial challenges of low communication efficiency and suboptimal task performance, making the careful design of the agents’ communication topologies particularly important. Inspired by the management theory that roles in an efficient team are often dynamically adjusted, we propose AgentDropout , which identifies redundant agents and communication across different communication rounds by optimizing the adjacency matrices of the communication graphs and eliminates them to enhance both token efficiency and task performance. Compared to state-of-the-art methods, AgentDropout achieves an average reduction of 21.6% in prompt token consumption and 18.4% in completion token consumption, along with a performance improvement of 1.14 on the tasks. Furthermore, the extended experiments demonstrate that AgentDropout achieves notable domain transferability and structure robustness, revealing its reliability and effectiveness. We release our code at https://github.com/wangzx1219/AgentDropout.", "bibtex": "@inproceedings{wang-etal-2025-agentdropout,\n    title = \"{A}gent{D}ropout: Dynamic Agent Elimination for Token-Efficient and High-Performance {LLM}-Based Multi-Agent Collaboration\",\n    author = \"Wang, Zhexuan  and\n      Wang, Yutong  and\n      Liu, Xuebo  and\n      Ding, Liang  and\n      Zhang, Miao  and\n      Liu, Jie  and\n      Zhang, Min\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1170/\",\n    doi = \"10.18653/v1/2025.acl-long.1170\",\n    pages = \"24013--24035\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long AgentDropout_ Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration.pdf", "retrieved_at": "2025-11-12T03:18:43.059760Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Fan Liu", "Zhe-Rui Yang", "Cancheng Liu", "Tianrui SONG", "Xiaofeng Gao", "Hao Liu"], "affinity_score": 0.701, "link": "https://openreview.net/pdf/e01a39be0de98c2f808394f7affa2bfb004c68a5.pdf", "abstract": "Mathematical modeling is a cornerstone of scientific discovery and engineering practice, enabling the translation of real-world problems into formal systems across domains such as physics, biology, and economics. Unlike mathematical reasoning, which assumes a predefined formulation, modeling requires open-ended problem analysis, abstraction, and principled formalization. While Large Language Models (LLMs) have shown strong reasoning capabilities, they fall short in rigorous model construction, limiting their utility in real-world problem-solving. To this end, we formalize the task of LLM-powered real-world mathematical modeling, where agents must analyze problems, construct domain-appropriate formulations, and generate complete end-to-end solutions.We introduce MM-Bench, a curated benchmark of 111 problems from the Mathematical Contest in Modeling (MCM/ICM), spanning the years 2000 to 2025 and across ten diverse domains such as physics, biology, and economics.  To tackle this task, we propose MM-Agent, an expert-inspired framework that decomposes mathematical modeling into four stages: open-ended problem analysis, structured model formulation, computational problem solving, and report generation.Experiments on MM-Bench show that MM-Agent significantly outperforms baseline agents, achieving an 11.88\\% improvement over human expert solutions while requiring only 15 minutes and \\$0.88 per task using GPT-4o. Furthermore, under official MCM/ICM protocols, MM-Agent assisted two undergraduate teams in winning the Finalist Award (\\textbf{top 2.0\\% among 27,456 teams}) in MCM/ICM 2025, demonstrating its practical effectiveness as a modeling copilot.", "bibtex": "@inproceedings{\nliu2025mmagent,\ntitle={{MM}-Agent: {LLM} as Agents for Real-world Mathematical Modeling Problem},\nauthor={Fan Liu and Zhe-Rui Yang and Cancheng Liu and Tianrui SONG and Xiaofeng Gao and Hao Liu},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=o8n5oNDsiq}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster MM-Agent_ LLM as Agents for Real-world Mathematical Modeling Problem.pdf", "retrieved_at": "2025-11-12T03:18:43.819800Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Yusuf H Roohani", "Andrew H. Lee", "Qian Huang", "Jian Vora", "Zachary Steinhart", "Kexin Huang", "Alexander Marson", "Percy Liang", "Jure Leskovec"], "affinity_score": 0.6997, "link": "https://openreview.net/pdf/dcfab1feaba7d38761a21e709247e9d97d4b98e2.pdf", "abstract": "Agents based on large language models have shown great potential in accelerating scientific discovery by leveraging their rich background knowledge and reasoning capabilities. In this paper, we introduce BioDiscoveryAgent, an agent that designs new experiments, reasons about their outcomes, and efficiently navigates the hypothesis space to reach desired solutions. We demonstrate our agent on the problem of designing genetic perturbation experiments, where the aim is to find a small subset out of many possible genes that, when perturbed, result in a specific phenotype (e.g., cell growth). Utilizing its biological knowledge, BioDiscoveryAgent can uniquely design new experiments without the need to train a machine learning model or explicitly design an acquisition function as in Bayesian optimization. Moreover, BioDiscoveryAgent using Claude 3.5 Sonnet achieves an average of 21% improvement in predicting relevant genetic perturbations across six datasets, and a 46% improvement in the harder task of non-essential gene perturbation, compared to existing Bayesian optimization baselines specifically trained for this task. Our evaluation includes one dataset that is unpublished, ensuring it is not part of the language model's training data. Additionally, BioDiscoveryAgent predicts gene combinations to perturb more than twice as accurately as a random baseline, a task so far not explored in the context of closed-loop experiment design. The agent also has access to tools for searching the biomedical literature, executing code to analyze biological datasets, and prompting another agent to critically evaluate its predictions. Overall, BioDiscoveryAgent is interpretable at every stage, representing an accessible new paradigm in the computational design of biological experiments with the potential to augment scientists' efficacy.", "bibtex": "@inproceedings{\nroohani2025biodiscoveryagent,\ntitle={BioDiscoveryAgent: An {AI} Agent for Designing Genetic Perturbation Experiments},\nauthor={Yusuf H Roohani and Andrew H. Lee and Qian Huang and Jian Vora and Zachary Steinhart and Kexin Huang and Alexander Marson and Percy Liang and Jure Leskovec},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=HAwZGLcye3}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster BioDiscoveryAgent_ An AI Agent for Designing Genetic Perturbation Experiments.pdf", "retrieved_at": "2025-11-12T03:18:44.492093Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AdaptAgent: Adapting Multimodal Web Agents with Few-Shot Learning from Human Demonstrations", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Gaurav Verma", "Rachneet Kaur", "Nishan Srishankar", "Zhen Zeng", "Tucker Balch", "Manuela Veloso"], "affinity_score": 0.6991, "link": "https://aclanthology.org/2025.acl-long.1008/", "abstract": "State-of-the-art multimodal web agents, powered by Multimodal Large Language Models (MLLMs), can autonomously execute many web tasks by processing user instructions and interacting with graphical user interfaces (GUIs). Current strategies for building web agents rely on (i) the generalizability of underlying MLLMs and their steerability via prompting, and (ii) large-scale fine-tuning of MLLMs on web-related tasks. However, web agents still struggle to automate tasks on unseen websites and domains, limiting their applicability to enterprise-specific and proprietary platforms. Beyond generalization from large-scale pre-training and fine-tuning, we propose building agents for few-shot adaptability using human demonstrations. We introduce the AdaptAgent framework that enables both proprietary and open-weights multimodal web agents to adapt to new websites and domains using few human demonstrations (up to 2). Our experiments on two popular benchmarks — Mind2Web & VisualWebArena — show that using in-context demonstrations (for proprietary models) or meta-adaptation demonstrations (for meta-learned open-weights models) boosts task success rate by 3.36% to 7.21% over non-adapted state-of-the-art models, corresponding to a relative increase of 21.03% to 65.75%. Furthermore, our additional analyses (a) show the effectiveness of multimodal demonstrations over text-only ones, (b) illuminate how different meta-learning data selection strategies influence the agent’s generalization, and (c) demonstrate how the number of few-shot examples affects the web agent’s success rate. Our results offer a complementary axis for developing widely applicable multimodal web agents beyond large-scale pre-training and fine-tuning, emphasizing few-shot adaptability.", "bibtex": "@inproceedings{verma-etal-2025-adaptagent,\n    title = \"{A}dapt{A}gent: Adapting Multimodal Web Agents with Few-Shot Learning from Human Demonstrations\",\n    author = \"Verma, Gaurav  and\n      Kaur, Rachneet  and\n      Srishankar, Nishan  and\n      Zeng, Zhen  and\n      Balch, Tucker  and\n      Veloso, Manuela\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1008/\",\n    doi = \"10.18653/v1/2025.acl-long.1008\",\n    pages = \"20635--20651\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long AdaptAgent_ Adapting Multimodal Web Agents with Few-Shot Learning from Human Demonstrations.pdf", "retrieved_at": "2025-11-12T03:18:45.778936Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MAMM-Refine: A Recipe for Improving Faithfulness in Generation with Multi-Agent Collaboration", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["David Wan", "Justin Chen", "Elias Stengel-Eskin", "Mohit Bansal"], "affinity_score": 0.699, "link": "https://aclanthology.org/2025.naacl-long.498/", "abstract": "Multi-agent collaboration among models has shown promise in reasoning tasks but is underexplored in long-form generation tasks like summarization and question-answering. We extend multi-agent multi-model reasoning to generation, specifically to improving faithfulness through refinement, i.e., revising model-generated outputs to remove factual inconsistencies. We investigate how iterative collaboration among multiple instances and types of large language models (LLMs) enhances subtasks in the refinement process, such as error detection, critiquing unfaithful sentences, and making corrections based on critiques. We design intrinsic evaluations for each subtask, with our findings indicating that both multi-agent (multiple instances) and multi-model (diverse LLM types) approaches benefit error detection and critiquing. Additionally, reframing critiquing and refinement as reranking rather than generation tasks improves multi-agent performance. We consolidate these insights into a final “recipe” called\nM\nulti-\nA\ngent\nM\nulti-\nM\nodel\nRefine\nment (MAMM-Refine), where multi-agent and multi-model collaboration significantly boosts performance on three summarization datasets as well as on long-form question answering, demonstrating the effectiveness and generalizability of our recipe. Our code is publicly available.", "bibtex": "@inproceedings{wan-etal-2025-mamm,\n    title = \"{MAMM}-Refine: A Recipe for Improving Faithfulness in Generation with Multi-Agent Collaboration\",\n    author = \"Wan, David  and\n      Chen, Justin  and\n      Stengel-Eskin, Elias  and\n      Bansal, Mohit\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.498/\",\n    doi = \"10.18653/v1/2025.naacl-long.498\",\n    pages = \"9882--9901\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long MAMM-Refine_ A Recipe for Improving Faithfulness in Generation with Multi-Agent Collaboration.pdf", "retrieved_at": "2025-11-12T03:18:46.008339Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Automated Composition of Agents: A Knapsack Approach for Agentic Component Selection", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Michelle Yuan", "Khushbu Pahwa", "Shuaichen Chang", "Mustafa Devrim Kaba", "MONICA SUNKARA", "Jiarong Jiang", "Xiaofei Ma", "Yi Zhang"], "affinity_score": 0.699, "link": "https://openreview.net/pdf/26b1e763944464b965e20433920eff6eeef74439.pdf", "abstract": "Designing effective agentic systems requires the seamless composition and integration of agents, tools, and models within dynamic and uncertain environments. Most existing methods rely on static, semantic retrieval approaches for tool or agent discovery. However, effective reuse and composition of existing components remain challenging due to incomplete capability descriptions and the limitations of retrieval methods. \nComponent selection suffers because the decisions are not based on capability, cost, and real-time utility.\nTo address these challenges, we introduce a structured, automated framework for agentic system composition that is inspired by the knapsack problem. Our framework enables a composer agent to systematically identify, select, and assemble an optimal set of agentic components by jointly considering performance, budget constraints, and compatibility. By dynamically testing candidate components and modeling their utility in real-time, our approach streamlines the assembly of agentic systems and facilitates scalable reuse of resources. Empirical evaluation with Claude 3.5 Sonnet across five benchmarking datasets shows that our online-knapsack-based composer consistently lies on the Pareto frontier, achieving higher success rates at significantly lower component costs compared to our baselines. \nIn the single-agent setup, the online knapsack composer shows a success rate improvement of up to 31.6\\% in comparison to the retrieval baselines. \nIn multi-agent systems, the online knapsack composer increases success rate from 37\\% to 87\\% when agents are selected from an agent inventory of 100+ agents. \nThe substantial performance gap confirms the robust adaptability of our method across diverse domains and budget constraints.", "bibtex": "@inproceedings{\nyuan2025automated,\ntitle={Automated Composition of Agents: A Knapsack Approach for Agentic Component Selection},\nauthor={Michelle Yuan and Khushbu Pahwa and Shuaichen Chang and Mustafa Devrim Kaba and MONICA SUNKARA and Jiarong Jiang and Xiaofei Ma and Yi Zhang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=1LPPMAUlaT}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Automated Composition of Agents_ A Knapsack Approach for Agentic Component Selection.pdf", "retrieved_at": "2025-11-12T03:18:46.471451Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Scaling Large Language Model-based Multi-Agent Collaboration", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Chen Qian", "Zihao Xie", "YiFei Wang", "Wei Liu", "Kunlun Zhu", "Hanchen Xia", "Yufan Dang", "Zhuoyun Du", "Weize Chen", "Cheng Yang", "Zhiyuan Liu", "Maosong Sun"], "affinity_score": 0.698, "link": "https://openreview.net/pdf/ae4a2f1ceb38887964f97458f71ef3306ae433cb.pdf", "abstract": "Recent breakthroughs in large language model-driven autonomous agents have revealed that multi-agent collaboration often surpasses each individual through collective reasoning. Inspired by the neural scaling law—increasing neurons enhances performance, this study explores whether the continuous addition of collaborative agents can yield similar benefits. Technically, we utilize directed acyclic graphs to organize agents into a multi-agent collaboration network (MacNet), upon which their interactive reasoning is topologically orchestrated for autonomous task solving. Extensive evaluations reveal that it effectively supports collaboration among over a thousand agents, with irregular topologies outperforming regular ones. We also identify a collaborative scaling law—the overall performance follows a logistic growth pattern as agents scale, with collaborative emergence occurring earlier than traditional neural emergence. We speculate this may be because scaling agents catalyzes their multidimensional considerations during interactive reflection and refinement, thereby producing more comprehensive artifacts. The code is available at https://github.com/OpenBMB/ChatDev/tree/macnet.", "bibtex": "@inproceedings{\nqian2025scaling,\ntitle={Scaling Large Language Model-based Multi-Agent Collaboration},\nauthor={Chen Qian and Zihao Xie and YiFei Wang and Wei Liu and Kunlun Zhu and Hanchen Xia and Yufan Dang and Zhuoyun Du and Weize Chen and Cheng Yang and Zhiyuan Liu and Maosong Sun},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=K3n5jPkrU6}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Scaling Large Language Model-based Multi-Agent Collaboration.pdf", "retrieved_at": "2025-11-12T03:18:47.771846Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Exploring Multi-Modal Data with Tool-Augmented LLM Agents for Precise Causal Discovery", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["ChengAo Shen", "Zhengzhang Chen", "Dongsheng Luo", "Dongkuan Xu", "Haifeng Chen", "Jingchao Ni"], "affinity_score": 0.6966, "link": "https://aclanthology.org/2025.findings-acl.36/", "abstract": "Causal discovery is an imperative foundation for decision-making across domains, such as smart health, AI for drug discovery and AIOps. Traditional statistical causal discovery methods, while well-established, predominantly rely on observational data and often overlook the semantic cues inherent in cause-and-effect relationships. The advent of Large Language Models (LLMs) has ushered in an affordable way of leveraging the semantic cues for knowledge-driven causal discovery, but the development of LLMs for causal discovery lags behind other areas, particularly in the exploration of multi-modal data. To bridge the gap, we introduce MatMCD, a multi-agent system powered by tool-augmented LLMs. MatMCD has two key agents: a Data Augmentation agent that retrieves and processes modality-augmented data, and a Causal Constraint agent that integrates multi-modal data for knowledge-driven reasoning. The proposed design of the inner-workings ensures successful cooperation of the agents. Our empirical study across seven datasets suggests the significant potential of multi-modality enhanced causal discovery.", "bibtex": "@inproceedings{shen-etal-2025-exploring,\n    title = \"Exploring Multi-Modal Data with Tool-Augmented {LLM} Agents for Precise Causal Discovery\",\n    author = \"Shen, ChengAo  and\n      Chen, Zhengzhang  and\n      Luo, Dongsheng  and\n      Xu, Dongkuan  and\n      Chen, Haifeng  and\n      Ni, Jingchao\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.36/\",\n    doi = \"10.18653/v1/2025.findings-acl.36\",\n    pages = \"636--660\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings Exploring Multi-Modal Data with Tool-Augmented LLM Agents for Precise Causal Discovery.pdf", "retrieved_at": "2025-11-12T03:18:48.015029Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Uncertainty Calibration for Tool-Using Language Agents", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Hao Liu", "Zi-Yi Dou", "Yixin Wang", "Nanyun Peng", "Yisong Yue"], "affinity_score": 0.6965, "link": "https://aclanthology.org/2024.findings-emnlp.978/", "abstract": "There is increasing interest in equipping language models with the ability to leverage external tools for complex, goal-oriented tasks. However, interacting with external tools introduces inherent uncertainties due to imperfections and misalignments between the tools’ outputs and the agents’ internal models, often leading to suboptimal outcomes. We thus study the problem of tool-use calibration in language agents, and identify prompt design and execution trace selection as two primary areas that suffer from miscalibration. We then propose ProbeCal, which recalibrates the internal probabilities of tool-using language agents to better reflect the actual effectiveness of tool, and enables a more appropriate selection of prompts and execution paths. We empirically show that ProbeCal can significantly and consistently improve off-the-shelf language models in tool-using applications.", "bibtex": "@inproceedings{liu-etal-2024-uncertainty,\n    title = \"Uncertainty Calibration for Tool-Using Language Agents\",\n    author = \"Liu, Hao  and\n      Dou, Zi-Yi  and\n      Wang, Yixin  and\n      Peng, Nanyun  and\n      Yue, Yisong\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.978/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.978\",\n    pages = \"16781--16805\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings Uncertainty Calibration for Tool-Using Language Agents.pdf", "retrieved_at": "2025-11-12T03:18:48.365685Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Advancing Collaborative Debates with Role Differentiation through Multi-Agent Reinforcement Learning", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Haoran Li", "Ziyi Su", "Yun Xue (薛云)", "Zhiliang Tian", "Yiping Song", "Minlie Huang"], "affinity_score": 0.6962, "link": "https://aclanthology.org/2025.acl-long.1105/", "abstract": "Multi-agent collaborative tasks exhibit exceptional capabilities in natural language applications and generation. By prompting agents to assign clear roles, it is possible to facilitate cooperation and achieve complementary capabilities among LLMs. A common strategy involves adopting a relatively general role assignment mechanism, such as introducing a “judge” or a “summarizer”. However, these approaches lack task-specific role customization based on task characteristics. Another strategy involves decomposing the task based on domain knowledge and task characteristics, followed by assigning appropriate roles according to LLMs’ respective strengths, such as programmers and testers. However, in some given tasks, obtaining domain knowledge related to task characteristics and getting the strengths of different LLMs is hard. To solve these problems, we propose a Multi-LLM Cooperation (MLC) framework with automatic role assignment capabilities. The core idea of the MLC is to initialize role assignments randomly and then allow the role embeddings to be learned jointly with the downstream task. To capture the state transitions of multiple LLMs during turn-based speaking, the role embedding is sequence-aware. At the same time, to avoid role convergence, the role differentiation module in MLC encourages behavioral differentiation between LLMs while ensuring the LLM team consistency, guiding different LLMs to develop complementary strengths from the optimization level. Our experiments on seven datasets demonstrate that MLC significantly enhances collaboration and expertise, which collaboratively addresses multi-agent tasks.", "bibtex": "@inproceedings{li-etal-2025-advancing,\n    title = \"Advancing Collaborative Debates with Role Differentiation through Multi-Agent Reinforcement Learning\",\n    author = \"Li, Haoran  and\n      Su, Ziyi  and\n      Xue, Yun  and\n      Tian, Zhiliang  and\n      Song, Yiping  and\n      Huang, Minlie\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1105/\",\n    doi = \"10.18653/v1/2025.acl-long.1105\",\n    pages = \"22655--22666\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Advancing Collaborative Debates with Role Differentiation through Multi-Agent Reinforcement Learning.pdf", "retrieved_at": "2025-11-12T03:18:48.600065Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "SE-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning with LLM-Based Agents", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Yifu Guo", "Jiaye Lin", "Huacan Wang", "Yuzhen Han", "Sen Hu", "Ziyi Ni", "Licheng Wang", "Mingguang Chen"], "affinity_score": 0.6958, "link": "https://openreview.net/pdf/814cd78232da3150c1f91b29920f4f2e4d70fb3c.pdf", "abstract": "Large Language Model (LLM)-based agents have recently shown impressive capabilities in complex reasoning and tool use via multi-step interactions with their environments. While these agents have the potential to tackle complicated tasks, their problem-solving process—agents' interaction trajectory leading to task completion—remains underexploited. These trajectories contain rich feedback that can navigate agents toward the right directions for solving problems correctly. Although prevailing approaches, such as Monte Carlo Tree Search (MCTS), can effectively balance exploration and exploitation, they ignore the interdependence among various trajectories and lack the diversity of search spaces, which leads to redundant reasoning and suboptimal outcomes. To address these challenges, we propose SE-Agent, a Self-Evolution framework that enables Agents to optimize their reasoning processes iteratively. Our approach revisits and enhances former pilot trajectories through three key operations: revision, recombination, and refinement. This evolutionary mechanism enables two critical advantages: (1) it expands the search space beyond local optima by intelligently exploring diverse solution paths guided by previous trajectories, and (2) it leverages cross-trajectory inspiration to efficiently enhance performance while mitigating the impact of suboptimal reasoning paths. Through these mechanisms, SE-Agent achieves continuous self-evolution that incrementally improves reasoning quality. We evaluate SE-Agent on SWE-bench Verified to resolve real-world GitHub issues. Experimental results across five strong LLMs show that integrating SE-Agent delivers up to 55% relative improvement, achieving state-of-the-art performance among all open-source agents on SWE-bench Verified.", "bibtex": "@inproceedings{\nguo2025seagent,\ntitle={{SE}-Agent: Self-Evolution Trajectory Optimization in Multi-Step Reasoning with {LLM}-Based Agents},\nauthor={Yifu Guo and Jiaye Lin and Huacan Wang and Yuzhen Han and Sen Hu and Ziyi Ni and Licheng Wang and Mingguang Chen},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=isATAFP71B}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster SE-Agent_ Self-Evolution Trajectory Optimization in Multi-Step Reasoning with LLM-Based Agents.pdf", "retrieved_at": "2025-11-12T03:18:49.373578Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Dayuan Fu", "Biqing Qi", "Yihuai Gao", "Che Jiang", "Guanting Dong", "Bowen Zhou"], "affinity_score": 0.6958, "link": "https://aclanthology.org/2024.emnlp-main.38/", "abstract": "Insight gradually becomes a crucial form of long-term memory for an agent. However, the emergence of irrelevant insight and the lack of general insight can greatly undermine the effectiveness of insight. To solve this problem, in this paper, we introduce\nM\nulti-\nS\ncale\nI\nnsight Agent (MSI-Agent), an embodied agent designed to improve LLMs’ planning and decision-making ability by summarizing and utilizing insight effectively across different scales. MSI achieves this through the experience selector, insight generator, and insight selector. Leveraging a three-part pipeline, MSI can generate task-specific and high-level insight, store it in a database, and then use relevant insight from it to aid in decision-making. Our experiments show that MSI outperforms another insight strategy when planning by GPT3.5. Moreover, We delve into the strategies for selecting seed experience and insight, aiming to provide LLM with more useful and relevant insight for better decision-making. Our observations also indicate that MSI exhibits better robustness when facing domain-shifting scenarios.", "bibtex": "@inproceedings{fu-etal-2024-msi,\n    title = \"{MSI}-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making\",\n    author = \"Fu, Dayuan  and\n      Qi, Biqing  and\n      Gao, Yihuai  and\n      Jiang, Che  and\n      Dong, Guanting  and\n      Zhou, Bowen\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.38/\",\n    doi = \"10.18653/v1/2024.emnlp-main.38\",\n    pages = \"643--659\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main MSI-Agent_ Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making.pdf", "retrieved_at": "2025-11-12T03:18:49.768945Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MasRouter: Learning to Route LLMs for Multi-Agent Systems", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Yanwei Yue", "Guibin Zhang", "Boyang Liu", "Guancheng Wan", "Kun Wang", "Dawei Cheng", "Yiyan Qi"], "affinity_score": 0.6954, "link": "https://aclanthology.org/2025.acl-long.757/", "abstract": "Multi-agent systems (MAS) powered by Large Language Models (LLMs) have been demonstrated to push the boundaries of LLM capabilities, yet they often incur significant costs and face challenges in dynamic LLM selection. Current LLM routing methods effectively reduce overhead in single-agent scenarios by customizing LLM selection for each query, but they overlook the critical decisions regarding collaboration modes and agent roles in MAS. In response to this challenge, we first introduce the problem of Multi-Agent System Routing (MASR) , which integrates all components of MAS into a unified routing framework. Toward this goal, we propose MasRouter, the first high-performing, cost-effective, and inductive MASR solution. MasRouter employs collaboration mode determination, role allocation, and LLM routing through a cascaded controller network, progressively constructing a MAS that balances effectiveness and efficiency. Extensive experiments demonstrate that MasRouter is (1) high-performing , achieving a 1.8 improvement over the state-of-the-art method on MBPP; (2) economical , reducing overhead by up to 52.07 compared to SOTA methods on HumanEval; and (3) plug-and-play , seamlessly integrating with mainstream MAS frameworks, reducing overhead by 17.21 via customized routing.", "bibtex": "@inproceedings{yue-etal-2025-masrouter,\n    title = \"{M}as{R}outer: Learning to Route {LLM}s for Multi-Agent Systems\",\n    author = \"Yue, Yanwei  and\n      Zhang, Guibin  and\n      Liu, Boyang  and\n      Wan, Guancheng  and\n      Wang, Kun  and\n      Cheng, Dawei  and\n      Qi, Yiyan\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.757/\",\n    doi = \"10.18653/v1/2025.acl-long.757\",\n    pages = \"15549--15572\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long MasRouter_ Learning to Route LLMs for Multi-Agent Systems.pdf", "retrieved_at": "2025-11-12T03:18:50.161438Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "SciVerse: Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Ziyu Guo", "Renrui Zhang", "Hao Chen (陈昊)", "Jialin Gao", "Dongzhi Jiang", "Jiaze Wang", "Pheng-Ann Heng"], "affinity_score": 0.6952, "link": "https://aclanthology.org/2025.findings-acl.1010/", "abstract": "The rapid advancement of Large Multi-modal Models (LMMs) has enabled their application in scientific problem-solving, yet their fine-grained capabilities remain under-explored. In this paper, we introduce SciVerse, a multi-modal scientific evaluation benchmark to thoroughly assess LMMs across 5,735 test instances in five distinct versions. We aim to investigate three key dimensions of LMMs: scientific knowledge comprehension, multi-modal content interpretation, and Chain-of-Thought (CoT) reasoning. To unveil whether LMMs possess sufficient scientific expertise, we first transform each problem into three versions containing different levels of knowledge required for solving, i.e., Knowledge-free, -lite, and -rich. Then, to explore how LMMs interpret multi-modal scientific content, we annotate another two versions, i.e., Vision-rich and -only, marking more question information from texts to diagrams. Comparing the results of different versions, SciVerse systematically examines the professional knowledge stock and visual perception skills of LMMs in scientific domains. In addition, to rigorously assess CoT reasoning, we propose a new scientific CoT evaluation strategy, conducting a step-wise assessment on knowledge and logical errors in model outputs. Our extensive evaluation of different LMMs on SciVerse reveals critical limitations in their scientific proficiency and provides new insights into future developments. Project page: https://sciverse-cuhk.github.io", "bibtex": "@inproceedings{guo-etal-2025-sciverse,\n    title = \"{S}ci{V}erse: Unveiling the Knowledge Comprehension and Visual Reasoning of {LMM}s on Multi-modal Scientific Problems\",\n    author = \"Guo, Ziyu  and\n      Zhang, Renrui  and\n      Chen, Hao  and\n      Gao, Jialin  and\n      Jiang, Dongzhi  and\n      Wang, Jiaze  and\n      Heng, Pheng-Ann\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1010/\",\n    doi = \"10.18653/v1/2025.findings-acl.1010\",\n    pages = \"19683--19704\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings SciVerse_ Unveiling the Knowledge Comprehension and Visual Reasoning of LMMs on Multi-modal Scientific Problems.pdf", "retrieved_at": "2025-11-12T03:18:51.459728Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AgentNet: Decentralized Evolutionary Coordination for LLM-based Multi-Agent Systems", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Yingxuan Yang", "Huacan Chai", "Shuai Shao", "Yuanyi Song", "Siyuan Qi", "Renting Rui", "Weinan Zhang"], "affinity_score": 0.695, "link": "https://openreview.net/pdf/38bdf6e7191adba7391b1fde1ad37e27887b2bac.pdf", "abstract": "The rapid advancement of Large Language Models (LLMs) has catalyzed the development of multi-agent systems, where multiple LLM-based agents collaborate to solve complex tasks.   However, existing systems predominantly rely on centralized coordination, which introduces scalability bottlenecks, limits adaptability, and creates single points of failure.   Additionally, concerns over privacy and proprietary knowledge sharing hinder cross-organizational collaboration, leading to siloed expertise.   To address these challenges, we propose AgentNet, a decentralized, Retrieval-Augmented Generation (RAG)-based framework that enables LLM-based agents to autonomously evolve their capabilities and collaborate efficiently in a Directed Acyclic Graph (DAG)-structured network.   Unlike traditional multi-agent systems that depend on static role assignments or centralized control, AgentNet allows agents to specialize dynamically, adjust their connectivity, and route tasks without relying on predefined workflows.\nAgentNet’s core design is built upon several key innovations: (1) Fully Decentralized Paradigm: Removing the central orchestrator, allowing agents to coordinate and specialize autonomously, fostering fault tolerance and emergent collective intelligence. (2) Dynamically Evolving Graph Topology: Real-time adaptation of agent connections based on task demands, ensuring scalability and resilience.\n(3) Adaptive Learning for Expertise Refinement: A retrieval-based memory system that enables agents to continuously update and refine their specialized skills.\nBy eliminating centralized control, AgentNet enhances fault tolerance, promotes scalable specialization, and enables privacy-preserving collaboration across organizations.      Through decentralized coordination and minimal data exchange, agents can leverage diverse knowledge sources while safeguarding sensitive information.      Experimental results demonstrate that AgentNet outperforms traditional centralized multi-agent systems, significantly improving efficiency, adaptability, and scalability in dynamic environments, making it a promising foundation for next-generation autonomous, privacy-respecting multi-agent ecosystems.", "bibtex": "@inproceedings{\nyang2025agentnet,\ntitle={AgentNet: Decentralized Evolutionary Coordination for {LLM}-based Multi-Agent Systems},\nauthor={Yingxuan Yang and Huacan Chai and Shuai Shao and Yuanyi Song and Siyuan Qi and Renting Rui and Weinan Zhang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=tXqLxHlb8Z}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster AgentNet_ Decentralized Evolutionary Coordination for LLM-based Multi-Agent Systems.pdf", "retrieved_at": "2025-11-12T03:18:52.198062Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Mengkang Hu", "Yuhang Zhou", "Wendong Fan", "Yuzhou Nie", "Ziyu Ye", "Bowei Xia", "Tao Sun", "Zhaoxuan Jin", "Yingru Li", "Zeyu Zhang", "Yifeng Wang", "Qianshuo Ye", "Bernard Ghanem", "Ping Luo", "Guohao Li"], "affinity_score": 0.6945, "link": "https://openreview.net/pdf/9ea2d3d5cf7f874c7669ab5c3f1270eb3bc794d1.pdf", "abstract": "Large Language Model (LLM)-based multi-agent systems show promise for automating real-world tasks but struggle to transfer across domains due to their domain-specific nature.\nCurrent approaches face two critical shortcomings: they require complete architectural redesign and full retraining of all components when applied to new domains.\nWe introduce\nWorkforce\n, a hierarchical multi-agent framework that decouples strategic planning from specialized execution through a modular architecture comprising:\n(i)\na\ndomain-agnostic\nPlanner\nfor task decomposition,\n(ii)\na\nCoordinator\nfor subtask management, and\n(iii)\nspecialized\nWorkers\nwith\ndomain-specific\ntool-calling capabilities.\nThis decoupling enables cross-domain transferability during both inference and training phases:\nDuring inference, Workforce seamlessly adapts to new domains by adding or modifying worker agents;\nFor training, we introduce\nOptimized Workforce Learning (OWL)\n, which improves generalization across domains by optimizing a domain-agnostic planner with reinforcement learning from real-world feedback.\nTo validate our approach, we evaluate Workforce on the GAIA benchmark, covering various realistic, multi-domain agentic tasks.\nExperimental results demonstrate Workforce achieves open-source state-of-the-art performance (\n69.70%\n), outperforming commercial systems like OpenAI's Deep Research by\n2.34%\n.\nMore notably, our OWL-trained 32B model achieves\n52.73%\naccuracy (\n+16.37%\n) and demonstrates performance comparable to GPT-4o on challenging tasks.\nTo summarize, by enabling scalable generalization and modular domain transfer, our work establishes a foundation for the next generation of general-purpose AI assistants.\nOur code is available at\nAnonymous URL\n, and our data is available at\nAnonymous URL\n.", "bibtex": "@inproceedings{\nhu2025owl,\ntitle={{OWL}: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation},\nauthor={Mengkang Hu and Yuhang Zhou and Wendong Fan and Yuzhou Nie and Ziyu Ye and Bowei Xia and Tao Sun and Zhaoxuan Jin and Yingru Li and Zeyu Zhang and Yifeng Wang and Qianshuo Ye and Bernard Ghanem and Ping Luo and Guohao Li},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=MBJ46gd1CT}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster OWL_ Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation.pdf", "retrieved_at": "2025-11-12T03:18:52.698025Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Yanqi Dai", "Huanran Hu", "Lei Wang", "Shengjie Jin", "Xu Chen", "Zhiwu Lu"], "affinity_score": 0.6944, "link": "https://openreview.net/pdf/6ea2631589425d5cf3de283aed71b80c80b56b62.pdf", "abstract": "Recently, Role-Playing Agents (RPAs) have garnered increasing attention for their potential to deliver emotional value and facilitate sociological research.\nHowever, existing studies are primarily confined to the textual modality, unable to simulate humans' multimodal perceptual capabilities.\nTo bridge this gap, we introduce the concept of Multimodal Role-Playing Agents (MRPAs), and propose a comprehensive framework, MMRole, for their development and evaluation, which comprises a personalized multimodal dataset and a robust evaluation approach.\nSpecifically, we construct a large-scale, high-quality dataset, MMRole-Data, consisting of 85 characters, 11K images, and 14K single or multi-turn dialogues.\nAdditionally, we present a robust evaluation approach, MMRole-Eval, encompassing eight metrics across three dimensions, where a reward model is designed to score MRPAs with the constructed ground-truth data for comparison.\nMoreover, we develop the first specialized MRPA, MMRole-Agent.\nExtensive evaluation results demonstrate the improved performance of MMRole-Agent and highlight the primary challenges in developing MRPAs, emphasizing the need for enhanced multimodal understanding and role-playing consistency.\nThe data, code, and models are all available at https://github.com/YanqiDai/MMRole.", "bibtex": "@inproceedings{\ndai2025mmrole,\ntitle={{MMR}ole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents},\nauthor={Yanqi Dai and Huanran Hu and Lei Wang and Shengjie Jin and Xu Chen and Zhiwu Lu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=FGSgsefE0Y}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster MMRole_ A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents.pdf", "retrieved_at": "2025-11-12T03:18:53.947553Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Self-Challenging Language Model Agents", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Yifei Zhou", "Sergey Levine", "Jason E Weston", "Xian Li", "Sainbayar Sukhbaatar"], "affinity_score": 0.6938, "link": "https://openreview.net/pdf/d7856a8a4e991dab71814a3f39f28fe17b6b93bd.pdf", "abstract": "Large language models  are quickly becoming the foundation for intelligent agents that are capable of using tools. However, training such agents is challenging because it requires human creation and annotation of a diverse set of tasks, tools, and evaluation criteria. In this paper, we propose  the Self-Challenging Agent framework for training an agent on high-quality tasks that are generated by itself. The agent first plays the role of challenger and generates a task after interacting with the given tools. The tasks take the form of a novel general class of problems termed Code-as-Task, which are defined by an instruction, a verification function and solution and failure cases which serve as tests, allowing to filter only for high-quality tasks.\nThe agent then takes an executor role and trains on those tasks with reinforcement learning using the evaluation feedback as a reward.  We show our method improves the performance of Llama-3.1-8B-Instruct on two existing multi-turn tool-use agent benchmarks, M$^3$ToolEval and TauBench, with a two-fold average success rate increase, despite using only self-generated training data.", "bibtex": "@inproceedings{\nzhou2025selfchallenging,\ntitle={Self-Challenging Language Model Agents},\nauthor={Yifei Zhou and Sergey Levine and Jason E Weston and Xian Li and Sainbayar Sukhbaatar},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=9yusqX9DpR}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Self-Challenging Language Model Agents.pdf", "retrieved_at": "2025-11-12T03:18:54.472792Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Interactive Speculative Planning: Enhance Agent Efficiency through Co-design of System and User Interface", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Wenyue Hua", "Mengting Wan", "JAGANNATH SHASHANK SUBRAMANYA SAI VADREVU", "Ryan Nadel", "Yongfeng Zhang", "Chi Wang"], "affinity_score": 0.6936, "link": "https://openreview.net/pdf/d0bfc62889cc4dd6dd559f11e0eefe99ed67a5a2.pdf", "abstract": "Agents, as user-centric tools, are increasingly deployed for human task delegation, assisting with a broad spectrum of requests by generating thoughts, engaging with user proxies, and producing action plans. However, agents based on large language models often face substantial planning latency due to two primary factors: the efficiency limitations of the underlying LLMs due to their large size and high demand, and the structural complexity of the agents due to the extensive generation of intermediate steps to produce the final output. Given that inefficiency in service provision can undermine the value of automation for users, this paper presents a human-centered efficient agent planning method – Interactive Speculative Planning – aiming at enhancing the efficiency of agent planning through both system design and user interaction. Our approach advocates for the co-design of the agent system and user interface, underscoring the importance of an agent system that can fluidly manage user interactions and interruptions. By integrating human interruptions as a fundamental component of the system, we not only make it more user-centric but also expedite the entire process by leveraging human-in-the-loop interactions to provide accurate intermediate steps.", "bibtex": "@inproceedings{\nhua2025interactive,\ntitle={Interactive Speculative Planning: Enhance Agent Efficiency through Co-design of System and User Interface},\nauthor={Wenyue Hua and Mengting Wan and JAGANNATH SHASHANK SUBRAMANYA SAI VADREVU and Ryan Nadel and Yongfeng Zhang and Chi Wang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=BwR8t91yqh}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Interactive Speculative Planning_ Enhance Agent Efficiency through Co-design of System and User Interface.pdf", "retrieved_at": "2025-11-12T03:18:55.100681Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "GROOT-2: Weakly Supervised Multimodal Instruction Following Agents", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Shaofei Cai", "Bowei Zhang", "Zihao Wang", "Haowei Lin", "Xiaojian Ma", "Anji Liu", "Yitao Liang"], "affinity_score": 0.6935, "link": "https://openreview.net/pdf/1535226a0ab0823a790f6e0174241d5e6c727dcd.pdf", "abstract": "Developing agents that can follow multimodal instructions remains a fundamental challenge in robotics and AI. Although large-scale pre-training on unlabeled datasets has enabled agents to learn diverse behaviors, these agents often struggle with following instructions. While augmenting the dataset with instruction labels can mitigate this issue, acquiring such high-quality annotations at scale is impractical. \nTo address this issue, we frame the problem as a semi-supervised learning task and introduce \\agent, a multimodal instructable agent trained using a novel approach that combines weak supervision with latent variable models. Our method consists of two key components: constrained self-imitating, which utilizes large amounts of unlabeled demonstrations to enable the policy to learn diverse behaviors, and human intention alignment, which uses a smaller set of labeled demonstrations to ensure the latent space reflects human intentions. \\agent’s effectiveness is validated across four diverse environments, ranging from video games to robotic manipulation, demonstrating its robust multimodal instruction-following capabilities.", "bibtex": "@inproceedings{\ncai2025groot,\ntitle={{GROOT}-2: Weakly Supervised Multimodal Instruction Following Agents},\nauthor={Shaofei Cai and Bowei Zhang and Zihao Wang and Haowei Lin and Xiaojian Ma and Anji Liu and Yitao Liang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=S9GyQUXzee}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster GROOT-2_ Weakly Supervised Multimodal Instruction Following Agents.pdf", "retrieved_at": "2025-11-12T03:18:56.263538Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Learning to Communicate Through Implicit Communication Channels", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Han Wang", "Binbin Chen", "Tieying Zhang", "Baoxiang Wang"], "affinity_score": 0.6934, "link": "https://openreview.net/pdf/21bbf5d741b8a34cd4e511e0cf7f9156fa9e416a.pdf", "abstract": "Effective communication is an essential component in collaborative multi-agent systems. Situations where explicit messaging is not feasible have been common in human society throughout history, which motivate the study of implicit communication. Previous works on learning implicit communication mostly rely on theory of mind (ToM), where agents infer the mental states and intentions of others by interpreting their actions. However, ToM-based methods become less effective in making accurate inferences in complex tasks. In this work, we propose the Implicit Channel Protocol (ICP) framework, which allows agents to communicate through implicit communication channels similar to the explicit ones. ICP leverages a subset of actions, denoted as the scouting actions, and a mapping between information and these scouting actions that encodes and decodes the messages. We propose training algorithms for agents to message and act, including learning with a randomly initialized information map and with a delayed information map. The efficacy of ICP has been tested on the tasks of Guessing Numbers, Revealing Goals, and Hanabi, where ICP significantly outperforms baseline methods through more efficient information transmission.", "bibtex": "@inproceedings{\nwang2025learning,\ntitle={Learning to Communicate Through Implicit Communication Channels},\nauthor={Han Wang and Binbin Chen and Tieying Zhang and Baoxiang Wang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=wm5wwAdiEt}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Learning to Communicate Through Implicit Communication Channels.pdf", "retrieved_at": "2025-11-12T03:18:57.302848Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Rogerio Bonatti", "Dan Zhao", "Francesco Bonacci", "Dillon Dupont", "Sara Abdali", "Yinheng Li", "Yadong Lu", "Justin Wagle", "Kazuhito Koishida", "Arthur Bucker", "Lawrence Keunho Jang", "Zheng Hui"], "affinity_score": 0.6931, "link": "https://openreview.net/pdf/649fdc07b1256b087a6db62c7d4274d3b265c9d2.pdf", "abstract": "Large language models (LLMs) show potential as computer agents, enhancing productivity and software accessibility in multi-modal tasks. \nHowever, measuring agent performance in sufficiently realistic and complex environments becomes increasingly challenging as: \n(i) most benchmarks are limited to specific modalities/domains (e.g., text-only, web navigation, Q&A) and \n(ii) full benchmark evaluations are slow (on order of magnitude of multiple hours/days) given the multi-step sequential nature of tasks.\nTo address these challenges, we introduce Windows Agent Arena: a general environment focusing exclusively on the Windows operating system (OS) where agents can operate freely within a real OS to use the same applications and tools available to human users when performing tasks.\nWe create 150+ diverse tasks across representative domains that require agentic abilities in planning, screen understanding, and tool usage.\nOur benchmark is scalable and can be seamlessly parallelized for a full benchmark evaluation in as little as $20$ minutes.\nOur work not only speeds up the development and evaluation cycle of multi-modal agents, but also highlights and analyzes existing shortfalls in the agentic  abilities of several multimodal LLMs as agents within the Windows computing environment---with the best achieving only a 19.5\\% success rate compared to a human success rate of 74.5\\%.", "bibtex": "@inproceedings{\nbonatti2025windows,\ntitle={Windows Agent Arena: Evaluating Multi-Modal {OS} Agents at Scale},\nauthor={Rogerio Bonatti and Dan Zhao and Francesco Bonacci and Dillon Dupont and Sara Abdali and Yinheng Li and Yadong Lu and Justin Wagle and Kazuhito Koishida and Arthur Bucker and Lawrence Keunho Jang and Zheng Hui},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=W9s817KqYf}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Windows Agent Arena_ Evaluating Multi-Modal OS Agents at Scale.pdf", "retrieved_at": "2025-11-12T03:18:58.560420Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "WebDancer: Towards Autonomous Information Seeking Agency", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Jialong Wu", "Baixuan Li", "Runnan Fang", "Wenbiao Yin", "Liwen Zhang", "Zhenglin Wang", "Zhengwei Tao", "Ding-Chu Zhang", "Zekun Xi", "Xiangru Tang", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Jingren Zhou"], "affinity_score": 0.6916, "link": "https://openreview.net/pdf/7c886fbc63b09377d123254d93907b41820d72d7.pdf", "abstract": "Addressing intricate real-world problems necessitates in-depth information seeking and multi-step reasoning. \nRecent progress in agentic systems, exemplified by Deep Research, underscores the potential for autonomous multi-step research. \nIn this work, we present a cohesive paradigm for building end-to-end agentic information seeking agents from a data-centric and training-stage perspective.\nOur approach consists of four key stages: (1) browsing data construction, (2) trajectories sampling, (3) supervised fine-tuning for effective cold start, and (4) reinforcement learning for enhanced generalisation.\nWe instantiate this framework in a web agent based on the ReAct format, WebDancer.\nEmpirical evaluations on the challenging GAIA and WebWalkerQA benchmarks demonstrate the strong performance of WebDancer, achieving considerable results and highlighting the efficacy of our training paradigm. \nFurther analysis of agent training provides valuable insights and actionable, systematic pathways for developing more capable agentic models.", "bibtex": "@inproceedings{\nwu2025webdancer,\ntitle={WebDancer: Towards Autonomous Information Seeking Agency},\nauthor={Jialong Wu and Baixuan Li and Runnan Fang and Wenbiao Yin and Liwen Zhang and Zhenglin Wang and Zhengwei Tao and Ding-Chu Zhang and Zekun Xi and Xiangru Tang and Yong Jiang and Pengjun Xie and Fei Huang and Jingren Zhou},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=quJdphBcdP}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster WebDancer_ Towards Autonomous Information Seeking Agency.pdf", "retrieved_at": "2025-11-12T03:18:59.072066Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ToolGen: Unified Tool Retrieval and Calling via Generation", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Renxi Wang", "Xudong Han", "Lei Ji", "Shu Wang", "Timothy Baldwin", "Haonan Li"], "affinity_score": 0.6906, "link": "https://openreview.net/pdf/b5d464a0c1f8e39ed945666ae1468185132c7754.pdf", "abstract": "As large language models (LLMs) advance, their inability to autonomously execute tasks by directly interacting with external tools remains a critical limitation. Traditional methods rely on inputting tool descriptions as context, which is constrained by context length and requires separate, often inefficient, retrieval mechanisms. We introduce ToolGen, a paradigm shift that integrates tool knowledge directly into the LLM’s parameters by representing each tool as a unique token. This enables the LLM to generate tool calls and arguments as part of its next token prediction capabilities, seamlessly blending tool invocation with language generation.  Our framework allows the LLM to access and utilize a vast amount of tools with no additional retrieval step, significantly enhancing both performance and scalability. Experimental results with over 47,000 tools show that ToolGen not only achieves superior results in both tool retrieval and autonomous task completion but also sets the stage for a new era of AI agents that can adapt to tools across diverse domains.  By fundamentally transforming tool retrieval into a generative process, ToolGen paves the way for more versatile, efficient, and autonomous AI systems. ToolGen enables end-to-end tool learning and opens opportunities for integration with other advanced techniques such as chain-of-thought and reinforcement learning, thereby expanding the practical capabilities of LLMs", "bibtex": "@inproceedings{\nwang2025toolgen,\ntitle={ToolGen: Unified Tool Retrieval and Calling via Generation},\nauthor={Renxi Wang and Xudong Han and Lei Ji and Shu Wang and Timothy Baldwin and Haonan Li},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=XLMAMmowdY}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster ToolGen_ Unified Tool Retrieval and Calling via Generation.pdf", "retrieved_at": "2025-11-12T03:19:00.516078Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AgentBreeder: Mitigating the AI Safety Risks of Multi-Agent Scaffolds via Self-Improvement", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["J Rosser", "Jakob Nicolaus Foerster"], "affinity_score": 0.6899, "link": "https://openreview.net/pdf/237ca0099a7a95299cd0bae4b495038b19873e08.pdf", "abstract": "Scaffolding Large Language Models (LLMs) into multi-agent systems often improves performance on complex tasks, but the safety impact of such scaffolds has not been thoroughly explored. We introduce AgentBreeder, a framework for multi-objective self-improving evolutionary search over scaffolds. We evaluate discovered scaffolds on widely recognized reasoning, mathematics, and safety benchmarks and compare them with popular baselines. In \"blue\" mode, we see a 79.4% average uplift in safety benchmark performance while maintaining or improving capability scores. In \"red\" mode, we find adversarially weak scaffolds emerging concurrently with capability optimization. Our work demonstrates the risks of multi-agent scaffolding and provides a framework for mitigating them. Code is available at \\url{https://github.com/jrosseruk/AgentBreeder}.", "bibtex": "@inproceedings{\nrosser2025agentbreeder,\ntitle={AgentBreeder: Mitigating the {AI} Safety Risks of Multi-Agent Scaffolds via Self-Improvement},\nauthor={J Rosser and Jakob Nicolaus Foerster},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=mlU9KqdZUS}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Spotlight AgentBreeder_ Mitigating the AI Safety Risks of Multi-Agent Scaffolds via Self-Improvement.pdf", "retrieved_at": "2025-11-12T03:19:01.296007Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Logan Cross", "Violet Xiang", "Agam Bhatia", "Daniel LK Yamins", "Nick Haber"], "affinity_score": 0.6891, "link": "https://openreview.net/pdf/b85a375d8c5672bb041b204393e3cab2f1552cac.pdf", "abstract": "Multi-agent reinforcement learning (MARL) methods struggle with the non-stationarity of multi-agent systems and fail to adaptively learn online when tested with novel agents. Here, we leverage large language models (LLMs) to create an autonomous agent that can handle these challenges. Our agent, Hypothetical Minds, consists of a cognitively-inspired architecture, featuring modular components for perception, memory, and hierarchical planning over two levels of abstraction. We introduce the Theory of Mind module that scaffolds the high-level planning process by generating hypotheses about other agents' strategies in natural language. It then evaluates and iteratively refines these hypotheses by reinforcing hypotheses that make correct predictions about the other agents' behavior. Hypothetical Minds significantly improves performance over previous LLM-agent and RL baselines on a range of competitive, mixed motive, and collaborative domains in the Melting Pot benchmark, including both dyadic and population-based environments. Additionally, comparisons against LLM-agent baselines and ablations reveal the importance of hypothesis evaluation and refinement for succeeding on complex scenarios.", "bibtex": "@inproceedings{\ncross2025hypothetical,\ntitle={Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models},\nauthor={Logan Cross and Violet Xiang and Agam Bhatia and Daniel LK Yamins and Nick Haber},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=otW0TJOUYF}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Hypothetical Minds_ Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models.pdf", "retrieved_at": "2025-11-12T03:19:02.146132Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Tianqi Xu", "Linyao Chen", "Dai-Jie Wu", "Yanjun Chen", "Zecheng Zhang", "Xiang Yao", "Zhiqiang Xie (谢志强)", "Yongchao Chen", "Shilong Liu", "Bochen Qian", "Anjie Yang", "Zhaoxuan Jin", "Jianbo Deng", "Philip Torr", "Bernard Ghanem", "Guohao Li"], "affinity_score": 0.6888, "link": "https://aclanthology.org/2025.findings-acl.1113/", "abstract": "The development of autonomous agents increasingly relies on Multimodal Language Models (MLMs) to perform tasks described in natural language with GUI environments, such as websites, desktop computers, or mobile phones. Existing benchmarks for MLM agents in interactive environments are limited by their focus on a single environment, lack of detailed and generalized evaluation methods, and thecomplexities of constructing tasks and evaluators. To overcome these limitations, we introduce CRAB, the first cross-environment agent benchmark framework, incorporating a graph-based fine-grained evaluation method and an efficient task generation method. Our framework supports multiple devices and can be easily extended to any environment with a Python interface. Leveraging CRAB, we develope CRAB Benchmark-v0 comprising 120 tasks in computer desktop and mobile phone environments. We evaluated 6 advanced MLMs using different single and multi-agent system configurations on this benchmark. The experimental results demonstrate that the single agent with GPT-4o achieves the best completion ratio of 38.01%.", "bibtex": "@inproceedings{xu-etal-2025-crab,\n    title = \"{CRAB}: Cross-environment Agent Benchmark for Multimodal Language Model Agents\",\n    author = \"Xu, Tianqi  and\n      Chen, Linyao  and\n      Wu, Dai-Jie  and\n      Chen, Yanjun  and\n      Zhang, Zecheng  and\n      Yao, Xiang  and\n      Xie, Zhiqiang  and\n      Chen, Yongchao  and\n      Liu, Shilong  and\n      Qian, Bochen  and\n      Yang, Anjie  and\n      Jin, Zhaoxuan  and\n      Deng, Jianbo  and\n      Torr, Philip  and\n      Ghanem, Bernard  and\n      Li, Guohao\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1113/\",\n    doi = \"10.18653/v1/2025.findings-acl.1113\",\n    pages = \"21607--21647\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings CRAB_ Cross-environment Agent Benchmark for Multimodal Language Model Agents.pdf", "retrieved_at": "2025-11-12T03:19:03.022856Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "SPA-BENCH: A COMPREHENSIVE BENCHMARK FOR SMARTPHONE AGENT EVALUATION", "venue": "ICLR 2025 Spotlight", "year": "2025", "authors": ["Jingxuan Chen", "Derek Yuen", "Bin Xie", "Yuhao Yang", "Gongwei Chen", "Zhihao Wu", "Li Yixing", "Xurui Zhou", "Weiwen Liu", "Shuai Wang", "Kaiwen Zhou", "Rui Shao", "Liqiang Nie", "Yasheng Wang", "Jianye HAO", "Jun Wang", "Kun Shao"], "affinity_score": 0.6883, "link": "https://openreview.net/pdf/d6e724ea54d8555e1cf78adf21853e302b21f716.pdf", "abstract": "Smartphone agents are increasingly important for helping users control devices efficiently, with (Multimodal) Large Language Model (MLLM)-based approaches emerging as key contenders. Fairly comparing these agents is essential but challenging, requiring a varied task scope, the integration of agents with different implementations, and a generalisable evaluation pipeline to assess their strengths and weaknesses. In this paper, we present SPA-Bench, a comprehensive SmartPhone Agent Benchmark designed to evaluate (M)LLM-based agents in an interactive environment that simulates real-world conditions. SPA-Bench offers three key contributions: (1) A diverse set of tasks covering system and third-party apps in both English and Chinese, focusing on features commonly used in daily routines; (2) A plug-and-play framework enabling real-time agent interaction with Android devices, integrating over ten agents with the flexibility to add more; (3) A novel evaluation pipeline that automatically assesses agent performance across multiple dimensions, encompassing seven metrics related to task completion and resource consumption. Our extensive experiments across tasks and agents reveal challenges like interpreting mobile user interfaces, action grounding, memory retention, and execution costs. We propose future research directions to ease these difficulties, moving closer to real-world smartphone agent applications.", "bibtex": "@inproceedings{\nchen2025spabench,\ntitle={{SPA}-{BENCH}: A {COMPREHENSIVE} {BENCHMARK} {FOR} {SMARTPHONE} {AGENT} {EVALUATION}},\nauthor={Jingxuan Chen and Derek Yuen and Bin Xie and Yuhao Yang and Gongwei Chen and Zhihao Wu and Li Yixing and Xurui Zhou and Weiwen Liu and Shuai Wang and Kaiwen Zhou and Rui Shao and Liqiang Nie and Yasheng Wang and Jianye HAO and Jun Wang and Kun Shao},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=OZbFRNhpwr}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Spotlight SPA-BENCH_ A COMPREHENSIVE BENCHMARK FOR SMARTPHONE AGENT EVALUATION.pdf", "retrieved_at": "2025-11-12T03:19:04.671858Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MMAU: A Holistic Benchmark of Agent Capabilities Across Diverse Domains", "venue": "NAACL 2025 Findings", "year": "2025", "authors": ["Guoli Yin", "Haoping Bai", "Shuang Ma", "Feng Nan", "Yanchao Sun", "Zhaoyang Xu", "Shen Ma", "Jiarui Lu", "Xiang Kong", "Aonan Zhang", "Dian Ang Yap", "Yizhe Zhang", "Karsten Ahnert", "Vik Kamath", "Mathias Berglund", "Dominic Walsh", "Tobias Gindele", "Juergen Wiest", "Zhengfeng Lai", "Xiaoming Simon Wang", "Jiulong Shan", "Meng Cao", "Ruoming Pang", "Zirui Wang"], "affinity_score": 0.6873, "link": "https://aclanthology.org/2025.findings-naacl.267/", "abstract": "Recent advances in large language models (LLMs) have increased the demand for comprehensive benchmarks to evaluate their capabilities as human-like agents. Existing benchmarks, while useful, often focus on specific application scenarios, emphasizing task completion but failing to dissect the underlying skills that drive these outcomes. This lack of granularity makes it difficult to deeply discern where failures stem from. Additionally, setting up these environments requires considerable effort, and issues of unreliability and reproducibility sometimes arise, especially in interactive tasks. To address these limitations, we introduce the Massive Multitask Agent Understanding (MMAU) benchmark, featuring comprehensive offline tasks that eliminate the need for complex environment setups. It evaluate models across five domains, including Tool-use, Directed Acyclic Graph (DAG) QA, Data Science and Machine Learning coding, Contest-level programming and Mathematics, and covering five essential capabilities: Understanding, Reasoning, Planning, Problem-solving, and Self-correction. With a total of 20 meticulously designed tasks encompassing over 3K distinct prompts, MMAU provides a comprehensive framework for evaluating the strengths and limitations of LLM agents. By testing 20 representative models on MMAU, we provide deep and insightful analyses. Ultimately, MMAU not only sheds light on the capabilities and limitations of LLM agents but also enhances the interpretability of their performance.", "bibtex": "@inproceedings{yin-etal-2025-mmau,\n    title = \"{MMAU}: A Holistic Benchmark of Agent Capabilities Across Diverse Domains\",\n    author = \"Yin, Guoli  and\n      Bai, Haoping  and\n      Ma, Shuang  and\n      Nan, Feng  and\n      Sun, Yanchao  and\n      Xu, Zhaoyang  and\n      Ma, Shen  and\n      Lu, Jiarui  and\n      Kong, Xiang  and\n      Zhang, Aonan  and\n      Yap, Dian Ang  and\n      Zhang, Yizhe  and\n      Ahnert, Karsten  and\n      Kamath, Vik  and\n      Berglund, Mathias  and\n      Walsh, Dominic  and\n      Gindele, Tobias  and\n      Wiest, Juergen  and\n      Lai, Zhengfeng  and\n      Wang, Xiaoming Simon  and\n      Shan, Jiulong  and\n      Cao, Meng  and\n      Pang, Ruoming  and\n      Wang, Zirui\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Findings of the Association for Computational Linguistics: NAACL 2025\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-naacl.267/\",\n    doi = \"10.18653/v1/2025.findings-naacl.267\",\n    pages = \"4737--4765\",\n    ISBN = \"979-8-89176-195-7\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Findings MMAU_ A Holistic Benchmark of Agent Capabilities Across Diverse Domains.pdf", "retrieved_at": "2025-11-12T03:19:05.054717Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Learning Evolving Tools for Large Language Models", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Guoxin Chen", "Zhong Zhang", "Xin Cong", "Fangda Guo", "Yesai Wu", "Yankai Lin", "Wenzheng Feng", "Yasheng Wang"], "affinity_score": 0.687, "link": "https://openreview.net/pdf/f184e31a03eb043e10e4af9cfe3ade524d5c625f.pdf", "abstract": "Tool learning enables large language models (LLMs) to interact with external tools and APIs, greatly expanding the application scope of LLMs. However, due to the dynamic nature of external environments, these tools and APIs may become outdated over time, preventing LLMs from correctly invoking tools. Existing research primarily focuses on static environments and overlooks this issue, limiting the adaptability of LLMs in real-world applications. In this paper, we propose ToolEVO, a novel framework designed to enhance the adaptive and reflective capabilities of LLMs against tool variability. By leveraging Monte Carlo Tree Search, ToolEVO facilitates active exploration and interaction of LLMs within dynamic environments, allowing for autonomous self-reflection and self-updating of tool usage based on environmental feedback. Additionally, we introduce ToolQA-D, a benchmark specifically designed to evaluate the impact of tool variability. Extensive experiments demonstrate the effectiveness and stability of our approach, highlighting the importance of adaptability to tool variability for effective tool learning.", "bibtex": "@inproceedings{\nchen2025learning,\ntitle={Learning Evolving Tools for Large Language Models},\nauthor={Guoxin Chen and Zhong Zhang and Xin Cong and Fangda Guo and Yesai Wu and Yankai Lin and Wenzheng Feng and Yasheng Wang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=wtrDLMFU9v}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Learning Evolving Tools for Large Language Models.pdf", "retrieved_at": "2025-11-12T03:19:05.547000Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Investigating and Extending Homans’ Social Exchange Theory with Large Language Model based Agents", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Lei Wang (王雷)", "Zheqing Zhang", "Xu Chen (陈旭)"], "affinity_score": 0.6865, "link": "https://aclanthology.org/2025.acl-long.481/", "abstract": "Homans’ Social Exchange Theory (SET) is widely recognized as a basic framework for understanding the formation and emergence of human civilizations and social structures. In social science, this theory is typically studied based on simple simulation experiments or real-world human studies, both of which either lack realism or are too expensive to control. In artificial intelligence, recent advances in large language models (LLMs) have shown promising capabilities in simulating human behaviors. Inspired by these insights, we adopt an interdisciplinary research perspective and propose using LLM-based agents to study Homans’ SET. Specifically, we construct a virtual society composed of three LLM agents and have them engage in a social exchange game to observe their behaviors. Through extensive experiments, we found that Homans’ SET is well validated in our agent society, demonstrating the consistency between the agent and human behaviors. Building on this foundation, we intentionally alter the settings of the agent society to extend the traditional Homans’ SET, making it more comprehensive and detailed. To the best of our knowledge, this paper marks the first step in studying Homans’ SET with LLM-based agents. More importantly, it introduces a novel and feasible research paradigm that bridges the fields of social science and computer science through LLM-based agents. Code is available at https://github.com/Paitesanshi/SET .", "bibtex": "@inproceedings{wang-etal-2025-investigating,\n    title = \"Investigating and Extending Homans' Social Exchange Theory with Large Language Model based Agents\",\n    author = \"Wang, Lei  and\n      Zhang, Zheqing  and\n      Chen, Xu\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.481/\",\n    doi = \"10.18653/v1/2025.acl-long.481\",\n    pages = \"9762--9777\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Investigating and Extending Homans’ Social Exchange Theory with Large Language Model based Agents.pdf", "retrieved_at": "2025-11-12T03:19:05.802429Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "REPRO-Bench: Can Agentic AI Systems Assess the Reproducibility of Social Science Research?", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Chuxuan Hu", "Liyun Zhang", "Yeji Lim", "Aum Wadhwani", "Austin Peters", "Daniel Kang"], "affinity_score": 0.6863, "link": "https://aclanthology.org/2025.findings-acl.1210/", "abstract": "Assessing the reproducibility of social science papers is essential for promoting rigor in research processes, but manual assessment is costly. With recent advances in agentic AI systems (i.e., AI agents), we seek to evaluate their capability to automate this process. However, existing benchmarks for reproducing research papers (1) focus solely on reproducing results using provided code and data without assessing their consistency with the paper, (2) oversimplify real-world scenarios, and (3) lack necessary diversity in data formats and programming languages. To address these issues, we introduce REPRO-Bench, a collection of 112 task instances, each representing a social science paper with a publicly available reproduction report. The agents are tasked with assessing the reproducibility of the paper based on the original paper PDF and the corresponding reproduction package. REPRO-Bench features end-to-end evaluation tasks on the reproducibility of social science papers with complexity comparable to real-world assessments. We evaluate three representative AI agents on REPRO-Bench, with the best-performing agent achieving an accuracy of only 21.4%. Building on our empirical analysis, we develop REPRO-Agent, which improves the highest accuracy achieved by existing agents by 71%. We conclude that more advanced AI agents should be developed to automate real-world reproducibility assessment. REPRO-Bench is publicly available at https://github.com/uiuc-kang-lab/REPRO-Bench.", "bibtex": "@inproceedings{hu-etal-2025-repro,\n    title = \"{REPRO}-Bench: Can Agentic {AI} Systems Assess the Reproducibility of Social Science Research?\",\n    author = \"Hu, Chuxuan  and\n      Zhang, Liyun  and\n      Lim, Yeji  and\n      Wadhwani, Aum  and\n      Peters, Austin  and\n      Kang, Daniel\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1210/\",\n    doi = \"10.18653/v1/2025.findings-acl.1210\",\n    pages = \"23616--23626\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings REPRO-Bench_ Can Agentic AI Systems Assess the Reproducibility of Social Science Research_.pdf", "retrieved_at": "2025-11-12T03:19:06.036180Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "M³HF: Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Ziyan Wang", "Zhicheng Zhang", "Fei Fang", "Yali Du"], "affinity_score": 0.6863, "link": "https://openreview.net/pdf/6eabc3fc2e2bb55ea755ec99bbdd42503c74487c.pdf", "abstract": "Designing effective reward functions in multi-agent reinforcement learning (MARL) is a significant challenge, often leading to suboptimal or misaligned behaviors in complex, coordinated environments. We introduce Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality ($\\text{M}^3\\text{HF}$), a novel framework that integrates multi-phase human feedback of mixed quality into the MARL training process. By involving humans with diverse expertise levels to provide iterative guidance, $\\text{M}^3\\text{HF}$ leverages both expert and non-expert feedback to continuously refine agents' policies. During training, we strategically pause agent learning for human evaluation, parse feedback using large language models to assign it appropriately and update reward functions through predefined templates and adaptive weights by using weight decay and performance-based adjustments. Our approach enables the integration of nuanced human insights across various levels of quality, enhancing the interpretability and robustness of multi-agent cooperation. Empirical results in challenging environments demonstrate that $\\text{M}^3\\text{HF}$ significantly outperforms state-of-the-art methods, effectively addressing the complexities of reward design in MARL and enabling broader human participation in the training process.", "bibtex": "@inproceedings{\nwang2025mhf,\ntitle={M{\\textthreesuperior}{HF}: Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality},\nauthor={Ziyan Wang and Zhicheng Zhang and Fei Fang and Yali Du},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=2Sl6Ex7Vmo}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster M³HF_ Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality.pdf", "retrieved_at": "2025-11-12T03:19:06.695505Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "EMOS: Embodiment-aware Heterogeneous Multi-robot Operating System with LLM Agents", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Junting Chen", "Checheng Yu", "Xunzhe Zhou", "Tianqi Xu", "Yao Mu", "Mengkang Hu", "Wenqi Shao", "Yikai Wang", "Guohao Li", "Lin Shao"], "affinity_score": 0.6861, "link": "https://openreview.net/pdf/4bb1e48853d7189b88d1e952850f6d577f85b849.pdf", "abstract": "Heterogeneous multi-robot systems (HMRS) have emerged as a powerful ap-\nproach for tackling complex tasks that single robots cannot manage alone. Current\nlarge-language-model-based multi-agent systems (LLM-based MAS) have shown\nsuccess in areas like software development and operating systems, but applying\nthese systems to robot control presents unique challenges. In particular, the ca-\npabilities of each agent in a multi-robot system are inherently tied to the physical\ncomposition of the robots, rather than predefined roles. To address this issue,\nwe introduce a novel multi-agent framework designed to enable effective collab-\noration among heterogeneous robots with varying embodiments and capabilities,\nalong with a new benchmark named Habitat-MAS. One of our key designs is\nRobot Resume: Instead of adopting human-designed role play, we propose a self-\nprompted approach, where agents comprehend robot URDF files and call robot\nkinematics tools to generate descriptions of their physics capabilities to guide\ntheir behavior in task planning and action execution. The Habitat-MAS bench-\nmark is designed to assess how a multi-agent framework handles tasks that require\nembodiment-aware reasoning, which includes 1) manipulation, 2) perception, 3)\nnavigation, and 4) comprehensive multi-floor object rearrangement. The experi-\nmental results indicate that the robot’s resume and the hierarchical design of our\nmulti-agent system are essential for the effective operation of the heterogeneous\nmulti-robot system within this intricate problem context.", "bibtex": "@inproceedings{\nchen2025emos,\ntitle={{EMOS}: Embodiment-aware Heterogeneous Multi-robot Operating System with {LLM} Agents},\nauthor={Junting Chen and Checheng Yu and Xunzhe Zhou and Tianqi Xu and Yao Mu and Mengkang Hu and Wenqi Shao and Yikai Wang and Guohao Li and Lin Shao},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=Ey8KcabBpB}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster EMOS_ Embodiment-aware Heterogeneous Multi-robot Operating System with LLM Agents.pdf", "retrieved_at": "2025-11-12T03:19:08.635135Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "On the Resilience of LLM-Based Multi-Agent Collaboration with Faulty Agents", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Jen-tse Huang", "Jiaxu Zhou", "Tailin Jin", "Xuhui Zhou", "Zixi Chen", "Wenxuan Wang", "Youliang Yuan", "Michael Lyu", "Maarten Sap"], "affinity_score": 0.686, "link": "https://openreview.net/pdf/9e2edbde1577fb0c18c09cfef297de459fecb239.pdf", "abstract": "Large language model-based multi-agent systems have shown great abilities across various tasks due to the collaboration of expert agents, each focusing on a specific domain. However, the impact of clumsy or even malicious agents—those who frequently make errors in their tasks—on the overall performance of the system remains underexplored. This paper investigates: (1) What is the resilience of various system structures (e.g., A$\\rightarrow$B$\\rightarrow$C, A$\\leftrightarrow$B$\\leftrightarrow$C) under faulty agents, on different downstream tasks? (2) How can we increase system resilience to defend against these agents? To simulate faulty agents, we propose two approaches—AutoTransform and AutoInject—which introduce mistakes into the agents' responses. Experiments on four downstream tasks using six systems show that the \"hierarchical\" structure, i.e., A$\\rightarrow$(B$\\leftrightarrow$C), exhibits superior resilience with the lowest performance drop of 5.5%, compared to 10.5% and 23.7% of other two structures. To further improve resilience, we introduce (1) Challenger, that introduces a mechanism for each agent to challenge others' outputs, and (2) Inspector, an additional agent to review and correct messages, recovering up to 96.4% errors made by faulty agents. Our code and data are available at https://github.com/CUHK-ARISE/MAS-Resilience.", "bibtex": "@inproceedings{\nhuang2025on,\ntitle={On the Resilience of {LLM}-Based Multi-Agent Collaboration with Faulty Agents},\nauthor={Jen-tse Huang and Jiaxu Zhou and Tailin Jin and Xuhui Zhou and Zixi Chen and Wenxuan Wang and Youliang Yuan and Michael Lyu and Maarten Sap},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=bkiM54QftZ}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster On the Resilience of LLM-Based Multi-Agent Collaboration with Faulty Agents.pdf", "retrieved_at": "2025-11-12T03:19:09.256522Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "TrajAgent: An LLM-Agent Framework for Trajectory Modeling via Large-and-Small Model Collaboration", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Yuwei Du", "Jie Feng", "Jie Zhao", "Yong Li"], "affinity_score": 0.6859, "link": "https://openreview.net/pdf/c36e83d73e7bc0e77b06be1538e0cde76fc637ac.pdf", "abstract": "Trajectory modeling, which includes research on trajectory data pattern mining and future prediction, has widespread applications in areas such as life services, urban transportation, and public administration. Numerous methods have been proposed to address specific problems within trajectory modeling. However, the heterogeneity of data and the diversity of trajectory tasks make effective and reliable trajectory modeling an important yet highly challenging endeavor, even for domain experts. In this paper, we propose TrajAgent, a agent framework powered by large language models (LLMs), designed to facilitate robust and efficient trajectory modeling through automation modeling. This framework leverages and optimizes diverse specialized models to address various trajectory modeling tasks across different datasets effectively. In TrajAgent, we first develop UniEnv, an execution environment with a unified data and model interface, to support the execution and training of various models. Building on UniEnv, we introduce an agentic workflow designed for automatic trajectory modeling across various trajectory tasks and data. Furthermore, we introduce collaborative learning schema between LLM-based agents and small speciallized models, to enhance the performance of the whole framework effectively. Extensive experiments on four tasks using four real-world datasets demonstrate the effectiveness of TrajAgent in automated trajectory modeling, achieving a performance improvement of 2.38%-69.91% over baseline methods. The codes and data can be accessed via https://github.com/tsinghua-fib-lab/TrajAgent.", "bibtex": "@inproceedings{\ndu2025trajagent,\ntitle={TrajAgent: An {LLM}-Agent Framework for Trajectory Modeling via Large-and-Small Model Collaboration},\nauthor={Yuwei Du and Jie Feng and Jie Zhao and Yong Li},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=9Ook5bXnPr}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster TrajAgent_ An LLM-Agent Framework for Trajectory Modeling via Large-and-Small Model Collaboration.pdf", "retrieved_at": "2025-11-12T03:19:09.792001Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MobileUse: A Hierarchical Reflection-Driven GUI Agent for Autonomous Mobile Operation", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Ning Li", "Xiangmou Qu", "Jiamu Zhou", "Jun Wang", "Muning Wen", "Kounianhua Du", "Xingyu Lou", "Qiuying Peng", "Weinan Zhang"], "affinity_score": 0.6857, "link": "https://openreview.net/pdf/0dfcd45aa867bf09cef726711a929960f019ea27.pdf", "abstract": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled the development of mobile agents that can understand visual inputs and follow user instructions, unlocking new possibilities for automating complex tasks on mobile devices. However, applying these models to real-world mobile scenarios remains a significant challenge due to the long-horizon task execution, difficulty in error recovery, and the cold-start problem in unfamiliar environments. To address these challenges, we propose MobileUse, a GUI agent designed for robust and adaptive mobile task execution. To improve resilience in long-horizon tasks and dynamic environments, we introduce a hierarchical reflection architecture that enables the agent to self-monitor, detect, and recover from errors across multiple temporal scales—ranging from individual actions to overall task completion—while maintaining efficiency through a Reflection-on-Demand strategy. To tackle cold-start issues, we further introduce a proactive exploration module, which enriches the agent’s understanding of the environment through self-planned exploration. Evaluations on the AndroidWorld and AndroidLab benchmarks demonstrate that MobileUse establishes new state-of-the-art performance, achieving success rates of 62.9% and 44.2%, respectively. To facilitate real-world applications, we release an out-of-the-box toolkit for automated task execution on physical mobile devices, which is available at https://github.com/MadeAgents/mobile-use.", "bibtex": "@inproceedings{\nli2025mobileuse,\ntitle={MobileUse: A Hierarchical Reflection-Driven {GUI} Agent for Autonomous Mobile Operation},\nauthor={Ning Li and Xiangmou Qu and Jiamu Zhou and Jun Wang and Muning Wen and Kounianhua Du and Xingyu Lou and Qiuying Peng and Jun Wang and Weinan Zhang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=KR6tnkb6h4}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster MobileUse_ A Hierarchical Reflection-Driven GUI Agent for Autonomous Mobile Operation.pdf", "retrieved_at": "2025-11-12T03:19:10.374544Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "From an LLM Swarm to a PDDL-empowered Hive: Planning Self-executed Instructions in a Multi-modal Jungle", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Kaustubh Vyas", "Damien Graux", "Yijun Yang", "Sebastien Montella", "Chenxin Diao", "Wendi Zhou", "Pavlos Vougiouklis", "Ruofei Lai", "Yang Ren", "Keshuang Li", "Jeff Z. Pan"], "affinity_score": 0.6845, "link": "https://openreview.net/pdf/c2952abe328f9668db8a7ed084a1e5458262e86d.pdf", "abstract": "In response to the call for agent-based solutions that leverage the ever-increasing capabilities of the deep models' ecosystem, we introduce a comprehensive solution for selecting appropriate models and subsequently planning a set of atomic actions to satisfy the end-users' instructions.\nOur system, Hive, operates over sets of models and, upon receiving natural language instructions, schedules and executes, explainable plans of atomic actions. These actions can involve one or more of the available models to achieve the overall task, while respecting end-users specific constraints. Hive is able to plan complex chains of actions while guaranteeing explainability, using an LLM-based formal logic backbone empowered by PDDL operations. We introduce the MuSE benchmark in order to offer a comprehensive evaluation of the multi-modal capabilities of agent systems. Our findings show that our framework redefines the state-of-the-art for task selection, outperforming other competing systems that plan operations across multiple models while offering transparency guarantees while fully adhering to user constraints.", "bibtex": "@inproceedings{\nvyas2025from,\ntitle={From an {LLM} Swarm to a {PDDL}-empowered Hive: Planning Self-executed Instructions in a Multi-modal Jungle},\nauthor={Kaustubh Vyas and Damien Graux and Yijun Yang and Sebastien Montella and Chenxin Diao and Wendi Zhou and Pavlos Vougiouklis and Ruofei Lai and Yang Ren and Keshuang Li and Jeff Z. Pan},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=QAAsnSRwgu}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster From an LLM Swarm to a PDDL-empowered Hive_ Planning Self-executed Instructions in a Multi-modal Jungle.pdf", "retrieved_at": "2025-11-12T03:19:11.392566Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Hongliang He", "Wenlin Yao", "Kaixin Ma", "Wenhao Yu", "Hongming Zhang", "Tianqing Fang", "Zhenzhong Lan", "Dong Yu (于东)"], "affinity_score": 0.6845, "link": "https://aclanthology.org/2025.acl-long.1336/", "abstract": "The advancement of foundation models has laid the groundwork for building autonomous agents for complex tasks such as web navigation. Recent efforts have also tried to equip the agent with the ability to explore environments and continuously improve over time. However, existing works only focused on building text-only agents in synthetic environments where the reward signals are clearly defined. Such agents can hardly generalize to realistic settings that require multimodal perception ability and provide no ground-truth signal. In this paper, we introduce an innovative multimodal web agent that can autonomously conduct real-world exploration and improve itself. We first train the base model with imitation learning to gain the basic abilities. We then let the agent explore the open web and collect feedback on its trajectories. After that, it further improves its policy by learning from well-performing trajectories judged by another general-purpose model. This exploration-feedback-optimization cycle can continue for several iterations. Experimental results show that our web agent successfully improves itself after each iteration, demonstrating strong performance across multiple test sets. We will release our code and model to encourage future research in this field.", "bibtex": "@inproceedings{he-etal-2025-openwebvoyager,\n    title = \"{O}pen{W}eb{V}oyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization\",\n    author = \"He, Hongliang  and\n      Yao, Wenlin  and\n      Ma, Kaixin  and\n      Yu, Wenhao  and\n      Zhang, Hongming  and\n      Fang, Tianqing  and\n      Lan, Zhenzhong  and\n      Yu, Dong\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1336/\",\n    doi = \"10.18653/v1/2025.acl-long.1336\",\n    pages = \"27545--27564\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long OpenWebVoyager_ Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization.pdf", "retrieved_at": "2025-11-12T03:19:11.675376Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Guibin Zhang", "Yanwei Yue", "Zhixun Li", "Sukwon Yun", "Guancheng Wan", "Kun Wang", "Dawei Cheng", "Jeffrey Xu Yu", "Tianlong Chen"], "affinity_score": 0.6844, "link": "https://openreview.net/pdf/490fff420d6359d82b48829601ac0ed820e335b4.pdf", "abstract": "Recent advancements in large language model (LLM)-powered agents have shown that collective intelligence can significantly outperform individual capabilities, largely attributed to the meticulously designed inter-agent communication topologies. Though impressive in performance, existing multi-agent pipelines inherently introduce substantial token overhead, as well as increased economic costs, which pose challenges for their large-scale deployments. In response to this challenge, we propose an economical, simple, and robust multi-agent communication framework, termed $\\texttt{AgentPrune}$, which can seamlessly integrate into mainstream multi-agent systems and prunes redundant or even malicious communication messages. Technically, $\\texttt{AgentPrune}$ is the first to identify and formally define the $\\textit{Communication Redundancy}$ issue present in current LLM-based multi-agent pipelines, and efficiently performs one-shot pruning on the spatial-temporal message-passing graph, yielding a token-economic and high-performing communication topology.\nExtensive experiments across six benchmarks demonstrate that $\\texttt{AgentPrune}$ $\\textbf{(I)}$ achieves comparable results as state-of-the-art topologies at merely $\\$5.6$ cost compared to their $\\$43.7$, $\\textbf{(II)}$ integrates seamlessly into existing multi-agent frameworks with $28.1\\%\\sim72.8\\%\\downarrow$ token reduction, and $\\textbf{(III)}$ successfully defend against two types of agent-based adversarial attacks with $3.5\\%\\sim10.8\\%\\uparrow$ performance boost. The source code is available at \\url{https://github.com/yanweiyue/AgentPrune}.", "bibtex": "@inproceedings{\nzhang2025cut,\ntitle={Cut the Crap: An Economical Communication Pipeline for {LLM}-based Multi-Agent Systems},\nauthor={Guibin Zhang and Yanwei Yue and Zhixun Li and Sukwon Yun and Guancheng Wan and Kun Wang and Dawei Cheng and Jeffrey Xu Yu and Tianlong Chen},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=LkzuPorQ5L}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Cut the Crap_ An Economical Communication Pipeline for LLM-based Multi-Agent Systems.pdf", "retrieved_at": "2025-11-12T03:19:13.311490Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "A Joint Optimization Framework for Enhancing Efficiency of Tool Utilization in LLM Agents", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Bin Wu (吴斌)", "Edgar Meij", "Emine Yilmaz"], "affinity_score": 0.684, "link": "https://aclanthology.org/2025.findings-acl.1149/", "abstract": "Large Language Models (LLMs) augmented with external tools have demonstrated remarkable capabilities in complex problem solving. Existing efforts for tool utilization typically involve an LLM agent that contains instructions on using the description of the available tools to determine and call the tools required to solve the problem. Inference Scaling techniques, such as chain-of-thought and tree-of-thought reasoning, are commonly used but require significant computational overhead and rendering such methods impractical in real-world applications. In this work, we recognize and formalize the critical role of instructions provided in agent prompts and tool descriptions—collectively referred to as\ncontext\n—and show that incomplete\ncontext\nis one of the reasons for this computational overhead.To fill this efficiency gap, we propose an optimization framework that jointly refines both the instructions provided in the agent prompt and tool description, enhancing their interaction. Experiments on StableToolBench and RestBench demonstrate that our optimized agents achieve superior efficiency while maintaining effectiveness. Our findings underscore the critical role of context optimization in improving LLM agents for tool utilization, paving the way for more responsive and cost-effective LLM agents. Our code is available at\nhttps://github.com/Bingo-W/ToolOptimization\n.", "bibtex": "@inproceedings{wu-etal-2025-joint,\n    title = \"A Joint Optimization Framework for Enhancing Efficiency of Tool Utilization in {LLM} Agents\",\n    author = \"Wu, Bin  and\n      Meij, Edgar  and\n      Yilmaz, Emine\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1149/\",\n    doi = \"10.18653/v1/2025.findings-acl.1149\",\n    pages = \"22361--22373\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings A Joint Optimization Framework for Enhancing Efficiency of Tool Utilization in LLM Agents.pdf", "retrieved_at": "2025-11-12T03:19:13.568044Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Vardaan Pahuja", "Yadong Lu", "Corby Rosset", "Boyu Gou", "Arindam Mitra", "Spencer Whitehead", "Yu Su", "Ahmed Hassan"], "affinity_score": 0.6833, "link": "https://aclanthology.org/2025.findings-acl.326/", "abstract": "Recent success in large multimodal models (LMMs) has sparked promising applications of agents capable of autonomously completing complex web tasks. While open-source LMM agents have made significant advances in offline evaluation benchmarks, their performance still falls substantially short of human-level capabilities in more realistic online settings. A key bottleneck is the lack of diverse and large-scale trajectory-level datasets across various domains, which are expensive to collect. In this paper, we address this challenge by developing a scalable recipe to synthesize the largest and most diverse trajectory-level dataset to date, containing over 94K successful multimodal web trajectories, spanning 49K unique URLs, 720K screenshots, and 33M web elements. In particular, we leverage extensive web exploration and refinement to obtain diverse task intents. The average cost is 28 cents per successful trajectory, making it affordable to a wide range of users in the community. Leveraging this dataset, we train Explorer, a multimodal web agent, and demonstrate strong performance on both offline and online web agent benchmarks such as Mind2Web-Live, Multimodal-Mind2Web, and MiniWob++. Additionally, our experiments highlight data scaling as a key driver for improving web agent capabilities. We hope this study makes state-of-the-art LMM-based agent research at a larger scale more accessible.", "bibtex": "@inproceedings{pahuja-etal-2025-explorer,\n    title = \"Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents\",\n    author = \"Pahuja, Vardaan  and\n      Lu, Yadong  and\n      Rosset, Corby  and\n      Gou, Boyu  and\n      Mitra, Arindam  and\n      Whitehead, Spencer  and\n      Su, Yu  and\n      Awadallah, Ahmed Hassan\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.326/\",\n    doi = \"10.18653/v1/2025.findings-acl.326\",\n    pages = \"6300--6323\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings Explorer_ Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents.pdf", "retrieved_at": "2025-11-12T03:19:13.837026Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems", "venue": "ICML 2025 Spotlightposter", "year": "2025", "authors": ["Shaokun Zhang", "Ming Yin", "Jieyu Zhang", "Jiale Liu", "Zhiguang Han", "Jingyang Zhang", "Beibin Li", "Chi Wang", "Huazheng Wang", "Yiran Chen", "Qingyun Wu"], "affinity_score": 0.6832, "link": "https://openreview.net/pdf/ff66e9a98409dd3de0dd970b8433fae8c26a3674.pdf", "abstract": "Failure attribution in LLM multi-agent systems—identifying the agent and step responsible for task failures—provides crucial clues for systems debugging but remains underexplored and labor-intensive. \nIn this paper, we propose and formulate a new research area: automated failure attribution for LLM multi-agent systems.\nTo support this initiative, we introduce the Who\\&When dataset, comprising extensive failure logs from 127 LLM multi-agent systems with fine-grained annotations linking failures to specific agents and decisive error steps.\nUsing the Who\\&When, we develop and evaluate three automated failure attribution methods, summarizing their corresponding pros and cons.  The best method achieves 53.5\\% accuracy in identifying failure-responsible agents but only 14.2\\% in pinpointing failure steps, with some methods performing below random.  Even SOTA reasoning models, such as OpenAI o1 and DeepSeek R1, fail to achieve practical usability. These results highlight the task's complexity and the need for further research in this area. Code and dataset are available in https://github.com/mingyin1/Agents_Failure_Attribution.", "bibtex": "@inproceedings{\nzhang2025which,\ntitle={Which Agent Causes Task Failures and When? On Automated Failure Attribution of {LLM} Multi-Agent Systems},\nauthor={Shaokun Zhang and Ming Yin and Jieyu Zhang and Jiale Liu and Zhiguang Han and Jingyang Zhang and Beibin Li and Chi Wang and Huazheng Wang and Yiran Chen and Qingyun Wu},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=GazlTYxZss}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Spotlightposter Which Agent Causes Task Failures and When_ On Automated Failure Attribution of LLM Multi-Agent Systems.pdf", "retrieved_at": "2025-11-12T03:19:14.482472Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "An Empirical Study of Group Conformity in Multi-Agent Systems", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Min Choi", "Keonwoo Kim", "Sungwon Chae", "Sangyeop Baek"], "affinity_score": 0.6832, "link": "https://aclanthology.org/2025.findings-acl.265/", "abstract": "Recent advances in Large Language Models (LLMs) have enabled multi-agent systems that simulate real-world interactions with near-human reasoning. While previous studies have extensively examined biases related to protected attributes such as race, the emergence and propagation of biases on socially contentious issues in multi-agent LLM interactions remain underexplored. This study explores how LLM agents shape public opinion through debates on five contentious topics. By simulating over 2,500 debates, we analyze how initially neutral agents, assigned a centrist disposition, adopt specific stances over time. Statistical analyses reveal significant group conformity mirroring human behavior; LLM agents tend to align with numerically dominant groups or more intelligent agents, exerting a greater influence. These findings underscore the crucial role of agent intelligence in shaping discourse and highlight the risks of bias amplification in online interactions. Our results emphasize the need for policy measures that promote diversity and transparency in LLM-generated discussions to mitigate the risks of bias propagation within anonymous online environments.", "bibtex": "@inproceedings{choi-etal-2025-empirical,\n    title = \"An Empirical Study of Group Conformity in Multi-Agent Systems\",\n    author = \"Choi, Min  and\n      Kim, Keonwoo  and\n      Chae, Sungwon  and\n      Baek, Sangyeop\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.265/\",\n    doi = \"10.18653/v1/2025.findings-acl.265\",\n    pages = \"5123--5139\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings An Empirical Study of Group Conformity in Multi-Agent Systems.pdf", "retrieved_at": "2025-11-12T03:19:15.686898Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Many Minds, One Goal: Time Series Forecasting via Sub-task Specialization and Inter-agent Cooperation", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Qihe Huang", "Zhengyang Zhou", "Yangze Li", "Kuo Yang", "Binwu Wang", "Yang Wang"], "affinity_score": 0.683, "link": "https://openreview.net/pdf/703b1261fdea6ed1048e2c011db26cfa5a8ecae0.pdf", "abstract": "Time series forecasting is a critical and complex task, characterized by diverse temporal patterns, varying statistical properties, and different prediction horizons across datasets and domains. Conventional approaches typically rely on a single, unified model architecture to handle all forecasting scenarios. However, such monolithic models struggle to generalize across dynamically evolving time series with shifting patterns. In reality, different types of time series may require distinct modeling strategies. Some benefit from homogeneous multi-scale forecasting awareness, while others rely on more complex and heterogeneous signal perception. Relying on a single model to capture all temporal diversity and structural variations leads to limited  performance and poor interpretability. To address this challenge, we propose a Multi-Agent Forecasting System (MAFS) that abandons the one-size-fits-all paradigm. MAFS decomposes the forecasting task into multiple sub-tasks, each handled by a dedicated agent trained on specific temporal perspectives (e.g., different forecasting resolutions or signal characteristics).  Furthermore, to achieve holistic forecasting, agents share and refine information through different communication topology, enabling cooperative reasoning across different temporal views. A lightweight voting aggregator then integrates their outputs into consistent final predictions. Extensive experiments across 11 benchmarks demonstrate that MAFS significantly outperforms traditional single-model approaches, yielding more robust and adaptable forecasts.", "bibtex": "@inproceedings{\nhuang2025many,\ntitle={Many Minds, One Goal: Time Series Forecasting via Sub-task Specialization and Inter-agent Cooperation},\nauthor={Qihe Huang and Zhengyang Zhou and Yangze Li and Kuo Yang and Binwu Wang and Yang Wang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=Uon41HfqR3}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Many Minds, One Goal_ Time Series Forecasting via Sub-task Specialization and Inter-agent Cooperation.pdf", "retrieved_at": "2025-11-12T03:19:17.081872Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Angana Borah", "Rada Mihalcea"], "affinity_score": 0.6827, "link": "https://aclanthology.org/2024.findings-emnlp.545/", "abstract": "As Large Language Models (LLMs) continue to evolve, they are increasingly being employed in numerous studies to simulate societies and execute diverse social tasks. However, LLMs are susceptible to societal biases due to their exposure to human-generated data. Given that LLMs are being used to gain insights into various societal aspects, it is essential to mitigate these biases. To that end, our study investigates the presence of implicit gender biases in multi-agent LLM interactions and proposes two strategies to mitigate these biases. We begin by creating a dataset of scenarios where implicit gender biases might arise, and subsequently develop a metric to assess the presence of biases. Our empirical analysis reveals that LLMs generate outputs characterized by strong implicit bias associations ( ≥ ≈ 50% of the time). Furthermore, these biases tend to escalate following multi-agent interactions. To mitigate them, we propose two strategies: self-reflection with in-context examples (ICE); and supervised fine-tuning. Our research demonstrates that both methods effectively mitigate implicit biases, with the ensemble of fine-tuning and self-reflection proving to be the most successful.", "bibtex": "@inproceedings{borah-mihalcea-2024-towards,\n    title = \"Towards Implicit Bias Detection and Mitigation in Multi-Agent {LLM} Interactions\",\n    author = \"Borah, Angana  and\n      Mihalcea, Rada\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.545/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.545\",\n    pages = \"9306--9326\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions.pdf", "retrieved_at": "2025-11-12T03:19:17.384430Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "COMBO: Compositional World Models for Embodied Multi-Agent Cooperation", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Hongxin Zhang", "Zeyuan Wang", "Qiushi Lyu", "Zheyuan Zhang", "Sunli Chen", "Tianmin Shu", "Behzad Dariush", "Kwonjoon Lee", "Yilun Du", "Chuang Gan"], "affinity_score": 0.6827, "link": "https://openreview.net/pdf/54baa5d646fd9a8bbe3d264abfa7e975492da99d.pdf", "abstract": "In this paper, we investigate the problem of embodied multi-agent cooperation, where decentralized agents must cooperate given only egocentric views of the world. To effectively plan in this setting, in contrast to learning world dynamics in a single-agent scenario, we must simulate world dynamics conditioned on an arbitrary number of agents' actions given only partial egocentric visual observations of the world. To address this issue of partial observability, we first train generative models to estimate the overall world state given partial egocentric observations. To enable accurate simulation of multiple sets of actions on this world state, we then propose to learn a compositional world model for multi-agent cooperation by factorizing the naturally composable joint actions of multiple agents and compositionally generating the video conditioned on the world state. By leveraging this compositional world model, in combination with Vision Language Models to infer the actions of other agents, we can use a tree search procedure to integrate these modules and facilitate online cooperative planning. We evaluate our methods on three challenging benchmarks with 2-4 agents. The results show our compositional world model is effective and the framework enables the embodied agents to cooperate efficiently with different agents across various tasks and an arbitrary number of agents, showing the promising future of our proposed methods. More videos can be found at https://umass-embodied-agi.github.io/COMBO", "bibtex": "@inproceedings{\nzhang2025combo,\ntitle={{COMBO}: Compositional World Models for Embodied Multi-Agent Cooperation},\nauthor={Hongxin Zhang and Zeyuan Wang and Qiushi Lyu and Zheyuan Zhang and Sunli Chen and Tianmin Shu and Behzad Dariush and Kwonjoon Lee and Yilun Du and Chuang Gan},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=YXRyYkb1im}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster COMBO_ Compositional World Models for Embodied Multi-Agent Cooperation.pdf", "retrieved_at": "2025-11-12T03:19:18.078978Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Tooling or Not Tooling? The Impact of Tools on Language Agents for Chemistry Problem Solving", "venue": "NAACL 2025 Findings", "year": "2025", "authors": ["Botao Yu", "Frazier N. Baker", "Ziru Chen", "Garrett Herb", "Boyu Gou", "Daniel Adu-Ampratwum", "Xia Ning", "Huan Sun"], "affinity_score": 0.6827, "link": "https://aclanthology.org/2025.findings-naacl.424/", "abstract": "To enhance large language models (LLMs) for chemistry problem solving, several LLM-based agents augmented with tools have been proposed, such as ChemCrow and Coscientist. However, their evaluations are narrow in scope, leaving a large gap in understanding the benefits of tools across diverse chemistry tasks. To bridge this gap, we develop ChemAgent, an enhanced chemistry agent over ChemCrow, and conduct a comprehensive evaluation of its performance on both specialized chemistry tasks and general chemistry questions. Surprisingly, ChemAgent does not consistently outperform its base LLMs without tools. Our error analysis with a chemistry expert suggests that: For specialized chemistry tasks, such as synthesis prediction, we should augment agents with specialized tools; however, for general chemistry questions like those in exams, agents’ ability to reason correctly with chemistry knowledge matters more, and tool augmentation does not always help.", "bibtex": "@inproceedings{yu-etal-2025-tooling,\n    title = \"Tooling or Not Tooling? The Impact of Tools on Language Agents for Chemistry Problem Solving\",\n    author = \"Yu, Botao  and\n      Baker, Frazier N.  and\n      Chen, Ziru  and\n      Herb, Garrett  and\n      Gou, Boyu  and\n      Adu-Ampratwum, Daniel  and\n      Ning, Xia  and\n      Sun, Huan\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Findings of the Association for Computational Linguistics: NAACL 2025\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-naacl.424/\",\n    doi = \"10.18653/v1/2025.findings-naacl.424\",\n    pages = \"7620--7640\",\n    ISBN = \"979-8-89176-195-7\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Findings Tooling or Not Tooling_ The Impact of Tools on Language Agents for Chemistry Problem Solving.pdf", "retrieved_at": "2025-11-12T03:19:18.307314Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Counterfactual Effect Decomposition in Multi-Agent Sequential Decision Making", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Stelios Triantafyllou", "Aleksa Sukovic", "Yasaman Zolfimoselo", "Goran Radanovic"], "affinity_score": 0.6819, "link": "https://openreview.net/pdf/2f7d4d2bfa2d4174af3cfb3e5252d97c84dea050.pdf", "abstract": "We address the challenge of explaining counterfactual outcomes in multi-agent Markov decision processes. In particular, we aim to explain the total counterfactual effect of an agent's action on the outcome of a realized scenario through its influence on the environment dynamics and the agents' behavior. To achieve this, we introduce a novel causal explanation formula that decomposes the counterfactual effect by attributing to each agent and state variable a score reflecting their respective contributions to the effect. First, we show that the total counterfactual effect of an agent's action can be decomposed into two components: one measuring the effect that propagates through all subsequent agents' actions and another related to the effect that propagates through the state transitions. Building on recent advancements in causal contribution analysis, we further decompose these two effects as follows. For the former, we consider agent-specific effects -- a causal concept that quantifies the counterfactual effect of an agent's action that propagates through a subset of agents. Based on this notion, we use Shapley value to attribute the effect to individual agents. For the latter, we consider the concept of structure-preserving interventions and attribute the effect to state variables based on their \"intrinsic'' contributions. Through extensive experimentation, we demonstrate the interpretability of our approach in a Gridworld environment with LLM-assisted agents and a sepsis management simulator.", "bibtex": "@inproceedings{\ntriantafyllou2025counterfactual,\ntitle={Counterfactual Effect Decomposition in Multi-Agent Sequential Decision Making},\nauthor={Stelios Triantafyllou and Aleksa Sukovic and Yasaman Zolfimoselo and Goran Radanovic},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=jHLSnYNt1m}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Counterfactual Effect Decomposition in Multi-Agent Sequential Decision Making.pdf", "retrieved_at": "2025-11-12T03:19:18.850498Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Junde Wu", "Jiayuan Zhu", "Yuyuan Liu", "Min Xu", "Yueming Jin"], "affinity_score": 0.6808, "link": "https://aclanthology.org/2025.acl-long.1383/", "abstract": "We introduce Agentic Reasoning, a framework that enhances large language model (LLM) reasoning by integrating external tool-using agents. Agentic Reasoning dynamically leverages web search, code execution, and structured memory to address complex problems requiring deep research. A key innovation in our framework is the Mind-Map agent, which constructs a structured knowledge graph to store reasoning context and track logical relationships, ensuring coherence in long reasoning chains with extensive tool usage. Additionally, we conduct a comprehensive exploration of the Web-Search agent, leading to a highly effective search mechanism that surpasses all prior approaches. When deployed on DeepSeek-R1, our method achieves a new state-of-the-art (SOTA) among public models and delivers performance comparable to OpenAI Deep Research, the leading proprietary model in this domain. Extensive ablation studies validate the optimal selection of agentic tools and confirm the effectiveness of our Mind-Map and Web-Search agents in enhancing LLM reasoning. Our code and data are publicly available.", "bibtex": "@inproceedings{wu-etal-2025-agentic,\n    title = \"Agentic Reasoning: A Streamlined Framework for Enhancing {LLM} Reasoning with Agentic Tools\",\n    author = \"Wu, Junde  and\n      Zhu, Jiayuan  and\n      Liu, Yuyuan  and\n      Xu, Min  and\n      Jin, Yueming\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1383/\",\n    doi = \"10.18653/v1/2025.acl-long.1383\",\n    pages = \"28489--28503\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Agentic Reasoning_ A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools.pdf", "retrieved_at": "2025-11-12T03:19:19.116684Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AgentGym: Evaluating and Training Large Language Model-based Agents across Diverse Environments", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Zhiheng Xi", "Yiwen Ding", "Wenxiang Chen", "Boyang Hong", "Honglin Guo", "Junzhe Wang", "Xin Guo (郭鑫)", "Dingwen Yang", "Chenyang Liao", "Wei He", "Songyang Gao", "Lu Chen", "Rui Zheng", "Yicheng Zou", "Tao Gui", "Qi Zhang (张琦)", "Xipeng Qiu (邱锡鹏)", "Xuan-Jing Huang (黄萱菁)", "Zuxuan Wu", "Yu-Gang Jiang"], "affinity_score": 0.6808, "link": "https://aclanthology.org/2025.acl-long.1355/", "abstract": "Large language models (LLMs) have emerged as a promising foundation to build generally-capable agents (LLM-based agents) that can handle multi-turn decision-making tasks across various environments. However, the community lacks a unified interactive framework that covers diverse environments for comprehensive evaluation of agents, and enables exploration and learning for their self-improvement. To address this, we propose AgentGym, a framework featuring 7 real-world scenarios, 14 environments, and 89 tasks for unified, real-time, and concurrent agent interaction. We construct expanded instruction set, high-quality trajectories, and comprehensive benchmarking suite for developing LLM-based agents. Moreover, AgentGym supports interactive exploration and learning for agents through multi-turn interactions and real-time feedback. Based on AgentGym, we take the initial step to develop LLM-based agents that can handle diverse tasks via methods like self-improvement or reinforcement learning. Experimental results show that the trained agents can achieve results comparable to commercial models. We hope our work can help the community develop more advanced LLM-based agents. We release the code, dataset, benchmark, and checkpoints at https://agentgym.github.io/.", "bibtex": "@inproceedings{xi-etal-2025-agentgym,\n    title = \"{A}gent{G}ym: Evaluating and Training Large Language Model-based Agents across Diverse Environments\",\n    author = \"Xi, Zhiheng  and\n      Ding, Yiwen  and\n      Chen, Wenxiang  and\n      Hong, Boyang  and\n      Guo, Honglin  and\n      Wang, Junzhe  and\n      Guo, Xin  and\n      Yang, Dingwen  and\n      Liao, Chenyang  and\n      He, Wei  and\n      Gao, Songyang  and\n      Chen, Lu  and\n      Zheng, Rui  and\n      Zou, Yicheng  and\n      Gui, Tao  and\n      Zhang, Qi  and\n      Qiu, Xipeng  and\n      Huang, Xuanjing  and\n      Wu, Zuxuan  and\n      Jiang, Yu-Gang\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1355/\",\n    doi = \"10.18653/v1/2025.acl-long.1355\",\n    pages = \"27914--27961\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long AgentGym_ Evaluating and Training Large Language Model-based Agents across Diverse Environments.pdf", "retrieved_at": "2025-11-12T03:19:19.385639Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Hierarchically Encapsulated Representation for Protocol Design in Self-Driving Labs", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Yu-Zhe Shi", "Mingchen Liu", "Fanxu Meng", "Qiao Xu", "Zhangqian Bi", "Kun He", "Lecheng Ruan", "Qining Wang"], "affinity_score": 0.6805, "link": "https://openreview.net/pdf/34f02eae08b127d9b0af3e67c0e5215e017f3d7a.pdf", "abstract": "Self-driving laboratories have begun to replace human experimenters in performing single experimental skills or predetermined experimental protocols. However, as the pace of idea iteration in scientific research has been intensified by Artificial Intelligence, the demand for rapid design of new protocols for new discoveries become evident. Efforts to automate protocol design have been initiated, but the capabilities of knowledge-based machine designers, such as Large Language Models, have not been fully elicited, probably for the absence of a systematic representation of experimental knowledge, as opposed to isolated, flatten pieces of information. To tackle this issue, we propose a multi-faceted, multi-scale representation, where instance actions, generalized operations, and product flow models are hierarchically encapsulated using Domain-Specific Languages. We further develop a data-driven algorithm based on non-parametric modeling that autonomously customizes these representations for specific domains. The proposed representation is equipped with various machine designers to manage protocol design tasks, including planning, modification, and adjustment. The results demonstrate that the proposed method could effectively complement Large Language Models in the protocol design process, serving as an auxiliary module in the realm of machine-assisted scientific exploration.", "bibtex": "@inproceedings{\nshi2025hierarchically,\ntitle={Hierarchically Encapsulated Representation for Protocol Design in Self-Driving Labs},\nauthor={Yu-Zhe Shi and Mingchen Liu and Fanxu Meng and Qiao Xu and Zhangqian Bi and Kun He and Lecheng Ruan and Qining Wang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=9nUBh4V6SA}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Hierarchically Encapsulated Representation for Protocol Design in Self-Driving Labs.pdf", "retrieved_at": "2025-11-12T03:19:20.233861Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Mircea Tudor Lică", "Ojas Shirekar", "Baptiste Colle", "Chirag Raman"], "affinity_score": 0.6796, "link": "https://openreview.net/pdf/aaff34bc5f2395383d58c98d38975df26262971c.pdf", "abstract": "Embodied agents powered by large language models (LLMs), such as Voyager, promise open-ended competence in worlds such as Minecraft. However, when powered by open-weight LLMs they still falter on elementary tasks after domain-specific fine-tuning. We propose MindForge, a generative-agent framework for cultural lifelong learning through explicit perspective taking. We introduce three key innovations: (1) a structured theory of mind representation linking percepts, beliefs, desires, and actions; (2) natural inter-agent communication; and (3) a multi-component memory system. Following the cultural learning framework, we test MindForge in both instructive and collaborative settings within Minecraft. In an instructive setting with GPT-4, MindForge agents powered by open-weight LLMs significantly outperform their Voyager counterparts in basic tasks yielding $3\\times$ more tech-tree milestones and collecting $2.3\\times$ more unique items than the Voyager baseline. Furthermore, in fully collaborative settings, we find that the performance of two underachieving agents improves with more communication rounds, echoing the Condorcet Jury Theorem. MindForge agents demonstrate sophisticated behaviors, including expert-novice knowledge transfer, collaborative problem solving, and adaptation to out-of-distribution tasks through accumulated cultural experiences.", "bibtex": "@inproceedings{\nlica2025mindforge,\ntitle={MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning},\nauthor={Mircea Tudor Lic{\\u{a}} and Ojas Shirekar and Baptiste Colle and Chirag Raman},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=u7jtLj46i9}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster MindForge_ Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning.pdf", "retrieved_at": "2025-11-12T03:19:21.715381Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Assessing and Verifying Task Utility in LLM-Powered Applications", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Negar Arabzadeh", "Siqing Huo", "Nikhil Mehta", "Qingyun Wu", "Chi Wang", "Ahmed Hassan", "Charles L. A. Clarke", "Julia Kiseleva"], "affinity_score": 0.6796, "link": "https://aclanthology.org/2024.emnlp-main.1219/", "abstract": "The rapid development of Large Language Models (LLMs) has led to a surge in applications that facilitate collaboration among multiple agents, assisting humans in their daily tasks. However, a significant gap remains in assessing to what extent LLM-powered applications genuinely enhance user experience and task execution efficiency. This highlights the need to verify utility of LLM-powered applications, particularly by ensuring alignment between the application’s functionality and end-user needs. We introduce AgentEval, a novel framework designed to simplify the utility verification process by automatically proposing a set of criteria tailored to the unique purpose of any given application. This allows for a comprehensive assessment, quantifying the utility of an application against the suggested criteria. We present a comprehensive analysis of the effectiveness and robustness of AgentEval for two open source datasets including Math Problem solving and ALFWorld House-hold related tasks. For reproducibility purposes, we make the data, code and all the logs publicly available at https://github.com/Narabzad/AgentEval", "bibtex": "@inproceedings{arabzadeh-etal-2024-assessing,\n    title = \"Assessing and Verifying Task Utility in {LLM}-Powered Applications\",\n    author = \"Arabzadeh, Negar  and\n      Huo, Siqing  and\n      Mehta, Nikhil  and\n      Wu, Qingyun  and\n      Wang, Chi  and\n      Awadallah, Ahmed Hassan  and\n      Clarke, Charles L. A.  and\n      Kiseleva, Julia\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.1219/\",\n    doi = \"10.18653/v1/2024.emnlp-main.1219\",\n    pages = \"21868--21888\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main Assessing and Verifying Task Utility in LLM-Powered Applications.pdf", "retrieved_at": "2025-11-12T03:19:23.100660Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Pragmatic Heterogeneous Collaborative Perception via Generative Communication Mechanism", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Junfei Zhou", "Penglin Dai", "Quanmin Wei", "Bingyi Liu", "Xiao Wu", "Jianping Wang"], "affinity_score": 0.6795, "link": "https://openreview.net/pdf/ff97d0cd60e0f9649a45a30aa8dcf125d2bb2a87.pdf", "abstract": "Multi-agent collaboration enhances the perception capabilities of individual agents through information sharing. However, in real-world applications, differences in sensors and models across heterogeneous agents inevitably lead to domain gaps during collaboration. Existing approaches based on adaptation and reconstruction fail to support\npragmatic heterogeneous collaboration\ndue to two key limitations: (1) Intrusive retraining of the encoder or core modules disrupts the established semantic consistency among agents; and (2) accommodating new agents incurs high computational costs, limiting scalability. To address these challenges, we present a novel\nGen\nerative\nComm\nunication mechanism (GenComm) that facilitates seamless perception across heterogeneous multi-agent systems through feature generation, without altering the original network, and employs lightweight numerical alignment of spatial information to efficiently integrate new agents at minimal cost. Specifically, a tailored Deformable Message Extractor is designed to extract spatial message for each collaborator, which is then transmitted in place of intermediate features. The Spatial-Aware Feature Generator, utilizing a conditional diffusion model,  generates features aligned with the ego agent's semantic space while preserving the spatial information of the collaborators. These generated features are further refined by a Channel Enhancer before fusion. Experiments conducted on the OPV2V-H, DAIR-V2X and V2X-Real datasets demonstrate that GenComm outperforms existing state-of-the-art methods, achieving an 81\\% reduction in both computational cost and parameter count when incorporating new agents. Our code is available at https://github.com/jeffreychou777/GenComm.", "bibtex": "@inproceedings{\nzhou2025pragmatic,\ntitle={Pragmatic Heterogeneous Collaborative Perception via Generative Communication Mechanism},\nauthor={Junfei Zhou and Penglin Dai and Quanmin Wei and Bingyi Liu and Xiao Wu and Jianping Wang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=CYG3kmFsgM}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Pragmatic Heterogeneous Collaborative Perception via Generative Communication Mechanism.pdf", "retrieved_at": "2025-11-12T03:19:24.708915Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Mixture-of-Agents Enhances Large Language Model Capabilities", "venue": "ICLR 2025 Spotlight", "year": "2025", "authors": ["Junlin Wang", "Jue WANG", "Ben Athiwaratkun", "Ce Zhang", "James Zou"], "affinity_score": 0.6795, "link": "https://openreview.net/pdf/6ec35d5989095ecc687734c8a3549468e2ce33d9.pdf", "abstract": "Recent advances in large language models (LLMs) demonstrate substantial capabilities in natural language understanding and generation tasks. With the growing number of LLMs, how to harness the collective expertise of multiple LLMs is an exciting open direction. Toward this goal, we propose a new approach that leverages the collective strengths of multiple LLMs through a Mixture-of-Agents (MoA) methodology. In our approach, we construct a layered MoA architecture wherein each layer comprises multiple LLM agents. Each agent takes all the outputs from agents in the previous layer as auxiliary information in generating its response. MoA models achieves state-of-art performance on AlpacaEval 2.0, Arena-Hard, MT-Bench, and FLASK, surpassing GPT-4 Omni. For example, our MoA using only open-source LLMs achieves a score of 65.1% on AlpacaEval 2.0 compared to 57.5% by GPT-4 Omni.", "bibtex": "@inproceedings{\nwang2025mixtureofagents,\ntitle={Mixture-of-Agents Enhances Large Language Model Capabilities},\nauthor={Junlin Wang and Jue WANG and Ben Athiwaratkun and Ce Zhang and James Zou},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=h0ZfDIrj7T}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Spotlight Mixture-of-Agents Enhances Large Language Model Capabilities.pdf", "retrieved_at": "2025-11-12T03:19:25.256003Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MLZero: A Multi-Agent System for End-to-end Machine Learning Automation", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Haoyang Fang", "Boran Han", "Nick Erickson", "Xiyuan Zhang", "Su Zhou", "Anirudh Dagar", "Jiani Zhang", "Ali Caner Turkmen", "Cuixiong Hu", "Huzefa Rangwala", "Ying Nian Wu", "Bernie Wang", "George Karypis"], "affinity_score": 0.6791, "link": "https://openreview.net/pdf/55f28109c8ee532fe1c950142c23f6efd636a79e.pdf", "abstract": "Existing AutoML systems have advanced the automation of machine learning (ML); however, they still require substantial manual configuration and expert input, particularly when handling multimodal data. We introduce MLZero, a novel multi-agent framework powered by Large Language Models (LLMs) that enables end-to-end ML automation across diverse data modalities with minimal human intervention. A cognitive perception module is first employed, transforming raw multimodal inputs into perceptual context that effectively guides the subsequent workflow. To address key limitations of LLMs, such as hallucinated code generation and outdated API knowledge, we enhance the iterative code generation process with semantic and episodic memory. MLZero demonstrates superior performance on MLE-Bench Lite, outperforming all competitors in both success rate and solution quality, securing six gold medals. Furthermore, when evaluated on our Multimodal AutoML Agent Benchmark, which includes 25 more challenging tasks spanning diverse data modalities, MLZero outperforms the competing methods by a large margin with a success rate of 0.92 (+263.6\\%) and an average rank of 2.28. Our approach maintains its robust effectiveness even with a compact 8B LLM, outperforming full-size systems from existing solutions.", "bibtex": "@inproceedings{\nfang2025mlzero,\ntitle={{MLZ}ero: A Multi-Agent System for End-to-end Machine Learning Automation},\nauthor={Haoyang Fang and Boran Han and Nick Erickson and Xiyuan Zhang and Su Zhou and Anirudh Dagar and Jiani Zhang and Ali Caner Turkmen and Cuixiong Hu and Huzefa Rangwala and Ying Nian Wu and Bernie Wang and George Karypis},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=9t7gfYUp0U}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster MLZero_ A Multi-Agent System for End-to-end Machine Learning Automation.pdf", "retrieved_at": "2025-11-12T03:19:26.804727Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Yang Zhang", "Shixin Yang", "Chenjia Bai", "Fei Wu", "Xiu Li", "Zhen Wang", "Xuelong Li"], "affinity_score": 0.6787, "link": "https://aclanthology.org/2025.findings-acl.84/", "abstract": "Grounding the reasoning ability of large language models (LLMs) for embodied tasks is challenging due to the complexity of the physical world. Especially, LLM planning for multi-agent collaboration requires communication of agents or credit assignment as the feedback to re-adjust the proposed plans and achieve effective coordination. However, existing methods that overly rely on physical verification or self-reflection suffer from excessive and inefficient querying of LLMs. In this paper, we propose a novel framework for multi-agent collaboration that introduces Reinforced Advantage feedback (ReAd) for efficient self-refinement of plans. Specifically, we perform critic regression to learn a sequential advantage function from LLM-planned data, and then treat the LLM planner as an optimizer to generate actions that maximize the advantage function. It endows the LLM with the foresight to discern whether the action contributes to accomplishing the final task. We provide theoretical analysis by extending advantage-weighted regression in reinforcement learning to multi-agent systems. Experiments on Overcooked-AI and a difficult variant of RoCoBench show that ReAd surpasses baselines in success rate, and also significantly decreases the interaction steps of agents and query rounds of LLMs, demonstrating its high efficiency for grounding LLMs. More results are given at https://read-llm.github.io/.", "bibtex": "@inproceedings{zhang-etal-2025-towards-efficient,\n    title = \"Towards Efficient {LLM} Grounding for Embodied Multi-Agent Collaboration\",\n    author = \"Zhang, Yang  and\n      Yang, Shixin  and\n      Bai, Chenjia  and\n      Wu, Fei  and\n      Li, Xiu  and\n      Wang, Zhen  and\n      Li, Xuelong\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.84/\",\n    doi = \"10.18653/v1/2025.findings-acl.84\",\n    pages = \"1663--1699\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration.pdf", "retrieved_at": "2025-11-12T03:19:27.154536Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "TheoremExplainAgent: Towards Video-based Multimodal Explanations for LLM Theorem Understanding", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Max Ku", "Cheuk Hei Chong", "Jonathan Leung", "Krish Shah", "Alvin Yu", "Wenhu Chen"], "affinity_score": 0.6782, "link": "https://aclanthology.org/2025.acl-long.332/", "abstract": "Understanding domain-specific theorems often requires more than just text-based reasoning; effective communication through structured visual explanations is crucial for deeper comprehension. While large language models (LLMs) demonstrate strong performance in text-based theorem reasoning, their ability to generate coherent and pedagogically meaningful visual explanations remains an open challenge. In this work, we introduce TheoremExplainAgent, an agentic approach for generating long-form theorem explanation videos (over 5 minutes) using Manim animations. To systematically evaluate multimodal theorem explanations, we propose TheoremExplainBench, a benchmark covering 240 theorems across multiple STEM disciplines, along with 5 automated evaluation metrics. Our results reveal that agentic planning is essential for generating detailed long-form videos, and the o3-mini agent achieves a success rate of 93.8% and an overall score of 0.77. However, our quantitative and qualitative studies show that most of the videos produced exhibit minor issues with visual element layout. Furthermore, multimodal explanations expose deeper reasoning flaws that text-based explanations fail to reveal, highlighting the importance of multimodal explanations.", "bibtex": "@inproceedings{ku-etal-2025-theoremexplainagent,\n    title = \"{T}heorem{E}xplain{A}gent: Towards Video-based Multimodal Explanations for {LLM} Theorem Understanding\",\n    author = \"Ku, Max  and\n      Chong, Cheuk Hei  and\n      Leung, Jonathan  and\n      Shah, Krish  and\n      Yu, Alvin  and\n      Chen, Wenhu\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.332/\",\n    doi = \"10.18653/v1/2025.acl-long.332\",\n    pages = \"6663--6684\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long TheoremExplainAgent_ Towards Video-based Multimodal Explanations for LLM Theorem Understanding.pdf", "retrieved_at": "2025-11-12T03:19:27.467926Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MICE for CATs: Model-Internal Confidence Estimation for Calibrating Agents with Tools", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Nishant Subramani", "Jason Eisner", "Justin Svegliato", "Benjamin Van Durme", "Yu Su", "Sam Thomson"], "affinity_score": 0.6777, "link": "https://aclanthology.org/2025.naacl-long.615/", "abstract": "Tool-using agents that act in the world need to be both useful and safe. Well-calibrated model confidences can be used to weigh the risk versus reward of potential actions, but prior work shows that many models are poorly calibrated. Inspired by interpretability literature exploring the internals of models, we propose a novel class of model-internal confidence estimators (MICE) to better assess confidence when calling tools. MICE first decodes from each intermediate layer of the language model using logit lens and then computes similarity scores between each layer’s generation and the final output. These features are fed into a learned probabilistic classifier to assess confidence in the decoded output. On the simulated trial and error (STE) tool-calling dataset using Llama3 models, we find that MICE beats or matches the baselines on smoothed expected calibration error. Using MICE confidences to determine whether to call a tool significantly improves over strong baselines on a new metric, expected tool-calling utility. Further experiments show that MICE is sample-efficient, can generalize zero-shot to unseen APIs, and results in higher tool-calling utility in scenarios with varying risk levels. Our code is open source, available at https://github.com/microsoft/mice_for_cats.", "bibtex": "@inproceedings{subramani-etal-2025-mice,\n    title = \"{MICE} for {CAT}s: Model-Internal Confidence Estimation for Calibrating Agents with Tools\",\n    author = \"Subramani, Nishant  and\n      Eisner, Jason  and\n      Svegliato, Justin  and\n      Van Durme, Benjamin  and\n      Su, Yu  and\n      Thomson, Sam\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.615/\",\n    doi = \"10.18653/v1/2025.naacl-long.615\",\n    pages = \"12362--12375\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long MICE for CATs_ Model-Internal Confidence Estimation for Calibrating Agents with Tools.pdf", "retrieved_at": "2025-11-12T03:19:27.703925Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AgentReview: Exploring Peer Review Dynamics with LLM Agents", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Yiqiao Jin", "Qinlin Zhao", "Yiyang Wang", "Hao Chen (陈昊)", "Kaijie Zhu", "Yijia Xiao", "Jindong Wang"], "affinity_score": 0.6775, "link": "https://aclanthology.org/2024.emnlp-main.70/", "abstract": "Peer review is fundamental to the integrity and advancement of scientific publication. Traditional methods of peer review analyses often rely on exploration and statistics of existing peer review data, which do not adequately address the multivariate nature of the process, account for the latent variables, and are further constrained by privacy concerns due to the sensitive nature of the data. We introduce AgentReview, the first large language model (LLM) based peer review simulation framework, which effectively disentangles the impacts of multiple latent factors and addresses the privacy issue. Our study reveals significant insights, including a notable 37.1% variation in paper decisions due to reviewers’ biases, supported by sociological theories such as the social influence theory, altruism fatigue, and authority bias. We believe that this study could offer valuable insights to improve the design of peer review mechanisms.", "bibtex": "@inproceedings{jin-etal-2024-agentreview,\n    title = \"{A}gent{R}eview: Exploring Peer Review Dynamics with {LLM} Agents\",\n    author = \"Jin, Yiqiao  and\n      Zhao, Qinlin  and\n      Wang, Yiyang  and\n      Chen, Hao  and\n      Zhu, Kaijie  and\n      Xiao, Yijia  and\n      Wang, Jindong\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.70/\",\n    doi = \"10.18653/v1/2024.emnlp-main.70\",\n    pages = \"1208--1226\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main AgentReview_ Exploring Peer Review Dynamics with LLM Agents.pdf", "retrieved_at": "2025-11-12T03:19:28.011398Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Metagent-P: A Neuro-Symbolic Planning Agent with Metacognition for Open Worlds", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Yanfang Zhou", "Yuntao Liu", "Xiaodong Li", "Yongqiang Zhao", "Xintong Wang", "Jinlong Tian", "Zhenyu Li", "Xinhai Xu"], "affinity_score": 0.6769, "link": "https://aclanthology.org/2025.findings-acl.1169/", "abstract": "The challenge of developing agents capable of open-world planning remains fundamental to artificial general intelligence (AGI). While large language models (LLMs) have made progress with their vast world knowledge, their limitations in perception, memory, and reliable reasoning still hinder LLM-based agents from achieving human-level performance in long-term tasks. Drawing inspiration from human cognitive-metacognitive collaboration, we propose Metagent-P , integrating the world knowledge of LLMs, the symbolic reasoning capabilities of cognitive architectures, and the self-reflection characteristic of metacognition to construct a “planning-verification-execution-reflection” framework. Metagent-P improves experience utilization through multimodal memory integration. It uses a neural-symbolic hierarchical representation structure to ensure the plan’s reasoning correctness in advance. Finally, it actively adapts the agent to dynamic environments through monitoring, evaluation, and regulation mechanisms. Experimental results show Metagent-P significantly outperforms current state-of-the-art methods in Minecraft. In long-term tasks, Metagent-P reduces the average replanning counts by 34% and exceeds the average human success rate by 18.96% . Additionally, Metagent-P also demonstrates self-evolution through step-by-step open-world exploration.", "bibtex": "@inproceedings{yanfangzhou-etal-2025-metagent,\n    title = \"Metagent-{P}: A Neuro-Symbolic Planning Agent with Metacognition for Open Worlds\",\n    author = \"Zhou, Yanfang  and\n      Liu, Yuntao  and\n      Li, Xiaodong  and\n      Zhao, Yongqiang  and\n      Wang, Xintong  and\n      Tian, Jinlong  and\n      Li, Zhenyu  and\n      Xu, Xinhai\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1169/\",\n    doi = \"10.18653/v1/2025.findings-acl.1169\",\n    pages = \"22747--22764\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings Metagent-P_ A Neuro-Symbolic Planning Agent with Metacognition for Open Worlds.pdf", "retrieved_at": "2025-11-12T03:19:28.283849Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with 100+ NLP Researchers", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Chenglei Si", "Diyi Yang", "Tatsunori Hashimoto"], "affinity_score": 0.6765, "link": "https://openreview.net/pdf/ba931cac8ba9b4d58275b6fc0d74bc21f4ffc882.pdf", "abstract": "Recent advancements in large language models (LLMs) have sparked optimism about their potential to accelerate scientific discovery, with a growing number of works proposing research agents that autonomously generate and validate new ideas. Despite this, no evaluations have shown that LLM systems can take the very first step of producing novel, expert-level ideas, let alone perform the entire research process. We address this by establishing an experimental design that evaluates research idea generation while controlling for confounders and performs the first comparison between expert NLP researchers and an LLM ideation agent. By recruiting over 100 NLP researchers to write novel ideas and blind reviews of both LLM and human ideas, we obtain the first statistically significant conclusion on current LLM capabilities for research ideation: we find LLM-generated ideas are judged as more novel (p < 0.05) than human expert ideas while being judged slightly weaker on feasibility. Studying our agent baselines closely, we identify open problems in building and evaluating research agents, including failures of LLM self-evaluation and their lack of diversity in generation.", "bibtex": "@inproceedings{\nsi2025can,\ntitle={Can {LLM}s Generate Novel Research Ideas? A Large-Scale Human Study with 100+ {NLP} Researchers},\nauthor={Chenglei Si and Diyi Yang and Tatsunori Hashimoto},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=M23dTGWCZy}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Can LLMs Generate Novel Research Ideas_ A Large-Scale Human Study with 100+ NLP Researchers.pdf", "retrieved_at": "2025-11-12T03:19:28.842317Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Saman Kazemkhani", "Aarav Pandya", "Daphne Cornelisse", "Brennan Shacklett", "Eugene Vinitsky"], "affinity_score": 0.6762, "link": "https://openreview.net/pdf/58416eb8dcfad96ca7cb5ada85252ab5f1d42c94.pdf", "abstract": "Multi-agent learning algorithms have been successful at generating superhuman planning in various games but have had limited impact on the design of deployed multi-agent planners. A key bottleneck in applying these techniques to multi-agent planning is that they require billions of steps of experience. To enable the study of multi-agent planning at scale, we present GPUDrive, a GPU-accelerated, multi-agent simulator built on top of the Madrona Game Engine capable of generating over a million simulation steps per second. Observation, reward, and dynamics functions are written directly in C++, allowing users to define complex, heterogeneous agent behaviors that are lowered to high-performance CUDA. Despite these low-level optimizations, GPUDrive is fully accessible through Python, offering a seamless and efficient workflow for multi-agent, closed-loop simulation. Using GPUDrive, we train reinforcement learning agents on the Waymo Open Motion Dataset, achieving efficient goal-reaching in minutes and scaling to thousands of scenarios in hours. We open-source the code and pre-trained agents at \\url{www.github.com/Emerge-Lab/gpudrive}.", "bibtex": "@inproceedings{\nkazemkhani2025gpudrive,\ntitle={{GPUD}rive: Data-driven, multi-agent driving simulation at 1 million {FPS}},\nauthor={Saman Kazemkhani and Aarav Pandya and Daphne Cornelisse and Brennan Shacklett and Eugene Vinitsky},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=ERv8ptegFi}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster GPUDrive_ Data-driven, multi-agent driving simulation at 1 million FPS.pdf", "retrieved_at": "2025-11-12T03:19:30.541584Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Tianyi Men", "Pengfei Cao", "Zhuoran Jin", "Yubo Chen (陈玉博)", "Kang Liu (刘康)", "Jun Zhao (军 赵)"], "affinity_score": 0.676, "link": "https://aclanthology.org/2025.acl-long.859/", "abstract": "With the development of large language models, they are widely used as agents in various fields. A key component of agents is memory, which stores vital information but is susceptible to jailbreak attacks. Existing research mainly focuses on single-agent attacks and shared memory attacks. However, real-world scenarios often involve independent memory. In this paper, we propose the Troublemaker Makes Chaos in Honest Town (TMCHT) task, a large-scale, multi-agent, multi-topology text-based attack evaluation framework. TMCHT involves one attacker agent attempting to mislead an entire society of agents. We identify two major challenges in multi-agent attacks: (1) Non-complete graph structure, (2) Large-scale systems. We attribute these challenges to a phenomenon we term toxicity disappearing. To address these issues, we propose an Adversarial Replication Contagious Jailbreak (ARCJ) method, which optimizes the retrieval suffix to make poisoned samples more easily retrieved and optimizes the replication suffix to make poisoned samples have contagious ability. We demonstrate the superiority of our approach in TMCHT, with 23.51%, 18.95%, and 52.93% improvements in line, star topologies, and 100-agent settings. It reveals potential contagion risks in widely used multi-agent architectures.", "bibtex": "@inproceedings{men-etal-2025-troublemaker,\n    title = \"A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns\",\n    author = \"Men, Tianyi  and\n      Cao, Pengfei  and\n      Jin, Zhuoran  and\n      Chen, Yubo  and\n      Liu, Kang  and\n      Zhao, Jun\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.859/\",\n    doi = \"10.18653/v1/2025.acl-long.859\",\n    pages = \"17561--17587\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns.pdf", "retrieved_at": "2025-11-12T03:19:30.796703Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Gravity-Bench-v1: A Benchmark on Gravitational Physics Discovery for Agents", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Nolan Koblischke", "Hyunseok Jang", "Kristen Menou", "Mohamad Ali-Dib"], "affinity_score": 0.6753, "link": "https://openreview.net/pdf/38e0e698321ef1012408b4d8e50ab1bd0274b784.pdf", "abstract": "Modern science emerged from reasoning over repeatedly-observed planetary motions. We present Gravity-Bench-v1, an environment-based benchmark that challenges AI agents on tasks that parallel this historical development. Gravity-Bench-v1 evaluates agents on the discovery of physics concealed within a dynamic environment, using rigorous gravitational dynamics simulations. Gravity-Bench includes out-of-distribution cases, i.e. with physics that deviates from the real world, to evaluate true scientific generalization capabilities. Agents must plan to collect data within an experimental budget and must perform a dynamic form of data analysis and reasoning to solve tasks efficiently. Our benchmark admits an open-ended space of solutions. Reference solutions for each task are provided to calibrate AI performance against human expertise. Technically at an upper-undergraduate level, our benchmark proves challenging to baseline AI agents. Gravity-Bench-v1 and planned extensions should help map out AI progress towards scientific discovery capabilities.", "bibtex": "@inproceedings{\nkoblischke2025gravitybenchv,\ntitle={Gravity-Bench-v1: A Benchmark on Gravitational Physics Discovery for Agents},\nauthor={Nolan Koblischke and Hyunseok Jang and Kristen Menou and Mohamad Ali-Dib},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=Vw4f8M67jE}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Gravity-Bench-v1_ A Benchmark on Gravitational Physics Discovery for Agents.pdf", "retrieved_at": "2025-11-12T03:19:31.501585Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Ponder & Press: Advancing Visual GUI Agent towards General Computer Control", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Yiqin Wang", "Haoji Zhang", "Jingqi Tian", "Yansong Tang"], "affinity_score": 0.6749, "link": "https://aclanthology.org/2025.findings-acl.76/", "abstract": "Most existing GUI agents typically depend on non-vision inputs like HTML source code or accessibility trees, limiting flexibility across diverse software environments and platforms. Current multimodal large language models (MLLMs), though excel at using vision to ground real-world objects, often struggle with accurately localizing GUI elements – a critical requirement for effective GUI automation – due to the semantic gap between real-world objects and GUI elements. In this work, we introduce Ponder & Press, a divide-and-conquer framework for general computer control that uses only visual input. Our approach combines a general-purpose MLLM as an ‘interpreter’, responsible for translating high-level user instructions into detailed action descriptions, with a GUI-specific MLLM as a ‘locator’ that precisely locates GUI elements for action placement. By leveraging a purely visual input, our agent offers a versatile, human-like interaction paradigm applicable to various applications. Ponder & Press locator outperforms existing models by +22.5% on the ScreenSpot GUI grounding benchmark. More offline and interactive agent benchmarks across various GUI environments – including web pages, desktop software, and mobile UIs – demonstrate that the Ponder & Press framework achieves state-of-the-art performance, highlighting the potential of visual GUI agents.", "bibtex": "@inproceedings{wang-etal-2025-ponder,\n    title = \"Ponder {\\&} Press: Advancing Visual {GUI} Agent towards General Computer Control\",\n    author = \"Wang, Yiqin  and\n      Zhang, Haoji  and\n      Tian, Jingqi  and\n      Tang, Yansong\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.76/\",\n    doi = \"10.18653/v1/2025.findings-acl.76\",\n    pages = \"1461--1473\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings Ponder & Press_ Advancing Visual GUI Agent towards General Computer Control.pdf", "retrieved_at": "2025-11-12T03:19:31.953189Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Yuzhe YANG", "Yifei Zhang", "Minghao Wu", "Kaidi Zhang", "Yunmiao Zhang", "Honghai Yu", "Yan Hu", "Benyou Wang"], "affinity_score": 0.674, "link": "https://openreview.net/pdf/cefb01d52e462ade9c6e1daafffb65ed49bcaa23.pdf", "abstract": "The study of social emergence has long been a central focus in social science. Traditional modeling approaches, such as rule-based Agent-Based Models (ABMs), struggle to capture the diversity and complexity of human behavior, particularly the irrational factors emphasized in behavioral economics. Recently, large language model (LLM) agents have gained traction as simulation tools for modeling human behavior in social science and role-playing applications. Studies suggest that LLMs can account for cognitive biases, emotional fluctuations, and other non-rational influences, enabling more realistic simulations of socio-economic dynamics. In this work, we introduce TwinMarket, a novel multi-agent framework that leverages LLMs to simulate socio-economic systems. Specifically, we examine how individual behaviors, through interactions and feedback mechanisms, give rise to collective dynamics and emergent phenomena. Through experiments in a simulated stock market environment, we demonstrate how individual actions can trigger group behaviors, leading to emergent outcomes such as financial bubbles and recessions. Our approach provides valuable insights into the complex interplay between individual decision-making and collective socio-economic patterns.", "bibtex": "@inproceedings{\nyang2025twinmarket,\ntitle={TwinMarket: A Scalable Behavioral and Social Simulation for Financial Markets},\nauthor={Yuzhe YANG and Yifei Zhang and Minghao Wu and Kaidi Zhang and Yunmiao Zhang and Honghai Yu and Yan Hu and Benyou Wang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=h60y6zlPyl}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster TwinMarket_ A Scalable Behavioral and Social Simulation for Financial Markets.pdf", "retrieved_at": "2025-11-12T03:19:32.784430Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Zhening Li", "Armando Solar-Lezama", "Yisong Yue", "Stephan Zheng"], "affinity_score": 0.6737, "link": "https://openreview.net/pdf/ec254672c2c5013801b6522a08e51c829a7ef814.pdf", "abstract": "We introduce a new approach to\nagent programming\n, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce\nprobabilistic angelic nondeterminism\n(PAN), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.", "bibtex": "@inproceedings{\nli2025encompass,\ntitle={EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths},\nauthor={Zhening Li and Armando Solar-Lezama and Yisong Yue and Stephan Zheng},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=IKVkpjSJzJ}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster EnCompass_ Enhancing Agent Programming with Search Over Program Execution Paths.pdf", "retrieved_at": "2025-11-12T03:19:33.310056Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Trajectory-Class-Aware Multi-Agent Reinforcement Learning", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Hyungho Na", "Kwanghyeon Lee", "Sumin Lee", "Il-chul Moon"], "affinity_score": 0.6729, "link": "https://openreview.net/pdf/a543548c257abbf6aa9bb9400fe32d07129a2557.pdf", "abstract": "In the context of multi-agent reinforcement learning,\ngeneralization\nis a challenge to solve various tasks that may require different joint policies or coordination without relying on policies specialized for each task. We refer to this type of problem as a\nmulti-task\n, and we train agents to be versatile in this multi-task setting through a single training process. To address this challenge, we introduce TRajectory-class-Aware Multi-Agent reinforcement learning (TRAMA). In TRAMA, agents recognize a task type by identifying the class of trajectories they are experiencing through partial observations, and the agents use this trajectory awareness or prediction as additional information for action policy. To this end, we introduce three primary objectives in TRAMA: (a) constructing a quantized latent space to generate trajectory embeddings that reflect key similarities among them; (b) conducting trajectory clustering using these trajectory embeddings; and (c) building a trajectory-class-aware policy. Specifically for (c), we introduce a trajectory-class predictor that performs agent-wise predictions on the trajectory class; and we design a trajectory-class representation model for each trajectory class. Each agent takes actions based on this trajectory-class representation along with its partial observation for task-aware execution. The proposed method is evaluated on various tasks, including multi-task problems built upon StarCraft II. Empirical results show further performance improvements over state-of-the-art baselines.", "bibtex": "@inproceedings{\nna2025trajectoryclassaware,\ntitle={Trajectory-Class-Aware Multi-Agent Reinforcement Learning},\nauthor={Hyungho Na and Kwanghyeon Lee and Sumin Lee and Il-chul Moon},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=uqe5HkjbT9}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Trajectory-Class-Aware Multi-Agent Reinforcement Learning.pdf", "retrieved_at": "2025-11-12T03:19:34.654399Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Large Language Model-based Human-Agent Collaboration for Complex Task Solving", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Xueyang Feng", "Zhi-Yuan Chen", "Yujia Qin", "Yankai Lin (林衍凯)", "Xu Chen (陈旭)", "Zhiyuan Liu", "Ji-Rong Wen"], "affinity_score": 0.672, "link": "https://aclanthology.org/2024.findings-emnlp.72/", "abstract": "In recent developments within the research community, the integration of Large Language Models (LLMs) in creating fully autonomous agents has garnered significant interest. Despite this, LLM-based agents frequently demonstrate notable shortcomings in adjusting to dynamic environments and fully grasping human needs. In this work, we introduce the problem of LLM-based human-agent collaboration for complex task-solving, exploring their synergistic potential. To tackle the problem, we propose a Reinforcement Learning-based Human-Agent Collaboration method, ReHAC, which trains a policy model designed to determine the most opportune stages for human intervention within the task-solving process. We conduct experiments under real and simulated human-agent collaboration scenarios. Experimental results demonstrate that the synergistic efforts of humans and LLM-based agents significantly improve performance in complex tasks, primarily through well-planned, limited human intervention. Datasets and code are available at: https://github.com/XueyangFeng/ReHAC/.", "bibtex": "@inproceedings{feng-etal-2024-large,\n    title = \"Large Language Model-based Human-Agent Collaboration for Complex Task Solving\",\n    author = \"Feng, Xueyang  and\n      Chen, Zhi-Yuan  and\n      Qin, Yujia  and\n      Lin, Yankai  and\n      Chen, Xu  and\n      Liu, Zhiyuan  and\n      Wen, Ji-Rong\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.72/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.72\",\n    pages = \"1336--1357\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings Large Language Model-based Human-Agent Collaboration for Complex Task Solving.pdf", "retrieved_at": "2025-11-12T03:19:34.919434Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "GAM-Agent: Game-Theoretic and Uncertainty-Aware Collaboration for Complex Visual Reasoning", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Jusheng Zhang", "Yijia Fan", "Wenjun Lin", "Ruiqi Chen", "Haoyi Jiang", "Wenhao Chai", "Jian Wang", "Keze Wang"], "affinity_score": 0.6717, "link": "https://openreview.net/pdf/55c4606303cc86c81ca99b5d5743cfe40d7fb140.pdf", "abstract": "We propose\nGAM-Agent\n, a game-theoretic multi-agent framework for enhancing vision-language reasoning. Unlike prior single-agent or monolithic models, GAM-Agent formulates the reasoning process as a non-zero-sum game between base agents—each specializing in visual perception subtasks—and a critical agent that verifies logic consistency and factual correctness. Agents communicate via structured claims, evidence, and uncertainty estimates. The framework introduces an uncertainty-aware controller to dynamically adjust agent collaboration, triggering multi-round debates when disagreement or ambiguity is detected. This process yields more robust and interpretable predictions. Experiments on four challenging benchmarks—MMMU, MMBench, MVBench, and V*Bench—demonstrate that GAM-Agent significantly improves performance across various VLM backbones. Notably, GAM-Agent boosts the accuracy of small-to-mid scale models (e.g., Qwen2.5-VL-7B, InternVL3-14B) by 5–6\\%, and still enhances strong models like GPT-4o by up to 2–3\\%. Our approach is modular, scalable, and generalizable, offering a path toward reliable and explainable multi-agent multimodal reasoning.", "bibtex": "@inproceedings{\nzhang2025gamagent,\ntitle={{GAM}-Agent: Game-Theoretic and Uncertainty-Aware Collaboration for Complex Visual Reasoning},\nauthor={Jusheng Zhang and Yijia Fan and Wenjun Lin and Ruiqi Chen and Haoyi Jiang and Wenhao Chai and Jian Wang and Keze Wang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=EKJhU5ioSo}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster GAM-Agent_ Game-Theoretic and Uncertainty-Aware Collaboration for Complex Visual Reasoning.pdf", "retrieved_at": "2025-11-12T03:19:35.525147Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Multi-Agent Collaboration via Evolving Orchestration", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Yufan Dang", "Chen Qian", "Xueheng Luo", "Jingru Fan", "Zihao Xie", "Ruijie Shi", "Weize Chen", "Cheng Yang", "Xiaoyin Che", "Ye Tian", "Xuantang Xiong", "Lei Han", "Zhiyuan Liu", "Maosong Sun"], "affinity_score": 0.6713, "link": "https://openreview.net/pdf/9727f658d788c52f49f12ae4b230baf4cf0d4007.pdf", "abstract": "Large language models (LLMs) have achieved remarkable results across diverse downstream tasks, but their monolithic nature restricts scalability and efficiency in complex problem-solving. While recent research explores multi-agent collaboration among LLMs, most approaches rely on static organizational structures that struggle to adapt as task complexity and agent numbers grow, resulting in coordination overhead and inefficiencies. To this end, we propose a puppeteer-style paradigm for LLM-based multi-agent collaboration, where a centralized orchestrator (\"puppeteer\") dynamically directs agents (\"puppets\") in response to evolving task states. This orchestrator is trained via reinforcement learning to adaptively sequence and prioritize agents, enabling flexible and evolvable collective reasoning. Experiments on closed- and open-domain scenarios show that this method achieves superior performance with reduced computational costs. Analyses further reveal that the key improvements consistently stem from the emergence of more compact, cyclic reasoning structures under the orchestrator’s evolution. Our code is available at https://github.com/OpenBMB/ChatDev/tree/puppeteer.", "bibtex": "@inproceedings{\ndang2025multiagent,\ntitle={Multi-Agent Collaboration via Evolving Orchestration},\nauthor={Yufan Dang and Chen Qian and Xueheng Luo and Jingru Fan and Zihao Xie and Ruijie Shi and Weize Chen and Cheng Yang and Xiaoyin Che and Ye Tian and Xuantang Xiong and Lei Han and Zhiyuan Liu and Maosong Sun},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=L0xZPXT3le}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Multi-Agent Collaboration via Evolving Orchestration.pdf", "retrieved_at": "2025-11-12T03:19:36.375788Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Patara Trirat", "Wonyong Jeong", "Sung Ju Hwang"], "affinity_score": 0.6712, "link": "https://openreview.net/pdf/e11df054e7e2b676ce0272b6b5318b01b7327210.pdf", "abstract": "Automated machine learning (AutoML) accelerates AI development by automating tasks in the development pipeline, such as optimal model search and hyperparameter tuning. Existing AutoML systems often require technical expertise to set up complex tools, which is in general time-consuming and requires a large amount of human effort. Therefore, recent works have started exploiting large language models (LLM) to lessen such burden and increase the usability of AutoML frameworks via a natural language interface, allowing non-expert users to build their data-driven solutions. These methods, however, are usually designed only for a particular process in the AI development pipeline and do not efficiently use the inherent capacity of the LLMs. This paper proposes\nAutoML-Agent\n, a novel multi-agent framework tailored for full-pipeline AutoML, i.e., from data retrieval to model deployment.\nAutoML-Agent\ntakes user's task descriptions, facilitates collaboration between specialized LLM agents, and delivers deployment-ready models. Unlike existing work, instead of devising a single plan, we introduce a retrieval-augmented planning strategy to enhance exploration to search for more optimal plans. We also decompose each plan into sub-tasks (e.g., data preprocessing and neural network design) each of which is solved by a specialized agent we build via prompting executing in parallel, making the search process more efficient. Moreover, we propose a multi-stage verification to verify executed results and guide the code generation LLM in implementing successful solutions. Extensive experiments on seven downstream tasks using fourteen datasets show that\nAutoML-Agent\nachieves a higher success rate in automating the full AutoML process, yielding systems with good performance throughout the diverse domains.", "bibtex": "@inproceedings{\ntrirat2025automlagent,\ntitle={Auto{ML}-Agent: A Multi-Agent {LLM} Framework for Full-Pipeline Auto{ML}},\nauthor={Patara Trirat and Wonyong Jeong and Sung Ju Hwang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=p1UBWkOvZm}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster AutoML-Agent_ A Multi-Agent LLM Framework for Full-Pipeline AutoML.pdf", "retrieved_at": "2025-11-12T03:19:38.270403Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ACC-Collab: An Actor-Critic Approach to Multi-Agent LLM Collaboration", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Andrew Estornell", "Jean-Francois Ton", "Yuanshun Yao", "Yang Liu"], "affinity_score": 0.6707, "link": "https://openreview.net/pdf/8a3b2842348cfd4559cafe483c35e5cc89ca6da8.pdf", "abstract": "Large language models (LLMs) have demonstrated a remarkable ability to serve as general-purpose tools for various language-based tasks. \n  Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models.\n  While these \n  paradigms show promise \n  in\n  improving model efficacy, most works in this area treat collaboration as an emergent behavior, rather than a learned behavior. \n  In doing so, current multi-agent frameworks rely on collaborative behaviors to have been sufficiently trained into off-the-shelf models. \n  To address this limitation, we propose ACC-Collab, an\nA\nctor-\nC\nriti\nc\nbased learning framework to produce a two-agent team (an actor-agent and a critic-agent) specialized in collaboration.\n  We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.", "bibtex": "@inproceedings{\nestornell2025acccollab,\ntitle={{ACC}-Collab: An Actor-Critic Approach to Multi-Agent {LLM} Collaboration},\nauthor={Andrew Estornell and Jean-Francois Ton and Yuanshun Yao and Yang Liu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=nfKfAzkiez}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster ACC-Collab_ An Actor-Critic Approach to Multi-Agent LLM Collaboration.pdf", "retrieved_at": "2025-11-12T03:19:39.889495Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Human Simulacra: Benchmarking the Personification of Large Language Models", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Qiujie Xie", "Qiming Feng", "Tianqi Zhang", "Qingqiu Li", "Linyi Yang", "Yuejie Zhang", "Rui Feng", "Liang He", "Shang Gao", "Yue Zhang"], "affinity_score": 0.6706, "link": "https://openreview.net/pdf/3834694dcd9d87ff5219773c802877eeaddc1297.pdf", "abstract": "Large Language Models (LLMs) are recognized as systems that closely mimic aspects of human intelligence. This capability has attracted the attention of the social science community, who see the potential in leveraging LLMs to replace human participants in experiments, thereby reducing research costs and complexity. In this paper, we introduce a benchmark for LLMs personification, including a strategy for constructing virtual characters' life stories from the ground up, a Multi-Agent Cognitive Mechanism capable of simulating human cognitive processes, and a psychology-guided evaluation method to assess human simulations from both self and observational perspectives. Experimental results demonstrate that our constructed simulacra can produce personified responses that align with their target characters.  We hope this work will serve as a benchmark in the field of human simulation, paving the way for future research.", "bibtex": "@inproceedings{\nxie2025human,\ntitle={Human Simulacra: Benchmarking the Personification of Large Language Models},\nauthor={Qiujie Xie and Qiming Feng and Tianqi Zhang and Qingqiu Li and Linyi Yang and Yuejie Zhang and Rui Feng and Liang He and Shang Gao and Yue Zhang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=BCP5nAHXqs}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Human Simulacra_ Benchmarking the Personification of Large Language Models.pdf", "retrieved_at": "2025-11-12T03:19:40.840688Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ToolACE: Winning the Points of LLM Function Calling", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Weiwen Liu", "Xu Huang", "Xingshan Zeng", "xinlong hao", "Shuai Yu", "Dexun Li", "Shuai Wang", "Weinan Gan", "Zhengying Liu", "Yuanqing Yu", "Zezhong WANG", "Yuxian Wang", "Wu Ning", "Yutai Hou", "Bin Wang", "Chuhan Wu", "Wang Xinzhi", "Yong Liu", "Yasheng Wang", "Duyu Tang", "Dandan Tu", "Lifeng Shang", "Xin Jiang", "Ruiming Tang", "Defu Lian", "Qun Liu", "Enhong Chen"], "affinity_score": 0.6697, "link": "https://openreview.net/pdf/9c7c53cc6199348d235063c044442216d84429c4.pdf", "abstract": "Function calling significantly extends the application boundary of large language models (LLMs), where high-quality and diverse training data is critical for unlocking this capability. However, collecting and annotating real function-calling data is challenging, while synthetic data from existing pipelines often lack coverage and accuracy. In this paper, we present ToolACE, an automatic agentic pipeline designed to generate accurate, complex, and diverse tool-learning data, specifically tailored to the capabilities of LLMs. ToolACE leverages a novel self-evolution synthesis process to curate a comprehensive API pool of 26,507 diverse APIs. Dialogs are further generated through the interplay among multiple agents, under the guidance of a complexity evaluator. To ensure data accuracy, we implement a dual-layer verification system combining rule-based and model-based checks. We demonstrate that models trained on our synthesized data---even with only 8B parameters---achieve state-of-the-art performance, comparable to the latest GPT-4 models. Our model and a subset of the data are publicly available at https://huggingface.co/Team-ACE.", "bibtex": "@inproceedings{\nliu2025toolace,\ntitle={Tool{ACE}: Winning the Points of {LLM} Function Calling},\nauthor={Weiwen Liu and Xu Huang and Xingshan Zeng and xinlong hao and Shuai Yu and Dexun Li and Shuai Wang and Weinan Gan and Zhengying Liu and Yuanqing Yu and Zezhong WANG and Yuxian Wang and Wu Ning and Yutai Hou and Bin Wang and Chuhan Wu and Wang Xinzhi and Yong Liu and Yasheng Wang and Duyu Tang and Dandan Tu and Lifeng Shang and Xin Jiang and Ruiming Tang and Defu Lian and Qun Liu and Enhong Chen},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=8EB8k6DdCU}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster ToolACE_ Winning the Points of LLM Function Calling.pdf", "retrieved_at": "2025-11-12T03:19:41.610484Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Generalizing Experience for Language Agents with Hierarchical MetaFlows", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Shengda Fan", "Xin Cong", "Zhong Zhang", "Yuepeng Fu", "Yesai Wu", "Hao Wang", "Xinyu Zhang", "Enrui Hu", "Yankai Lin"], "affinity_score": 0.6695, "link": "https://openreview.net/pdf/e5e7cd3c074c77adae516f8d392136a8fe8657f5.pdf", "abstract": "Recent efforts to employ large language models (LLMs) as agents have demonstrated promising results in a wide range of multi-step agent tasks. However, existing agents lack an effective experience reuse approach to leverage historical completed tasks. In this paper, we propose a novel experience reuse framework MetaFlowLLM, which constructs a hierarchical experience tree from historically completed tasks. Each node in this experience tree is presented as a MetaFlow which contains static execution workflow and subtask required by agents to complete dynamically. Then, we propose a Hierarchical MetaFlow Merging algorithm to construct the hierarchical experience tree. When accomplishing a new task, MetaFlowLLM can first retrieve the most relevant MetaFlow node from the experience tree and then execute it accordingly. To effectively generate valid MetaFlows from historical data, we further propose a reinforcement learning pipeline to train the MetaFlowGen. Extensive experimental results on AppWorld and WorkBench demonstrate that integrating with MetaFlowLLM, existing agents (e.g., ReAct, Reflexion) can gain substantial performance improvement with reducing execution costs. Notably, MetaFlowLLM achieves an average success rate improvement of 32.3% on AppWorld and 6.2% on WorkBench, respectively.", "bibtex": "@inproceedings{\nfan2025generalizing,\ntitle={Generalizing Experience for Language Agents with Hierarchical MetaFlows},\nauthor={Shengda Fan and Xin Cong and Zhong Zhang and Yuepeng Fu and Yesai Wu and Hao Wang and Xinyu Zhang and Enrui Hu and Yankai Lin},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=QsQGMijLhL}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Generalizing Experience for Language Agents with Hierarchical MetaFlows.pdf", "retrieved_at": "2025-11-12T03:19:42.355477Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Towards Rationality in Language and Multimodal Agents: A Survey", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Bowen Jiang", "Yangxinyu Xie", "Xiaomeng Wang", "Yuan Yuan", "Zhuoqun Hao", "Xinyi Bai", "Weijie J Su", "Camillo Jose Taylor", "Tanwi Mallick"], "affinity_score": 0.6692, "link": "https://aclanthology.org/2025.naacl-long.186/", "abstract": "This work discusses how to build more rational language and multimodal agents and what criteria define rationality in intelligent systems.Rationality is the quality of being guided by reason, characterized by decision-making that aligns with evidence and logical principles. It plays a crucial role in reliable problem-solving by ensuring well-grounded and consistent solutions. Despite their progress, large language models (LLMs) often fall short of rationality due to their bounded knowledge space and inconsistent outputs. In response, recent efforts have shifted toward developing multimodal and multi-agent systems, as well as integrating modules like external tools, programming codes, symbolic reasoners, utility function, and conformal risk controls rather than relying solely on a single LLM for decision-making. This paper surveys state-of-the-art advancements in language and multimodal agents, assesses their role in enhancing rationality, and outlines open challenges and future research directions. We maintain an open repository at https://github.com/bowen-upenn/Agent_Rationality.", "bibtex": "@inproceedings{jiang-etal-2025-towards,\n    title = \"Towards Rationality in Language and Multimodal Agents: A Survey\",\n    author = \"Jiang, Bowen  and\n      Xie, Yangxinyu  and\n      Wang, Xiaomeng  and\n      Yuan, Yuan  and\n      Hao, Zhuoqun  and\n      Bai, Xinyi  and\n      Su, Weijie J  and\n      Taylor, Camillo Jose  and\n      Mallick, Tanwi\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.186/\",\n    doi = \"10.18653/v1/2025.naacl-long.186\",\n    pages = \"3656--3675\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long Towards Rationality in Language and Multimodal Agents_ A Survey.pdf", "retrieved_at": "2025-11-12T03:19:42.620488Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Toward Efficient Multi-Agent Exploration With Trajectory Entropy Maximization", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Tianxu Li", "Kun Zhu"], "affinity_score": 0.6692, "link": "https://openreview.net/pdf/dd89f301bd928d0b44b44bf9d4d9a194fe80f1e4.pdf", "abstract": "Recent works have increasingly focused on learning decentralized policies for agents as a solution to the scalability challenges in Multi-Agent Reinforcement Learning (MARL), where agents typically share the parameters of a policy network to make action decisions. However, this parameter sharing can impede efficient exploration, as it may lead to similar behaviors among agents. Different from previous mutual information-based methods that promote multi-agent diversity, we introduce a novel multi-agent exploration method called Trajectory Entropy Exploration (TEE). Our method employs a particle-based entropy estimator to maximize the entropy of different agents' trajectories in a contrastive trajectory representation space, resulting in diverse trajectories and efficient exploration. This entropy estimator avoids challenging density modeling and scales effectively in high-dimensional multi-agent settings. We integrate our method with MARL algorithms by deploying an intrinsic reward for each agent to encourage entropy maximization. To validate the effectiveness of our method, we test our method in challenging multi-agent tasks from several MARL benchmarks. The results demonstrate that our method consistently outperforms existing state-of-the-art methods.", "bibtex": "@inproceedings{\nli2025toward,\ntitle={Toward Efficient Multi-Agent Exploration With Trajectory Entropy Maximization},\nauthor={Tianxu Li and Kun Zhu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=YvKJGYL4j7}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Toward Efficient Multi-Agent Exploration With Trajectory Entropy Maximization.pdf", "retrieved_at": "2025-11-12T03:19:43.976904Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MegaAgent: A Large-Scale Autonomous LLM-based Multi-Agent System Without Predefined SOPs", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Qian Wang", "Tianyu Wang", "Zhenheng Tang", "Qinbin Li", "Nuo Chen", "Jingsheng Liang", "Bingsheng He"], "affinity_score": 0.6692, "link": "https://aclanthology.org/2025.findings-acl.259/", "abstract": "LLM-based multi-agent systems (MAS) have shown promise in tackling complex tasks. However, existing solutions often suffer from limited agent coordination and heavy reliance on predefined Standard Operating Procedures (SOPs), which demand extensive human input. To address these limitations, we propose MegaAgent , a large-scale autonomous LLM-based multi-agent system. MegaAgent generates agents based on task complexity and enables dynamic task decomposition, parallel execution, efficient communication, and comprehensive system monitoring of agents. In evaluations, MegaAgent demonstrates exceptional performance, successfully developing a Gobang game within 800 seconds and scaling up to 590 agents in a national policy simulation to generate multi-domain policies. It significantly outperforms existing systems, such as MetaGPT, in both task completion efficiency and scalability. By eliminating the need for predefined SOPs, MegaAgent demonstrates exceptional scalability and autonomy, setting a foundation for advancing true autonomy in MAS.", "bibtex": "@inproceedings{wang-etal-2025-megaagent,\n    title = \"{M}ega{A}gent: A Large-Scale Autonomous {LLM}-based Multi-Agent System Without Predefined {SOP}s\",\n    author = \"Wang, Qian  and\n      Wang, Tianyu  and\n      Tang, Zhenheng  and\n      Li, Qinbin  and\n      Chen, Nuo  and\n      Liang, Jingsheng  and\n      He, Bingsheng\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.259/\",\n    doi = \"10.18653/v1/2025.findings-acl.259\",\n    pages = \"4998--5036\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings MegaAgent_ A Large-Scale Autonomous LLM-based Multi-Agent System Without Predefined SOPs.pdf", "retrieved_at": "2025-11-12T03:19:44.214049Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Vighnesh Subramaniam", "Yilun Du", "Joshua B. Tenenbaum", "Antonio Torralba", "Shuang Li", "Igor Mordatch"], "affinity_score": 0.6686, "link": "https://openreview.net/pdf/2df12554b353f4c99981918b614fa32dd8d0239c.pdf", "abstract": "Large language models (LLMs) have achieved remarkable performance in recent years but are fundamentally limited by the underlying training data. To improve models beyond the training data, recent works have explored how LLMs can be used to generate synthetic data for autonomous self-improvement. However, successive steps of self-improvement can reach a point of diminishing returns. In this work, we propose a complementary approach towards self-improvement where finetuning is applied to a multiagent society of language models. A group of language models, all starting from the same base model, are independently specialized by updating each one using data generated through multiagent interactions among the models. By training each model on independent sets of data, we illustrate how this approach enables specialization across models and diversification over the set of models. As a result, our overall system is able to preserve diverse reasoning chains and autonomously improve over many more rounds of fine-tuning than single-agent self-improvement methods. We quantitatively illustrate the efficacy of the approach across a wide suite of reasoning tasks.", "bibtex": "@inproceedings{\nsubramaniam2025multiagent,\ntitle={Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains},\nauthor={Vighnesh Subramaniam and Yilun Du and Joshua B. Tenenbaum and Antonio Torralba and Shuang Li and Igor Mordatch},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=JtGPIZpOrz}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Multiagent Finetuning_ Self Improvement with Diverse Reasoning Chains.pdf", "retrieved_at": "2025-11-12T03:19:45.006738Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "SYMPHONY: Synergistic Multi-agent Planning with Heterogeneous Language Model Assembly", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Wei Zhu", "Zhiwen Tang", "Kun Yue"], "affinity_score": 0.6681, "link": "https://openreview.net/pdf/4334c20856e35aabcc60e8000970b5cedab83044.pdf", "abstract": "Recent advancements have increasingly focused on leveraging large language models (LLMs) to construct autonomous agents for complex problem-solving tasks. However, existing approaches predominantly employ a single-agent framework to generate search branches and estimate rewards during Monte Carlo Tree Search (MCTS) planning. This single-agent paradigm inherently limits exploration capabilities, often resulting in insufficient diversity among generated branches and suboptimal planning performance.\nTo overcome these limitations, we propose  $\\textbf{SY}$nergistic $\\textbf{M}$ulti-agent $\\textbf{P}$lanning with $\\textbf{H}$eter$\\textbf{O}$geneous la$\\textbf{N}$gauge model assembl$\\textbf{Y}$ ($\\textbf{SYMPHONY}$),  a novel multi-agent planning framework that integrates a pool of heterogeneous language model-based agents. \nBy leveraging diverse reasoning patterns across agents, SYMPHONY enhances rollout diversity and facilitates more effective exploration.\nEmpirical results across multiple benchmark tasks show that SYMPHONY achieves strong performance even when instantiated with open-source LLMs deployable on consumer-grade hardware. When enhanced with cloud-based LLMs accessible via API, SYMPHONY demonstrates further improvements, outperforming existing state-of-the-art baselines and underscoring the effectiveness of heterogeneous multi-agent coordination in planning tasks.", "bibtex": "@inproceedings{\nzhu2025symphony,\ntitle={{SYMPHONY}: Synergistic Multi-agent Planning with Heterogeneous Language Model Assembly},\nauthor={Wei Zhu and Zhiwen Tang and Kun Yue},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=7Spt8cAJq0}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster SYMPHONY_ Synergistic Multi-agent Planning with Heterogeneous Language Model Assembly.pdf", "retrieved_at": "2025-11-12T03:19:45.601824Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "SketchMind:  A Multi-Agent Cognitive Framework for Assessing Student-Drawn Scientific Sketches", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Ehsan Latif", "Zirak Khan", "Xiaoming Zhai"], "affinity_score": 0.668, "link": "https://openreview.net/pdf/1f29ebbf550ce3d0ac8e2654e8faf2819c05fa9b.pdf", "abstract": "Scientific sketches (e.g., models) offer a powerful lens into students' conceptual understanding, yet AI-powered automated assessment of such free-form, visually diverse artifacts remains a critical challenge. Existing solutions often treat sketch evaluation as either an image classification task or monolithic vision-language models, which lack interpretability, pedagogical alignment, and adaptability across cognitive levels. To address these limitations, we present SketchMind, a cognitively grounded, multi-agent framework for evaluating and improving student-drawn scientific sketches. SketchMind introduces Sketch Reasoning Graphs (SRGs), semantic graph representations that embed domain concepts and Bloom's taxonomy-based cognitive labels. The system comprises modular agents responsible for rubric parsing, sketch perception, cognitive alignment, and iterative feedback with sketch modification, enabling personalized and transparent evaluation. We evaluate SketchMind on a curated dataset of 3,575 student-generated sketches across six science assessment items with different highest order of Bloom's level that require students to draw models to explain phenomena. Compared to baseline GPT-4o performance without SRG (average accuracy: 55.6%), the model with SRG integration achieves 77.1% average accuracy (+21.4% average absolute gain). We also demonstrate that multi-agent orchestration with SRG enhances SketchMind performance, for example, SketchMind with GPT-4.1 gains an average 8.9% increase in sketch prediction accuracy, outperforming single-agent pipelines across all items. Human evaluators rated the feedback and co-created sketches generated by SketchMind with GPT-4.1, which achieved an average of 4.1 out of 5, significantly higher than those of baseline models (e.g., 2.3 for GPT-4o). Experts noted the system’s potential to meaningfully support conceptual growth through guided revision. Our code and (pending approval) dataset will be released to support reproducibility and future research in AI-driven education.", "bibtex": "@inproceedings{\nlatif2025sketchmind,\ntitle={SketchMind:  A Multi-Agent Cognitive Framework for Assessing Student-Drawn Scientific Sketches},\nauthor={Ehsan Latif and Zirak Khan and Xiaoming Zhai},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=qS3WgmGs9s}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster SketchMind_ A Multi-Agent Cognitive Framework for Assessing Student-Drawn Scientific Sketches.pdf", "retrieved_at": "2025-11-12T03:19:47.728582Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "BOOKWORLD: From Novels to Interactive Agent Societies for Story Creation", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Yiting Ran", "Xintao Wang", "Tian Qiu", "Jiaqing Liang", "Yanghua Xiao", "Deqing Yang"], "affinity_score": 0.668, "link": "https://aclanthology.org/2025.acl-long.773/", "abstract": "Recent advances in large language models (LLMs) have enabled social simulation through multi-agent systems. Prior efforts focus on agent societies created from scratch, assigning agents with newly defined personas. However, simulating established fictional worlds and characters remain largely underexplored, despite its significant practical value. In this paper, we introduce BookWorld, a comprehensive system for constructing and simulating book-based multi-agent societies. BookWorld’s design covers comprehensive real-world intricacies, including diverse and dynamic characters, fictional worldviews, geographical constraints and changes, e.t.c. BookWorld enables diverse applications including story generation, interactive games and social simulation, offering novel ways to extend and explore beloved fictional works. Through extensive experiments, we demonstrate that BookWorld generates creative, high-quality stories while maintaining fidelity to the source books, surpassing previous methods with a win rate of 75.36%. The code and demo of this paper can be found at the project page: https://bookworld2025.github.io/.", "bibtex": "@inproceedings{ran-etal-2025-bookworld,\n    title = \"{BOOKWORLD}: From Novels to Interactive Agent Societies for Story Creation\",\n    author = \"Ran, Yiting  and\n      Wang, Xintao  and\n      Qiu, Tian  and\n      Liang, Jiaqing  and\n      Xiao, Yanghua  and\n      Yang, Deqing\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.773/\",\n    doi = \"10.18653/v1/2025.acl-long.773\",\n    pages = \"15898--15912\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long BOOKWORLD_ From Novels to Interactive Agent Societies for Story Creation.pdf", "retrieved_at": "2025-11-12T03:19:48.067421Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MLLM as Retriever: Interactively Learning Multimodal Retrieval for Embodied Agents", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Junpeng Yue", "Xinrun Xu", "Börje F. Karlsson", "Zongqing Lu"], "affinity_score": 0.6679, "link": "https://openreview.net/pdf/1682dac5606689ac86e6ce0527a24c01f9f70f8d.pdf", "abstract": "MLLM agents demonstrate potential for complex embodied tasks by retrieving multimodal task-relevant trajectory data. However, current retrieval methods primarily focus on surface-level similarities of textual or visual cues in trajectories, neglecting their effectiveness for the specific task at hand. To address this issue, we propose a novel method, MART, which enhances the performance of embodied agents by utilizing interaction data to fine-tune an MLLM retriever based on preference learning, such that the retriever fully considers the effectiveness of trajectories and prioritize them for unseen tasks. We also introduce Trajectory Abstraction, a mechanism that leverages MLLMs' summarization capabilities to represent trajectories with fewer tokens while preserving key information, enabling agents to better comprehend milestones in the trajectory. Experimental results across various environments demonstrate our method significantly improves task success rates in unseen scenes compared to baseline methods. This work presents a new paradigm for multimodal retrieval in embodied agents, by fine-tuning a general-purpose MLLM as the retriever to assess trajectory effectiveness. All the code for benchmark tasks, simulator modifications and the MLLM retriever is available at https://github.com/PKU-RL/MART.", "bibtex": "@inproceedings{\nyue2025mllm,\ntitle={{MLLM} as Retriever: Interactively Learning Multimodal Retrieval for Embodied Agents},\nauthor={Junpeng Yue and Xinrun Xu and B{\\\"o}rje F. Karlsson and Zongqing Lu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=K5yeB4dTtS}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster MLLM as Retriever_ Interactively Learning Multimodal Retrieval for Embodied Agents.pdf", "retrieved_at": "2025-11-12T03:19:50.174466Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Lin Xu", "Zhiyuan Hu", "Daquan Zhou", "Hongyu Ren", "Zhen Dong", "Kurt Keutzer", "See Kiong Ng", "Jiashi Feng"], "affinity_score": 0.667, "link": "https://aclanthology.org/2024.emnlp-main.416/", "abstract": "Large Language Models (LLMs) have significantly advanced natural language processing, demonstrating exceptional reasoning, tool usage, and memory capabilities. As their applications expand into multi-agent environments, there arises a need for a comprehensive evaluation framework that captures LLMs’ reasoning, planning, collaboration, and other social abilities. This work introduces a novel competition-based benchmark framework specifically designed to assess LLMs within multi-agent settings, providing quantitative metrics to evaluate their judgment, reasoning, deception, self-awareness, cooperation, coordination, and rationality.We utilize two social deduction games alongside three game-theory scenarios to create diverse environments.Our frame is fortified with the probabilistic graphic modeling (PGM) method, enhancing the LLMs’ capabilities in navigating complex social and cognitive dimensions. We evaluate seven LLMs, quantitatively highlighting a significant capability gap of over threefold between the strongest, GPT o1, and the weakest, Llama-2-70B. It also confirms that our PGM enhancement boosts the abilities of all selected models by an average of 37%. Our data and code can be found here https://github.com/cathyxl/MAgIC.", "bibtex": "@inproceedings{xu-etal-2024-magic,\n    title = \"{MA}g{IC}: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration\",\n    author = \"Xu, Lin  and\n      Hu, Zhiyuan  and\n      Zhou, Daquan  and\n      Ren, Hongyu  and\n      Dong, Zhen  and\n      Keutzer, Kurt  and\n      Ng, See-Kiong  and\n      Feng, Jiashi\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.416/\",\n    doi = \"10.18653/v1/2024.emnlp-main.416\",\n    pages = \"7315--7332\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main MAgIC_ Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration.pdf", "retrieved_at": "2025-11-12T03:19:50.484457Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Rui Ye", "Shuo Tang", "Rui Ge", "Yaxin Du", "Zhenfei Yin", "Siheng Chen", "Jing Shao"], "affinity_score": 0.667, "link": "https://openreview.net/pdf/1f479b93fec4660d50da88780197574d2cb64155.pdf", "abstract": "LLM-based multi-agent systems (MAS) have shown significant potential in tackling diverse tasks.\nHowever, to design effective MAS, existing approaches heavily rely on manual configurations or multiple calls of advanced LLMs, resulting in inadaptability and high inference costs.\nIn this paper, we simplify the process of building an MAS by reframing it as a generative language task, where the input is a user query and the output is a corresponding MAS.\nTo address this novel task, we unify the representation of MAS as executable code and propose a consistency-oriented data construction pipeline to create a high-quality dataset comprising coherent and consistent query-MAS pairs.\nUsing this dataset, we train MAS-GPT, an open-source medium-sized LLM that is capable of generating query-adaptive MAS within a single LLM inference. The generated MAS can be seamlessly applied to process user queries and deliver high-quality responses. Extensive experiments on 9 benchmarks and 5 LLMs show that the proposed MAS-GPT consistently outperforms 10+ baseline MAS methods on diverse settings, indicating MAS-GPT's high effectiveness, efficiency and strong generalization ability.\nThe codes are released at \\url{https://github.com/rui-ye/MAS-GPT}.", "bibtex": "@inproceedings{\nye2025masgpt,\ntitle={{MAS}-{GPT}: Training {LLM}s to Build {LLM}-based Multi-Agent Systems},\nauthor={Rui Ye and Shuo Tang and Rui Ge and Yaxin Du and Zhenfei Yin and Siheng Chen and Jing Shao},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=3CiSpY3QdZ}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster MAS-GPT_ Training LLMs to Build LLM-based Multi-Agent Systems.pdf", "retrieved_at": "2025-11-12T03:19:51.656846Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "A Dual-Mind Framework for Strategic and Expressive Negotiation Agent", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Yutong Liu", "Lida Shi", "Rui Song (宋锐)", "Hao Xu"], "affinity_score": 0.6665, "link": "https://aclanthology.org/2025.acl-long.1161/", "abstract": "Negotiation agents need to influence the attitudes or intentions of users to reach a consensus. Strategy planning and expressive optimization are crucial aspects of effective negotiations. However, previous studies have typically focused on only one of these aspects, neglecting the fact that their combined synergistic effect can lead to better performance. Inspired by the dual-process theory in human cognition, we propose a Dual-Mind Negotiation Agent (DMNA) framework. This framework integrates an intuitive module for rapid, experience-based response and a deliberative module for slow, expression optimization. The intuitive module is trained using Monte Carlo Tree Search (MCTS) and Direct Preference Optimization (DPO), enabling it to make suitable strategic planning and expression. The deliberative module employs a multifaceted reflexion mechanism to enhance the quality of expression. Experiments conducted on negotiation datasets confirm that DMNA achieves state-of-the-art results, demonstrating an enhancement in the negotiation ability of agents.", "bibtex": "@inproceedings{liu-etal-2025-dual,\n    title = \"A Dual-Mind Framework for Strategic and Expressive Negotiation Agent\",\n    author = \"Liu, Yutong  and\n      Shi, Lida  and\n      Song, Rui  and\n      Xu, Hao\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1161/\",\n    doi = \"10.18653/v1/2025.acl-long.1161\",\n    pages = \"23840--23860\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long A Dual-Mind Framework for Strategic and Expressive Negotiation Agent.pdf", "retrieved_at": "2025-11-12T03:19:51.895035Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Adapting While Learning: Grounding LLMs for Scientific Problems with Tool Usage Adaptation", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Bohan Lyu", "Yadi Cao", "Duncan Watson-Parris", "Leon Bergen", "Taylor Berg-Kirkpatrick", "Rose Yu"], "affinity_score": 0.666, "link": "https://openreview.net/pdf/9b4aee0104190e3ba06797e50c0a41ee8bdf8ad8.pdf", "abstract": "Large Language Models (LLMs) demonstrate promising capabilities in solving scientific problems but often suffer from the issue of hallucination. While integrating LLMs with tools can mitigate this issue, models fine-tuned on tool usage become overreliant on them and incur unnecessary costs.\n    Inspired by how human experts assess problem complexity before selecting solutions, we propose a novel two-component fine-tuning method,\nAdapting while Learning\n(AWL). In the first component\nWorld Knowledge Learning\n(WKL), LLMs internalize scientific knowledge by learning from tool-generated solutions. In the second component\nTool Usage Adaptation\n(TUA), we categorize problems as easy or hard based on the model's accuracy, and train it to maintain direct reasoning for easy problems while switching to tools for hard ones.\n    We validate our method on 6 scientific benchmark datasets across climate science, epidemiology, physics, and other domains. Compared to the original instruct model (8B), models post-trained with AWL achieve 29.11\\% higher answer accuracy and 12.72\\% better tool usage accuracy, even surpassing state-of-the-art models including GPT-4o and Claude-3.5 on 4 custom-created datasets. Our code is open-source at \\url{https://github.com/Rose-STL-Lab/Adapting-While-Learning}.", "bibtex": "@inproceedings{\nlyu2025adapting,\ntitle={Adapting While Learning: Grounding {LLM}s for Scientific Problems with Tool Usage Adaptation},\nauthor={Bohan Lyu and Yadi Cao and Duncan Watson-Parris and Leon Bergen and Taylor Berg-Kirkpatrick and Rose Yu},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=owulFly8oQ}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Adapting While Learning_ Grounding LLMs for Scientific Problems with Tool Usage Adaptation.pdf", "retrieved_at": "2025-11-12T03:19:52.819549Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Rethinking Stateful Tool Use in Multi-Turn Dialogues: Benchmarks and Challenges", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Hongru Wang", "Wenyu Huang", "Yufei Wang", "Yuanhao Xi", "Jianqiao Lu", "Huan Zhang (张欢)", "Nan Hu", "Zeming Liu", "Jeff Z. Pan", "Kam-Fai Wong"], "affinity_score": 0.6656, "link": "https://aclanthology.org/2025.findings-acl.284/", "abstract": "Existing benchmarks that assess Language Models (LMs) as Language Agents (LAs) for tool use primarily focus on stateless, single-turn interactions or partial evaluations, such as tool selection in a single turn, overlooking the inherent stateful nature of interactions in multi-turn applications. To fulfill this gap, we propose DialogTool, a multi-turn dialogue dataset with stateful tool interactions considering the whole life cycle of tool use, across six key tasks in three stages: 1) tool creation ; 2) tool utilization : tool awareness, tool selection, tool execution; and 3) role-consistent response : response generation and role play. Furthermore, we build VirtualMobile – an embodied virtual mobile evaluation environment to simulate API calls and assess the robustness of the created APIs. Taking advantage of these artifacts, we conduct comprehensive evaluation on 13 distinct open- and closed-source LLMs and provide detailed analysis at each stage, revealing that the existing state-of-the-art LLMs still cannot perform well to use tools over long horizons .", "bibtex": "@inproceedings{wang-etal-2025-rethinking-stateful,\n    title = \"Rethinking Stateful Tool Use in Multi-Turn Dialogues: Benchmarks and Challenges\",\n    author = \"Wang, Hongru  and\n      Huang, Wenyu  and\n      Wang, Yufei  and\n      Xi, Yuanhao  and\n      Lu, Jianqiao  and\n      Zhang, Huan  and\n      Hu, Nan  and\n      Liu, Zeming  and\n      Pan, Jeff Z.  and\n      Wong, Kam-Fai\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.284/\",\n    doi = \"10.18653/v1/2025.findings-acl.284\",\n    pages = \"5433--5453\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings Rethinking Stateful Tool Use in Multi-Turn Dialogues_ Benchmarks and Challenges.pdf", "retrieved_at": "2025-11-12T03:19:53.361647Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Yakun Zhu", "Shaohang Wei", "Xu Wang", "Kui Xue", "Shaoting Zhang", "Xiaofan Zhang"], "affinity_score": 0.6655, "link": "https://aclanthology.org/2025.naacl-long.263/", "abstract": "Integrating tools into Large Language Models (LLMs) has facilitated the widespread application. Despite this, in specialized downstream task contexts, reliance solely on tools is insufficient to fully address the complexities of the real world. This particularly restricts the effective deployment of LLMs in fields such as medicine. In this paper, we focus on the downstream tasks of medical calculators, which use standardized tests to assess an individual’s health status. We introduce MeNTi, a universal agent architecture for LLMs. MeNTi integrates a specialized medical toolkit and employs meta-tool and nested calling mechanisms to enhance LLM tool utilization. Specifically, it achieves flexible tool selection and nested tool calling to address practical issues faced in intricate medical scenarios, including calculator selection, slot filling, and unit conversion. To assess the capabilities of LLMs for quantitative assessment throughout the clinical process of calculator scenarios, we introduce CalcQA. This benchmark requires LLMs to use medical calculators to perform calculations and assess patient health status. CalcQA is constructed by professional physicians and includes 100 case-calculator pairs, complemented by a toolkit of 281 medical tools. The experimental results demonstrate significant performance improvements with our framework. This research paves new directions for applying LLMs in demanding scenarios of medicine.", "bibtex": "@inproceedings{zhu-etal-2025-menti,\n    title = \"{M}e{NT}i: Bridging Medical Calculator and {LLM} Agent with Nested Tool Calling\",\n    author = \"Zhu, Yakun  and\n      Wei, Shaohang  and\n      Wang, Xu  and\n      Xue, Kui  and\n      Zhang, Shaoting  and\n      Zhang, Xiaofan\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.263/\",\n    doi = \"10.18653/v1/2025.naacl-long.263\",\n    pages = \"5097--5116\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long MeNTi_ Bridging Medical Calculator and LLM Agent with Nested Tool Calling.pdf", "retrieved_at": "2025-11-12T03:19:53.643300Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models", "venue": "NAACL 2025 Findings", "year": "2025", "authors": ["Saaket Agashe", "Yue Fan", "Anthony Reyna", "Xin Eric Wang"], "affinity_score": 0.665, "link": "https://aclanthology.org/2025.findings-naacl.448/", "abstract": "Large Language Models (LLMs) have demonstrated emergent common-sense reasoning and Theory of Mind (ToM) capabilities, making them promising candidates for developing coordination agents. This study introduces the LLM-Coordination Benchmark, a novel benchmark for analyzing LLMs in the context of Pure Coordination Settings, where agents must cooperate to maximize gains. Our benchmark evaluates LLMs through two distinct tasks. The first is Agentic Coordination, where LLMs act as proactive participants in four pure coordination games. The second is Coordination Question Answering (CoordQA), which tests LLMs on 198 multiple-choice questions across these games to evaluate three key abilities: Environment Comprehension, ToM Reasoning, and Joint Planning. Results from Agentic Coordination experiments reveal that LLM-Agents excel in multi-agent coordination settings where decision-making primarily relies on environmental variables but face challenges in scenarios requiring active consideration of partners’ beliefs and intentions. The CoordQA experiments further highlight significant room for improvement in LLMs’ Theory of Mind reasoning and joint planning capabilities. Zero-Shot Coordination (ZSC) experiments in the Agentic Coordination setting demonstrate that LLM agents, unlike RL methods, exhibit robustness to unseen partners. These findings indicate the potential of LLMs as Agents in pure coordination setups and underscore areas for improvement.", "bibtex": "@inproceedings{agashe-etal-2025-llm,\n    title = \"{LLM}-Coordination: Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models\",\n    author = \"Agashe, Saaket  and\n      Fan, Yue  and\n      Reyna, Anthony  and\n      Wang, Xin Eric\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Findings of the Association for Computational Linguistics: NAACL 2025\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-naacl.448/\",\n    doi = \"10.18653/v1/2025.findings-naacl.448\",\n    pages = \"8038--8057\",\n    ISBN = \"979-8-89176-195-7\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Findings LLM-Coordination_ Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models.pdf", "retrieved_at": "2025-11-12T03:19:53.985174Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Enhancing Tool Retrieval with Iterative Feedback from Large Language Models", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Qiancheng Xu", "Yongqi Li", "Heming Xia", "Wenjie Li"], "affinity_score": 0.6649, "link": "https://aclanthology.org/2024.findings-emnlp.561/", "abstract": "Tool learning aims to enhance and expand large language models’ (LLMs) capabilities with external tools, which has gained significant attention recently. Current methods have shown that LLMs can effectively handle a certain amount of tools through in-context learning or fine-tuning. However, in real-world scenarios, the number of tools is typically extensive and irregularly updated, emphasizing the necessity for a dedicated tool retrieval component. Tool retrieval is nontrivial due to the following challenges: 1) complex user instructions and tool descriptions; 2) misalignment between tool retrieval and tool usage models. To address the above issues, we propose to enhance tool retrieval with iterative feedback from the large language model. Specifically, we prompt the tool usage model, i.e., the LLM, to provide feedback for the tool retriever model in multi-round, which could progressively improve the tool retriever’s understanding of instructions and tools and reduce the gap between the two standalone components. We build a unified and comprehensive benchmark to evaluate tool retrieval models. The extensive experiments indicate that our proposed approach achieves advanced performance in both in-domain evaluation and out-of-domain evaluation.", "bibtex": "@inproceedings{xu-etal-2024-enhancing-tool,\n    title = \"Enhancing Tool Retrieval with Iterative Feedback from Large Language Models\",\n    author = \"Xu, Qiancheng  and\n      Li, Yongqi  and\n      Xia, Heming  and\n      Li, Wenjie\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.561/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.561\",\n    pages = \"9609--9619\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings Enhancing Tool Retrieval with Iterative Feedback from Large Language Models.pdf", "retrieved_at": "2025-11-12T03:19:55.242898Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Gödel Agent: A Self-Referential Agent Framework for Recursively Self-Improvement", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Xunjian Yin", "Xinyi Wang", "Liangming Pan", "Li Lin", "Xiaojun Wan", "William Yang Wang"], "affinity_score": 0.6648, "link": "https://aclanthology.org/2025.acl-long.1354/", "abstract": "The rapid advancement of large language models (LLMs) has significantly enhanced the capabilities of agents across various tasks. However, existing agentic systems, whether based on fixed pipeline algorithms or pre-defined meta-learning frameworks, cannot search the whole agent design space due to the restriction of human-designed components, and thus might miss the more optimal agent design. In this paper, we introduce Gödel Agent, a self-evolving framework inspired by the Gödel Machine, enabling agents to recursively improve themselves without relying on predefined routines or fixed optimization algorithms. Gödel Agent leverages LLMs to dynamically modify its own logic and behavior, guided solely by high-level objectives through prompting. Experimental results on multiple domains demonstrate that the implementation of Gödel Agent can achieve continuous self-improvement, surpassing manually crafted agents in performance, efficiency, and generalizability.", "bibtex": "@inproceedings{yin-etal-2025-godel,\n    title = {G{\\\"o}del Agent: A Self-Referential Agent Framework for Recursively Self-Improvement},\n    author = \"Yin, Xunjian  and\n      Wang, Xinyi  and\n      Pan, Liangming  and\n      Lin, Li  and\n      Wan, Xiaojun  and\n      Wang, William Yang\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1354/\",\n    doi = \"10.18653/v1/2025.acl-long.1354\",\n    pages = \"27890--27913\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Gödel Agent_ A Self-Referential Agent Framework for Recursively Self-Improvement.pdf", "retrieved_at": "2025-11-12T03:19:55.502697Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Shao Zhang", "Xihuai Wang", "Wenhao Zhang", "Chaoran Li", "Junru Song", "Tingyu Li", "Lin Qiu", "Xuezhi Cao", "Xunliang Cai", "Wen Yao", "Weinan Zhang", "Xinbing Wang", "Ying Wen"], "affinity_score": 0.6638, "link": "https://aclanthology.org/2025.acl-long.206/", "abstract": "Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction. Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without explicit instructions. Through experiments with current independent\nSystem 1\nand\nSystem 2\nmethods, we validate the necessity of using Dual Process Theory (DPT) in real-time tasks. We propose DPT-Agent, a novel language agent framework that integrates\nSystem 1\nand\nSystem 2\nfor efficient real-time simultaneous human-AI collaboration. DPT-Agent’s\nSystem 1\nuses a Finite-state Machine (FSM) and code-as-policy for fast, intuitive, and controllable decision-making. DPT-Agent’s\nSystem 2\nintegrates Theory of Mind (ToM) and asynchronous reflection to infer human intentions and perform reasoning-based autonomous decisions. We demonstrate the effectiveness of DPT-Agent through further experiments with rule-based agents and human collaborators, showing significant improvements over mainstream LLM-based frameworks. To the best of our knowledge, DPT-Agent is the first language agent framework that achieves successful real-time simultaneous human-AI collaboration autonomously. Code of DPT-Agent can be found in https://github.com/sjtu-marl/DPT-Agent.", "bibtex": "@inproceedings{zhang-etal-2025-leveraging,\n    title = \"Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-{AI} Collaboration\",\n    author = \"Zhang, Shao  and\n      Wang, Xihuai  and\n      Zhang, Wenhao  and\n      Li, Chaoran  and\n      Song, Junru  and\n      Li, Tingyu  and\n      Qiu, Lin  and\n      Cao, Xuezhi  and\n      Cai, Xunliang  and\n      Yao, Wen  and\n      Zhang, Weinan  and\n      Wang, Xinbing  and\n      Wen, Ying\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.206/\",\n    doi = \"10.18653/v1/2025.acl-long.206\",\n    pages = \"4081--4108\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration.pdf", "retrieved_at": "2025-11-12T03:19:55.868052Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Qinzhuo Wu", "Wei Liu", "Jian Luan", "Bin Wang"], "affinity_score": 0.6638, "link": "https://aclanthology.org/2024.emnlp-main.1018/", "abstract": "Recently, tool-augmented LLMs have gained increasing attention. Given an instruction, tool-augmented LLMs can interact with various external tools in multiple rounds and provide a final answer. However, previous LLMs were trained on overly detailed instructions, which included API names or parameters, while real users would not explicitly mention these API details. This leads to a gap between trained LLMs and real-world scenarios. In addition, most works ignore whether the interaction process follows the instruction. To address these issues, we constructed a training dataset called MGToolBench, which contains statement and category-level instructions to better reflect real-world scenarios. In addition, we propose ToolPlanner, a two-stage reinforcement learning framework that utilizes path planning and two feedback mechanisms to enhance the LLM’s task completion and instruction-following capabilities. Experimental results show that ToolPlanner significantly improves the Match Rate, Pass Rate and Win Rate by 26.8%, 20.2%, and 5.6% compared to the SOTA model. Human evaluation verifies that the multi-granularity instructions can better align with users’ usage habits. Our data and code will be released upon acceptance.", "bibtex": "@inproceedings{wu-etal-2024-toolplanner,\n    title = \"{T}ool{P}lanner: A Tool Augmented {LLM} for Multi Granularity Instructions with Path Planning and Feedback\",\n    author = \"Wu, Qinzhuo  and\n      Liu, Wei  and\n      Luan, Jian  and\n      Wang, Bin\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.1018/\",\n    doi = \"10.18653/v1/2024.emnlp-main.1018\",\n    pages = \"18315--18339\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main ToolPlanner_ A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback.pdf", "retrieved_at": "2025-11-12T03:19:56.086163Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "NetSafe: Exploring the Topological Safety of Multi-agent System", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Miao Yu", "Shilong Wang", "Guibin Zhang", "Junyuan Mao", "Chenlong Yin", "Qijiong Liu", "Kun Wang", "Qingsong Wen", "Yang Wang"], "affinity_score": 0.6635, "link": "https://aclanthology.org/2025.findings-acl.150/", "abstract": "Large language models (LLMs) have fueled significant progress in intelligent Multi-agent Systems (MAS), with expanding academic and industrial applications. However, safeguarding these systems from malicious queries receives relatively little attention, while methods for single-agent safety are challenging to transfer. In this paper, we explore MAS safety from a topological perspective, aiming at identifying structural properties that enhance security. To this end, we propose NetSafe framework, unifying diverse MAS workflows via iterative RelCom interactions to enable generalized analysis. We identify several critical phenomena for MAS under attacks (misinformation, bias, and harmful content), termed as Agent Hallucination , Aggregation Safety and Security Bottleneck . Furthermore, we verify that highly connected and larger systems are more vulnerable to adversarial spread, with task performance in a Star Graph Topology decreasing by 29.7%. In conclusion, our work introduces a new perspective on MAS safety and discovers unreported phenomena, offering insights and posing challenges to the community.", "bibtex": "@inproceedings{yu-etal-2025-netsafe,\n    title = \"{N}et{S}afe: Exploring the Topological Safety of Multi-agent System\",\n    author = \"Yu, Miao  and\n      Wang, Shilong  and\n      Zhang, Guibin  and\n      Mao, Junyuan  and\n      Yin, Chenlong  and\n      Liu, Qijiong  and\n      Wang, Kun  and\n      Wen, Qingsong  and\n      Wang, Yang\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.150/\",\n    doi = \"10.18653/v1/2025.findings-acl.150\",\n    pages = \"2905--2938\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings NetSafe_ Exploring the Topological Safety of Multi-agent System.pdf", "retrieved_at": "2025-11-12T03:19:56.480105Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Learning “Partner-Aware” Collaborators in Multi-Party Collaboration", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Abhijnan Nath", "Nikhil Krishnaswamy"], "affinity_score": 0.6627, "link": "https://openreview.net/pdf/40d31b0852235d5e98c6f82c41aa70978247a0dd.pdf", "abstract": "Large Language Models (LLMs) are increasingly bring deployed in agentic settings where they act as collaborators with humans. Therefore, it is increasingly important to be able to evaluate their abilities to collaborate effectively in multi-turn, multi-party tasks. In this paper, we build on the AI alignment and “safe interruptability” literature to offer novel theoretical insights on collaborative behavior between LLM-driven\ncollaborator agents\nand an\nintervention agent\n. Our goal is to learn an ideal “partner-aware” collaborator that increases the group’s common-ground (CG)—alignment on task-relevant propositions—by intelligently collecting information provided in\ninterventions\nby a partner agent.We show how LLM agents trained using standard RLHF and related approaches are naturally inclined to ignore possibly well-meaning interventions, which makes increasing group common ground non-trivial in this setting. We employ a two-player Modified-Action MDP to examine this suboptimal behavior of standard AI agents, and propose\nInterruptible Collaborative Roleplayer (ICR)\n—a novel “partner-aware” learning algorithm to train CG-optimal collaborators. Experiments on multiple collaborative task environments show that ICR, on average, is more capable of promoting successful CG convergence and exploring more diverse solutions in such tasks.", "bibtex": "@inproceedings{\nnath2025learning,\ntitle={Learning {\\textquotedblleft}Partner-Aware{\\textquotedblright} Collaborators in Multi-Party Collaboration},\nauthor={Abhijnan Nath and Nikhil Krishnaswamy},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=yFfWVr2TmZ}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Learning “Partner-Aware” Collaborators in Multi-Party Collaboration.pdf", "retrieved_at": "2025-11-12T03:19:58.033106Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Reidentify: Context-Aware Identity Generation for Contextual Multi-Agent Reinforcement Learning", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Zhiwei Xu", "Kun Hu", "Xin Xin", "Weiliang Meng", "Yiwei Shi", "Hangyu Mao", "Bin Zhang", "Dapeng Li", "Jiangjin Yin"], "affinity_score": 0.6626, "link": "https://openreview.net/pdf/eee5c253e8b2421db7f1821b4ffd74fe67842b0e.pdf", "abstract": "Generalizing multi-agent reinforcement learning (MARL) to accommodate variations in problem configurations remains a critical challenge in real-world applications, where even subtle differences in task setups can cause pre-trained policies to fail. To address this, we propose Context-Aware Identity Generation (CAID), a novel framework to enhance MARL performance under the Contextual MARL (CMARL) setting. CAID dynamically generates unique agent identities through the agent identity decoder built on a causal Transformer architecture. These identities provide contextualized representations that align corresponding agents across similar problem variants, facilitating policy reuse and improving sample efficiency. Furthermore, the action regulator in CAID incorporates these agent identities into the action-value space, enabling seamless adaptation to varying contexts. Extensive experiments on CMARL benchmarks demonstrate that CAID significantly outperforms existing approaches by enhancing both sample efficiency and generalization across diverse context variants.", "bibtex": "@inproceedings{\nxu2025reidentify,\ntitle={Reidentify: Context-Aware Identity Generation for Contextual Multi-Agent Reinforcement Learning},\nauthor={Zhiwei Xu and Kun Hu and Xin Xin and Weiliang Meng and Yiwei Shi and Hangyu Mao and Bin Zhang and Dapeng Li and Jiangjin Yin},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=vUDWRMB3tX}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Reidentify_ Context-Aware Identity Generation for Contextual Multi-Agent Reinforcement Learning.pdf", "retrieved_at": "2025-11-12T03:19:58.804075Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "CodeSim: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging", "venue": "NAACL 2025 Findings", "year": "2025", "authors": ["Md. Ashraful Islam", "Mohammed Eunus Ali", "Md. Rizwan Parvez"], "affinity_score": 0.6625, "link": "https://aclanthology.org/2025.findings-naacl.285/", "abstract": "No Abstract Available. Search Based on Title. The Result Could Be Suboptimal.", "bibtex": "@inproceedings{islam-etal-2025-codesim,\n    title = \"{C}ode{S}im: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging\",\n    author = \"Islam, Md. Ashraful  and\n      Ali, Mohammed Eunus  and\n      Parvez, Md Rizwan\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Findings of the Association for Computational Linguistics: NAACL 2025\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-naacl.285/\",\n    doi = \"10.18653/v1/2025.findings-naacl.285\",\n    pages = \"5113--5139\",\n    ISBN = \"979-8-89176-195-7\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Findings CodeSim_ Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging.pdf", "retrieved_at": "2025-11-12T03:19:59.049463Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Belief-Calibrated Multi-Agent Consensus Seeking for Complex NLP Tasks", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Wentao Deng", "Jiahuan Pei", "Zhiwei Xu", "Zhaochun Ren", "Zhumin Chen", "Pengjie Ren"], "affinity_score": 0.6624, "link": "https://openreview.net/pdf/39b359519c1bf6d78ee6a18e9e8d68df5457c0bd.pdf", "abstract": "A multi-agent system (MAS) enhances its capacity to solve complex natural language processing (NLP) tasks through collaboration among multiple agents, where consensus-seeking serves as a fundamental mechanism.\nHowever, existing consensus-seeking approaches typically rely on voting mechanisms to judge consensus, overlooking contradictions in system-internal beliefs that destabilize the consensus.\nMoreover, these methods often involve agents updating their results through indiscriminate collaboration with every other agent.\nSuch uniform interaction fails to identify the optimal collaborators for each agent, hindering the emergence of a stable consensus.\nTo address these challenges, we provide a theoretical framework for selecting optimal collaborators that maximize consensus stability.\nBased on the theorems, we propose the Belief-Calibrated Consensus Seeking (BCCS) framework to facilitate stable consensus via selecting optimal collaborators and calibrating the consensus judgment by system-internal beliefs.\nExperimental results on the MATH and MMLU benchmark datasets demonstrate that the proposed BCCS framework outperforms the best existing results by 2.23\\% and 3.95\\% of accuracy on challenging tasks, respectively.\nOur code and data are available at https://github.com/dengwentao99/BCCS.", "bibtex": "@inproceedings{\ndeng2025beliefcalibrated,\ntitle={Belief-Calibrated Multi-Agent Consensus Seeking for Complex {NLP} Tasks},\nauthor={Wentao Deng and Jiahuan Pei and Zhiwei Xu and Zhaochun Ren and Zhumin Chen and Pengjie Ren},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=AYqtMLRwzj}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Belief-Calibrated Multi-Agent Consensus Seeking for Complex NLP Tasks.pdf", "retrieved_at": "2025-11-12T03:20:00.274735Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Junjie Ye (叶俊杰)", "Zhengyin Du", "Xuesong Yao", "Weijian Lin", "Yufei Xu", "Zehui Chen", "Zaiyuan Wang", "Sining Zhu", "Zhiheng Xi", "Siyu Yuan", "Tao Gui", "Qi Zhang (张琦)", "Xuan-Jing Huang (黄萱菁)", "Jiecao Chen"], "affinity_score": 0.6623, "link": "https://aclanthology.org/2025.acl-long.150/", "abstract": "Effective evaluation of multi-hop tool use is critical for analyzing the understanding, reasoning, and function-calling capabilities of large language models (LLMs). However, progress has been hindered by a lack of reliable evaluation datasets. To address this, we present ToolHop, a dataset comprising 995 user queries and 3,912 associated tools, specifically designed for rigorous evaluation of multi-hop tool use. ToolHop ensures diverse queries, meaningful interdependencies, locally executable tools, detailed feedback, and verifiable answers through a novel query-driven data construction approach that includes tool creation, document refinement, and code generation. We evaluate 14 LLMs across five model families (i.e., LLaMA3.1, Qwen2.5, Gemini1.5, Claude3.5, and GPT), uncovering significant challenges in handling multi-hop tool-use scenarios. The leading model, GPT-4o, achieves an accuracy of 49.04%, underscoring substantial room for improvement. Further analysis reveals variations in tool-use strategies for various families, offering actionable insights to guide the development of more effective approaches. Code and data can be found in https://huggingface.co/datasets/bytedance-research/ToolHop.", "bibtex": "@inproceedings{ye-etal-2025-toolhop,\n    title = \"{T}ool{H}op: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use\",\n    author = \"Ye, Junjie  and\n      Du, Zhengyin  and\n      Yao, Xuesong  and\n      Lin, Weijian  and\n      Xu, Yufei  and\n      Chen, Zehui  and\n      Wang, Zaiyuan  and\n      Zhu, Sining  and\n      Xi, Zhiheng  and\n      Yuan, Siyu  and\n      Gui, Tao  and\n      Zhang, Qi  and\n      Huang, Xuanjing  and\n      Chen, Jiecao\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.150/\",\n    doi = \"10.18653/v1/2025.acl-long.150\",\n    pages = \"2995--3021\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long ToolHop_ A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use.pdf", "retrieved_at": "2025-11-12T03:20:00.524750Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "LLM-Assisted Semantically Diverse Teammate Generation for Efficient Multi-agent Coordination", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Lihe Li", "Lei Yuan", "Pengsen Liu", "Tao Jiang", "Yang Yu"], "affinity_score": 0.6622, "link": "https://openreview.net/pdf/020a3dead523fff24c0a3659c860dc18c9a2101c.pdf", "abstract": "Training with diverse teammates is the key for learning generalizable agents. Typical approaches aim to generate diverse teammates by utilizing techniques like randomization, designing regularization terms, or reducing policy compatibility, etc. However, such teammates lack semantic information, resulting in inefficient teammate generation and poor adaptability of the agents. To tackle these challenges, we propose Semantically Diverse Teammate Generation (SemDiv), a novel framework leveraging the capabilities of large language models (LLMs) to discover and learn diverse coordination behaviors at the semantic level. In each iteration, SemDiv first generates a novel coordination behavior described in natural language, then translates it into a reward function to train a teammate policy. Once the policy is verified to be meaningful, novel, and aligned with the behavior, the agents train a policy for coordination. Through this iterative process, SemDiv efficiently generates a diverse set of semantically grounded teammates, enabling agents to develop specialized policies, and select the most suitable ones through language-based reasoning to adapt to unseen teammates. Experiments show that SemDiv generates teammates covering a wide range of coordination behaviors, including those unreachable by baseline methods. Evaluation across four MARL environments, each with five unseen representative teammates, demonstrates SemDiv's superior coordination and adaptability. Our code is available at https://github.com/lilh76/SemDiv.", "bibtex": "@inproceedings{\nli2025llmassisted,\ntitle={{LLM}-Assisted Semantically Diverse Teammate Generation for Efficient Multi-agent Coordination},\nauthor={Lihe Li and Lei Yuan and Pengsen Liu and Tao Jiang and Yang Yu},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=Vhktpw6Vid}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster LLM-Assisted Semantically Diverse Teammate Generation for Efficient Multi-agent Coordination.pdf", "retrieved_at": "2025-11-12T03:20:02.898910Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "KABB: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Jusheng Zhang", "Zimeng Huang", "Yijia Fan", "Ningyuan Liu", "Mingyan Li", "Zhuojie Yang", "Jiawei Yao", "Jian Wang", "Keze Wang"], "affinity_score": 0.6621, "link": "https://openreview.net/pdf/fef86ef3f2607c65a7525f944813d72168cf794d.pdf", "abstract": "As scaling large language models faces prohibitive costs, multi-agent systems emerge as a promising alternative, though challenged by static knowledge assumptions and coordination inefficiencies. We introduce Knowledge-Aware Bayesian Bandits (KABB), a novel framework that enhances multi-agent system coordination through semantic understanding and dynamic adaptation. The framework features three key innovations: a customized knowledge distance model for deep semantic understanding, a dual-adaptation mechanism for continuous expert optimization, and a knowledge-aware Thompson Sampling strategy for efficient expert selection. Extensive evaluation demonstrates KABB achieves an optimal cost-performance balance, maintaining high performance while keeping computational demands relatively low in multi-agent coordination.", "bibtex": "@inproceedings{\nzhang2025kabb,\ntitle={{KABB}: Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems},\nauthor={Jusheng Zhang and Zimeng Huang and Yijia Fan and Ningyuan Liu and Mingyan Li and Zhuojie Yang and Jiawei Yao and Jian Wang and Keze Wang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=AKvy9a4jho}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster KABB_ Knowledge-Aware Bayesian Bandits for Dynamic Expert Coordination in Multi-Agent Systems.pdf", "retrieved_at": "2025-11-12T03:20:04.724148Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Yu Gu (谷峪)", "Yiheng Shu", "Hao Yu (余浩)", "Xiao Liu", "Yuxiao Dong", "Jie Tang", "Jayanth Srinivasa", "Hugo Latapie", "Yu Su"], "affinity_score": 0.6621, "link": "https://aclanthology.org/2024.emnlp-main.436/", "abstract": "The applications of large language models (LLMs) have expanded well beyond the confines of text processing, signaling a new era where LLMs are envisioned as generalist agents capable of operating within complex environments. These environments are often highly expansive, making it impossible for the LLM to process them within its short-term memory. Motivated by recent research on extending the capabilities of LLMs with tools, we seek to investigate the intriguing potential of tools to augment LLMs in handling such complexity by introducing a novel class of tools, termed\nmiddleware\n, to aid in the proactive exploration within these massive environments. Such specialized tools can serve as a middleware layer shielding the LLM from environmental complexity. In two representative complex environments—knowledge bases (KBs) and databases—we demonstrate the significant potential of augmenting language agents with tools in complex environments. Notably, equipped with the middleware, GPT-4 achieves\n2.8\nX the performance of the best baseline in tasks requiring access to database content and\n2.2\nX in KB tasks. Our findings illuminate the path for advancing language agents in real-world applications.", "bibtex": "@inproceedings{gu-etal-2024-middleware,\n    title = \"Middleware for {LLM}s: Tools Are Instrumental for Language Agents in Complex Environments\",\n    author = \"Gu, Yu  and\n      Shu, Yiheng  and\n      Yu, Hao  and\n      Liu, Xiao  and\n      Dong, Yuxiao  and\n      Tang, Jie  and\n      Srinivasa, Jayanth  and\n      Latapie, Hugo  and\n      Su, Yu\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.436/\",\n    doi = \"10.18653/v1/2024.emnlp-main.436\",\n    pages = \"7646--7663\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main Middleware for LLMs_ Tools Are Instrumental for Language Agents in Complex Environments.pdf", "retrieved_at": "2025-11-12T03:20:05.183149Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities", "venue": "ICML 2025 Oral", "year": "2025", "authors": ["Wendong Bu", "Yang Wu", "Qifan Yu", "Minghe Gao", "Bingchen Miao", "Zhenkui Zhang", "Kaihang Pan", "liyunfei", "Mengze Li", "Wei Ji", "Juncheng Li", "Siliang Tang", "Yueting Zhuang"], "affinity_score": 0.6619, "link": "https://openreview.net/pdf/d5d3691187b9f32f92e8e287e5005d40aa429f80.pdf", "abstract": "As multimodal large language models (MLLMs) advance, MLLM-based virtual agents have demonstrated remarkable performance. However, existing benchmarks face significant limitations, including uncontrollable task complexity, extensive manual annotation, and a lack of multidimensional evaluation. In response to these challenges, we introduce OmniBench, a self-generating, graph-based benchmark with an automated pipeline for synthesizing tasks of controllable complexity through subtask composition. To evaluate the diverse capabilities of virtual agents on the graph, we further present OmniEval, a multidimensional evaluation framework that includes subtask-level evaluation, graph-based metrics, and comprehensive tests across 10 capabilities. Our synthesized dataset contains 36k graph-structured tasks across 20 scenarios, achieving a 91% human acceptance rate. Training on our graph-structured data shows that it improves generalization across environments. We conduct multidimensional evaluations for virtual agents, revealing their performance across various capabilities and paving the way for future advancements. Our project is available at https://omni-bench.github.io.", "bibtex": "@inproceedings{\nbu2025what,\ntitle={What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities},\nauthor={Wendong Bu and Yang Wu and Qifan Yu and Minghe Gao and Bingchen Miao and Zhenkui Zhang and Kaihang Pan and liyunfei and Mengze Li and Wei Ji and Juncheng Li and Siliang Tang and Yueting Zhuang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=4tFSKOY2mT}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Oral What Limits Virtual Agent Application_ OmniBench_ A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities.pdf", "retrieved_at": "2025-11-12T03:20:06.260340Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "TrustAgent: Towards Safe and Trustworthy LLM-based Agents", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Wenyue Hua", "Xianjun Yang", "Mingyu Jin", "Zelong Li", "Wei Cheng", "Ruixiang Tang", "Yongfeng Zhang"], "affinity_score": 0.6618, "link": "https://aclanthology.org/2024.findings-emnlp.585/", "abstract": "The rise of LLM-based agents shows great potential to revolutionize task planning, capturing significant attention. Given that these agents will be integrated into high-stake domains, ensuring their reliability and safety is crucial. This paper presents an Agent-Constitution-based agent framework, TrustAgent, with a particular focus on improving the LLM-based agent safety. The proposed framework ensures strict adherence to the Agent Constitution through three strategic components: pre-planning strategy which injects safety knowledge to the model before plan generation, in-planning strategy which enhances safety during plan generation, and post-planning strategy which ensures safety by post-planning inspection. Our experimental results demonstrate that the proposed framework can effectively enhance an LLM agent’s safety across multiple domains by identifying and mitigating potential dangers during the planning. Further analysis reveals that the framework not only improves safety but also enhances the helpfulness of the agent. Additionally, we highlight the importance of the LLM reasoning ability in adhering to the Constitution. This paper sheds light on how to ensure the safe integration of LLM-based agents into human-centric environments. Data and code are available at https://anonymous.4open.science/r/TrustAgent-06DC .", "bibtex": "@inproceedings{hua-etal-2024-trustagent,\n    title = \"{T}rust{A}gent: Towards Safe and Trustworthy {LLM}-based Agents\",\n    author = \"Hua, Wenyue  and\n      Yang, Xianjun  and\n      Jin, Mingyu  and\n      Li, Zelong  and\n      Cheng, Wei  and\n      Tang, Ruixiang  and\n      Zhang, Yongfeng\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.585/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.585\",\n    pages = \"10000--10016\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings TrustAgent_ Towards Safe and Trustworthy LLM-based Agents.pdf", "retrieved_at": "2025-11-12T03:20:06.523590Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Yanfei Chen", "Jinsung Yoon", "Devendra Singh Sachan", "Qingze Wang", "Vincent Cohen-Addad", "Mohammadhossein Bateni", "Chen-Yu Lee", "Tomas Pfister"], "affinity_score": 0.6617, "link": "https://aclanthology.org/2024.findings-emnlp.270/", "abstract": "Recent advances in large language models (LLMs) have enabled autonomous agents with complex reasoning and task-fulfillment capabilities using a wide range of tools. However, effectively identifying the most relevant tools for a given task becomes a key bottleneck as the toolset size grows, hindering reliable tool utilization. To address this, we introduce Re-Invoke, an unsupervised tool retrieval method designed to scale effectively to large toolsets without training. Specifically, we first generate a diverse set of synthetic queries that comprehensively cover different aspects of the query space associated with each tool document during the tool indexing phase. Second, we leverage LLM’s query understanding capabilities to extract key tool-related context and underlying intents from user queries during the inference phase. Finally, we employ a novel multi-view similarity ranking strategy based on intents to pinpoint the most relevant tools for each query. Our evaluation demonstrates that Re-Invoke significantly outperforms state-of-the-art alternatives in both single-tool and multi-tool scenarios, all within a fully unsupervised setting. Notably, on the ToolE datasets, we achieve a 20% relative improvement in nDCG@5 for single-tool retrieval and a 39% improvement for multi-tool retrieval.", "bibtex": "@inproceedings{chen-etal-2024-invoke,\n    title = \"Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval\",\n    author = \"Chen, Yanfei  and\n      Yoon, Jinsung  and\n      Sachan, Devendra Singh  and\n      Wang, Qingze  and\n      Cohen-Addad, Vincent  and\n      Bateni, Mohammadhossein  and\n      Lee, Chen-Yu  and\n      Pfister, Tomas\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.270/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.270\",\n    pages = \"4705--4726\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings Re-Invoke_ Tool Invocation Rewriting for Zero-Shot Tool Retrieval.pdf", "retrieved_at": "2025-11-12T03:20:06.779718Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MisoDICE: Multi-Agent Imitation from Mixed-Quality Demonstrations", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["The Viet Bui", "Tien Anh Mai", "Thanh Hong Nguyen"], "affinity_score": 0.6616, "link": "https://openreview.net/pdf/4b2409e02a7e2d01eabd842a20cb992608dc0256.pdf", "abstract": "We study offline imitation learning (IL) in cooperative multi-agent settings, where demonstrations have unlabeled mixed quality - containing both expert and suboptimal trajectories. Our proposed solution is structured in two stages: trajectory labeling and multi-agent imitation learning, designed jointly to enable effective learning from heterogeneous, unlabeled data. In the first stage, we combine advances in large language models and preference-based reinforcement learning to construct a progressive labeling pipeline that distinguishes expert-quality trajectories. In the second stage, we introduce MisoDICE, a novel multi-agent IL algorithm that leverages these labels to learn robust policies while addressing the computational complexity of large joint state-action spaces. By extending the popular single-agent DICE framework to multi-agent settings with a new value decomposition and mixing architecture, our method yields a convex policy optimization objective and ensures consistency between global and local policies. We evaluate MisoDICE on multiple standard multi-agent RL benchmarks and demonstrate superior performance, especially when expert data is scarce.", "bibtex": "@inproceedings{\nbui2025misodice,\ntitle={Miso{DICE}: Multi-Agent Imitation from Mixed-Quality Demonstrations},\nauthor={The Viet Bui and Tien Anh Mai and Thanh Hong Nguyen},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=krG6UHAvYr}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster MisoDICE_ Multi-Agent Imitation from Mixed-Quality Demonstrations.pdf", "retrieved_at": "2025-11-12T03:20:07.799549Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Simulating Classroom Education with LLM-Empowered Agents", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Zheyuan Zhang", "Daniel Zhang-Li", "Jifan Yu", "Linlu Gong", "Jinchang Zhou", "Zhanxin Hao", "Jianxiao Jiang", "Jie Cao", "Huiqin Liu", "Zhiyuan Liu", "Lei Hou", "Juanzi Li"], "affinity_score": 0.6614, "link": "https://aclanthology.org/2025.naacl-long.520/", "abstract": "Large language models (LLMs) have been applied across various intelligent educational tasks to assist teaching. While preliminary studies have focused on task-specific, independent LLM-empowered agents, the potential of LLMs within a multi-agent collaborative framework for classroom simulation with real user participation remains unexplored. In this work, we propose SimClass, a multi-agent classroom simulation teaching framework. We recognize representative class roles and introduce a novel class control mechanism for automatic classroom teaching, and conduct user experiments in two real-world courses. Using the Flanders Interactive Analysis System and Community of Inquiry theoretical frameworks from educational analysis, we demonstrate that LLMs can simulate a dynamic learning environment for users with active teacher-student and student-student interactions. We also observe group behaviors among agents in SimClass, where agents collaborate to create enlivening interactions in classrooms to improve user learning process. We hope this work pioneers the application of LLM-empowered multi-agent systems in virtual classroom teaching. Our implementation and service can be found at https://github.com/THU-MAIC/SimClass.", "bibtex": "@inproceedings{zhang-etal-2025-simulating,\n    title = \"Simulating Classroom Education with {LLM}-Empowered Agents\",\n    author = \"Zhang, Zheyuan  and\n      Zhang-Li, Daniel  and\n      Yu, Jifan  and\n      Gong, Linlu  and\n      Zhou, Jinchang  and\n      Hao, Zhanxin  and\n      Jiang, Jianxiao  and\n      Cao, Jie  and\n      Liu, Huiqin  and\n      Liu, Zhiyuan  and\n      Hou, Lei  and\n      Li, Juanzi\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.520/\",\n    doi = \"10.18653/v1/2025.naacl-long.520\",\n    pages = \"10364--10379\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long Simulating Classroom Education with LLM-Empowered Agents.pdf", "retrieved_at": "2025-11-12T03:20:08.065497Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Cradle: Empowering Foundation Agents towards General Computer Control", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Weihao Tan", "Wentao Zhang", "Xinrun Xu", "Haochong Xia", "Ziluo Ding", "Boyu Li", "Bohan Zhou", "Junpeng Yue", "Jiechuan Jiang", "Yewen Li", "Ruyi An", "Molei Qin", "Chuqiao Zong", "Longtao Zheng", "YuJie Wu", "Xiaoqiang Chai", "Yifei Bi", "Tianbao Xie", "Pengjie Gu", "Xiyun Li", "Ceyao Zhang", "Long Tian", "Chaojie Wang", "Xinrun Wang", "Börje F. Karlsson", "Bo An", "Shuicheng YAN", "Zongqing Lu"], "affinity_score": 0.6613, "link": "https://openreview.net/pdf/3d1e188a8d22526e5f74b4daa4e464094b008106.pdf", "abstract": "Despite their success in specific scenarios, existing foundation agents still struggle to generalize across various virtual scenarios, mainly due to the dramatically different encapsulations of environments with manually designed observation and action spaces. To handle this issue, we propose the General Computer Control (GCC) setting to restrict foundation agents to interact with software through the most unified and standardized interface, i.e., using screenshots as input and keyboard and mouse actions as output. We introduce Cradle, a modular and flexible LMM-powered framework, as a preliminary attempt towards GCC. Enhanced by six key modules, Information Gathering, Self-Reflection, Task Inference, Skill Curation, Action Planning, and Memory, Cradle is able to understand input screenshots and output executable code for low-level keyboard and mouse control after high-level planning and information retrieval, so that Cradle can interact with any software and complete long-horizon complex tasks without relying on any built-in APIs. Experimental results show that Cradle exhibits remarkable generalizability and impressive performance across four previously unexplored commercial video games (Red Dead Redemption 2, Cities:Skylines, Stardew Valley and Dealer's Life 2), five software applications (Chrome, Outlook, Feishu, Meitu and CapCut), and a comprehensive benchmark, OSWorld. With a unified interface to interact with any software, Cradle greatly extends the reach of foundation agents thus paving the way for generalist agents.", "bibtex": "@inproceedings{\ntan2025cradle,\ntitle={Cradle: Empowering Foundation Agents towards General Computer Control},\nauthor={Weihao Tan and Wentao Zhang and Xinrun Xu and Haochong Xia and Ziluo Ding and Boyu Li and Bohan Zhou and Junpeng Yue and Jiechuan Jiang and Yewen Li and Ruyi An and Molei Qin and Chuqiao Zong and Longtao Zheng and YuJie Wu and Xiaoqiang Chai and Yifei Bi and Tianbao Xie and Pengjie Gu and Xiyun Li and Ceyao Zhang and Long Tian and Chaojie Wang and Xinrun Wang and B{\\\"o}rje F. Karlsson and Bo An and Shuicheng YAN and Zongqing Lu},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=6CAgbrjHTc}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Cradle_ Empowering Foundation Agents towards General Computer Control.pdf", "retrieved_at": "2025-11-12T03:20:09.643231Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Revealing Multimodal Causality with Large Language Models", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Jin Li", "Shoujin Wang", "Qi Zhang", "Feng Liu", "Tongliang Liu", "Longbing Cao", "Shui Yu", "Fang Chen"], "affinity_score": 0.6612, "link": "https://openreview.net/pdf/6fd0ed368b98ef83e704c98c8326dd77b764dd02.pdf", "abstract": "Uncovering cause-and-effect mechanisms from data is fundamental to scientific progress. While large language models (LLMs) show promise for enhancing causal discovery (CD) from unstructured data, their application to the increasingly prevalent multimodal setting remains a critical challenge. Even with the advent of multimodal LLMs (MLLMs), their efficacy in multimodal CD is hindered by two primary limitations: (1) difficulty in exploring intra- and inter-modal interactions for comprehensive causal variable identification; and (2) insufficiency to handle structural ambiguities with purely observational data. To address these challenges, we propose MLLM-CD, a novel framework for multimodal causal discovery from unstructured data. It consists of three key components: (1) a novel contrastive factor discovery module to identify genuine multimodal factors based on the interactions explored from contrastive sample pairs; (2) a statistical causal structure discovery module to infer causal relationships among discovered factors; and (3) an iterative multimodal counterfactual reasoning module to refine the discovery outcomes iteratively by incorporating the world knowledge and reasoning capabilities of MLLMs. Extensive experiments on both synthetic and real-world datasets demonstrate the effectiveness of the proposed MLLM-CD in revealing genuine factors and causal relationships among them from multimodal unstructured data. The implementation code and data are available at https://github.com/JinLi-i/MLLM-CD.", "bibtex": "@inproceedings{\nli2025revealing,\ntitle={Revealing Multimodal Causality with Large Language Models},\nauthor={Jin Li and Shoujin Wang and Qi Zhang and Feng Liu and Tongliang Liu and Longbing Cao and Shui Yu and Fang Chen},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=nufqobhME7}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Revealing Multimodal Causality with Large Language Models.pdf", "retrieved_at": "2025-11-12T03:20:11.503366Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Craftium: Bridging Flexibility and Efficiency for Rich 3D Single- and Multi-Agent Environments", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Mikel Malagón", "Josu Ceberio", "Jose A. Lozano"], "affinity_score": 0.6611, "link": "https://openreview.net/pdf/a834b5fb79305e685bf19594caefd1d17a946dca.pdf", "abstract": "Advances in large models, reinforcement learning, and open-endedness have accelerated progress toward autonomous agents that can learn and interact in the real world. To achieve this, flexible tools are needed to create rich, yet computationally efficient, environments. While scalable 2D environments fail to address key real-world challenges like 3D navigation and spatial reasoning, more complex 3D environments are computationally expensive and lack features like customizability and multi-agent support. This paper introduces Craftium, a highly customizable and easy-to-use platform for building rich 3D single- and multi-agent environments. We showcase environments of different complexity and nature: from single- and multi-agent tasks to vast worlds with many creatures and biomes, and customizable procedural task generators. Benchmarking shows that Craftium significantly reduces the computational cost of alternatives of similar richness, achieving +2K steps per second more than Minecraft-based frameworks.", "bibtex": "@inproceedings{\nmalagon2025craftium,\ntitle={Craftium: Bridging Flexibility and Efficiency for Rich 3D Single- and Multi-Agent Environments},\nauthor={Mikel Malag{\\'o}n and Josu Ceberio and Jose A. Lozano},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=htP5YRXcS9}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Craftium_ Bridging Flexibility and Efficiency for Rich 3D Single- and Multi-Agent Environments.pdf", "retrieved_at": "2025-11-12T03:20:13.669580Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Meta-Tool: Unleash Open-World Function Calling Capabilities of General-Purpose Large Language Models", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Shengqian Qin", "Yakun Zhu", "Linjie Mu", "Shaoting Zhang", "Xiaofan Zhang"], "affinity_score": 0.6611, "link": "https://aclanthology.org/2025.acl-long.1481/", "abstract": "Large language models (LLMs) have showcased remarkable capabilities as autonomous agents when augmented with external tools. Equipped with fixed tool sets, LLMs struggle with addressing diverse user inquiries in open-world tasks. To evaluate and boost the performance of LLMs in dealing with complex demands in the real-world, we propose open-world function calling, where LLMs need to retrieve suitable tools from a pre-defined external tool library and use retrieved tools to resolve the user’s problem. We introduce Meta-Tool, a versatile and plug-and-play tool retrieval system as the access of LLMs to external tool library. Drawing inspiration from the myriad of enhanced approaches associated with Retrieval-Augmented Generation (RAG), Meta-Tool employs a hypothesize-retrieve-invoke framework. We further propose Meta-Bench, a comprehensive benchmark for evaluating LLMs in open-world function calling and associated tasks. Meta-Bench encompasses 2,800 dialogues and 7,361 tools, spanning ten distinct scenarios to provide robust and diverse test categories. In conjunction, we present MT-LLaMA, a finetuned version of LLaMA-3.1, which exhibits remarkable performance improvements. Our empirical experiments reveal that Meta-Tool significantly enhances the ability of advanced LLMs to retrieve and leverage the most suitable tools compared to previous tool retrieval methods. Moreover, our fine-tuning enables even smaller-sized LLMs to achieve comparable even exceeding results to GPT-4o. Both the benchmark and the model are made publicly available at https://github.com/qinshengqian/Meta-Tool to foster further research and development in the field.", "bibtex": "@inproceedings{qin-etal-2025-meta,\n    title = \"Meta-Tool: Unleash Open-World Function Calling Capabilities of General-Purpose Large Language Models\",\n    author = \"Qin, Shengqian  and\n      Zhu, Yakun  and\n      Mu, Linjie  and\n      Zhang, Shaoting  and\n      Zhang, Xiaofan\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1481/\",\n    doi = \"10.18653/v1/2025.acl-long.1481\",\n    pages = \"30653--30677\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Meta-Tool_ Unleash Open-World Function Calling Capabilities of General-Purpose Large Language Models.pdf", "retrieved_at": "2025-11-12T03:20:13.924907Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "SimWorld: An Open-ended Simulator for Agents in Physical and Social Worlds", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Xiaokang Ye", "Jiawei Ren", "Yan Zhuang", "Xuhong He", "Yiming Liang", "Yiqing Yang", "Mrinaal Dogra", "Xianrui Zhong", "Eric Liu", "Kevin Benavente", "Rajiv Mandya Nagaraju", "Dhruv Vivek Sharma", "Ziqiao Ma", "Tianmin Shu", "Zhiting Hu", "Lianhui Qin"], "affinity_score": 0.6607, "link": "https://openreview.net/pdf/a98dee23d8b37552151336bbac20c838fd5e9ee1.pdf", "abstract": "While LLM/VLM-powered AI agents have advanced rapidly in math, coding, and computer use, their applications in complex physical and social environments remain challenging. Building agents that can survive and thrive in the real world (e.g., by autonomously earning income) requires massive-scale interaction, reasoning, training, and evaluation across diverse scenarios. However, existing world simulators for such development fall short: they often rely on limited hand-crafted environments, simulate simplified game-like physics and social rules, and lack native support for LLM/VLM agents. We introduce SimWorld, a new simulator built on Unreal Engine 5, designed for developing and evaluating LLM/VLM agents in rich, real-world-like settings. SimWorld offers three core capabilities: (1) realistic, open-ended world simulation, including accurate physical and social dynamics and language-driven procedural environment generation; (2) rich interface for LLM/VLM agents, with multi-modal world inputs/feedback and open-vocabulary action outputs at varying levels of abstraction; and (3) diverse physical and social reasoning scenarios that are easily customizable by users. We demonstrate SimWorld by deploying frontier LLM agents (e.g., Gemini-2.5-Flash, Claude-3.5, GPT-4o, and DeepSeek-Prover-V2) on both short-horizon navigation tasks requiring grounded re-planning, and long-horizon multi-agent food delivery tasks involving strategic cooperation and competition. The results reveal distinct reasoning patterns and limitations across models. We open-source SimWorld and hope it becomes a foundational platform for advancing real-world agent intelligence across disciplines. Please refer to the project website for the most up-to-date information: http://simworld.org/.", "bibtex": "@inproceedings{\nye2025simworld,\ntitle={SimWorld: An Open-ended Simulator for Agents in Physical and Social Worlds},\nauthor={Xiaokang Ye and Jiawei Ren and Yan Zhuang and Xuhong He and Yiming Liang and Yiqing Yang and Mrinaal Dogra and Xianrui Zhong and Eric Liu and Kevin Benavente and Rajiv Mandya Nagaraju and Dhruv Vivek Sharma and Ziqiao Ma and Tianmin Shu and Zhiting Hu and Lianhui Qin},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=FxCy8TvQHO}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Spotlight SimWorld_ An Open-ended Simulator for Agents in Physical and Social Worlds.pdf", "retrieved_at": "2025-11-12T03:20:16.451529Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MMSciBench: Benchmarking Language Models on Chinese Multimodal Scientific Problems", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Xinwu Ye", "Chengfan Li", "Siming Chen", "Wei Wei", "Robert Tang"], "affinity_score": 0.6605, "link": "https://aclanthology.org/2025.findings-acl.755/", "abstract": "Recent advances in large language models (LLMs) and vision-language models (LVLMs) have shown promise across many tasks, yet their scientific reasoning capabilities remain untested, particularly in multimodal settings. We present MMSciBench, a benchmark for evaluating mathematical and physical reasoning through text-only and text-image formats, with human-annotated difficulty levels, solutions with detailed explanations, and taxonomic mappings. Evaluation of state-of-the-art models reveals significant limitations, with even the best model achieving only 63.77% accuracy and particularly struggling with visual reasoning tasks. Our analysis exposes critical gaps in complex reasoning and visual-textual integration, establishing MMSciBench as a rigorous standard for measuring progress in multimodal scientific understanding. The code for MMSciBench is open-sourced at GitHub, and the dataset is available at Hugging Face.", "bibtex": "@inproceedings{ye-etal-2025-mmscibench,\n    title = \"{MMS}ci{B}ench: Benchmarking Language Models on {C}hinese Multimodal Scientific Problems\",\n    author = \"Ye, Xinwu  and\n      Li, Chengfan  and\n      Chen, Siming  and\n      Wei, Wei  and\n      Tang, Robert\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.755/\",\n    doi = \"10.18653/v1/2025.findings-acl.755\",\n    pages = \"14621--14663\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings MMSciBench_ Benchmarking Language Models on Chinese Multimodal Scientific Problems.pdf", "retrieved_at": "2025-11-12T03:20:16.879740Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "CodeScientist: End-to-End Semi-Automated Scientific Discovery with Code-based Experimentation", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Peter Jansen", "Oyvind Tafjord", "Marissa Radensky", "Pao Siangliulue", "Tom Hope", "Bhavana Dalvi", "Bodhisattwa Prasad Majumder", "Daniel S. Weld", "Peter Clark"], "affinity_score": 0.6602, "link": "https://aclanthology.org/2025.findings-acl.692/", "abstract": "Despite the surge of interest in autonomous scientific discovery (ASD) of software artifacts (e.g., improved ML algorithms), current ASD systems face two key limitations: (1) they largely explore variants of existing codebases or similarly constrained design spaces, and (2) they produce large volumes of research artifacts (such as automatically generated papers and code) that are typically evaluated using conference-style paper review with limited evaluation of code. In this work we introduce CodeScientist, a novel ASD system that frames ideation and experiment construction as a form of genetic search jointly over combinations of research articles and codeblocks defining common actions in a domain (like prompting a language model). We use this paradigm to conduct hundreds of automated experiments on machine-generated ideas broadly in the domain of agents and virtual environments, with the system returning 19 discoveries, 6 of which were judged as being both at least minimally sound and incrementally novel after a multi-faceted evaluation beyond that typically conducted in prior work, including external (conference-style) review, code review, and replication attempts. Moreover, the discoveries span new tasks, agents, metrics, and data, suggesting a qualitative shift from benchmark optimization to broader discoveries.", "bibtex": "@inproceedings{jansen-etal-2025-codescientist,\n    title = \"{C}ode{S}cientist: End-to-End Semi-Automated Scientific Discovery with Code-based Experimentation\",\n    author = \"Jansen, Peter  and\n      Tafjord, Oyvind  and\n      Radensky, Marissa  and\n      Siangliulue, Pao  and\n      Hope, Tom  and\n      Dalvi Mishra, Bhavana  and\n      Majumder, Bodhisattwa Prasad  and\n      Weld, Daniel S  and\n      Clark, Peter\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.692/\",\n    doi = \"10.18653/v1/2025.findings-acl.692\",\n    pages = \"13370--13467\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings CodeScientist_ End-to-End Semi-Automated Scientific Discovery with Code-based Experimentation.pdf", "retrieved_at": "2025-11-12T03:20:17.252895Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "POGEMA: A Benchmark Platform for Cooperative Multi-Agent Pathfinding", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Alexey Skrynnik", "Anton Andreychuk", "Anatolii Borzilov", "Alexander Chernyavskiy", "Konstantin Yakovlev", "Aleksandr Panov"], "affinity_score": 0.6602, "link": "https://openreview.net/pdf/19e55d87f236d0ca49d30994ced3703e8bd5a14e.pdf", "abstract": "Multi-agent reinforcement learning (MARL) has recently excelled in solving challenging cooperative and competitive multi-agent problems in various environments, typically involving a small number of agents and full observability. Moreover, a range of crucial robotics-related tasks, such as multi-robot pathfinding, which have traditionally been approached with classical non-learnable methods (e.g., heuristic search), are now being suggested for solution using learning-based or hybrid methods. However, in this domain, it remains difficult, if not impossible, to conduct a fair comparison between classical, learning-based, and hybrid approaches due to the lack of a unified framework that supports both learning and evaluation. To address this, we introduce POGEMA, a comprehensive set of tools that includes a fast environment for learning, a problem instance generator, a collection of predefined problem instances, a visualization toolkit, and a benchmarking tool for automated evaluation. We also introduce and define an evaluation protocol that specifies a range of domain-related metrics, computed based on primary evaluation indicators (such as success rate and path length), enabling a fair multi-fold comparison. The results of this comparison, which involves a variety of state-of-the-art MARL, search-based, and hybrid methods, are presented.", "bibtex": "@inproceedings{\nskrynnik2025pogema,\ntitle={{POGEMA}: A Benchmark Platform for Cooperative Multi-Agent Pathfinding},\nauthor={Alexey Skrynnik and Anton Andreychuk and Anatolii Borzilov and Alexander Chernyavskiy and Konstantin Yakovlev and Aleksandr Panov},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=6VgwE2tCRm}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster POGEMA_ A Benchmark Platform for Cooperative Multi-Agent Pathfinding.pdf", "retrieved_at": "2025-11-12T03:20:18.037862Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "LONGAGENT: Achieving Question Answering for 128k-Token-Long Documents through Multi-Agent Collaboration", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Jun Zhao (军 赵)", "Can Zu", "Xu Hao", "Yi Lu", "Wei He", "Yiwen Ding", "Tao Gui", "Qi Zhang (张琦)", "Xuan-Jing Huang (黄萱菁)"], "affinity_score": 0.6599, "link": "https://aclanthology.org/2024.emnlp-main.912/", "abstract": "Large language models (LLMs) have achieved tremendous success in understanding language and processing text. However, question-answering (QA) on lengthy documents faces challenges of resource constraints and a high propensity for errors, even for the most advanced models such as GPT-4 and Claude2.In this paper, we introduce\nLongAgent\n, a multi-agent collaboration method that enables efficient and effective QA over 128k -token-long documents.\nLongAgent\nadopts a\ndivide-and-conquer\nstrategy, breaking down lengthy documents into shorter, more manageable text chunks. A leader agent comprehends the user’s query and organizes the member agents to read their assigned chunks, reasoning a final answer through multiple rounds of discussion.Due to members’ hallucinations, it’s difficult to guarantee that every response provided by each member is accurate.To address this, we develop an\ninter-member communication\nmechanism that facilitates information sharing, allowing for the detection and mitigation of hallucinatory responses.Experimental results show that a LLaMA-2 7B driven by\nLongAgent\ncan effectively support QA over 128k -token documents, achieving 16.42% and 1.63% accuracy gains over GPT-4 on single-hop and multi-hop QA settings, respectively.", "bibtex": "@inproceedings{zhao-etal-2024-longagent,\n    title = \"{LONGAGENT}: Achieving Question Answering for 128k-Token-Long Documents through Multi-Agent Collaboration\",\n    author = \"Zhao, Jun  and\n      Zu, Can  and\n      Hao, Xu  and\n      Lu, Yi  and\n      He, Wei  and\n      Ding, Yiwen  and\n      Gui, Tao  and\n      Zhang, Qi  and\n      Huang, Xuanjing\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.912/\",\n    doi = \"10.18653/v1/2024.emnlp-main.912\",\n    pages = \"16310--16324\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main LONGAGENT_ Achieving Question Answering for 128k-Token-Long Documents through Multi-Agent Collaboration.pdf", "retrieved_at": "2025-11-12T03:20:18.275962Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Thinking vs. Doing: Improving Agent Reasoning by  Scaling Test-Time Interaction", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Junhong Shen", "Hao Bai", "Lunjun Zhang", "Yifei Zhou", "Amrith Setlur", "Shengbang Tong", "Diego Caples", "Nan Jiang", "Tong Zhang", "Ameet Talwalkar", "Aviral Kumar"], "affinity_score": 0.6599, "link": "https://openreview.net/pdf/20cba89765ebda48a0c183f17ceb68d13f90d0dc.pdf", "abstract": "Test-time scaling in agentic tasks often relies on generating long reasoning traces (\"think\" more) before acting, but this does not allow agents to acquire new information from the environment or adapt behavior over time. In this work, we propose scaling test-time interaction, an untapped dimension for test-time scaling that increases the agent's interaction horizon to enable rich behaviors such as exploration, backtracking, and dynamic re-planning within a single rollout. To demonstrate the promise of this scaling dimension, we situate our study in the domain of web agents. We first show that even prompting-based interaction scaling can improve task success on web benchmarks non-trivially. Building on this, we introduce TTI, a curriculum-based online reinforcement learning (RL) approach that trains agents by adaptively adjusting their interaction lengths during rollout. Using a Gemma 3 12B model, TTI sets a new state-of-the-art among open-source agents trained on public data on WebVoyager and WebArena. Case studies further reveal that TTI enables agents to balance exploration and exploitation adaptively. Our results establish interaction scaling as a powerful, complementary axis to scaling per-action compute, offering new avenues for training robust and adaptive agents.", "bibtex": "@inproceedings{\nshen2025thinking,\ntitle={Thinking vs. Doing: Improving Agent Reasoning by  Scaling Test-Time Interaction},\nauthor={Junhong Shen and Hao Bai and Lunjun Zhang and Yifei Zhou and Amrith Setlur and Shengbang Tong and Diego Caples and Nan Jiang and Tong Zhang and Ameet Talwalkar and Aviral Kumar},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=un1TRwNgiv}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Thinking vs. Doing_ Improving Agent Reasoning by Scaling Test-Time Interaction.pdf", "retrieved_at": "2025-11-12T03:20:20.462284Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Jinhao Jiang", "Kun Zhou", "Wayne Xin Zhao", "Yang Song", "Chen Zhu", "Hengshu Zhu", "Ji-Rong Wen"], "affinity_score": 0.6595, "link": "https://aclanthology.org/2025.acl-long.468/", "abstract": "In this paper, we aim to improve the reasoning ability of large language models(LLMs) over knowledge graphs(KGs) to answer complex questions. Inspired by existing methods that design the interaction strategy between LLMs and KG, we propose an autonomous LLM-based agent framework, called KG-Agent , which enables a small LLM to actively make decisions until finishing the reasoning process over KGs. In KG-Agent, we integrate the LLM, multifunctional toolbox, KG-based executor, and knowledge memory, and develop an iteration mechanism that autonomously selects the tool and then updates the memory for reasoning over KG. To guarantee the effectiveness, we leverage program language to formulate the multi-hop reasoning process over the KG and synthesize a code-based instruction dataset to fine-tune the base LLM. Extensive experiments demonstrate that only using 10K samples for tuning LLaMA2-7B can outperform competitive methods using larger LLMs or more data, on both in-domain and out-domain datasets. Our code and data will be publicly released.", "bibtex": "@inproceedings{jiang-etal-2025-kg,\n    title = \"{KG}-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph\",\n    author = \"Jiang, Jinhao  and\n      Zhou, Kun  and\n      Zhao, Xin  and\n      Song, Yang  and\n      Zhu, Chen  and\n      Zhu, Hengshu  and\n      Wen, Ji-Rong\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.468/\",\n    doi = \"10.18653/v1/2025.acl-long.468\",\n    pages = \"9505--9523\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long KG-Agent_ An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph.pdf", "retrieved_at": "2025-11-12T03:20:20.687454Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Collaborative Reasoner: Self-Improving Social Agents with Synthetic Conversations", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Ansong Ni", "Ruta Desai", "Yang Li", "Xinjie Lei", "Dong Wang", "Jiemin Zhang", "Jane Yu", "Ramya Raghavendra", "Gargi Ghosh", "Shang-Wen Li", "Asli Celikyilmaz"], "affinity_score": 0.6595, "link": "https://openreview.net/pdf/42a338bca40ea896002753679729eb2240bf62b3.pdf", "abstract": "With increasingly powerful large language models (LLMs) and LLM-based agents tackling an ever-growing list of tasks, we envision a future where numerous LLM agents work seamlessly with other AI agents and humans to solve complex problems and enhance daily life. To achieve these goals, LLM agents must develop collaborative skills such as effective persuasion, assertion and disagreement, which are often overlooked in the prevalent single-turn training and evaluation of LLMs. In this work, we present Collaborative Reasoner (Coral), a framework to evaluate and improve the collaborative reasoning abilities of language models. In particular, tasks and metrics in Coral necessitate agents to disagree with incorrect solutions, convince their partners of a correct solution, and ultimately agree as a team to commit to a final solution, all through a natural multi-turn conversation. Through comprehensive evaluation on six collaborative reasoning tasks covering domains of coding, math, scientific QA and social reasoning, we show that current models cannot effectively collaborate due to undesirable social behaviors, collapsing even on problems that they can solve singlehandedly. To improve the collaborative reasoning capabilities of LLMs, we propose a self-play method to generate synthetic multi-turn preference data and further train the language models to be better collaborators. Experiments with Llama-3.1, Ministral and Qwen-2.5 models show that our proposed self-improvement approach consistently outperforms finetuned chain-of-thought performance of the same base model, yielding gains up to 16.7% absolute. Human evaluations show that the models exhibit more effective disagreement and produce more natural conversations after training on our synthetic interaction data.", "bibtex": "@inproceedings{\nni2025collaborative,\ntitle={Collaborative Reasoner: Self-Improving Social Agents with Synthetic Conversations},\nauthor={Ansong Ni and Ruta Desai and Yang Li and Xinjie Lei and Dong Wang and Jiemin Zhang and Jane Yu and Ramya Raghavendra and Gargi Ghosh and Shang-Wen Li and Asli Celikyilmaz},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=dye9w8IOV0}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Collaborative Reasoner_ Self-Improving Social Agents with Synthetic Conversations.pdf", "retrieved_at": "2025-11-12T03:20:21.314317Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "CURIE: Evaluating LLMs on Multitask Scientific Long-Context Understanding and Reasoning", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Hao Cui", "Zahra Shamsi", "Gowoon Cheon", "Xuejian Ma", "Shutong Li", "Maria Tikhanovskaya", "Peter Christian Norgaard", "Nayantara Mudur", "Martyna Beata Plomecka", "Paul Raccuglia", "Yasaman Bahri", "Victor V. Albert", "Pranesh Srinivasan", "Haining Pan", "Philippe Faist", "Brian A Rohr", "Michael J. Statt", "Dan Morris", "Drew Purves", "Elise Kleeman", "Ruth Alcantara", "Matthew Abraham", "Muqthar Mohammad", "Ean Phing VanLee", "Chenfei Jiang", "Elizabeth Dorfman", "Eun-Ah Kim", "Michael Brenner", "Sameera S Ponda", "Subhashini Venugopalan"], "affinity_score": 0.6594, "link": "https://openreview.net/pdf/cdb4a7c6aa15fcb43b966794be08258eaafd8c1d.pdf", "abstract": "Scientific problem-solving involves synthesizing information while applying expert  knowledge.   We  introduce  CURIE,  a  scientific  long-Context  Understanding, Reasoning, and Information Extraction benchmark to measure the potential of Large Language Models (LLMs) in scientific problem-solving and assisting scientists in realistic workflows. This benchmark introduces ten challenging tasks with a total of 580 problems and solution pairs curated by experts in six disciplines - materials science, condensed matter physics, quantum computing, geo-spatial analysis, biodiversity, and proteins - covering both experimental and theoretical work-flows in science. We evaluate a range of closed and open LLMs on tasks in CURIE which requires domain expertise, comprehension of long in-context information,and multi-step reasoning.  While Gemini Flash 2.0 and Claude-3 show consistent high comprehension across domains, the popular GPT-4o and command-R+ fail dramatically on protein sequencing tasks. With the best performance at 32% there is much room for improvement for all models. We hope that insights gained from CURIE can guide the future development of LLMs in sciences. Links to the data and evaluation code are in https://github.com/google/curie", "bibtex": "@inproceedings{\ncui2025curie,\ntitle={{CURIE}: Evaluating {LLM}s on Multitask Scientific Long-Context Understanding and Reasoning},\nauthor={Hao Cui and Zahra Shamsi and Gowoon Cheon and Xuejian Ma and Shutong Li and Maria Tikhanovskaya and Peter Christian Norgaard and Nayantara Mudur and Martyna Beata Plomecka and Paul Raccuglia and Yasaman Bahri and Victor V. Albert and Pranesh Srinivasan and Haining Pan and Philippe Faist and Brian A Rohr and Michael J. Statt and Dan Morris and Drew Purves and Elise Kleeman and Ruth Alcantara and Matthew Abraham and Muqthar Mohammad and Ean Phing VanLee and Chenfei Jiang and Elizabeth Dorfman and Eun-Ah Kim and Michael Brenner and Sameera S Ponda and Subhashini Venugopalan},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=jw2fC6REUB}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster CURIE_ Evaluating LLMs on Multitask Scientific Long-Context Understanding and Reasoning.pdf", "retrieved_at": "2025-11-12T03:20:25.082830Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "UI-Vision: A Desktop-centric GUI Benchmark for Visual Perception and Interaction", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Shravan Nayak", "Xiangru Jian", "Kevin Qinghong Lin", "Juan A. Rodriguez", "Montek Kalsi", "Nicolas Chapados", "M. Tamer Özsu", "Aishwarya Agrawal", "David Vazquez", "Christopher Pal", "Perouz Taslakian", "Spandana Gella", "Sai Rajeswar"], "affinity_score": 0.6593, "link": "https://openreview.net/pdf/dea9d6856a1edbb3e8eb8d5f5cf27826da64fab6.pdf", "abstract": "Autonomous agents that navigate Graphical User Interfaces (GUIs) to automate tasks like document editing and file management can greatly enhance computer workflows. While existing research focuses on online settings, desktop environments, critical for many professional and everyday tasks, remain underexplored due to data collection challenges and licensing issues. We introduce UI-Vision, the first comprehensive, license-permissive benchmark for offline, fine-grained evaluation of computer use agents in real-world desktop environments. Unlike online benchmarks, UI-Vision provides: (i) dense, high-quality annotations of human demonstrations, including bounding boxes, UI labels, and action trajectories (clicks, drags, and keyboard inputs) across 83 software applications, and (ii) three fine-to-coarse grained tasks—Element Grounding, Layout Grounding, and Action Prediction—with well-defined metrics to rigorously evaluate agents' performance in desktop environments. Our evaluation reveals critical limitations in state-of-the-art models like UI-TARS-72B, including issues with understanding professional software, spatial reasoning, and complex actions like drag-and-drop. These findings highlight the challenges in developing fully autonomous computer-use agents. With UI-Vision, we aim to advance the development of more capable agents for real-world desktop tasks.", "bibtex": "@inproceedings{\nnayak2025uivision,\ntitle={{UI}-Vision: A Desktop-centric {GUI} Benchmark for Visual Perception and Interaction},\nauthor={Shravan Nayak and Xiangru Jian and Kevin Qinghong Lin and Juan A. Rodriguez and Montek Kalsi and Nicolas Chapados and M. Tamer {\\\"O}zsu and Aishwarya Agrawal and David Vazquez and Christopher Pal and Perouz Taslakian and Spandana Gella and Sai Rajeswar},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=5Rtj4mYH1C}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster UI-Vision_ A Desktop-centric GUI Benchmark for Visual Perception and Interaction.pdf", "retrieved_at": "2025-11-12T03:20:26.816237Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Grounding Language in Multi-Perspective Referential Communication", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Zineng Tang", "Lingjun Mao", "Alane Suhr"], "affinity_score": 0.6593, "link": "https://aclanthology.org/2024.emnlp-main.1100/", "abstract": "We introduce a task and dataset for referring expression generation and comprehension in multi-agent embodied environments.In this task, two agents in a shared scene must take into account one another’s visual perspective, which may be different from their own, to both produce and understand references to objects in a scene and the spatial relations between them.We collect a dataset of 2,970 human-written referring expressions, each paired with human comprehension judgments, and evaluate the performance of automated models as speakers and listeners paired with human partners, finding that model performance in both reference generation and comprehension lags behind that of pairs of human agents.Finally, we experiment training an open-weight speaker model with evidence of communicative success when paired with a listener, resulting in an improvement from 58.9 to 69.3% in communicative success and even outperforming the strongest proprietary model.", "bibtex": "@inproceedings{tang-etal-2024-grounding,\n    title = \"Grounding Language in Multi-Perspective Referential Communication\",\n    author = \"Tang, Zineng  and\n      Mao, Lingjun  and\n      Suhr, Alane\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.1100/\",\n    doi = \"10.18653/v1/2024.emnlp-main.1100\",\n    pages = \"19727--19741\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main Grounding Language in Multi-Perspective Referential Communication.pdf", "retrieved_at": "2025-11-12T03:20:27.257417Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Can MLLMs Reason in Multimodality? EMMA: An Enhanced MultiModal ReAsoning Benchmark", "venue": "ICML 2025 Oral", "year": "2025", "authors": ["Yunzhuo Hao", "Jiawei Gu", "Huichen Will Wang", "Linjie Li", "Zhengyuan Yang", "Lijuan Wang", "Yu Cheng"], "affinity_score": 0.6591, "link": "https://openreview.net/pdf/2ed8cc3801e22b8ada2e3d50fdf6cf6f5713f938.pdf", "abstract": "The ability to organically reason over and with both text and images is a pillar of human intelligence, yet the ability of Multimodal Large Language Models (MLLMs) to perform such multimodal reasoning remains under-explored. Existing benchmarks often emphasize text-dominant reasoning or rely on shallow visual cues, failing to adequately assess integrated visual and textual reasoning. We introduce EMMA (Enhanced MultiModal reAsoning), a benchmark targeting organic multimodal reasoning across mathematics, physics, chemistry, and coding. EMMA tasks demand advanced cross-modal reasoning that cannot be addressed by reasoning independently in each modality, offering an enhanced test suite for MLLMs' reasoning capabilities. Our evaluation of state-of-the-art MLLMs on EMMA reveals significant limitations in handling complex multimodal and multi-step reasoning tasks, even with advanced techniques like Chain-of-Thought prompting and test-time compute scaling underperforming. These findings underscore the need for improved multimodal architectures and training paradigms to close the gap between human and model reasoning in multimodality.", "bibtex": "@inproceedings{\nhao2025can,\ntitle={Can {MLLM}s Reason in Multimodality? {EMMA}: An Enhanced MultiModal ReAsoning Benchmark},\nauthor={Yunzhuo Hao and Jiawei Gu and Huichen Will Wang and Linjie Li and Zhengyuan Yang and Lijuan Wang and Yu Cheng},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=v26vwjxOEz}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Oral Can MLLMs Reason in Multimodality_ EMMA_ An Enhanced MultiModal ReAsoning Benchmark.pdf", "retrieved_at": "2025-11-12T03:20:28.335288Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ToolSpectrum: Towards Personalized Tool Utilization for Large Language Models", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Zihao Cheng", "Hongru Wang", "Zeming Liu", "Yuhang Guo (郭宇航)", "Yuanfang Guo", "Yunhong Wang", "Haifeng Wang"], "affinity_score": 0.6588, "link": "https://aclanthology.org/2025.findings-acl.1063/", "abstract": "While integrating external tools into large language models (LLMs) enhances their ability to access real-time information and domain-specific services, existing approaches focus narrowly on functional tool selection following user instructions while overlooking the critical role of context-aware personalization in tool selection. This oversight leads to suboptimal user satisfaction and inefficient tool utilization, particularly when overlapping toolsets require nuanced selection based on contextual factors. To bridge this gap, we introduce ToolSpectrum, a benchmark designed to evaluate LLMs’ capabilities in personalized tool utilization. Specifically, we formalize two key dimensions of personalization, user profile and environmental factors, and analyze their individual and synergistic impacts on tool selection. Through extensive experiments on ToolSpectrum, we demonstrate that personalized tool selection significantly improves user experience across diverse scenarios. However, even state-of-the-art LLMs exhibit the limited ability to reason jointly about user profiles and environmental factors, often prioritizing one dimension at the expense of the other. Our findings underscore the necessity of context-aware personalization in tool-augmented LLMs and reveal critical limitations for current models. Our data and code will be released soon.", "bibtex": "@inproceedings{cheng-etal-2025-toolspectrum,\n    title = \"{T}ool{S}pectrum: Towards Personalized Tool Utilization for Large Language Models\",\n    author = \"Cheng, Zihao  and\n      Wang, Hongru  and\n      Liu, Zeming  and\n      Guo, Yuhang  and\n      Guo, Yuanfang  and\n      Wang, Yunhong  and\n      Wang, Haifeng\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1063/\",\n    doi = \"10.18653/v1/2025.findings-acl.1063\",\n    pages = \"20679--20699\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings ToolSpectrum_ Towards Personalized Tool Utilization for Large Language Models.pdf", "retrieved_at": "2025-11-12T03:20:28.640130Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Many LLMs Are More Utilitarian Than One", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Anita Keshmirian", "Razan Baltaji", "Babak Hemmatian", "Hadi Asghari", "Lav R. Varshney"], "affinity_score": 0.6585, "link": "https://openreview.net/pdf/11ffe64728aca47ad87dbc980cf2ab76b2b81aa3.pdf", "abstract": "Moral judgment is integral to large language models' (LLMs) social reasoning. As multi-agent systems gain prominence, it becomes crucial to understand how LLMs function when collaborating compared to operating as individual agents. In human moral judgment, group deliberation leads to a Utilitarian Boost: a tendency to endorse norm violations that inflict harm but maximize benefits for the greatest number of people. We study whether a similar dynamic emerges in multi-agent LLM systems. We test six models on well-established sets of moral dilemmas across two conditions: (1) Solo, where models reason independently, and (2) Group, where they engage in multi-turn discussions in pairs or triads. In personal dilemmas, where agents decide whether to directly harm an individual for the benefit of others, all models rated moral violations as more acceptable when part of a group, demonstrating a Utilitarian Boost similar to that observed in humans. However, the mechanism for the boost in LLMs differed: While humans in groups become more utilitarian due to heightened sensitivity to decision outcomes, LLM groups showed diverse profiles, for example, reduced sensitivity to norms or enhanced impartiality. We report model differences in when and how strongly the boost manifests. We also discuss prompt and agent compositions that enhance or mitigate the effect. We end with a discussion of the implications for AI alignment, multi-agent design, and artificial moral reasoning. Code available at: https://github.com/baltaci-r/MoralAgents", "bibtex": "@inproceedings{\nkeshmirian2025many,\ntitle={Many {LLM}s Are More Utilitarian Than One},\nauthor={Anita Keshmirian and Razan Baltaji and Babak Hemmatian and Hadi Asghari and Lav R. Varshney},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=wn3VBRz5GK}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Many LLMs Are More Utilitarian Than One.pdf", "retrieved_at": "2025-11-12T03:20:31.290026Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Multiple LLM Agents Debate for Equitable Cultural Alignment", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Dayeon Ki", "Rachel Rudinger", "Tianyi Zhou", "Marine Carpuat"], "affinity_score": 0.6576, "link": "https://aclanthology.org/2025.acl-long.1210/", "abstract": "Large Language Models (LLMs) need to adapt their predictions to diverse cultural contexts to benefit diverse communities across the world. While previous efforts have focused on single-LLM, single-turn approaches, we propose to exploit the complementary strengths of multiple LLMs to promote cultural adaptability. We introduce a Multi-Agent Debate framework, where two LLM-based agents debate over a cultural scenario and collaboratively reach a final decision. We propose two variants: one where either LLM agents exclusively debate and another where they dynamically choose between self-reflection and debate during their turns. We evaluate these approaches on 7 open-weight LLMs (and 21 LLM combinations) using the NormAd-ETI benchmark for social etiquette norms in 75 countries. Experiments show that debate improves both overall accuracy and cultural group parity over single-LLM baselines. Notably, multi-agent debate enables relatively small LLMs (7-9B) to achieve accuracies comparable to that of a much larger model (27B parameters).", "bibtex": "@inproceedings{ki-etal-2025-multiple,\n    title = \"Multiple {LLM} Agents Debate for Equitable Cultural Alignment\",\n    author = \"Ki, Dayeon  and\n      Rudinger, Rachel  and\n      Zhou, Tianyi  and\n      Carpuat, Marine\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1210/\",\n    doi = \"10.18653/v1/2025.acl-long.1210\",\n    pages = \"24841--24877\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Multiple LLM Agents Debate for Equitable Cultural Alignment.pdf", "retrieved_at": "2025-11-12T03:20:31.615575Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "GenTool: Enhancing Tool Generalization in Language Models through Zero-to-One and Weak-to-Strong Simulation", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Jie He", "Jennifer Neville", "Mengting Wan", "Longqi Yang", "Hui Liu", "Xiaofeng Xu", "Xia Song", "Jeff Z. Pan", "Pei Zhou"], "affinity_score": 0.6575, "link": "https://aclanthology.org/2025.findings-acl.61/", "abstract": "Large Language Models (LLMs) can enhance their capabilities as AI assistants by integrating external tools, allowing them to access a wider range of information. While recent LLMs are typically fine-tuned with tool usage examples during supervised fine-tuning (SFT), questions remain about their ability to develop robust tool-usage skills and can effectively generalize to unseen queries and tools. In this work, we present GenTool, a novel training framework that prepares LLMs for diverse generalization challenges in tool utilization. Our approach addresses two fundamental dimensions critical for real-world applications: Zero-to-One Generalization, enabling the model to address queries initially lacking a suitable tool by adopting and utilizing one when it becomes available, and Weak-to-Strong Generalization, allowing models to leverage enhanced versions of existing tools to solve queries. To achieve this, we develop synthetic training data simulating these two dimensions of tool usage and introduce a two-stage fine-tuning approach: optimizing tool ranking, then refining tool selection. Through extensive experiments across four generalization scenarios, we demonstrate that our method significantly enhances the tool-usage capabilities of LLMs ranging from 1B to 8B parameters, achieving performance that surpasses GPT-4o. Furthermore, our analysis also provides valuable insights into the challenges LLMs encounter in tool generalization.", "bibtex": "@inproceedings{he-etal-2025-gentool,\n    title = \"{G}en{T}ool: Enhancing Tool Generalization in Language Models through Zero-to-One and Weak-to-Strong Simulation\",\n    author = \"He, Jie  and\n      Neville, Jennifer  and\n      Wan, Mengting  and\n      Yang, Longqi  and\n      Liu, Hui  and\n      Xu, Xiaofeng  and\n      Song, Xia  and\n      Pan, Jeff Z.  and\n      Zhou, Pei\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.61/\",\n    doi = \"10.18653/v1/2025.findings-acl.61\",\n    pages = \"1097--1122\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings GenTool_ Enhancing Tool Generalization in Language Models through Zero-to-One and Weak-to-Strong Simulation.pdf", "retrieved_at": "2025-11-12T03:20:31.918713Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Agent Workflow Memory", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Zora Zhiruo Wang", "Jiayuan Mao", "Daniel Fried", "Graham Neubig"], "affinity_score": 0.657, "link": "https://openreview.net/pdf/c7ec3d6eaa775686f3b8750477e00bc7a65034e3.pdf", "abstract": "Despite the potential of language model-based agents to solve real-world tasks such as web navigation, current methods still struggle with long-horizon tasks with complex action trajectories. In contrast, humans can flexibly solve complex tasks by learning reusable task workflows from past experiences and using them to guide future actions. To build agents that can similarly benefit from this process, we introduce Agent Workflow Memory (AWM), a method for inducing commonly reused routines, i.e., workflows, and selectively providing workflows to the agent to guide subsequent generations. AWM flexibly applies to both offline and online scenarios, where agents induce workflows from training examples beforehand or from test queries on the fly. We experiment on two major web navigation benchmarks — Mind2Web and WebArena — that collectively cover 1000+ tasks from 200+ domains across travel, shopping, and social media, among others. AWM substantially improves the baseline results by 24.6% and 51.1% relative success rate on Mind2Web and WebArena while reducing the number of steps taken to solve WebArena tasks successfully. Furthermore, online AWM robustly generalizes in cross-task, website, and domain evaluations, surpassing baselines from 8.9 to 14.0 absolute points as train-test task distribution gaps widen.", "bibtex": "@inproceedings{\nwang2025agent,\ntitle={Agent Workflow Memory},\nauthor={Zora Zhiruo Wang and Jiayuan Mao and Daniel Fried and Graham Neubig},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=NTAhi2JEEE}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Agent Workflow Memory.pdf", "retrieved_at": "2025-11-12T03:20:33.884151Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Infogent: An Agent-Based Framework for Web Information Aggregation", "venue": "NAACL 2025 Findings", "year": "2025", "authors": ["Revanth Gangi Reddy", "Sagnik Mukherjee", "Jeonghwan Kim", "Zhenhailong Wang", "Dilek Hakkani-Tur", "Heng Ji"], "affinity_score": 0.6568, "link": "https://aclanthology.org/2025.findings-naacl.318/", "abstract": "Despite seemingly performant web agents on the task-completion benchmarks, most existing methods evaluate the agents based on a presupposition: the web navigation task consists of a linear sequence of actions with an end state that marks task completion. In contrast, our work focuses on web navigation for information aggregation, wherein the agent must explore different websites to gather information for a complex query. We consider web information aggregation from two different perspectives: i) Direct API-driven Access relies on a text-only view of the Web, leveraging external tools such as Google Search API to navigate the Web and a scraper to extract website contents. (ii) Interactive Visual Access uses screenshots of the webpages and requires interaction with the browser to navigate and access information. Motivated by these diverse information access settings, we introduce Infogent, a novel modular framework for web information aggregation involving three distinct components: Navigator, Extractor, and Aggregator. Experiments on different information access settings demonstrate that Infogent beats an existing SOTA multi-agent search framework by 7% under Direct API-Driven Access on FRAMES and improves over an existing information-seeking web agent by 4.3% under Interactive Visual Access on AssistantBench.", "bibtex": "@inproceedings{gangi-reddy-etal-2025-infogent,\n    title = \"Infogent: An Agent-Based Framework for Web Information Aggregation\",\n    author = {Gangi Reddy, Revanth  and\n      Mukherjee, Sagnik  and\n      Kim, Jeonghwan  and\n      Wang, Zhenhailong  and\n      Hakkani-T{\\\"u}r, Dilek  and\n      Ji, Heng},\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Findings of the Association for Computational Linguistics: NAACL 2025\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-naacl.318/\",\n    doi = \"10.18653/v1/2025.findings-naacl.318\",\n    pages = \"5745--5758\",\n    ISBN = \"979-8-89176-195-7\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Findings Infogent_ An Agent-Based Framework for Web Information Aggregation.pdf", "retrieved_at": "2025-11-12T03:20:34.394777Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AffordBot: 3D Fine-grained Embodied Reasoning via Multimodal Large Language Models", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Xinyi Wang", "Xun Yang", "Yanlong Xu", "Yuchen Wu", "Zhen Li", "Na Zhao"], "affinity_score": 0.6568, "link": "https://openreview.net/pdf/686a233441037675c3bfb6cea63ba14355cad978.pdf", "abstract": "Effective human-agent collaboration in physical environments requires understanding not only what to act upon, but also where the actionable elements are and how to interact with them. Existing approaches often operate at the object level or disjointedly handle fine-grained affordance reasoning, lacking coherent, instruction-driven grounding and reasoning. In this work, we introduce a new task: Fine-grained 3D Embodied Reasoning, which requires an agent to predict, for each referenced affordance element in a 3D scene, a structured triplet comprising its spatial location, motion type, and motion axis, based on a task instruction. To solve this task, we propose AffordBot, a novel framework that integrates Multimodal Large Language Models (MLLMs) with a tailored chain-of-thought (CoT) reasoning paradigm. To bridge the gap between 3D input and 2D-compatible MLLMs, we render surround-view images of the scene and project 3D element candidates into these views, forming a rich visual representation aligned with the scene geometry. Our CoT pipeline begins with an active perception stage, prompting the MLLM to select the most informative viewpoint based on the instruction, before proceeding with step-by-step reasoning to localize affordance elements and infer plausible interaction motions. Evaluated on the SceneFun3D dataset, AffordBot achieves state-of-the-art performance, demonstrating strong generalization and physically grounded reasoning with only 3D point cloud input and MLLMs.", "bibtex": "@inproceedings{\nwang2025affordbot,\ntitle={AffordBot: 3D Fine-grained Embodied Reasoning via Multimodal Large Language Models},\nauthor={Xinyi Wang and Xun Yang and Yanlong Xu and Yuchen Wu and Zhen Li and Na Zhao},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=N5vXT7AGuo}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster AffordBot_ 3D Fine-grained Embodied Reasoning via Multimodal Large Language Models.pdf", "retrieved_at": "2025-11-12T03:20:37.530323Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials", "venue": "ICLR 2025 Spotlight", "year": "2025", "authors": ["Yiheng Xu", "Dunjie Lu", "Zhennan Shen", "Junli Wang", "Zekun Wang", "Yuchen Mao", "Caiming Xiong", "Tao Yu"], "affinity_score": 0.6561, "link": "https://openreview.net/pdf/e95d923ccea15b1bab268aeeb8b3845547e3dafe.pdf", "abstract": "Graphical User Interface (GUI) agents hold great potential for automating complex tasks across diverse digital environments, from web applications to desktop software. However, the development of such agents is hindered by the lack of high-quality, multi-step trajectory data required for effective training. Existing approaches rely on expensive and labor-intensive human annotation, making them unsustainable at scale. To address this challenge, we propose AgentTrek, a scalable data synthesis pipeline that generates high-quality web agent trajectories by leveraging web tutorials. Our method automatically gathers tutorial-like texts from the internet, transforms them into task goals with step-by-step instructions, and employs a visual-language model (VLM) agent to simulate their execution in a real digital environment. A VLM-based evaluator ensures the correctness of the generated trajectories. We demonstrate that training GUI agents with these synthesized trajectories significantly improves their grounding and planning performance over the current models. Moreover, our approach is more cost-efficient compared to traditional human annotation methods. This work underscores the potential of guided replay with web tutorials as a viable strategy for large-scale GUI agent training, paving the way for more capable and autonomous digital agents.", "bibtex": "@inproceedings{\nxu2025agenttrek,\ntitle={AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials},\nauthor={Yiheng Xu and Dunjie Lu and Zhennan Shen and Junli Wang and Zekun Wang and Yuchen Mao and Caiming Xiong and Tao Yu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=EEgYUccwsV}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Spotlight AgentTrek_ Agent Trajectory Synthesis via Guiding Replay with Web Tutorials.pdf", "retrieved_at": "2025-11-12T03:20:41.313053Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Mohammed Saidul Islam", "Md Tahmid Rahman Laskar", "Md. Rizwan Parvez", "Enamul Hoque", "Shafiq Joty"], "affinity_score": 0.6559, "link": "https://aclanthology.org/2024.emnlp-main.1073/", "abstract": "Data-driven storytelling is a powerful method for conveying insights by combining narrative techniques with visualizations and text. These stories integrate visual aids, such as highlighted bars and lines in charts, along with textual annotations explaining insights. However, creating such stories requires a deep understanding of the data and meticulous narrative planning, often necessitating human intervention, which can be time-consuming and mentally taxing. While Large Language Models (LLMs) excel in various NLP tasks, their ability to generate coherent and comprehensive data stories remains underexplored. In this work, we introduce a novel task for data story generation and a benchmark containing 1,449 stories from diverse sources. To address the challenges of crafting coherent data stories, we propose a multi-agent framework employing two LLM agents designed to replicate the human storytelling process: one for understanding and describing the data (Reflection), generating the outline, and narration, and another for verification at each intermediary step. While our agentic framework generally outperforms non-agentic counterparts in both model-based and human evaluations, the results also reveal unique challenges in data story generation.", "bibtex": "@inproceedings{islam-etal-2024-datanarrative,\n    title = \"{D}ata{N}arrative: Automated Data-Driven Storytelling with Visualizations and Texts\",\n    author = \"Islam, Mohammed Saidul  and\n      Laskar, Md Tahmid Rahman  and\n      Parvez, Md Rizwan  and\n      Hoque, Enamul  and\n      Joty, Shafiq\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.1073/\",\n    doi = \"10.18653/v1/2024.emnlp-main.1073\",\n    pages = \"19253--19286\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main DataNarrative_ Automated Data-Driven Storytelling with Visualizations and Texts.pdf", "retrieved_at": "2025-11-12T03:20:42.049953Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "mABC: Multi-Agent Blockchain-inspired Collaboration for Root Cause Analysis in Micro-Services Architecture", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Wei Zhang", "Hongcheng Guo", "Jian Yang", "Zhoujin Tian", "Yi Zhang", "Yan Chaoran", "Zhoujun Li", "Tongliang Li", "Xu Shi", "Liangfan Zheng", "Bo Zhang (波章", ")"], "affinity_score": 0.6557, "link": "https://aclanthology.org/2024.findings-emnlp.232/", "abstract": "Root cause analysis (RCA) in Micro-services architecture (MSA) with escalating complexity encounters complex challenges in maintaining system stability and efficiency due to fault propagation and circular dependencies among nodes. Diverse root cause analysis faults require multi-agents with diverse expertise. To mitigate the hallucination problem of large language models (LLMs), we design blockchain-inspired voting to ensure the reliability of the analysis by using a decentralized decision-making process. To avoid non-terminating loops led by common circular dependency in MSA, we objectively limit steps and standardize task processing through Agent Workflow. We propose a pioneering framework, multi-Agent Blockchain-inspired Collaboration for root cause analysis in micro-services architecture (mABC), where multiple agents based on the powerful LLMs follow Agent Workflow and collaborate in blockchain-inspired voting. Specifically, seven specialized agents derived from Agent Workflow each provide valuable insights towards root cause analysis based on their expertise and the intrinsic software knowledge of LLMs collaborating within a decentralized chain. Our experiments on the AIOps challenge dataset and a newly created Train-Ticket dataset demonstrate superior performance in identifying root causes and generating effective resolutions. The ablation study further highlights Agent Workflow, multi-agent, and blockchain-inspired voting is crucial for achieving optimal performance. mABC offers a comprehensive automated root cause analysis and resolution in micro-services architecture and significantly improves the IT Operation domain.", "bibtex": "@inproceedings{zhang-etal-2024-mabc,\n    title = \"m{ABC}: Multi-Agent Blockchain-inspired Collaboration for Root Cause Analysis in Micro-Services Architecture\",\n    author = \"Zhang, Wei  and\n      Guo, Hongcheng  and\n      Yang, Jian  and\n      Tian, Zhoujin  and\n      Zhang, Yi  and\n      Chaoran, Yan  and\n      Li, Zhoujun  and\n      Li, Tongliang  and\n      Shi, Xu  and\n      Zheng, Liangfan  and\n      Zhang, Bo\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.232/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.232\",\n    pages = \"4017--4033\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings mABC_ Multi-Agent Blockchain-inspired Collaboration for Root Cause Analysis in Micro-Services Architecture.pdf", "retrieved_at": "2025-11-12T03:20:42.747307Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Debate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Sijia Wang", "Lifu Huang"], "affinity_score": 0.6557, "link": "https://aclanthology.org/2024.findings-emnlp.958/", "abstract": "We propose a multi-agent debate as optimization (DAO) system for event extraction, where the primary objective is to iteratively refine the large language models (LLMs) outputs through debating without parameter tuning. In DAO, we introduce two novel modules: the Diverse-RAG (DRAG) module and the Adaptive Conformal Prediction (AdaCP) module. DRAG systematically retrieves supporting information that best fits the debate discussion, while AdaCP enhances the accuracy and reliability of event extraction by effectively rejecting less promising answers. Experimental results demonstrate a significant reduction in the performance gap between supervised approaches and tuning-free LLM-based methods by 18.1% and 17.8% on ACE05 and 17.9% and 15.2% on CASIE for event detection and argument extraction respectively.", "bibtex": "@inproceedings{wang-huang-2024-debate,\n    title = \"Debate as Optimization: Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction\",\n    author = \"Wang, Sijia  and\n      Huang, Lifu\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.958/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.958\",\n    pages = \"16422--16435\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings Debate as Optimization_ Adaptive Conformal Prediction and Diverse Retrieval for Event Extraction.pdf", "retrieved_at": "2025-11-12T03:20:42.987311Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Zhentao Xie", "Chengcheng Han", "Jinxin Shi", "Wenjun Cui", "Wayne Xin Zhao", "Xingjiao Wu", "Jiabao Zhao"], "affinity_score": 0.6557, "link": "https://aclanthology.org/2025.findings-acl.342/", "abstract": "Although multi-agent systems based on large language models show strong capabilities on multiple tasks, they are still limited by high computational overhead, information loss, and robustness. Inspired by ResNet’s residual learning, we propose Residual Mixture-of-Agents (RMoA), integrating residual connections to optimize efficiency and reliability. To maximize information utilization from model responses while minimizing computational costs, we innovatively design an embedding-based diversity selection mechanism that greedily selects responses via vector similarity. Furthermore, to mitigate iterative information degradation, we introduce a Residual Extraction Agent to preserve cross-layer incremental information by capturing inter-layer response differences, coupled with a Residual Aggregation Agent for hierarchical information integration. Additionally, we propose an adaptive termination mechanism that dynamically halts processing based on residual convergence, further improving inference efficiency. RMoA achieves state-of-the-art performance on the benchmarks of across alignment, mathematical reasoning, code generation, and multitasking understanding, while significantly reducing computational overhead. Code is available at https://github.com/mindhunter01/RMoA.", "bibtex": "@inproceedings{xie-etal-2025-rmoa,\n    title = \"{RM}o{A}: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation\",\n    author = \"Xie, Zhentao  and\n      Han, Chengcheng  and\n      Shi, Jinxin  and\n      Cui, Wenjun  and\n      Zhao, Xin  and\n      Wu, Xingjiao  and\n      Zhao, Jiabao\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.342/\",\n    doi = \"10.18653/v1/2025.findings-acl.342\",\n    pages = \"6575--6602\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings RMoA_ Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation.pdf", "retrieved_at": "2025-11-12T03:20:43.269266Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "HoneyComb: A Flexible LLM-Based Agent System for Materials Science", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Huan Zhang (张欢)", "Yu Song", "Ziyu Hou", "Santiago Miret", "Bang Liu"], "affinity_score": 0.6555, "link": "https://aclanthology.org/2024.findings-emnlp.192/", "abstract": "The emergence of specialized large language models (LLMs) has shown promise in addressing complex tasks in materials science. Many LLMs, however, often struggle with the distinct complexities of materials science tasks, such as computational challenges, and rely heavily on outdated implicit knowledge, leading to inaccuracies and hallucinations. To address these challenges, we introduce HoneyComb, the first LLM-based agent system specifically designed for materials science. HoneyComb leverages a reliable, high-quality materials science knowledge base (MatSciKB) and a sophisticated tool hub (ToolHub) tailored specifically for materials science to enhance its reasoning and computational capabilities. MatSciKB is a curated, structured knowledge collection based on reliable literature, while ToolHub employs an Inductive Tool Construction method to generate, decompose, and refine API tools for materials science. Additionally, HoneyComb leverages a retriever module that adaptively selects the appropriate knowledge source or tools for specific tasks, thereby ensuring accuracy and relevance. Our results demonstrate that HoneyComb significantly outperforms baseline models across various tasks in materials science, effectively bridging the gap between current LLM capabilities and the specialized needs of this domain. Furthermore, our adaptable framework can be easily extended to other scientific domains, highlighting its potential for broad applicability in advancing scientific research and applications.", "bibtex": "@inproceedings{zhang-etal-2024-honeycomb,\n    title = \"{H}oney{C}omb: A Flexible {LLM}-Based Agent System for Materials Science\",\n    author = \"Zhang, Huan  and\n      Song, Yu  and\n      Hou, Ziyu  and\n      Miret, Santiago  and\n      Liu, Bang\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.192/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.192\",\n    pages = \"3369--3382\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings HoneyComb_ A Flexible LLM-Based Agent System for Materials Science.pdf", "retrieved_at": "2025-11-12T03:20:43.734383Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Adaptively Coordinating with Novel Partners via Learned Latent Strategies", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Benjamin Li", "Shuyang Shi", "Lucia Romero", "Huao Li", "Yaqi Xie", "Woojun Kim", "Stefanos Nikolaidis", "Charles Michael Lewis", "Katia P. Sycara", "Simon Stepputtis"], "affinity_score": 0.6554, "link": "https://openreview.net/pdf/69238b8875d33eff314d02a7b2788594acaa629d.pdf", "abstract": "Adaptation is the cornerstone of effective collaboration among heterogeneous team members. In human-agent teams, artificial agents need to adapt to their human partners in real time, as individuals often have unique preferences and policies that may change dynamically throughout interactions. This becomes particularly challenging in tasks with time pressure and complex strategic spaces, where identifying partner behaviors and selecting suitable responses is difficult.\nIn this work, we introduce a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a broad range of potential partner strategies in real-time. \nOur approach encodes strategies with a variational autoencoder to learn a latent strategy space from agent trajectory data, identifies distinct strategy types through clustering, and trains a cooperator agent conditioned on these clusters by generating partners of each strategy type.\nFor online adaptation to novel partners, we leverage a fixed-share regret minimization algorithm that dynamically infers and adjusts the partner's strategy estimation during interaction.\nWe evaluate our method in a modified version of the Overcooked domain, a complex collaborative cooking environment that requires effective coordination among two players with a diverse potential strategy space.\nThrough these experiments and an online user study, we demonstrate that our proposed agent achieves state of the art performance compared to existing baselines when paired with novel human, and agent teammates.", "bibtex": "@inproceedings{\nli2025adaptively,\ntitle={Adaptively Coordinating with Novel Partners via Learned Latent Strategies},\nauthor={Benjamin Li and Shuyang Shi and Lucia Romero and Huao Li and Yaqi Xie and Woojun Kim and Stefanos Nikolaidis and Charles Michael Lewis and Katia P. Sycara and Simon Stepputtis},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=M1DA33qucy}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Adaptively Coordinating with Novel Partners via Learned Latent Strategies.pdf", "retrieved_at": "2025-11-12T03:20:45.587845Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Red-Teaming LLM Multi-Agent Systems via Communication Attacks", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Pengfei He", "Yuping Lin", "Shen Dong", "Han Xu", "Yue Xing", "Hui Liu"], "affinity_score": 0.6553, "link": "https://aclanthology.org/2025.findings-acl.349/", "abstract": "Large Language Model-based Multi-Agent Systems (LLM-MAS) have revolutionized complex problem-solving capability by enabling sophisticated agent collaboration through message-based communications. While the communication framework is crucial for agent coordination, it also introduces a critical yet unexplored security vulnerability. In this work, we introduce Agent-in-the-Middle (AiTM), a novel attack that exploits the fundamental communication mechanisms in LLM-MAS by intercepting and manipulating inter-agent messages. Unlike existing attacks that compromise individual agents, AiTM demonstrates how an adversary can compromise entire multi-agent systems by only manipulating the messages passing between agents. To enable the attack under the challenges of limited control and role-restricted communication format, we develop an LLM-powered adversarial agent with a reflection mechanism that generates contextually-aware malicious instructions. Our comprehensive evaluation across various frameworks, communication structures, and real-world applications demonstrates that LLM-MAS is vulnerable to communication-based attacks, highlighting the need for robust security measures in multi-agent systems.", "bibtex": "@inproceedings{he-etal-2025-red,\n    title = \"Red-Teaming {LLM} Multi-Agent Systems via Communication Attacks\",\n    author = \"He, Pengfei  and\n      Lin, Yuping  and\n      Dong, Shen  and\n      Xu, Han  and\n      Xing, Yue  and\n      Liu, Hui\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.349/\",\n    doi = \"10.18653/v1/2025.findings-acl.349\",\n    pages = \"6726--6747\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings Red-Teaming LLM Multi-Agent Systems via Communication Attacks.pdf", "retrieved_at": "2025-11-12T03:20:45.836620Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Mengkang Hu", "Tianxing Chen", "Qiguang Chen (陈麒光)", "Yao Mu", "Wenqi Shao", "Ping Luo"], "affinity_score": 0.6552, "link": "https://aclanthology.org/2025.acl-long.1575/", "abstract": "Large Language Model (LLM)-based agents exhibit significant potential across various domains, operating as interactive systems that process environmental observations to generate executable actions for target tasks. The effectiveness of these agents is significantly influenced by their memory mechanism, which records historical experiences as sequences of action-observation pairs. We categorize memory into two types: cross-trial memory, accumulated across multiple attempts, and in-trial memory (working memory), accumulated within a single attempt. While considerable research has optimized performance through cross-trial memory, the enhancement of agent performance through improved working memory utilization remains underexplored. Instead, existing approaches often involve directly inputting entire historical action-observation pairs into LLMs, leading to redundancy in long-horizon tasks. Inspired by human problem-solving strategies, this paper introduces HiAgent, a framework that leverages subgoals as memory chunks to manage the working memory of LLM-based agents hierarchically. Specifically, HiAgent prompts LLMs to formulate subgoals before generating executable actions and enables LLMs to decide proactively to replace previous subgoals with summarized observations, retaining only the action-observation pairs relevant to the current subgoal. Experimental results across five long-horizon tasks demonstrate that HiAgent achieves a twofold increase in success rate and reduces the average number of steps required by 3.8. Additionally, our analysis shows that HiAgent consistently improves performance across various steps, highlighting its robustness and generalizability. Code is available in this URL: https://github.com/HiAgent2024/HiAgent", "bibtex": "@inproceedings{hu-etal-2025-hiagent,\n    title = \"{H}i{A}gent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model\",\n    author = \"Hu, Mengkang  and\n      Chen, Tianxing  and\n      Chen, Qiguang  and\n      Mu, Yao  and\n      Shao, Wenqi  and\n      Luo, Ping\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1575/\",\n    doi = \"10.18653/v1/2025.acl-long.1575\",\n    pages = \"32779--32798\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long HiAgent_ Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model.pdf", "retrieved_at": "2025-11-12T03:20:46.217281Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AutoToM: Scaling Model-based Mental Inference via Automated Agent Modeling", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Zhining Zhang", "Chuanyang Jin", "Mung Yao Jia", "Shunchi Zhang", "Tianmin Shu"], "affinity_score": 0.6549, "link": "https://openreview.net/pdf/97d508cdb6040e0326e1f3e82a7473020de10424.pdf", "abstract": "Theory of Mind (ToM), the ability to understand people's minds based on their behavior, is key to developing socially intelligent agents. Current approaches to ToM reasoning either rely on prompting Large Language Models (LLMs), which are prone to systematic errors, or use handcrafted, rigid agent models for model-based inference, which are more robust but fail to generalize across domains. In this work, we introduce\nAutoToM\n, an automated agent modeling method for scalable, robust, and interpretable mental inference. Given a ToM problem,\nAutoToM\nfirst proposes an initial agent model and then performs automated Bayesian inverse planning based on this model, leveraging an LLM backend. Guided by inference uncertainty, it iteratively refines the model by introducing additional mental variables and/or incorporating more timesteps in the context. Across five diverse benchmarks,\nAutoToM\noutperforms existing ToM methods and even large reasoning models. Additionally, we show that\nAutoToM\ncan produce human‐like confidence estimates and enable online mental inference for embodied decision-making.", "bibtex": "@inproceedings{\nzhang2025autotom,\ntitle={AutoToM: Scaling Model-based Mental Inference via Automated Agent Modeling},\nauthor={Zhining Zhang and Chuanyang Jin and Mung Yao Jia and Shunchi Zhang and Tianmin Shu},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=oeZZusZheP}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Spotlight AutoToM_ Scaling Model-based Mental Inference via Automated Agent Modeling.pdf", "retrieved_at": "2025-11-12T03:20:51.534054Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Yifan Song", "Weimin Xiong", "Xiutian Zhao", "Dawei Zhu", "Wenhao Wu", "Ke Wang", "Cheng Li", "Wei Peng", "Sujian Li (李素建)"], "affinity_score": 0.6546, "link": "https://aclanthology.org/2024.findings-emnlp.116/", "abstract": "Fine-tuning on agent-environment interaction trajectory data holds significant promise for surfacing generalized agent capabilities in open-source large language models (LLMs). In this work, we introduce AgentBank, by far the largest trajectory tuning data collection featuring more than 50k diverse high-quality interaction trajectories which comprises 16 tasks covering five distinct agent skill dimensions. Leveraging a novel annotation pipeline, we are able to scale the annotated trajectories and generate a trajectory dataset with minimized difficulty bias. Furthermore, we fine-tune LLMs on AgentBank to get a series of agent models, Samoyed. Our comparative experiments demonstrate the effectiveness of scaling the interaction trajectory data to acquire generalized agent capabilities. Additional studies also reveal some key observations regarding trajectory tuning and agent skill generalization.", "bibtex": "@inproceedings{song-etal-2024-agentbank,\n    title = \"{A}gent{B}ank: Towards Generalized {LLM} Agents via Fine-Tuning on 50000+ Interaction Trajectories\",\n    author = \"Song, Yifan  and\n      Xiong, Weimin  and\n      Zhao, Xiutian  and\n      Zhu, Dawei  and\n      Wu, Wenhao  and\n      Wang, Ke  and\n      Li, Cheng  and\n      Peng, Wei  and\n      Li, Sujian\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.116/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.116\",\n    pages = \"2124--2141\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings AgentBank_ Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories.pdf", "retrieved_at": "2025-11-12T03:20:51.804997Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Improving Retrieval-Augmented Generation through Multi-Agent Reinforcement Learning", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Yiqun Chen", "Lingyong Yan", "Weiwei Sun", "Xinyu Ma", "Yi Zhang", "Shuaiqiang Wang", "Dawei Yin", "Yiming Yang", "Jiaxin Mao"], "affinity_score": 0.6542, "link": "https://openreview.net/pdf/0bc82f5b29d7122b8b021ba8fad9f4e5ce031dd8.pdf", "abstract": "Retrieval-augmented generation (RAG) is widely utilized to incorporate external knowledge into large language models, thereby enhancing factuality and reducing hallucinations in question-answering (QA) tasks. A standard RAG pipeline consists of several components, such as query rewriting, document retrieval, document filtering, and answer generation. However, these components are typically optimized separately through supervised fine-tuning, which can lead to misalignments between the objectives of individual components and the overarching aim of generating accurate answers. Although recent efforts have explored using reinforcement learning (RL) to optimize specific RAG components, these approaches often focus on simple pipelines with only two components or do not adequately address the complex interdependencies and collaborative interactions among the modules. To overcome these limitations, we propose treating the complex RAG pipeline with multiple components as a multi-agent cooperative task, in which each component can be regarded as an RL agent. Specifically, we present MMOA-RAG\\footnote{The code of MMOA-RAG is on \\url{https://github.com/chenyiqun/MMOA-RAG}.}, \\textbf{M}ulti-\\textbf{M}odule joint \\textbf{O}ptimization \\textbf{A}lgorithm for \\textbf{RAG}, which employs multi-agent reinforcement learning to harmonize all agents' goals toward a unified reward, such as the F1 score of the final answer. Experiments conducted on various QA benchmarks demonstrate that MMOA-RAG effectively boost the overall performance of the pipeline and outperforms existing baselines. Furthermore, comprehensive ablation studies validate the contributions of individual components and demonstrate MMOA-RAG can be adapted to different RAG pipelines and benchmarks.", "bibtex": "@inproceedings{\nchen2025improving,\ntitle={Improving Retrieval-Augmented Generation through Multi-Agent Reinforcement Learning},\nauthor={Yiqun Chen and Lingyong Yan and Weiwei Sun and Xinyu Ma and Yi Zhang and Shuaiqiang Wang and Dawei Yin and Yiming Yang and Jiaxin Mao},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=9Ia0KiVAut}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Improving Retrieval-Augmented Generation through Multi-Agent Reinforcement Learning.pdf", "retrieved_at": "2025-11-12T03:21:33.411275Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "X-WebAgentBench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Peng Wang", "Ruihan Tao", "Qiguang Chen (陈麒光)", "Mengkang Hu", "Libo Qin"], "affinity_score": 0.6542, "link": "https://aclanthology.org/2025.findings-acl.988/", "abstract": "Recently, large language model (LLM)-based agents have achieved significant success in interactive environments, attracting significant academic and industrial attention. Despite these advancements, current research predominantly focuses on English scenarios. In reality, there are over 7,000 languages worldwide, all of which demand access to comparable agentic services. Nevertheless, the development of language agents remains inadequate for meeting the diverse requirements of multilingual agentic applications. To fill this gap, we introduce X-WebAgentBench, a novel multilingual agent benchmark in an interactive web environment, which evaluates the planning and interaction performance of language agents across multiple languages, thereby contributing to the advancement of global agent intelligence. Additionally, we assess the performance of various LLMs and cross-lingual alignment methods, examining their effectiveness in enhancing agents. Our findings reveal that even advanced models like GPT-4o, when combined with cross-lingual techniques, fail to achieve satisfactory results. We hope that X-WebAgentBench can serve as a valuable benchmark for multilingual agent scenario in real-world applications.", "bibtex": "@inproceedings{wang-etal-2025-x,\n    title = \"{X}-{W}eb{A}gent{B}ench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System\",\n    author = \"Wang, Peng  and\n      Tao, Ruihan  and\n      Chen, Qiguang  and\n      Hu, Mengkang  and\n      Qin, Libo\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.988/\",\n    doi = \"10.18653/v1/2025.findings-acl.988\",\n    pages = \"19320--19335\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings X-WebAgentBench_ A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System.pdf", "retrieved_at": "2025-11-12T03:21:33.649833Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities", "venue": "NAACL 2025 Findings", "year": "2025", "authors": ["Jiarui Lu", "Thomas Holleis", "Yizhe Zhang", "Bernhard Aumayer", "Feng Nan", "Haoping Bai", "Shuang Ma", "Shen Ma", "Mengyu Li", "Guoli Yin", "Zirui Wang", "Ruoming Pang"], "affinity_score": 0.654, "link": "https://aclanthology.org/2025.findings-naacl.65/", "abstract": "Recent large language models (LLMs) advancements sparked a growing research interest in tool assisted LLMs solving real-world challenges, which calls for comprehensive evaluation of tool-use capabilities. While previous works focused on either evaluating over stateless web services (RESTful API), based on a single turn user prompt, or an off-policy dialog trajectory, ToolSandbox includes stateful tool execution, implicit state dependencies between tools, a built-in user simulator supporting on-policy conversational evaluation and a dynamic evaluation strategy for intermediate and final milestones over arbitrary trajectory. We show that open source and proprietary models has a significant performance gap, and complex tasks like State Dependency, Canonicalization and Insufficient Information defined in ToolSandbox are challenging even the most capable SOTA LLMs, providing brand-new insights to tool-use LLM capabilities. Datasets and evaluation scripts of ToolSandbox are released at\n.", "bibtex": "@inproceedings{lu-etal-2025-toolsandbox,\n    title = \"{T}ool{S}andbox: A Stateful, Conversational, Interactive Evaluation Benchmark for {LLM} Tool Use Capabilities\",\n    author = \"Lu, Jiarui  and\n      Holleis, Thomas  and\n      Zhang, Yizhe  and\n      Aumayer, Bernhard  and\n      Nan, Feng  and\n      Bai, Haoping  and\n      Ma, Shuang  and\n      Ma, Shen  and\n      Li, Mengyu  and\n      Yin, Guoli  and\n      Wang, Zirui  and\n      Pang, Ruoming\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Findings of the Association for Computational Linguistics: NAACL 2025\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-naacl.65/\",\n    doi = \"10.18653/v1/2025.findings-naacl.65\",\n    pages = \"1160--1183\",\n    ISBN = \"979-8-89176-195-7\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Findings ToolSandbox_ A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities.pdf", "retrieved_at": "2025-11-12T03:21:34.530738Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Data Interpreter: An LLM Agent for Data Science", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Sirui Hong", "Yizhang Lin", "Bang Liu", "Bangbang Liu", "Binhao Wu (吴斌浩)", "Ceyao Zhang", "Danyang Li", "Jiaqi Chen", "Jiayi Zhang", "Jinlin Wang", "Li Zhang", "Lingyao Zhang", "Min Yang", "Mingchen Zhuge", "Taicheng Guo", "Tuo Zhou", "Wei Tao", "Robert Tang", "Xiangtao Lu", "Xiawu Zheng", "Xinbing Liang", "Yaying Fei", "Yuheng Cheng", "Yongxin Ni", "Zhibin Gou", "Zongze Xu", "Yuyu Luo", "Chenglin Wu"], "affinity_score": 0.6537, "link": "https://aclanthology.org/2025.findings-acl.1016/", "abstract": "Large Language Model (LLM)-based agents have excelled in various domains but face significant challenges when applied to data science workflows due to their complex, multi-stage nature. Current LLM-based agents struggle with non-linear relationships, recursive dependencies, implicit data- and logic-dependent reasoning, and managing extensive context. In this paper, we introduce Data Interpreter, an LLM-based agent that addresses these challenges through hierarchical graph-based modeling to represent the complexity and a progressive strategy for step-by-step verification, refinement, and consistent context management. Extensive experiments confirm the effectiveness of Data Interpreter. On InfiAgent-DABench, it boosts performance by 25% (from 75.9% to 94.9%), and on machine learning and open-ended tasks, it lifts accuracy from 88% to 95% and from 60% to 97%, respectively. Moreover, our method surpasses state-of-the-art baselines by 26% on the MATH dataset. We will release the code upon publication.", "bibtex": "@inproceedings{hong-etal-2025-data,\n    title = \"Data Interpreter: An {LLM} Agent for Data Science\",\n    author = \"Hong, Sirui  and\n      Lin, Yizhang  and\n      Liu, Bang  and\n      Liu, Bangbang  and\n      Wu, Binhao  and\n      Zhang, Ceyao  and\n      Li, Danyang  and\n      Chen, Jiaqi  and\n      Zhang, Jiayi  and\n      Wang, Jinlin  and\n      Zhang, Li  and\n      Zhang, Lingyao  and\n      Yang, Min  and\n      Zhuge, Mingchen  and\n      Guo, Taicheng  and\n      Zhou, Tuo  and\n      Tao, Wei  and\n      Tang, Robert  and\n      Lu, Xiangtao  and\n      Zheng, Xiawu  and\n      Liang, Xinbing  and\n      Fei, Yaying  and\n      Cheng, Yuheng  and\n      Ni, Yongxin  and\n      Gou, Zhibin  and\n      Xu, Zongze  and\n      Luo, Yuyu  and\n      Wu, Chenglin\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1016/\",\n    doi = \"10.18653/v1/2025.findings-acl.1016\",\n    pages = \"19796--19821\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings Data Interpreter_ An LLM Agent for Data Science.pdf", "retrieved_at": "2025-11-12T03:21:35.466429Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "The Behavior Gap: Evaluating Zero-shot LLM Agents in Complex Task-Oriented Dialogs", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Avinash Baidya", "Kamalika Das", "Xiang Gao"], "affinity_score": 0.6537, "link": "https://aclanthology.org/2025.findings-acl.1205/", "abstract": "Large Language Model (LLM)-based agents have significantly impacted Task-Oriented Dialog Systems (TODS) but continue to face notable performance challenges, especially in zero-shot scenarios. While prior work has noted this performance gap, the behavioral factors driving the performance gap remain under-explored. This study proposes a comprehensive evaluation framework to quantify the behavior gap between AI agents and human experts, focusing on discrepancies in dialog acts, tool usage, and knowledge utilization. Our findings reveal that this behavior gap is a critical factor negatively impacting the performance of LLM agents. Notably, as task complexity increases, the behavior gap widens (correlation: 0.963), leading to a degradation of agent performance on complex task-oriented dialogs. For the most complex task in our study, even the GPT-4o-based agent exhibits low alignment with human behavior, with low F1 scores for dialog acts (0.464), excessive and often misaligned tool usage with a F1 score of 0.139, and ineffective usage of external knowledge. Reducing such behavior gaps leads to significant performance improvement (24.3% on average). This study highlights the importance of comprehensive behavioral evaluations and improved alignment strategies to enhance the effectiveness of LLM-based TODS in handling complex tasks.", "bibtex": "@inproceedings{baidya-etal-2025-behavior,\n    title = \"The Behavior Gap: Evaluating Zero-shot {LLM} Agents in Complex Task-Oriented Dialogs\",\n    author = \"Baidya, Avinash  and\n      Das, Kamalika  and\n      Gao, Xiang\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1205/\",\n    doi = \"10.18653/v1/2025.findings-acl.1205\",\n    pages = \"23455--23472\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings The Behavior Gap_ Evaluating Zero-shot LLM Agents in Complex Task-Oriented Dialogs.pdf", "retrieved_at": "2025-11-12T03:21:35.719740Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Can External Validation Tools Improve Annotation Quality for LLM-as-a-Judge?", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Arduin Findeis", "Floris Weers", "Guoli Yin", "Ke Ye", "Ruoming Pang", "Tom Gunter"], "affinity_score": 0.6535, "link": "https://aclanthology.org/2025.acl-long.779/", "abstract": "Pairwise preferences over model responses are widely collected to evaluate and provide feedback to large language models (LLMs). Given two alternative model responses to the same input, a human or AI annotator selects the “better” response. This approach can provide feedback for domains where other hard-coded metrics are difficult to obtain (e.g., chat response quality), thereby helping model evaluation or training. However, for some domains high-quality pairwise comparisons can be tricky to obtain - from AI and humans. For example, for responses with many factual statements, annotators may disproportionately weigh writing quality rather than underlying facts. In this work, we explore augmenting standard AI annotator systems with additional tools to improve performance on three challenging response domains: long-form factual, math and code tasks. We propose a tool-using agentic system to provide higher quality feedback on these domains. Our system uses web-search and code execution to ground itself based on external validation, independent of the LLM’s internal knowledge and biases. We provide extensive experimental results evaluating our method across the three targeted response domains as well as general annotation tasks, using RewardBench (incl. AlpacaEval and LLMBar), RewardMath, as well as three new datasets for domains with saturated pre-existing datasets. Our results indicate that external tools can indeed improve performance in many, but not all, cases. More generally, our experiments highlight the sensitivity of performance to simple parameters (e.g., prompt) and the need for improved (non-saturated) annotator benchmarks. We share our code at https://github.com/apple/ml-agent-evaluator.", "bibtex": "@inproceedings{findeis-etal-2025-external,\n    title = \"Can External Validation Tools Improve Annotation Quality for {LLM}-as-a-Judge?\",\n    author = \"Findeis, Arduin  and\n      Weers, Floris  and\n      Yin, Guoli  and\n      Ye, Ke  and\n      Pang, Ruoming  and\n      Gunter, Tom\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.779/\",\n    doi = \"10.18653/v1/2025.acl-long.779\",\n    pages = \"15997--16020\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Can External Validation Tools Improve Annotation Quality for LLM-as-a-Judge_.pdf", "retrieved_at": "2025-11-12T03:21:36.029005Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents", "venue": "ICML 2025 Oral", "year": "2025", "authors": ["Rui Yang", "Hanyang Chen", "Junyu Zhang", "Mark Zhao", "Cheng Qian", "Kangrui Wang", "Qineng Wang", "Teja Venkat Koripella", "Marziyeh Movahedi", "Manling Li", "Heng Ji", "Huan Zhang", "Tong Zhang"], "affinity_score": 0.6534, "link": "https://openreview.net/pdf/b9e775a028b2a809c09d3c36562f179b9cac55a4.pdf", "abstract": "Leveraging Multi-modal Large Language Models (MLLMs) to create embodied agents offers a promising avenue for tackling real-world tasks. While language-centric embodied agents have garnered substantial attention, MLLM-based embodied agents remain underexplored due to the lack of comprehensive evaluation frameworks. To bridge this gap, we introduce EmbodiedBench, an extensive benchmark designed to evaluate vision-driven embodied agents.\nEmbodiedBench features: (1) a diverse set of 1,128 testing tasks across four environments, ranging from high-level semantic tasks (e.g., household) to low-level tasks involving atomic actions (e.g., navigation and manipulation); and (2) six meticulously curated subsets evaluating essential agent capabilities like commonsense reasoning, complex instruction understanding, spatial awareness, visual perception, and long-term planning.\nThrough extensive experiments, we evaluated 24 leading proprietary and open-source MLLMs within EmbodiedBench. Our findings reveal that: MLLMs excel at high-level tasks but struggle with low-level manipulation, with the best model, GPT-4o, scoring only $28.9\\%$ on average. EmbodiedBench provides a multifaceted standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance MLLM-based embodied agents. Our code and dataset are available at\nhttps://embodiedbench.github.io\n.", "bibtex": "@inproceedings{\nyang2025embodiedbench,\ntitle={EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents},\nauthor={Rui Yang and Hanyang Chen and Junyu Zhang and Mark Zhao and Cheng Qian and Kangrui Wang and Qineng Wang and Teja Venkat Koripella and Marziyeh Movahedi and Manling Li and Heng Ji and Huan Zhang and Tong Zhang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=DgGF2LEBPS}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Oral EmbodiedBench_ Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents.pdf", "retrieved_at": "2025-11-12T03:21:37.012095Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MAT-Agent: Adaptive Multi-Agent Training Optimization", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Jusheng Zhang", "Kaitong Cai", "Yijia Fan", "Ningyuan Liu", "Keze Wang"], "affinity_score": 0.6529, "link": "https://openreview.net/pdf/f812e65f877761cb57d994cd3c97d5b1b748442b.pdf", "abstract": "We propose a novel collaborative multi-agent optimization framework for adaptive training in multi-label image classification, fundamentally advancing beyond static decision rules and isolated automation. Our method deploys a set of distributed, task-specific agents, each responsible for dynamically orchestrating critical training components—including data augmentation, optimization methods, learning rate schedules, and loss functions—according to evolving visual-semantic relationships and training states. Each agent employs an advanced non-stationary multi-armed bandit algorithm, integrating both $\\epsilon$-greedy and upper confidence bound strategies, to judiciously balance exploration with exploitation throughout the training lifecycle. A hierarchical composite reward mechanism synergizes overall classification accuracy, rare class recognition, and training stability, fostering both independent optimization and implicit collaborative behavior among agents. The framework further leverages refined techniques such as dual-rate exponential moving average smoothing and structured mixed-precision training to enhance robustness and computational efficiency. Extensive experiments across benchmarks including Pascal VOC, COCO, Yeast, and Mediamill demonstrate that our approach achieves superior mean average precision and rare-class F1 scores compared to state-of-the-art methods, while also exhibiting rapid convergence and remarkable cross-domain generalization. Our results indicate that collaborative multi-agent adaptive optimization offers a scalable and principled solution for self-optimizing deep learning in complex multi-label scenarios.", "bibtex": "@inproceedings{\nzhang2025matagent,\ntitle={{MAT}-Agent: Adaptive Multi-Agent Training Optimization},\nauthor={Jusheng Zhang and Kaitong Cai and Yijia Fan and Ningyuan Liu and Keze Wang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=YDWRTYgR79}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster MAT-Agent_ Adaptive Multi-Agent Training Optimization.pdf", "retrieved_at": "2025-11-12T03:21:37.525156Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Agent-to-Sim: Learning Interactive Behavior Models from Casual Longitudinal Videos", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Gengshan Yang", "Andrea Bajcsy", "Shunsuke Saito", "Angjoo Kanazawa"], "affinity_score": 0.6529, "link": "https://openreview.net/pdf/820d935ac808829b5fa49bdd152286c2ae6c3054.pdf", "abstract": "We present Agent-to-Sim (ATS), a framework for learning interactive behavior models of 3D agents from casual longitudinal video collections. Different from prior works that rely on marker-based tracking and multiview cameras, ATS learns natural behaviors of animal agents non-invasively through video observations recorded over a long time-span (e.g. a month) in a single environment.\nModeling 3D behavior of an agent requires persistent 3D tracking (e.g., knowing which point corresponds to which) over a long time period. To obtain such data, we develop a coarse-to-fine registration method that tracks the agent and the camera over time through a canonical 3D space, resulting in a complete and persistent spacetime 4D representation. We then train a generative model of agent behaviors using paired data of perception and motion of an agent queried from the 4D reconstruction. ATS enables real-to-sim transfer from video recordings of an agent to an interactive behavior simulator. We demonstrate results on animals given monocular RGBD videos captured by a smartphone. Project page: gengshan-y.github.io/agent2sim-www.", "bibtex": "@inproceedings{\nyang2025agenttosim,\ntitle={Agent-to-Sim: Learning Interactive Behavior Models from Casual Longitudinal Videos},\nauthor={Gengshan Yang and Andrea Bajcsy and Shunsuke Saito and Angjoo Kanazawa},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=y80D4IojuY}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Agent-to-Sim_ Learning Interactive Behavior Models from Casual Longitudinal Videos.pdf", "retrieved_at": "2025-11-12T03:21:40.732862Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "QuBE: Question-based Belief Enhancement for Agentic LLM Reasoning", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Minsoo Kim", "Jongyoon Kim", "Jihyuk Kim", "Seung-won Hwang"], "affinity_score": 0.6527, "link": "https://aclanthology.org/2024.emnlp-main.1193/", "abstract": "Despite advancements in Large Language Models (LLMs), many complex tasks are not easily solved in a single inference step, requiring the use of agentic LLMs in interactive environments. However, agentic LLMs suffer from a phenomenon known as reasoning derailment, due to the indiscriminate incorporation of observations from partially observable environments. We introduce QuBE, a method that enhances agents’ focus on task-relevant contexts, by constructing a belief state via question answering. We validate QuBE through experiments in two agentic LLM scenarios with partial observability: 1) a canonical interactive decision-making scenario using text-based game engines, and 2) an interactive retrieval-augmented generation (RAG) scenario using search engines. In the AlfWorld text-based game, QuBE outperforms established baselines by substantial margins, and in the search engine scenario, it achieves marked improvements on the BeIR zero-shot retrieval benchmark. The results demonstrate that QuBE significantly mitigates reasoning derailment, refining the decision-making process of LLM agents in partially observed environments.", "bibtex": "@inproceedings{kim-etal-2024-qube,\n    title = \"{Q}u{BE}: Question-based Belief Enhancement for Agentic {LLM} Reasoning\",\n    author = \"Kim, Minsoo  and\n      Kim, Jongyoon  and\n      Kim, Jihyuk  and\n      Hwang, Seung-won\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.1193/\",\n    doi = \"10.18653/v1/2024.emnlp-main.1193\",\n    pages = \"21403--21423\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main QuBE_ Question-based Belief Enhancement for Agentic LLM Reasoning.pdf", "retrieved_at": "2025-11-12T03:21:41.081725Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Reducing Tool Hallucination via Reliability Alignment", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Hongshen Xu", "Zichen Zhu", "Lei Pan", "Zihan Wang", "Su Zhu", "Da Ma", "Ruisheng Cao", "Lu Chen", "Kai Yu"], "affinity_score": 0.6526, "link": "https://openreview.net/pdf/a6830971d126495933a67327ca0c64b6008cdaae.pdf", "abstract": "Large Language Models (LLMs) have expanded their capabilities beyond language generation to interact with external tools, enabling automation and real-world applications. However, tool hallucinations—where models either select inappropriate tools or misuse them—pose significant challenges, leading to erroneous task execution, increased computational costs, and reduced system reliability. To systematically address this issue, we define and categorize tool hallucinations into two main types: tool selection hallucination and tool usage hallucination. To evaluate and mitigate these issues, we introduce RelyToolBench, which integrates specialized test cases and novel metrics to assess hallucination-aware task success and efficiency. Finally, we propose Relign, a reliability alignment framework that expands the tool-use action space to include indecisive actions, allowing LLMs to defer tool use, seek clarification, or adjust tool selection dynamically. Through extensive experiments, we demonstrate that Relign significantly reduces tool hallucinations, improves task reliability, and enhances the efficiency of LLM tool interactions. The code and data will be publicly available.", "bibtex": "@inproceedings{\nxu2025reducing,\ntitle={Reducing Tool Hallucination via Reliability Alignment},\nauthor={Hongshen Xu and Zichen Zhu and Lei Pan and Zihan Wang and Su Zhu and Da Ma and Ruisheng Cao and Lu Chen and Kai Yu},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=WeOLZmDXyA}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Reducing Tool Hallucination via Reliability Alignment.pdf", "retrieved_at": "2025-11-12T03:21:41.602124Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ADAM: An Embodied Causal Agent in Open-World Environments", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Shu Yu", "Chaochao Lu"], "affinity_score": 0.6525, "link": "https://openreview.net/pdf/6bfe0db3cb5fbdacb1827ee3bab9bd4a55628238.pdf", "abstract": "In open-world environments like Minecraft, existing agents face challenges in continuously learning structured knowledge, particularly causality. These challenges stem from the opacity inherent in black-box models and an excessive reliance on prior knowledge during training, which impair their interpretability and generalization capability. To this end, we introduce ADAM, An emboDied causal Agent in Minecraft, which can autonomously navigate the open world, perceive multimodal context, learn causal world knowledge, and tackle complex tasks through lifelong learning. ADAM is empowered by four key components: 1) an interaction module, enabling the agent to execute actions while recording the interaction processes; 2) a causal model module, tasked with constructing an ever-growing causal graph from scratch, which enhances interpretability and reduces reliance on prior knowledge; 3) a controller module, comprising a planner, an actor, and a memory pool, using the learned causal graph to accomplish tasks; 4) a perception module, powered by multimodal large language models, enabling ADAM to perceive like a human player. Extensive experiments show that ADAM constructs a nearly perfect causal graph from scratch, enabling efficient task decomposition and execution with strong interpretability. Notably, in the modified Minecraft game where no prior knowledge is available, ADAM excels with remarkable robustness and generalization capability. ADAM pioneers a novel paradigm that integrates causal methods and embodied agents synergistically. Our project page is at https://opencausalab.github.io/ADAM.", "bibtex": "@inproceedings{\nyu2025adam,\ntitle={{ADAM}: An Embodied Causal Agent in Open-World Environments},\nauthor={Shu Yu and Chaochao Lu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=Ouu3HnIVBc}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster ADAM_ An Embodied Causal Agent in Open-World Environments.pdf", "retrieved_at": "2025-11-12T03:21:42.298539Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Yifan Xu", "Xiao Liu", "Xueqiao Sun", "Siyi Cheng", "Hao Yu (余浩)", "Hanyu Lai", "Shudan Zhang", "Dan Zhang", "Jie Tang", "Yuxiao Dong"], "affinity_score": 0.6524, "link": "https://aclanthology.org/2025.acl-long.107/", "abstract": "Autonomous agents have become increasingly important for interacting with the real world. Android agents, in particular, have been a frequently-mentioned interaction method. However, existing studies for training and evaluating Android agents lack systematic research on both open-source and closed-source models. In this work, we propose AndroidLab as a systematic Android agent framework. It includes an operation environment with different modalities, action space, and a reproducible benchmark. It supports both large language models (LLMs) and multimodal models (LMMs) in the same action space. AndroidLab benchmark includes predefined Android virtual devices and 138 tasks across nine apps built on these devices. By using the AndroidLab environment, we develop an Android Instruction dataset and train six open-source LLMs and LMMs, lifting the average success rates from 4.59% to 21.50% for LLMs and from 1.93% to 13.28% for LMMs. AndroidLab is open-sourced and publicly available at https://github.com/THUDM/Android-Lab.", "bibtex": "@inproceedings{xu-etal-2025-androidlab,\n    title = \"{A}ndroid{L}ab: Training and Systematic Benchmarking of Android Autonomous Agents\",\n    author = \"Xu, Yifan  and\n      Liu, Xiao  and\n      Sun, Xueqiao  and\n      Cheng, Siyi  and\n      Yu, Hao  and\n      Lai, Hanyu  and\n      Zhang, Shudan  and\n      Zhang, Dan  and\n      Tang, Jie  and\n      Dong, Yuxiao\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.107/\",\n    doi = \"10.18653/v1/2025.acl-long.107\",\n    pages = \"2144--2166\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long AndroidLab_ Training and Systematic Benchmarking of Android Autonomous Agents.pdf", "retrieved_at": "2025-11-12T03:21:42.695430Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "OS-Kairos: Adaptive Interaction for MLLM-Powered GUI Agents", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Pengzhou Cheng", "Zheng Wu", "Zongru Wu", "Tianjie Ju", "Aston Zhang", "Zhuosheng Zhang", "Gongshen Liu"], "affinity_score": 0.6519, "link": "https://aclanthology.org/2025.findings-acl.348/", "abstract": "Autonomous graphical user interface (GUI) agents powered by multimodal large language models have shown great promise. However, a critical yet underexplored issue persists: over-execution , where the agent executes tasks in a fully autonomous way, without adequate assessment of its action confidence to compromise an adaptive human-agent collaboration. This poses substantial risks in complex scenarios, such as those involving ambiguous user instructions, unexpected interruptions, and environmental hijacks. To address the issue, we introduce OS-Kairos , an adaptive GUI agent capable of predicting confidence levels at each interaction step and efficiently deciding whether to act autonomously or seek human intervention. OS-Kairos is developed through two key mechanisms: (i) collaborative probing that annotates confidence scores at each interaction step; (ii) confidence-driven interaction that leverages these confidence scores to elicit the ability of adaptive interaction. Experimental results show that OS-Kairos substantially outperforms existing models on our curated dataset featuring complex scenarios, as well as on established benchmarks such as AITZ and Meta-GUI, with 24.59%~87.29% improvements in task success rate. OS-Kairos facilitates an adaptive human-agent collaboration, prioritizing effectiveness, generality, scalability, and efficiency for real-world GUI interaction. The dataset and codes are available at Anonymous.", "bibtex": "@inproceedings{cheng-etal-2025-os,\n    title = \"{OS}-Kairos: Adaptive Interaction for {MLLM}-Powered {GUI} Agents\",\n    author = \"Cheng, Pengzhou  and\n      Wu, Zheng  and\n      Wu, Zongru  and\n      Ju, Tianjie  and\n      Zhang, Aston  and\n      Zhang, Zhuosheng  and\n      Liu, Gongshen\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.348/\",\n    doi = \"10.18653/v1/2025.findings-acl.348\",\n    pages = \"6701--6725\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings OS-Kairos_ Adaptive Interaction for MLLM-Powered GUI Agents.pdf", "retrieved_at": "2025-11-12T03:21:43.527436Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Agents Robust to Distribution Shifts Learn Causal World Models Even Under Mediation", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Matteo Ceriscioli", "Karthika Mohan"], "affinity_score": 0.6513, "link": "https://openreview.net/pdf/87ab0dc2d16adaecf9fc19c3d53702417f98bf63.pdf", "abstract": "In this work, we prove that agents capable of adapting to distribution shifts must have learned the causal model of their environment even in the presence of mediation. This term describes situations where an agent's actions affect its environment, a dynamic common to most real-world settings. For example, a robot in an industrial plant might interact with tools, move through space, and transform products to complete its task. We introduce an algorithm for eliciting causal knowledge from robust agents using optimal policy oracles, with the flexibility to incorporate prior causal knowledge. We further demonstrate its effectiveness in mediated single-agent scenarios and multi-agent environments. We identify conditions under which the presence of a single robust agent is sufficient to recover the full causal model and derive optimal policies for other agents in the same environment. Finally, we show how to apply these results to sequential decision-making tasks modeled as Partially Observable Markov Decision Processes (POMDPs).", "bibtex": "@inproceedings{\nceriscioli2025agents,\ntitle={Agents Robust to Distribution Shifts Learn Causal World Models Even Under Mediation},\nauthor={Matteo Ceriscioli and Karthika Mohan},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=JvHif4fyeP}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Agents Robust to Distribution Shifts Learn Causal World Models Even Under Mediation.pdf", "retrieved_at": "2025-11-12T03:21:44.100336Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "GUI Agents: A Survey", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Dang Nguyen", "Jian Chen", "Yu Wang (王昱", "王雨)", "Gang Wu", "Namyong Park", "Zhengmian Hu", "Hanjia Lyu", "Junda Wu", "Ryan Aponte", "Yu Xia", "Xintong Li", "Jing Shi", "Hongjie Chen", "Viet Dac Lai", "Zhouhang Xie", "Sungchul Kim", "Ruiyi Zhang", "Tong Yu", "Mehrab Tanjim", "Nesreen K. Ahmed", "Puneet Mathur", "Seunghyun Yoon", "Lina Yao", "Branislav Kveton", "Jihyung Kil", "Thien Huu Nguyen", "Trung Bui", "Tianyi Zhou", "Ryan A. Rossi", "Franck Dernoncourt"], "affinity_score": 0.6511, "link": "https://aclanthology.org/2025.findings-acl.1158/", "abstract": "Graphical User Interface (GUI) agents, powered by Large Foundation Models, have emerged as a transformative approach to automating human-computer interaction. These agents autonomously interact with digital systems via GUIs, emulating human actions such as clicking, typing, and navigating visual elements across diverse platforms. Motivated by the growing interest and fundamental importance of GUI agents, we provide a comprehensive survey that categorizes their benchmarks, evaluation metrics, architectures, and training methods. We propose a unified framework that delineates their perception, reasoning, planning, and acting capabilities. Furthermore, we identify important open challenges and discuss key future directions. Finally, this work serves as a basis for practitioners and researchers to gain an intuitive understanding of current progress, techniques, benchmarks, and critical open problems that remain to be addressed.", "bibtex": "@inproceedings{nguyen-etal-2025-gui,\n    title = \"{GUI} Agents: A Survey\",\n    author = \"Nguyen, Dang  and\n      Chen, Jian  and\n      Wang, Yu  and\n      Wu, Gang  and\n      Park, Namyong  and\n      Hu, Zhengmian  and\n      Lyu, Hanjia  and\n      Wu, Junda  and\n      Aponte, Ryan  and\n      Xia, Yu  and\n      Li, Xintong  and\n      Shi, Jing  and\n      Chen, Hongjie  and\n      Lai, Viet Dac  and\n      Xie, Zhouhang  and\n      Kim, Sungchul  and\n      Zhang, Ruiyi  and\n      Yu, Tong  and\n      Tanjim, Mehrab  and\n      Ahmed, Nesreen K.  and\n      Mathur, Puneet  and\n      Yoon, Seunghyun  and\n      Yao, Lina  and\n      Kveton, Branislav  and\n      Kil, Jihyung  and\n      Nguyen, Thien Huu  and\n      Bui, Trung  and\n      Zhou, Tianyi  and\n      Rossi, Ryan A.  and\n      Dernoncourt, Franck\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1158/\",\n    doi = \"10.18653/v1/2025.findings-acl.1158\",\n    pages = \"22522--22538\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings GUI Agents_ A Survey.pdf", "retrieved_at": "2025-11-12T03:21:44.332131Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Qwen2.5-xCoder: Multi-Agent Collaboration for Multilingual Code Instruction Tuning", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Jian Yang", "Wei Zhang", "Yibo Miao", "Shanghaoran Quan", "Zhenhe Wu", "Qiyao Peng", "Liqun Yang", "Tianyu Liu", "Zeyu Cui", "Binyuan Hui", "Junyang Lin"], "affinity_score": 0.6511, "link": "https://aclanthology.org/2025.acl-long.642/", "abstract": "Recent advancement in code understanding and generation demonstrates that code LLMs fine-tuned on a high-quality instruction dataset can gain powerful capabilities to address wide-ranging code-related tasks. However, most previous existing methods mainly view each programming language in isolation and ignore the knowledge transfer among different programming languages. To bridge the gap among different programming languages, we introduce a novel multi-agent collaboration framework to enhance multilingual instruction tuning for code LLMs, where multiple language-specific intelligent agent components with generation memory work together to transfer knowledge from one language to another efficiently and effectively. Specifically, we first generate the language-specific instruction data from the code snippets and then provide the generated data as the seed data for language-specific agents. Multiple language-specific agents discuss and collaborate to formulate a new instruction and its corresponding solution (A new programming language or existing programming language), To further encourage the cross-lingual transfer, each agent stores its generation history as memory and then summarizes its merits and faults. Finally, the high-quality multilingual instruction data is used to encourage knowledge transfer among different programming languages to train Qwen2.5-xCoder. Experimental results on multilingual programming benchmarks demonstrate the superior performance of Qwen2.5-xCoder in sharing common knowledge, highlighting its potential to reduce the cross-lingual gap.", "bibtex": "@inproceedings{yang-etal-2025-qwen2,\n    title = \"Qwen2.5-x{C}oder: Multi-Agent Collaboration for Multilingual Code Instruction Tuning\",\n    author = \"Yang, Jian  and\n      Zhang, Wei  and\n      Miao, Yibo  and\n      Quan, Shanghaoran  and\n      Wu, Zhenhe  and\n      Peng, Qiyao  and\n      Yang, Liqun  and\n      Liu, Tianyu  and\n      Cui, Zeyu  and\n      Hui, Binyuan  and\n      Lin, Junyang\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.642/\",\n    doi = \"10.18653/v1/2025.acl-long.642\",\n    pages = \"13121--13131\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Qwen2.5-xCoder_ Multi-Agent Collaboration for Multilingual Code Instruction Tuning.pdf", "retrieved_at": "2025-11-12T03:21:44.594387Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MALinZero: Efficient Low-Dimensional Search for Mastering Complex Multi-Agent Planning", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Sizhe Tang", "Jiayu Chen", "Tian Lan"], "affinity_score": 0.651, "link": "https://openreview.net/pdf/8e363493ff9d9b3fa837f8d6bb3198fa13ba65f4.pdf", "abstract": "Monte Carlo Tree Search (MCTS), which leverages Upper Confidence Bound for Trees (UCTs) to balance exploration and exploitation through randomized sampling, is instrumental to solving complex planning problems. However, for multi-agent planning, MCTS is confronted with a large combinatorial action space that often grows exponentially with the number of agents. As a result, the branching factor of MCTS during tree expansion also increases exponentially, making it very difficult to efficiently explore and exploit during tree search. To this end, we propose MALinZero, a new approach to leverage low-dimensional representational structures on joint-action returns and enable efficient MCTS in complex multi-agent planning. Our solution can be viewed as projecting the joint-action returns into the low-dimensional space representable using a contextual linear bandit problem formulation. We solve the contextual linear bandit problem with convex and $\\mu$-smooth loss functions -- in order to place more importance on better joint actions and mitigate potential representational limitations -- and derive a linear Upper Confidence Bound applied to trees (LinUCT) to enable novel multi-agent exploration and exploitation in the low-dimensional space. We analyze the regret of MALinZero for low-dimensional reward functions and propose an $(1-\\tfrac1e)$-approximation algorithm for the joint action selection by maximizing a sub-modular objective. MALinZero demonstrates state-of-the-art performance on multi-agent benchmarks such as matrix games, SMAC, and SMACv2, outperforming both model-based and model-free multi-agent reinforcement learning baselines with faster learning speed and better performance.", "bibtex": "@inproceedings{\ntang2025malinzero,\ntitle={{MAL}inZero: Efficient Low-Dimensional Search for Mastering Complex Multi-Agent Planning},\nauthor={Sizhe Tang and Jiayu Chen and Tian Lan},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=Rxdon7jWni}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster MALinZero_ Efficient Low-Dimensional Search for Mastering Complex Multi-Agent Planning.pdf", "retrieved_at": "2025-11-12T03:21:45.187704Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AgentMove: A Large Language Model based Agentic Framework for Zero-shot Next Location Prediction", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Jie Feng", "Yuwei Du", "Jie Zhao", "Yong Li"], "affinity_score": 0.651, "link": "https://aclanthology.org/2025.naacl-long.61/", "abstract": "Next location prediction plays a crucial role in various real-world applications. Recently, due to the limitation of existing deep learning methods, attempts have been made to apply large language models (LLMs) to zero-shot next location prediction task. However, they directly generate the final output using LLMs without systematic design, which limits the potential of LLMs to uncover complex mobility patterns and underestimates their extensive reserve of global geospatial knowledge. In this paper, we introduce AgentMove, a systematic agentic prediction framework to achieve generalized next location prediction. In AgentMove, we first decompose the mobility prediction task and design specific modules to complete them, including spatial-temporal memory for individual mobility pattern mining, world knowledge generator for modeling the effects of urban structure and collective knowledge extractor for capturing the shared patterns among population. Finally, we combine the results of three modules and conduct a reasoning step to generate the final predictions. Extensive experiments utilizing mobility data from two distinct sources reveal that AgentMove surpasses the leading baseline by 3.33% to 8.57% across 8 out of 12 metrics and it shows robust predictions with various LLMs as base and also less geographical bias across cities. Our codes are available via https://github.com/tsinghua-fib-lab/AgentMove.", "bibtex": "@inproceedings{feng-etal-2025-agentmove,\n    title = \"{A}gent{M}ove: A Large Language Model based Agentic Framework for Zero-shot Next Location Prediction\",\n    author = \"Feng, Jie  and\n      Du, Yuwei  and\n      Zhao, Jie  and\n      Li, Yong\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.61/\",\n    doi = \"10.18653/v1/2025.naacl-long.61\",\n    pages = \"1322--1338\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long AgentMove_ A Large Language Model based Agentic Framework for Zero-shot Next Location Prediction.pdf", "retrieved_at": "2025-11-12T03:21:46.668567Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "RTADev: Intention Aligned Multi-Agent Framework for Software Development", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Jie Liu (刘杰)", "Guohua Wang", "Ronghui Yang", "Jiajie Zeng", "Mengchen Zhao", "Yi Cai"], "affinity_score": 0.6509, "link": "https://aclanthology.org/2025.findings-acl.80/", "abstract": "LLM-based Multi-agent frameworks have shown a great potential in solving real-world software development tasks, where the agents of different roles can communicate much more efficiently than humans. Despite their efficiency, LLM-based agents can hardly fully understand each other, which frequently causes errors during the development process. Moreover, the accumulation of errors could easily lead to the failure of the whole project. In order to reduce such errors, we introduce an intention aligned multi-agent framework RTADev, which utilizes a self-correction mechanism to ensure that all agents work based on a consensus. RTADev mimics human teams where individuals are free to start meetings anytime for reaching agreement. Specifically, RTADev integrates an alignment checking phase and a conditional ad hoc group review phase, so that the errors can be effectively reduced with minimum agent communications. Our experiments on various software development tasks show that RTADev significantly improves the quality of generated software code in terms of executability, structural and functional completeness. The code of our project is available at https://github.com/codeagent-rl/RTADev.", "bibtex": "@inproceedings{liu-etal-2025-rtadev,\n    title = \"{RTAD}ev: Intention Aligned Multi-Agent Framework for Software Development\",\n    author = \"Liu, Jie  and\n      Wang, Guohua  and\n      Yang, Ronghui  and\n      Zeng, Jiajie  and\n      Zhao, Mengchen  and\n      Cai, Yi\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.80/\",\n    doi = \"10.18653/v1/2025.findings-acl.80\",\n    pages = \"1548--1581\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings RTADev_ Intention Aligned Multi-Agent Framework for Software Development.pdf", "retrieved_at": "2025-11-12T03:21:47.065461Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "From Debate to Equilibrium: Belief‑Driven Multi‑Agent LLM Reasoning via Bayesian Nash Equilibrium", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Xie Yi", "Zhanke Zhou", "Chentao Cao", "Qiyu Niu", "Tongliang Liu", "Bo Han"], "affinity_score": 0.6508, "link": "https://openreview.net/pdf/a1eece15699456124c78cf6db973f89168b5b339.pdf", "abstract": "Multi-agent frameworks can substantially boost the reasoning power of large language models (LLMs), but they typically incur heavy computational costs and lack convergence guarantees. To overcome these challenges, we recast multi-LLM coordination as an incomplete-information game and seek a Bayesian Nash equilibrium (BNE), in which each agent optimally responds to its probabilistic beliefs about the strategies of others. We introduce Efficient Coordination via Nash Equilibrium (ECON), a hierarchical reinforcement-learning paradigm that marries distributed reasoning with centralized final output. Under ECON, each LLM independently selects responses that maximize its expected reward, conditioned on its beliefs about co-agents, without requiring costly inter-agent exchanges.\nWe mathematically prove that ECON attains a markedly tighter regret bound than non-equilibrium multi-agent schemes. Empirically, ECON outperforms existing multi-LLM approaches by 11.2% on average across six benchmarks spanning complex reasoning and planning tasks. Further experiments demonstrate ECON’s ability to flexibly incorporate additional models, confirming its scalability and paving the way toward larger, more powerful multi-LLM ensembles. The code is publicly available at: https://github.com/tmlr-group/ECON.", "bibtex": "@inproceedings{\nyi2025from,\ntitle={From Debate to Equilibrium: Belief\\nobreakdash-Driven Multi\\nobreakdash-Agent {LLM} Reasoning via Bayesian Nash Equilibrium},\nauthor={Xie Yi and Zhanke Zhou and Chentao Cao and Qiyu Niu and Tongliang Liu and Bo Han},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=RQwexjUCxm}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster From Debate to Equilibrium_ Belief‑Driven Multi‑Agent LLM Reasoning via Bayesian Nash Equilibrium.pdf", "retrieved_at": "2025-11-12T03:21:47.799696Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Jie Liu", "Pan Zhou", "Yingjun Du", "Ah-Hwee Tan", "Cees G. M. Snoek", "Jan-Jakob Sonke", "Efstratios Gavves"], "affinity_score": 0.6508, "link": "https://openreview.net/pdf/58310c0a0043720fb0a50f8c2c38c08e8a5904d5.pdf", "abstract": "In this work, we address the cooperation problem among large language model (LLM) based embodied agents, where agents must cooperate to achieve a common goal. Previous methods often execute actions extemporaneously and incoherently, without long-term  strategic and cooperative planning, leading to redundant steps, failures, and even serious repercussions in complex tasks like search-and-rescue missions where discussion and cooperative plan are crucial.  To solve this issue, we propose Cooperative Plan Optimization (CaPo) to enhance the cooperation efficiency of LLM-based embodied agents. Inspired by human cooperation schemes, CaPo improves cooperation efficiency with two  phases: 1) meta plan generation, and 2) progress-adaptive meta plan and execution. In the first phase, all agents analyze the task, discuss, and cooperatively create a meta-plan that decomposes the task into subtasks with detailed steps, ensuring a long-term strategic and coherent plan for efficient coordination.  In the second phase, agents execute tasks according to the meta-plan and dynamically adjust it based on their latest progress (e.g., discovering a target object) through multi-turn discussions.  This progress-based adaptation eliminates redundant actions, improving the overall cooperation efficiency of agents. Experimental results on the ThreeDworld Multi-Agent Transport and Communicative Watch-And-Help tasks demonstrate CaPo's much higher task completion rate and efficiency compared with  state-of-the-arts. The code is released at https://github.com/jliu4ai/CaPo.", "bibtex": "@inproceedings{\nliu2025capo,\ntitle={CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation},\nauthor={Jie Liu and Pan Zhou and Yingjun Du and Ah-Hwee Tan and Cees G. M. Snoek and Jan-Jakob Sonke and Efstratios Gavves},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=KRv9NubipP}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster CaPo_ Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation.pdf", "retrieved_at": "2025-11-12T03:21:48.365182Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "The Sample Complexity of Online Strategic Decision Making with Information Asymmetry and Knowledge Transportability", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Jiachen Hu", "Rui Ai", "Han Zhong", "Xiaoyu Chen", "Liwei Wang", "Zhaoran Wang", "Zhuoran Yang"], "affinity_score": 0.6501, "link": "https://openreview.net/pdf/57c9cc365a39179d357eb4b459f2630cf355a53a.pdf", "abstract": "Information asymmetry is a pervasive feature of multi-agent systems, especially evident in economics and social sciences. In these settings, agents tailor their actions based on private information to maximize their rewards. These strategic behaviors often introduce complexities due to confounding variables. Simultaneously, knowledge transportability poses another significant challenge, arising from the difficulties of conducting experiments in target environments. It requires transferring knowledge from environments where empirical data is more readily available. Against these backdrops, this paper explores a fundamental question in online learning: Can we employ non-i.i.d. actions to learn about confounders even when requiring knowledge transfer? We present a sample-efficient algorithm designed to accurately identify system dynamics under information asymmetry and to navigate the challenges of knowledge transfer effectively in reinforcement learning, framed within an online strategic interaction model. Our method provably achieves learning of an $\\epsilon$-optimal policy with a tight sample complexity of $\\tilde{O}(1/\\epsilon^2)$.", "bibtex": "@inproceedings{\nhu2025the,\ntitle={The Sample Complexity of Online Strategic Decision Making with Information Asymmetry and Knowledge Transportability},\nauthor={Jiachen Hu and Rui Ai and Han Zhong and Xiaoyu Chen and Liwei Wang and Zhaoran Wang and Zhuoran Yang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=e5yAhjSJ4j}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster The Sample Complexity of Online Strategic Decision Making with Information Asymmetry and Knowledge Transportability.pdf", "retrieved_at": "2025-11-12T03:21:49.191998Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "OpenCUA: Open Foundations for Computer-Use Agents", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Xinyuan Wang", "Bowen Wang", "Dunjie Lu", "Junlin Yang", "Tianbao Xie", "Junli Wang", "Jiaqi Deng", "Xiaole Guo", "Yiheng Xu", "Chen Henry Wu", "Zhennan Shen", "Zhuokai Li", "Ryan Li", "Xiaochuan Li", "Junda Chen", "Zheng Boyuan", "LI PEIHANG", "Fangyu Lei", "Ruisheng Cao", "Yeqiao Fu", "Dongchan Shin", "Martin Shin", "Hu Jiarui", "Yuyan Wang", "Jixuan Chen", "Yuxiao Ye", "Danyang Zhang", "Yipu Wang", "Heng Wang", "Diyi Yang", "Victor Zhong", "Y.Charles", "Zhilin Yang", "Tao Yu"], "affinity_score": 0.6501, "link": "https://openreview.net/pdf/eb1bd0238abbc386303352dba1049a4d5d1fec83.pdf", "abstract": "Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state–action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-72B achieves an average success rate of 45.0% on OSWorld‑Verified, establishing a new state-of-the-art (SOTA) among open-source models. Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research.", "bibtex": "@inproceedings{\nwang2025opencua,\ntitle={Open{CUA}: Open Foundations for Computer-Use Agents},\nauthor={Xinyuan Wang and Bowen Wang and Dunjie Lu and Junlin Yang and Tianbao Xie and Junli Wang and Jiaqi Deng and Xiaole Guo and Yiheng Xu and Chen Henry Wu and Zhennan Shen and Zhuokai Li and Ryan Li and Xiaochuan Li and Junda Chen and Zheng Boyuan and LI PEIHANG and Fangyu Lei and Ruisheng Cao and Yeqiao Fu and Dongchan Shin and Martin Shin and Hu Jiarui and Yuyan Wang and Jixuan Chen and Yuxiao Ye and Danyang Zhang and Yipu Wang and Heng Wang and Diyi Yang and Victor Zhong and Y.Charles and Zhilin Yang and Tao Yu},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=6iRZvJiC9Q}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Spotlight OpenCUA_ Open Foundations for Computer-Use Agents.pdf", "retrieved_at": "2025-11-12T03:21:50.699805Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Fan Yin", "Zifeng Wang", "I-Hung Hsu", "Jun Yan", "Ke Jiang", "Yanfei Chen", "Jindong Gu", "Long Le", "Kai-Wei Chang", "Chen-Yu Lee", "Hamid Palangi", "Tomas Pfister"], "affinity_score": 0.6498, "link": "https://aclanthology.org/2025.acl-long.1566/", "abstract": "Large language models (LLMs) have exhibited the ability to effectively utilize external tools to address user queries. However, their performance may be limited in complex, multi-turn interactions involving users and multiple tools. To address this, we propose Magnet, a principled framework for synthesizing high-quality training trajectories to enhance the function calling capability of large language model agents in multi-turn conversations with humans. The framework is based on automatic and iterative translations from a function signature path to a sequence of queries and executable function calls. We model the complicated function interactions in multi-turn cases with graph and design novel node operations to build reliable signature paths. Motivated by context distillation, when guiding the generation of positive and negative trajectories using a teacher model, we provide reference function call sequences as positive hints in context and contrastive, incorrect function calls as negative hints. Experiments show that training with the positive trajectories with supervised fine-tuning and preference optimization against negative trajectories, our 14B model, Magnet-14B-mDPO, obtains 68.01 on BFCL-v3 and 73.30 on ToolQuery, surpassing the performance of the teacher model Gemini-1.5-pro-002 by a large margin in function calling.", "bibtex": "@inproceedings{yin-etal-2025-magnet,\n    title = \"Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation\",\n    author = \"Yin, Fan  and\n      Wang, Zifeng  and\n      Hsu, I-Hung  and\n      Yan, Jun  and\n      Jiang, Ke  and\n      Chen, Yanfei  and\n      Gu, Jindong  and\n      Le, Long  and\n      Chang, Kai-Wei  and\n      Lee, Chen-Yu  and\n      Palangi, Hamid  and\n      Pfister, Tomas\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1566/\",\n    doi = \"10.18653/v1/2025.acl-long.1566\",\n    pages = \"32600--32616\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Magnet_ Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation.pdf", "retrieved_at": "2025-11-12T03:21:51.012408Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "OS Agents: A Survey on MLLM-based Agents for Computer, Phone and Browser Use", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Xueyu Hu", "Tao Xiong", "Biao Yi", "Zishu Wei", "Ruixuan Xiao", "Yurun Chen", "Jiasheng Ye", "Meiling Tao", "Xiangxin Zhou", "Ziyu Zhao", "Yuhuai Li", "Shengze Xu", "Shenzhi Wang", "Xinchen Xu", "Shuofei Qiao", "Zhaokai Wang", "Kun Kuang", "Tieyong Zeng", "Liang Wang", "Jiwei Li", "Yuchen Eleanor Jiang", "Wangchunshu Zhou", "Guoyin Wang", "Keting Yin", "Zhou Zhao", "Hongxia Yang", "Fan Wu (吴凡", "吴钒)", "Shengyu Zhang", "Fei Wu"], "affinity_score": 0.6497, "link": "https://aclanthology.org/2025.acl-long.369/", "abstract": "The dream to create AI assistants as capable and versatile as the fictional J.A.R.V.I.S from Iron Man has long captivated imaginations. With the evolution of multi-modal large language models ((M)LLMs), this dream is closer to reality, as (M)LLM-based Agents using computers, mobile phones and web browsers by operating within the environments and interfaces (e.g., Graphical User Interface (GUI) and Command Line Interface (CLI)) provided by operating systems (OS) to automate tasks have significantly advanced. This paper presents a comprehensive survey on these advanced agents, designated as OS Agents. We begin by elucidating the fundamentals of OS Agents, exploring their key components and capabilities. We then examine methodologies for constructing OS Agents, focusing on domain-specific foundation models and agent frameworks. A detailed review of evaluation metrics and benchmarks highlights how OS Agents are assessed across diverse platforms and tasks. Finally, we discuss current challenges and identify promising directions for future research. An open-source GitHub repository is maintained as a dynamic resource to foster further innovation in this field.", "bibtex": "@inproceedings{hu-etal-2025-os,\n    title = \"{OS} Agents: A Survey on {MLLM}-based Agents for Computer, Phone and Browser Use\",\n    author = \"Hu, Xueyu  and\n      Xiong, Tao  and\n      Yi, Biao  and\n      Wei, Zishu  and\n      Xiao, Ruixuan  and\n      Chen, Yurun  and\n      Ye, Jiasheng  and\n      Tao, Meiling  and\n      Zhou, Xiangxin  and\n      Zhao, Ziyu  and\n      Li, Yuhuai  and\n      Xu, Shengze  and\n      Wang, Shenzhi  and\n      Xu, Xinchen  and\n      Qiao, Shuofei  and\n      Wang, Zhaokai  and\n      Kuang, Kun  and\n      Zeng, Tieyong  and\n      Wang, Liang  and\n      Li, Jiwei  and\n      Jiang, Yuchen Eleanor  and\n      Zhou, Wangchunshu  and\n      Wang, Guoyin  and\n      Yin, Keting  and\n      Zhao, Zhou  and\n      Yang, Hongxia  and\n      Wu, Fan  and\n      Zhang, Shengyu  and\n      Wu, Fei\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.369/\",\n    doi = \"10.18653/v1/2025.acl-long.369\",\n    pages = \"7436--7465\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long OS Agents_ A Survey on MLLM-based Agents for Computer, Phone and Browser Use.pdf", "retrieved_at": "2025-11-12T03:21:51.400419Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "HYGMA: Hypergraph Coordination Networks with Dynamic Grouping for Multi-Agent Reinforcement Learning", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Chiqiang Liu", "Dazi Li"], "affinity_score": 0.6496, "link": "https://openreview.net/pdf/33b171228d99ae0600b13ea7f6202a034fcfdf84.pdf", "abstract": "Cooperative multi-agent reinforcement learning faces significant challenges in effectively organizing agent relationships and facilitating information exchange, particularly when agents need to adapt their coordination patterns dynamically. This paper presents a novel framework that integrates dynamic spectral clustering with hypergraph neural networks to enable adaptive group formation and efficient information processing in multi-agent systems. The proposed framework dynamically constructs and updates hypergraph structures through spectral clustering on agents' state histories, enabling higher-order relationships to emerge naturally from agent interactions. The hypergraph structure is enhanced with attention mechanisms for selective information processing, providing an expressive and efficient way to model complex agent relationships. This architecture can be implemented in both value-based and policy-based paradigms through a unified objective combining task performance with structural regularization. Extensive experiments on challenging cooperative tasks demonstrate that our method significantly outperforms state-of-the-art approaches in both sample efficiency and final performance. The code is available at: https://github.com/mysteryelder/HYGMA.", "bibtex": "@inproceedings{\nliu2025hygma,\ntitle={{HYGMA}: Hypergraph Coordination Networks with Dynamic Grouping for Multi-Agent Reinforcement Learning},\nauthor={Chiqiang Liu and Dazi Li},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=mgJkeqc685}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster HYGMA_ Hypergraph Coordination Networks with Dynamic Grouping for Multi-Agent Reinforcement Learning.pdf", "retrieved_at": "2025-11-12T03:21:51.906181Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "RE-Bench: Evaluating Frontier AI R&D Capabilities of Language Model Agents against Human Experts", "venue": "ICML 2025 Spotlightposter", "year": "2025", "authors": ["Hjalmar Wijk", "Tao Roa Lin", "Joel Becker", "Sami Jawhar", "Neev Parikh", "Thomas Broadley", "Lawrence Chan", "Michael Chen", "Joshua M Clymer", "Jai Dhyani", "Elena Ericheva", "Katharyn Garcia", "Brian Goodrich", "Nikola Jurkovic", "Megan Kinniment", "Aron Lajko", "Seraphina Nix", "Lucas Jun Koba Sato", "William Saunders", "Maksym Taran", "Ben West", "Elizabeth Barnes"], "affinity_score": 0.6496, "link": "https://openreview.net/pdf/4ecca478c42f4d707b818055092b92bfb1094b98.pdf", "abstract": "Frontier AI safety policies highlight automation of AI research and development (R&D) by AI agents as an important capability to anticipate. However, there exist few evaluations for AI R&D capabilities, and none that are highly realistic and have a direct comparison to human performance. We introduce RE-Bench (Research Engineering Benchmark, V1), which consists of 7 challenging, open-ended ML research engineering environments and data from 71 8-hour attempts by 61 distinct human experts. We confirm that our experts make progress in the environments given 8 hours, with 82% of expert attempts achieving a non-zero score and 24% matching or exceeding our strong reference solutions. We compare humans to several public frontier models through best-of-$k$ with varying time budgets and agent designs, and find that the best AI agents achieve a score 4× higher than human experts when both are given a total time budget of 2 hours per environment. However, humans currently display better returns to increasing time budgets, narrowly exceeding the top AI agent scores given an 8-hour budget, and achieving 2× the score of the top AI agent when both are given 32 total hours (across different attempts).", "bibtex": "@inproceedings{\nwijk2025rebench,\ntitle={{RE}-Bench: Evaluating Frontier {AI} R\\&D Capabilities of Language Model Agents against Human Experts},\nauthor={Hjalmar Wijk and Tao Roa Lin and Joel Becker and Sami Jawhar and Neev Parikh and Thomas Broadley and Lawrence Chan and Michael Chen and Joshua M Clymer and Jai Dhyani and Elena Ericheva and Katharyn Garcia and Brian Goodrich and Nikola Jurkovic and Megan Kinniment and Aron Lajko and Seraphina Nix and Lucas Jun Koba Sato and William Saunders and Maksym Taran and Ben West and Elizabeth Barnes},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=3rB0bVU6z6}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Spotlightposter RE-Bench_ Evaluating Frontier AI R&D Capabilities of Language Model Agents against Human Experts.pdf", "retrieved_at": "2025-11-12T03:21:53.060063Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AXIS: Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Junting Lu", "Zhiyang Zhang", "Fangkai Yang", "Jue Zhang", "Lu Wang", "Chao Du", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang", "Qi Zhang (张琦)"], "affinity_score": 0.6496, "link": "https://aclanthology.org/2025.acl-long.381/", "abstract": "Multimodal large language models (MLLMs) have enabled LLM-based agents to directly interact with application user interfaces (UIs), enhancing agents’ performance in complex tasks. However, these agents often suffer from high latency and low reliability due to the extensive sequential UI interactions. To address this issue, we propose AXIS, a novel LLM-based agents framework that prioritize actions through application programming interfaces (APIs) over UI actions. This framework also facilitates the creation and expansion of APIs through automated exploration of applications. Our experiments on Microsoft Word demonstrate that AXIS reduces task completion time by 65%-70% and cognitive workload by 38%-53%, while maintaining accuracy of 97%-98% compared to humans. Our work contributes to a new human-agent-computer interaction (HACI) framework and explores a fresh UI design principle for application providers to turn applications into agents in the era of LLMs, paving the way towards an agent-centric operating system (Agent OS). The code and dataset will be available at https://aka.ms/haci_axis.", "bibtex": "@inproceedings{lu-etal-2025-axis,\n    title = \"{AXIS}: Efficient Human-Agent-Computer Interaction with {API}-First {LLM}-Based Agents\",\n    author = \"Lu, Junting  and\n      Zhang, Zhiyang  and\n      Yang, Fangkai  and\n      Zhang, Jue  and\n      Wang, Lu  and\n      Du, Chao  and\n      Lin, Qingwei  and\n      Rajmohan, Saravan  and\n      Zhang, Dongmei  and\n      Zhang, Qi\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.381/\",\n    doi = \"10.18653/v1/2025.acl-long.381\",\n    pages = \"7711--7743\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long AXIS_ Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents.pdf", "retrieved_at": "2025-11-12T03:21:54.484078Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Sports-Traj: A Unified Trajectory Generation Model for Multi-Agent Movement in Sports", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Yi Xu", "Yun Fu"], "affinity_score": 0.6493, "link": "https://openreview.net/pdf/cf8be66b512605ced9183cbe431e01a01ab83ca0.pdf", "abstract": "Understanding multi-agent movement is critical across various fields. The conventional approaches typically focus on separate tasks such as trajectory prediction, imputation, or spatial-temporal recovery. Considering the unique formulation and constraint of each task, most existing methods are tailored for only one, limiting the ability to handle multiple tasks simultaneously, which is a common requirement in real-world scenarios. Another limitation is that widely used public datasets mainly focus on pedestrian movements with casual, loosely connected patterns, where interactions between individuals are not always present, especially at a long distance, making them less representative of more structured environments. To overcome these limitations, we propose a Unified Trajectory Generation model, UniTraj, that processes arbitrary trajectories as masked inputs, adaptable to diverse scenarios in the domain of sports games. Specifically, we introduce a Ghost Spatial Masking (GSM) module, embedded within a Transformer encoder, for spatial feature extraction. We further extend recent State Space Models (SSMs), known as the Mamba model, into a Bidirectional Temporal Mamba (BTM) to better capture temporal dependencies. Additionally, we incorporate a Bidirectional Temporal Scaled (BTS) module to thoroughly scan trajectories while preserving temporal missing relationships. Furthermore, we curate and benchmark three practical sports datasets, Basketball-U, Football-U, and Soccer-U, for evaluation. Extensive experiments demonstrate the superior performance of our model. We hope that our work can advance the understanding of human movement in real-world applications, particularly in sports. Our datasets, code, and model weights are available here https://github.com/colorfulfuture/UniTraj-pytorch.", "bibtex": "@inproceedings{\nxu2025sportstraj,\ntitle={Sports-Traj: A Unified Trajectory Generation Model for Multi-Agent Movement in Sports},\nauthor={Yi Xu and Yun Fu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=9aTZf71uiD}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Sports-Traj_ A Unified Trajectory Generation Model for Multi-Agent Movement in Sports.pdf", "retrieved_at": "2025-11-12T03:21:55.008847Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "SWE-Search: Enhancing Software Agents with Monte Carlo Tree Search and Iterative Refinement", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Antonis Antoniades", "Albert Örwall", "Kexun Zhang", "Yuxi Xie", "Anirudh Goyal", "William Yang Wang"], "affinity_score": 0.6493, "link": "https://openreview.net/pdf/fd21b53183d7f37c46833653eed82df55976adf4.pdf", "abstract": "Software engineers operating in complex and dynamic environments must continuously adapt to evolving requirements, learn iteratively from experience, and reconsider their approaches based on new insights. However, current large language model (LLM)-based software agents often follow linear, sequential processes that prevent backtracking and exploration of alternative solutions, limiting their ability to rethink their strategies when initial approaches prove ineffective. To address these challenges, we propose SWE-Search, a multi-agent framework that integrates Monte Carlo Tree Search (MCTS) with a self-improvement mechanism to enhance software agents' performance on repository-level software tasks. SWE-Search extends traditional MCTS by incorporating a hybrid value function that leverages LLMs for both numerical value estimation and qualitative evaluation. This enables self-feedback loops where agents iteratively refine their strategies based on both quantitative numerical evaluations and qualitative natural language assessments of pursued trajectories. The framework includes a SWE-Agent for adaptive exploration, a Value Agent for iterative feedback, and a Discriminator Agent that facilitates multi-agent debate for collaborative decision-making. Applied to the SWE-bench benchmark, our approach demonstrates a 23% relative improvement in performance across five models compared to standard open-source agents without MCTS. Our analysis reveals how performance scales with increased inference-time compute through deeper search, providing a pathway to improve software agents without requiring larger models or additional training data. This highlights the potential of self-evaluation driven search techniques in complex software engineering environments.", "bibtex": "@inproceedings{\nantoniades2025swesearch,\ntitle={{SWE}-Search: Enhancing Software Agents with Monte Carlo Tree Search and Iterative Refinement},\nauthor={Antonis Antoniades and Albert {\\\"O}rwall and Kexun Zhang and Yuxi Xie and Anirudh Goyal and William Yang Wang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=G7sIFXugTX}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster SWE-Search_ Enhancing Software Agents with Monte Carlo Tree Search and Iterative Refinement.pdf", "retrieved_at": "2025-11-12T03:21:55.879430Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via Role-Specialized Collaboration", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Yucheng Zhou", "Lingran Song", "Jianbing Shen"], "affinity_score": 0.6492, "link": "https://aclanthology.org/2025.findings-acl.1298/", "abstract": "Recent advancements in medical Large Language Models (LLMs) have showcased their powerful reasoning and diagnostic capabilities. Despite their success, current unified multimodal medical LLMs face limitations in knowledge update costs, comprehensiveness, and flexibility. To address these challenges, we introduce the Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis (MAM). Inspired by our empirical findings highlighting the benefits of role assignment and diagnostic discernment in LLMs, MAM decomposes the medical diagnostic process into specialized roles: a General Practitioner, Specialist Team, Radiologist, Medical Assistant, and Director, each embodied by an LLM-based agent. This modular and collaborative framework enables efficient knowledge updates and leverages existing medical LLMs and knowledge bases. Extensive experimental evaluations conducted on a wide range of publicly accessible multimodal medical datasets, incorporating text, image, audio, and video modalities, demonstrate that MAM consistently surpasses the performance of modality-specific LLMs. Notably, MAM achieves significant performance improvements ranging from 18% to 365% compared to baseline models. Our code, data, and prompts are released at https://github.com/yczhou001/MAM .", "bibtex": "@inproceedings{zhou-etal-2025-mam,\n    title = \"{MAM}: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via Role-Specialized Collaboration\",\n    author = \"Zhou, Yucheng  and\n      Song, Lingran  and\n      Shen, Jianbing\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1298/\",\n    doi = \"10.18653/v1/2025.findings-acl.1298\",\n    pages = \"25319--25333\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings MAM_ Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via Role-Specialized Collaboration.pdf", "retrieved_at": "2025-11-12T03:21:56.130129Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Guibin Zhang", "Muxin Fu", "Kun Wang", "Guancheng Wan", "Miao Yu", "Shuicheng YAN"], "affinity_score": 0.6491, "link": "https://openreview.net/pdf/52f961783a3212459f228b4ec297f523ba2d0c95.pdf", "abstract": "Large language model (LLM)-powered multi-agent systems (MAS) have demonstrated cognitive and execution capabilities that far exceed those of single LLM agents, yet their capacity for self-evolution remains hampered by underdeveloped memory architectures. Upon close inspection, we are alarmed to discover that prevailing MAS memory mechanisms (1) are overly simplistic, completely disregarding the nuanced inter-agent collaboration trajectories, and (2) lack cross-trial and agent-specific customization, in stark contrast to the expressive memory developed for single agents. To bridge this gap, we introduce G-Memory, a hierarchical, agentic memory system for MAS inspired by organizational memory theory, which manages the lengthy MAS interaction via a three-tier graph hierarchy: insight, query, and interaction graphs. Upon receiving a new user query, G-Memory performs bi-directional memory traversal to retrieve both \\textit{high-level, generalizable insights} that enable the system to leverage cross-trial knowledge, and \\textit{fine-grained, condensed interaction trajectories} that compactly encode prior collaboration experiences. Upon task execution, the entire hierarchy evolves by assimilating new collaborative trajectories, nurturing the progressive evolution of agent teams. Extensive experiments across five benchmarks, three LLM backbones, and three popular MAS frameworks demonstrate that G-Memory improves success rates in embodied action and accuracy in knowledge QA by up to $20.89\\%$ and $10.12\\%$, respectively, without any modifications to the original frameworks.", "bibtex": "@inproceedings{\nzhang2025gmemory,\ntitle={G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems},\nauthor={Guibin Zhang and Muxin Fu and Kun Wang and Guancheng Wan and Miao Yu and Shuicheng YAN},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=mmIAp3cVS0}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Spotlight G-Memory_ Tracing Hierarchical Memory for Multi-Agent Systems.pdf", "retrieved_at": "2025-11-12T03:21:56.984315Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "The Emergence of Compositional Languages in Multi-entity Referential Games: from Image to Graph Representations", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Daniel Akkerman", "Phong Le", "Raquel G. Alhama"], "affinity_score": 0.6489, "link": "https://aclanthology.org/2024.emnlp-main.1042/", "abstract": "To study the requirements needed for a human-like language to develop, Language Emergence research uses jointly trained artificial agents which communicate to solve a task, the most popular of which is a referential game. The targets that agents refer to typically involve a single entity, which limits their ecological validity and the complexity of the emergent languages. Here, we present a simple multi-entity game in which targets include multiple entities that are spatially related. We ask whether agents dealing with multi-entity targets benefit from the use of graph representations, and explore four different graph schemes. Our game requires more sophisticated analyses to capture the extent to which the emergent languages are compositional, and crucially, what the decomposed features are. We find that emergent languages from our setup exhibit a considerable degree of compositionality, but not over all features.", "bibtex": "@inproceedings{akkerman-etal-2024-emergence,\n    title = \"The Emergence of Compositional Languages in Multi-entity Referential Games: from Image to Graph Representations\",\n    author = \"Akkerman, Daniel  and\n      Le, Phong  and\n      Alhama, Raquel G.\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.1042/\",\n    doi = \"10.18653/v1/2024.emnlp-main.1042\",\n    pages = \"18713--18723\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main The Emergence of Compositional Languages in Multi-entity Referential Games_ from Image to Graph Representations.pdf", "retrieved_at": "2025-11-12T03:21:57.265520Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Minki Kang", "Jongwon Jeong", "Seanie Lee", "Jaewoong Cho", "Sung Ju Hwang"], "affinity_score": 0.6488, "link": "https://openreview.net/pdf/c3ead64f6c3fd03156d79bf7aa5185204700b2a2.pdf", "abstract": "Large language models (LLMs) excel at complex reasoning tasks but remain computationally expensive, limiting their practical deployment.\nTo address this, recent works have focused on distilling reasoning capabilities into smaller language models (sLMs) using chain-of-thought (CoT) traces from teacher LLMs.\nHowever, this approach struggles in scenarios requiring rare factual knowledge or precise computation, where sLMs often hallucinate due to limited capability.\nIn this work, we propose Agent Distillation, a framework for transferring not only reasoning capability but full task-solving behavior from LLM-based agents into sLMs with retrieval and code tools. \nWe improve agent distillation along two complementary axes: (1) we introduce a prompting method called first-thought prefix to enhance the quality of teacher-generated trajectories; \nand (2) we propose a self-consistent action generation for improving test-time robustness of small agents.\nWe evaluate our method on eight reasoning tasks across factual and mathematical domains, covering both in-domain and out-of-domain generalization.\nOur results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents.", "bibtex": "@inproceedings{\nkang2025distilling,\ntitle={Distilling {LLM} Agent into Small Models with Retrieval and Code Tools},\nauthor={Minki Kang and Jongwon Jeong and Seanie Lee and Jaewoong Cho and Sung Ju Hwang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=VkicTqszOn}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Spotlight Distilling LLM Agent into Small Models with Retrieval and Code Tools.pdf", "retrieved_at": "2025-11-12T03:21:57.774696Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Mind the (Belief) Gap: Group Identity in the World of LLMs", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Angana Borah", "Marwa Houalla", "Rada Mihalcea"], "affinity_score": 0.6488, "link": "https://aclanthology.org/2025.findings-acl.948/", "abstract": "Social biases and belief-driven behaviors can significantly impact Large Language Models’ (LLMs’) decisions on several tasks. As LLMs are increasingly used in multi-agent systems for societal simulations, their ability to model fundamental group psychological characteristics remains critical yet under-explored. In this study, we present a multi-agent framework that simulates belief congruence, a classical group psychology theory that plays a crucial role in shaping societal interactions and preferences. Our findings reveal that LLMs exhibit amplified belief congruence compared to humans, across diverse contexts. We further investigate the implications of this behavior on two downstream tasks: (1) misinformation dissemination and (2) LLM learning, finding that belief congruence in LLMs increases misinformation dissemination and impedes learning. To mitigate these negative impacts, we propose strategies inspired by: (1) contact hypothesis, (2) accuracy nudges, and (3) global citizenship framework. Our results show that the best strategies reduce misinformation dissemination by up to (37%) and enhance learning by (11%). Bridging social psychology and AI, our work provides insights to navigate real-world interactions using LLMs while addressing belief-driven biases.", "bibtex": "@inproceedings{borah-etal-2025-mind,\n    title = \"Mind the (Belief) Gap: Group Identity in the World of {LLM}s\",\n    author = \"Borah, Angana  and\n      Houalla, Marwa  and\n      Mihalcea, Rada\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.948/\",\n    doi = \"10.18653/v1/2025.findings-acl.948\",\n    pages = \"18441--18463\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings Mind the (Belief) Gap_ Group Identity in the World of LLMs.pdf", "retrieved_at": "2025-11-12T03:21:58.030936Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Ziye Wang", "Li Kang", "Yiran Qin", "Jiahua Ma", "zhanglin peng", "LEI BAI", "Ruimao Zhang"], "affinity_score": 0.6486, "link": "https://openreview.net/pdf/31d2d65ea2b64e0aa8bf80c7d1c8684b3210b92e.pdf", "abstract": "Despite significant advances in robotic policy generation, effective coordination in embodied multi-agent systems remains a fundamental challenge—particularly in scenarios where agents must balance individual perspectives with global environmental awareness.\nExisting approaches often struggle to balance fine-grained local control with comprehensive scene understanding, resulting in limited scalability and compromised collaboration quality.\nIn this paper, we present GauDP, a novel Gaussian-image synergistic representation that facilitates scalable, perception-aware imitation learning in multi-agent collaborative systems.\nSpecifically, GauDP reconstructs a globally consistent 3D Gaussian field from local-view RGB images, allowing all agents to dynamically query task-relevant features from a shared scene representation. \nThis design facilitates both fine-grained control and globally coherent behavior without requiring additional sensing modalities. \nWe evaluate GauDP on the RoboFactory benchmark, which includes diverse multi-arm manipulation tasks. \nOur method achieves superior performance over existing image-based methods and approaches the effectiveness of point-cloud-driven methods, while maintaining strong scalability as the number of agents increases. \nExtensive ablations and visualizations further demonstrate the robustness and efficiency of our unified local-global perception framework for multi-agent embodied learning.", "bibtex": "@inproceedings{\nwang2025reinventing,\ntitle={Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies},\nauthor={Ziye Wang and Li Kang and Yiran Qin and Jiahua Ma and zhanglin peng and LEI BAI and Ruimao Zhang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=asS4W7Yw5e}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T03:21:58.226893Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking Through Options", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Lakshmi Nair", "Ian Trase", "J. Mark Kim"], "affinity_score": 0.6486, "link": "https://openreview.net/pdf/76dab439ad54e5c6beda75b12506660aa929c9d6.pdf", "abstract": "We present a novel reasoning approach called Flow-of-Options (FoO), designed to address intrinsic biases in Large Language Models (LLMs). Flow-of-Options enables LLMs to systematically explore a diverse range of possibilities in their reasoning, as demonstrated by an FoO-based agentic framework developed for autonomously solving Machine Learning (ML) tasks. FoO enforces diversity in LLM solutions through compressed and interpretable task representations, resulting in improvements of 38.2% - 69.2% on standard data science tasks, and 37.4% - 47.9% on therapeutic chemistry tasks, as compared to state-of-the-art baselines. With an overall operation cost under $1 per task, our framework is well-suited for cost-sensitive applications. Going beyond tabular classification and regression, we show the broader applicability of our FoO-based agentic system to tasks such as reinforcement learning and image generation. Our code is open-sourced at: https://github.com/flagshippioneering/Flow-of-Options.", "bibtex": "@inproceedings{\nnair2025flowofoptions,\ntitle={Flow-of-Options: Diversified and Improved {LLM} Reasoning by Thinking Through Options},\nauthor={Lakshmi Nair and Ian Trase and J. Mark Kim},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=EiSXjzgBK4}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T03:21:58.416479Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MCU: An Evaluation Framework for Open-Ended Game Agents", "venue": "ICML 2025 Spotlightposter", "year": "2025", "authors": ["Xinyue Zheng", "Haowei Lin", "Kaichen He", "Zihao Wang", "QIANG FU", "Haobo Fu", "Zilong Zheng", "Yitao Liang"], "affinity_score": 0.6485, "link": "https://openreview.net/pdf/f293c1c135a7e3ab045d15897631d1f8efad035c.pdf", "abstract": "Developing AI agents capable of interacting with open-world environments to solve diverse tasks is a compelling challenge. However, evaluating such open-ended agents remains difficult, with current benchmarks facing scalability limitations. To address this, we introduce \\textit{Minecraft Universe} (MCU), a comprehensive evaluation framework set within the open-world video game Minecraft. MCU incorporates three key components: (1) an expanding collection of 3,452 composable atomic tasks that encompasses 11 major categories and 41 subcategories of challenges; (2) a task composition mechanism capable of generating infinite diverse tasks with varying difficulty; and (3) a general evaluation framework that achieves 91.5\\% alignment with human ratings for open-ended task assessment. Empirical results reveal that even state-of-the-art foundation agents struggle with the increasing diversity and complexity of tasks. These findings highlight the necessity of MCU as a robust benchmark to drive progress in AI agent development within open-ended environments. Our evaluation code and scripts are available at https://github.com/CraftJarvis/MCU.", "bibtex": "@inproceedings{\nzheng2025mcu,\ntitle={{MCU}: An Evaluation Framework for Open-Ended Game Agents},\nauthor={Xinyue Zheng and Haowei Lin and Kaichen He and Zihao Wang and QIANG FU and Haobo Fu and Zilong Zheng and Yitao Liang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=hrdLhNDAzp}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Spotlightposter MCU_ An Evaluation Framework for Open-Ended Game Agents.pdf", "retrieved_at": "2025-11-12T03:22:00.579450Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Jiawei Zhang", "Shuang Yang", "Bo Li"], "affinity_score": 0.6484, "link": "https://openreview.net/pdf/1489f884ee66981b358bb3e08dcb5c1b74ebbf4f.pdf", "abstract": "Large Language Model (LLM) agents equipped with external tools have become increasingly powerful for complex tasks such as web shopping, automated email replies, and financial trading. However, these advancements amplify the risks of adversarial attacks, especially when agents can access sensitive external functionalities. Nevertheless, manipulating LLM agents into performing targeted malicious actions or invoking specific tools remains challenging, as these agents extensively reason or plan before executing final actions. In this work, we present UDora, a unified red teaming framework designed for LLM agents that dynamically hijacks the agent's reasoning processes to compel malicious behavior. Specifically, UDora first generates the model’s reasoning trace for the given task, then automatically identifies optimal points within this trace to insert targeted perturbations. The resulting perturbed reasoning is then used as a surrogate response for optimization. By iteratively applying this process, the LLM agent will then be induced to undertake designated malicious actions or to invoke specific malicious tools. Our approach demonstrates superior effectiveness compared to existing methods across three LLM agent datasets. The code is available at https://github.com/AI-secure/UDora.", "bibtex": "@inproceedings{\nzhang2025udora,\ntitle={{UD}ora: A Unified Red Teaming Framework against {LLM} Agents by Dynamically Hijacking Their Own Reasoning},\nauthor={Jiawei Zhang and Shuang Yang and Bo Li},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=pRmxQHgjb1}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T03:22:00.782327Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Hazards in Daily Life? Enabling Robots to Proactively Detect and Resolve Anomalies", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Zirui Song", "Guangxian Ouyang", "Meng Fang", "Hongbin Na", "Zijing Shi", "Zhenhao Chen", "Fu Yujie", "Zeyu Zhang", "Shiyu Jiang", "Miao Fang", "Ling Chen", "Xiuying Chen"], "affinity_score": 0.6484, "link": "https://aclanthology.org/2025.naacl-long.379/", "abstract": "Existing household robots have made significant progress in performing routine tasks, such as cleaning floors or delivering objects. However, a key limitation of these robots is their inability to recognize potential problems or dangers in home environments. For example, a child may pick up and ingest medication that has fallen on the floor, posing a serious risk. We argue that household robots should proactively detect such hazards or anomalies within the home, and propose the task of anomaly scenario generation. To accomplish this task, we leverage foundational models instead of relying on manually labeled data to build simulated environments. Specifically, we introduce a multi-agent brainstorming approach, where agents collaborate and generate diverse scenarios covering household hazards, hygiene management, and child safety. These textual task descriptions are then integrated with designed 3D assets to simulate realistic environments. Within these constructed environments, our LLM-based robotic agent learns the necessary skills to proactively discover and handle the proposed anomalies through task decomposition, optimal learning approach selection. We demonstrate that our generated environment outperforms others in terms of task description and scene diversity, ultimately enabling robotic agents to better address potential household hazards.", "bibtex": "@inproceedings{song-etal-2025-hazards,\n    title = \"Hazards in Daily Life? Enabling Robots to Proactively Detect and Resolve Anomalies\",\n    author = \"Song, Zirui  and\n      Ouyang, Guangxian  and\n      Fang, Meng  and\n      Na, Hongbin  and\n      Shi, Zijing  and\n      Chen, Zhenhao  and\n      Yujie, Fu  and\n      Zhang, Zeyu  and\n      Jiang, Shiyu  and\n      Fang, Miao  and\n      Chen, Ling  and\n      Chen, Xiuying\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.379/\",\n    doi = \"10.18653/v1/2025.naacl-long.379\",\n    pages = \"7399--7415\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long Hazards in Daily Life_ Enabling Robots to Proactively Detect and Resolve Anomalies.pdf", "retrieved_at": "2025-11-12T03:22:01.195952Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Xiao Liu", "Tianjie Zhang", "Yu Gu", "Iat Long Iong", "Song XiXuan", "Yifan Xu", "Shudan Zhang", "Hanyu Lai", "Jiadai Sun", "Xinyue Yang", "Yu Yang", "Zehan Qi", "Shuntian Yao", "Xueqiao Sun", "Siyi Cheng", "Qinkai Zheng", "Hao Yu", "Hanchen Zhang", "Wenyi Hong", "Ming Ding", "Lihang Pan", "Xiaotao Gu", "Aohan Zeng", "Zhengxiao Du", "Chan Hee Song", "Yu Su", "Yuxiao Dong", "Jie Tang"], "affinity_score": 0.648, "link": "https://openreview.net/pdf/bee7975a3c8aa69c07f6b3df50d3f4b390af6700.pdf", "abstract": "Large Multimodal Models (LMMs) have ushered in a new era in artificial intelligence, merging capabilities in both language and vision to form highly capable \\textbf{Visual Foundation Agents} that are postulated to excel across a myriad of tasks. However, existing benchmarks fail to sufficiently challenge or showcase the full potential of LMMs as visual foundation agents in complex, real-world environments. To address this gap, we introduce VisualAgentBench (VAB), a comprehensive and unified benchmark specifically designed to train and evaluate LMMs as visual foundation agents across diverse scenarios in one standard setting, including Embodied, Graphical User Interface, and Visual Design, with tasks formulated to probe the depth of LMMs' understanding and interaction capabilities. Through rigorous testing across 9 proprietary LMM APIs and 9 open models (18 in total), we demonstrate the considerable yet still developing visual agent capabilities of these models. Additionally, VAB explores the synthesizing of visual agent trajectory data through hybrid methods including Program-based Solvers, LMM Agent Bootstrapping, and Human Demonstrations, offering insights into obstacles, solutions, and trade-offs one may meet in developing open LMM agents. Our work not only aims to benchmark existing models but also provides an instrumental playground for future development into visual foundation agents. Code, train, and test data are available at \\url{https://github.com/THUDM/VisualAgentBench}.", "bibtex": "@inproceedings{\nliu2025visualagentbench,\ntitle={VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents},\nauthor={Xiao Liu and Tianjie Zhang and Yu Gu and Iat Long Iong and Song XiXuan and Yifan Xu and Shudan Zhang and Hanyu Lai and Jiadai Sun and Xinyue Yang and Yu Yang and Zehan Qi and Shuntian Yao and Xueqiao Sun and Siyi Cheng and Qinkai Zheng and Hao Yu and Hanchen Zhang and Wenyi Hong and Ming Ding and Lihang Pan and Xiaotao Gu and Aohan Zeng and Zhengxiao Du and Chan Hee Song and Yu Su and Yuxiao Dong and Jie Tang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=2snKOc7TVp}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T03:22:01.376187Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Revisiting Multi-Agent World Modeling from a Diffusion-Inspired Perspective", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Yang Zhang", "Xinran Li", "Jianing Ye", "Shuang Qiu", "Delin Qu", "Xiu Li", "Chongjie Zhang", "Chenjia Bai"], "affinity_score": 0.6479, "link": "https://openreview.net/pdf/c9213e44761a54b3065c1cafc662367acc7fa15c.pdf", "abstract": "World models have recently attracted growing interest in Multi-Agent Reinforcement Learning (MARL) due to their ability to improve sample efficiency for policy learning. However, accurately modeling environments in MARL is challenging due to the exponentially large joint action space and highly uncertain dynamics inherent in multi-agent systems. To address this, we reduce modeling complexity by shifting from jointly modeling the entire state-action transition dynamics to focusing on the state space alone at each timestep through sequential agent modeling. Specifically, our approach enables the model to progressively resolve uncertainty while capturing the structured dependencies among agents, providing a more accurate representation of how agents influence the state. Interestingly, this sequential revelation of agents' actions in a multi-agent system aligns with the reverse process in diffusion models—a class of powerful generative models known for their expressiveness and training stability compared to autoregressive or latent variable models. Leveraging this insight, we develop a flexible and robust world model for MARL using diffusion models. Our method, \\textbf{D}iffusion-\\textbf{I}nspired \\textbf{M}ulti-\\textbf{A}gent world model (DIMA), achieves state-of-the-art performance across multiple multi-agent control benchmarks, significantly outperforming prior world models in terms of final return and sample efficiency, including MAMuJoCo and Bi-DexHands. DIMA establishes a new paradigm for constructing multi-agent world models, advancing the frontier of MARL research.", "bibtex": "@inproceedings{\nzhang2025revisiting,\ntitle={Revisiting Multi-Agent World Modeling from a Diffusion-Inspired Perspective},\nauthor={Yang Zhang and Xinran Li and Jianing Ye and Shuang Qiu and Delin Qu and Xiu Li and Chongjie Zhang and Chenjia Bai},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=rRxFIOoEeF}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Revisiting Multi-Agent World Modeling from a Diffusion-Inspired Perspective.pdf", "retrieved_at": "2025-11-12T03:22:02.090014Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Christopher Rawles", "Sarah Clinckemaillie", "Yifan Chang", "Jonathan Waltz", "Gabrielle Lau", "Marybeth Fair", "Alice Li", "William E Bishop", "Wei Li", "Folawiyo Campbell-Ajala", "Daniel Kenji Toyama", "Robert James Berry", "Divya Tyamagundlu", "Timothy P Lillicrap", "Oriana Riva"], "affinity_score": 0.6478, "link": "https://openreview.net/pdf/47ef762908227ecf3c9f07aea77ea162a772b501.pdf", "abstract": "Autonomous agents that execute human tasks by controlling computers can enhance human productivity and application accessibility. However, progress in this field will be driven by realistic and reproducible benchmarks. We present AndroidWorld, a fully functional Android environment that provides reward signals for 116 programmatic tasks across 20 real-world Android apps. Unlike existing interactive environments, which provide a static test set, AndroidWorld dynamically constructs tasks that are parameterized and expressed in natural language in unlimited ways, thus enabling testing on a much larger and more realistic suite of tasks. To ensure reproducibility, each task includes dedicated initialization, success-checking, and tear-down logic, which modifies and inspects the device’s system state.\nWe experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks, leaving ample room for future work. Furthermore, we adapt a popular desktop web agent to work on Android, which we find to be less effective on mobile, suggesting future research is needed to achieve universal, cross-platform agents. Finally, we also conduct a robustness analysis, showing that task variations can significantly affect agent performance, demonstrating that without such testing, agent performance metrics may not fully reflect practical challenges. AndroidWorld and the experiments in this paper are available at https://github.com/google-research/android_world.", "bibtex": "@inproceedings{\nrawles2025androidworld,\ntitle={AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents},\nauthor={Christopher Rawles and Sarah Clinckemaillie and Yifan Chang and Jonathan Waltz and Gabrielle Lau and Marybeth Fair and Alice Li and William E Bishop and Wei Li and Folawiyo Campbell-Ajala and Daniel Kenji Toyama and Robert James Berry and Divya Tyamagundlu and Timothy P Lillicrap and Oriana Riva},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=il5yUQsrjC}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T03:22:02.316513Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Agents' Room:  Narrative Generation through Multi-step Collaboration", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Fantine Huot", "Reinald Kim Amplayo", "Jennimaria Palomaki", "Alice Shoshana Jakobovits", "Elizabeth Clark", "Mirella Lapata"], "affinity_score": 0.6476, "link": "https://openreview.net/pdf/28c4bdc08fd7e4c2b2b7308c42d0447cbf1a0620.pdf", "abstract": "Writing compelling fiction is a multifaceted process combining elements such as crafting a plot, developing interesting characters, and using evocative language. While large language models (LLMs) show promise for story writing, they currently rely heavily on intricate prompting, which limits their use. We propose Agents' Room, a generation framework inspired by narrative theory, that decomposes narrative writing into subtasks tackled by specialized agents. To illustrate our method, we introduce Tell Me A Story, a high-quality dataset of complex writing prompts and human-written stories, and a novel evaluation framework designed specifically for assessing long narratives. We show that Agents' Room generates stories that are preferred by expert evaluators over those produced by baseline systems by leveraging collaboration and specialization to decompose the complex story writing task into tractable components. We provide extensive analysis with automated and human-based metrics of the generated output.", "bibtex": "@inproceedings{\nhuot2025agents,\ntitle={Agents' Room:  Narrative Generation through Multi-step Collaboration},\nauthor={Fantine Huot and Reinald Kim Amplayo and Jennimaria Palomaki and Alice Shoshana Jakobovits and Elizabeth Clark and Mirella Lapata},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=HfWcFs7XLR}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Agents' Room_ Narrative Generation through Multi-step Collaboration.pdf", "retrieved_at": "2025-11-12T03:22:02.843926Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Agent Reviewers: Domain-specific Multimodal Agents with Shared Memory for Paper Review", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Kai Lu", "Shixiong Xu", "Jinqiu Li", "Kun Ding", "Gaofeng Meng"], "affinity_score": 0.6475, "link": "https://openreview.net/pdf/2294c4a695dd37359e55a4596e6f2ab9b5ac44b2.pdf", "abstract": "Feedback from peer review is essential to improve the quality of scientific articles. However, at present, many manuscripts do not receive sufficient external feedback for refinement before or during submission. Therefore, a system capable of providing detailed and professional feedback is crucial for enhancing research efficiency. In this paper, we have compiled the largest dataset of paper reviews to date by collecting historical open-access papers and their corresponding review comments and standardizing them using LLM. We then developed a multi-agent system that mimics real human review processes, based on LLMs. This system, named Agent Reviewers, includes the innovative introduction of multimodal reviewers to provide feedback on the visual elements of papers. Additionally, a shared memory pool that stores historical papers' metadata is preserved, which supplies reviewer agents with background knowledge from different fields. Our system is evaluated using ICLR 2024 papers and achieves superior performance compared to existing AI-based review systems. Comprehensive ablation studies further demonstrate the effectiveness of each module and agent in this system.", "bibtex": "@inproceedings{\nlu2025agent,\ntitle={Agent Reviewers: Domain-specific Multimodal Agents with Shared Memory for Paper Review},\nauthor={Kai Lu and Shixiong Xu and Jinqiu Li and Kun Ding and Gaofeng Meng},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=s7HUJamWqX}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Agent Reviewers_ Domain-specific Multimodal Agents with Shared Memory for Paper Review.pdf", "retrieved_at": "2025-11-12T03:22:03.361139Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Francesco Cozzi", "Marco Pangallo", "Alan Perotti", "André Panisson", "Corrado Monti"], "affinity_score": 0.6469, "link": "https://openreview.net/pdf/730e7372a852363418f6cd5d5cb8e74011f6ebcb.pdf", "abstract": "Agent-Based Models (ABMs) are powerful tools for studying emergent properties in complex systems. In ABMs, agent behaviors are governed by local interactions and stochastic rules. However, these rules are ad hoc and, in general, non-differentiable, limiting the use of gradient-based methods for optimization, and thus integration with real-world data. We propose a novel framework to learn a differentiable surrogate of any ABM by observing its generated data. Our method combines diffusion models to capture behavioral stochasticity and graph neural networks to model agent interactions. Distinct from prior surrogate approaches, our method introduces a fundamental shift: rather than approximating system-level outputs, it models individual agent behavior directly, preserving the decentralized, bottom-up dynamics that define ABMs. We validate our approach on two ABMs (Schelling's segregation model and a Predator-Prey ecosystem) showing that it replicates individual-level patterns and accurately forecasts emergent dynamics beyond training. Our results demonstrate the potential of combining diffusion models and graph learning for data-driven ABM simulation.", "bibtex": "@inproceedings{\ncozzi2025learning,\ntitle={Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks},\nauthor={Francesco Cozzi and Marco Pangallo and Alan Perotti and Andr{\\'e} Panisson and Corrado Monti},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=N9sJRKzVK7}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks.pdf", "retrieved_at": "2025-11-12T03:22:04.443717Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Attractive Metadata Attack: Inducing LLM Agents to Invoke Malicious Tools", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Kanghua Mo", "Li Hu", "Yucheng Long", "Zhihao li"], "affinity_score": 0.6466, "link": "https://openreview.net/pdf/58fd047ac6ca0bee4f61d85fc98df7a5c5b55e31.pdf", "abstract": "Large language model (LLM) agents have demonstrated remarkable capabilities in complex reasoning and decision-making by leveraging external tools. However, this tool-centric paradigm introduces a previously underexplored attack surface, where adversaries can manipulate tool metadata---such as names, descriptions, and parameter schemas---to influence agent behavior. We identify this as a new and stealthy threat surface that allows malicious tools to be preferentially selected by LLM agents, without requiring prompt injection or access to model internals. To demonstrate and exploit this vulnerability, we propose the Attractive Metadata Attack (AMA), a black-box in-context learning framework that generates highly attractive but syntactically and semantically valid tool metadata through iterative optimization. The proposed attack integrates seamlessly into standard tool ecosystems and requires no modification to the agent’s execution framework. \nExtensive experiments across ten realistic, simulated tool-use scenarios and a range of popular LLM agents demonstrate consistently high attack success rates (81\\%-95\\%) and significant privacy leakage, with negligible impact on primary task execution. Moreover, the attack remains effective even against prompt-level defenses, auditor-based detection, and structured tool-selection protocols such as the Model Context Protocol, revealing systemic vulnerabilities in current agent architectures.\nThese findings reveal that metadata manipulation constitutes a potent and stealthy attack surface. \nNotably, AMA is orthogonal to injection attacks and can be combined with them to achieve stronger attack efficacy, highlighting the need for execution-level defenses beyond prompt-level and auditor-based mechanisms.\nCode is available at \\url{https://github.com/SEAIC-M/AMA}.", "bibtex": "@inproceedings{\nmo2025attractive,\ntitle={Attractive Metadata Attack: Inducing {LLM} Agents to Invoke Malicious Tools},\nauthor={Kanghua Mo and Li Hu and Yucheng Long and Zhihao li},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=oLGtPYdRzU}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Attractive Metadata Attack_ Inducing LLM Agents to Invoke Malicious Tools.pdf", "retrieved_at": "2025-11-12T03:22:04.972179Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "OpenHands: An Open Platform for AI Software Developers as Generalist Agents", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Xingyao Wang", "Boxuan Li", "Yufan Song", "Frank F. Xu", "Xiangru Tang", "Mingchen Zhuge", "Jiayi Pan", "Yueqi Song", "Bowen Li", "Jaskirat Singh", "Hoang H. Tran", "Fuqiang Li", "Ren Ma", "Mingzhang Zheng", "Bill Qian", "Yanjun Shao", "Niklas Muennighoff", "Yizhe Zhang", "Binyuan Hui", "Junyang Lin", "Robert Brennan", "Hao Peng", "Heng Ji", "Graham Neubig"], "affinity_score": 0.6462, "link": "https://openreview.net/pdf/95990590797cff8b93c33af989ecf4ac58bde9bb.pdf", "abstract": "Software is one of the most powerful tools that we humans have at our disposal; it allows a skilled programmer to interact with the world in complex and profound ways. At the same time, thanks to improvements in large language models (LLMs), there has also been a rapid development in AI agents that interact with and effect change in their surrounding environments. In this paper, we introduce OpenHands, a platform for the development of powerful and flexible AI agents that interact with the world in similar ways to a human developer: by writing code, interacting with a command line, and browsing the web. We describe how the platform allows for the implementation of new agents, utilization of various LLMs, safe interaction with sandboxed environments for code execution, and incorporation of evaluation benchmarks. Based on our currently incorporated benchmarks, we perform an evaluation of agents over 13 challenging tasks, including software engineering (e.g., SWE-Bench) and web browsing (e.g., WebArena), amongst others. Released under the permissive MIT license, OpenHands is a community project spanning academia and industry with more than 2K contributions from over 186 contributors in less than six months of development, and will improve going forward.", "bibtex": "@inproceedings{\nwang2025openhands,\ntitle={OpenHands: An Open Platform for {AI} Software Developers as Generalist Agents},\nauthor={Xingyao Wang and Boxuan Li and Yufan Song and Frank F. Xu and Xiangru Tang and Mingchen Zhuge and Jiayi Pan and Yueqi Song and Bowen Li and Jaskirat Singh and Hoang H. Tran and Fuqiang Li and Ren Ma and Mingzhang Zheng and Bill Qian and Yanjun Shao and Niklas Muennighoff and Yizhe Zhang and Binyuan Hui and Junyang Lin and Robert Brennan and Hao Peng and Heng Ji and Graham Neubig},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=OJd3ayDDoF}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster OpenHands_ An Open Platform for AI Software Developers as Generalist Agents.pdf", "retrieved_at": "2025-11-12T03:22:06.583603Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Sparse Rewards Can Self-Train Dialogue Agents", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Barrett Martin Lattimer", "Varun Prashant Gangal", "Ryan McDonald", "Yi Yang"], "affinity_score": 0.6459, "link": "https://aclanthology.org/2025.findings-acl.1302/", "abstract": "Recent advancements in state-of-the-art (SOTA) Large Language Model (LLM) agents, especially in multi-turn dialogue tasks, have been primarily driven by supervised fine-tuning and high-quality human feedback. However, as base LLM models continue to improve, acquiring meaningful human feedback has become increasingly challenging and costly. In certain domains, base LLM agents may eventually exceed human capabilities, making traditional feedback-driven methods impractical. In this paper, we introduce a novel self-improvement paradigm that empowers LLM agents to autonomously enhance their performance without external human feedback. Our method, Juxtaposed Outcomes for Simulation Harvesting (JOSH), is a self-alignment algorithm that leverages a sparse reward simulation environment to extract ideal behaviors and further train the LLM on its own outputs. We present ToolWOZ, a sparse reward tool-calling simulation environment derived from MultiWOZ. We demonstrate that models trained with JOSH, both small and frontier, significantly improve tool-based interactions while preserving general model capabilities across diverse benchmarks. Our code and data are publicly available on GitHub.", "bibtex": "@inproceedings{lattimer-etal-2025-sparse,\n    title = \"Sparse Rewards Can Self-Train Dialogue Agents\",\n    author = \"Lattimer, Barrett Martin  and\n      Gangal, Varun Prashant  and\n      McDonald, Ryan  and\n      Yang, Yi\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1302/\",\n    doi = \"10.18653/v1/2025.findings-acl.1302\",\n    pages = \"25395--25413\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings Sparse Rewards Can Self-Train Dialogue Agents.pdf", "retrieved_at": "2025-11-12T03:22:06.842330Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Yusheng Liao", "Shuyang Jiang", "Yanfeng Wang", "Yu Wang (王昱", "王雨)"], "affinity_score": 0.6458, "link": "https://aclanthology.org/2025.acl-long.663/", "abstract": "Large Language Models (LLMs) have shown promising potential in the medical domain, assisting with tasks like clinical note generation and patient communication. However, current LLMs are limited to text-based communication, hindering their ability to interact with diverse forms of information in clinical environments. Despite clinical agents succeeding in diverse signal interaction, they are oriented to a single clinical scenario and hence fail for broader applications. To evaluate clinical agents holistically, we propose ClinicalAgent Bench (CAB), a comprehensive medical agent benchmark consisting of 18 tasks across five key realistic clinical dimensions. Building on this, we introduce ReflectTool, a novel framework that excels at utilizing domain-specific tools within two stages. The first optimization stage progressively enlarges a long-term memory by saving successful solving processes and tool-wise experience of agents in a tiny pre-defined training set. In the following inference stage, ReflectTool can search for supportive successful demonstrations from already built long-term memory to guide the tool selection strategy, and a verifier improves the tool usage according to the tool-wise experience with two verification methods–iterative refinement and candidate selection. Extensive experiments on CAB demonstrate that ReflectTool surpasses the pure LLMs with more than 10 points and the well-established agent-based methods with 3 points, highlighting its adaptability and effectiveness in solving complex clinical tasks. Our code and datasets are available at https://github.com/BlueZeros/ReflecTool.", "bibtex": "@inproceedings{liao-etal-2025-reflectool,\n    title = \"{R}eflec{T}ool: Towards Reflection-Aware Tool-Augmented Clinical Agents\",\n    author = \"Liao, Yusheng  and\n      Jiang, Shuyang  and\n      Wang, Yanfeng  and\n      Wang, Yu\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.663/\",\n    doi = \"10.18653/v1/2025.acl-long.663\",\n    pages = \"13507--13531\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long ReflecTool_ Towards Reflection-Aware Tool-Augmented Clinical Agents.pdf", "retrieved_at": "2025-11-12T03:22:07.123141Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Tong Zhang", "Chen Huang", "Yang Deng", "Hongru Liang", "Jia Liu", "Zujie Wen", "Wenqiang Lei", "Tat-Seng Chua"], "affinity_score": 0.6451, "link": "https://aclanthology.org/2024.emnlp-main.26/", "abstract": "We investigate non-collaborative dialogue agents, which are expected to engage in strategic conversations with diverse users, for securing a mutual agreement that leans favorably towards the system’s objectives. This poses two main challenges for existing dialogue agents: 1) The inability to integrate user-specific characteristics into the strategic planning, and 2) The difficulty of training strategic planners that can be generalized to diverse users. To address these challenges, we propose TRIP to enhance the capability in tailored strategic planning, incorporating a user-aware strategic planning module and a population-based training paradigm. Through experiments on benchmark non-collaborative dialogue tasks, we demonstrate the effectiveness of TRIP in catering to diverse users.", "bibtex": "@inproceedings{zhang-etal-2024-strength,\n    title = \"Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation\",\n    author = \"Zhang, Tong  and\n      Huang, Chen  and\n      Deng, Yang  and\n      Liang, Hongru  and\n      Liu, Jia  and\n      Wen, Zujie  and\n      Lei, Wenqiang  and\n      Chua, Tat-Seng\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.26/\",\n    doi = \"10.18653/v1/2024.emnlp-main.26\",\n    pages = \"424--444\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation.pdf", "retrieved_at": "2025-11-12T03:22:07.376686Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Peijie Dong", "Zhenheng Tang", "Xiang Liu", "Lujun Li", "Xiaowen Chu", "Bo Li"], "affinity_score": 0.645, "link": "https://openreview.net/pdf/b3a4b8fbc846757b6e3fd02e54880bec9d6a7720.pdf", "abstract": "Post-training compression reduces the computational and memory costs of large language models (LLMs), enabling resource-efficient deployment. However, existing compression benchmarks focus narrowly on language modeling (e.g., perplexity) and natural language understanding tasks (e.g., GLUE accuracy), ignoring the agentic capabilities—workflow, tool use/function call, long-context understanding and real-world application. We introduce the Agent Compression Benchmark (ACBench), the first comprehensive benchmark for evaluating how compression impacts LLMs' agentic abilities. ACBench spans (1) 12 tasks across 4 capabilities (e.g., WorfBench for workflow generation, Needle-in-Haystack for long-context retrieval), (2) 4-bit quantization (GPTQ, AWQ) and 50% pruning (Wanda, SparseGPT), and (3) 15 models, including small (Gemma-2B), standard (Qwen2.5-7B), and distilled reasoning LLMs (DeepSeek-R1-Distill). Our experiments reveal compression tradeoffs: 4-bit quantization preserves workflow generation and tool use (1%--3% drop) but degrades real-world application accuracy by 10%--15%. We introduce ERank, Top-k Ranking Correlation and Energy to systematize analysis. ACBench provides actionable insights for optimizing LLM compression in agentic scenarios, bridging the gap between algorithmic efficiency and real-world applicability.", "bibtex": "@inproceedings{\ndong2025can,\ntitle={Can Compressed {LLM}s Truly Act? An Empirical Evaluation of Agentic Capabilities in {LLM} Compression},\nauthor={Peijie Dong and Zhenheng Tang and Xiang Liu and Lujun Li and Xiaowen Chu and Bo Li},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=rkwXYSDKso}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Can Compressed LLMs Truly Act_ An Empirical Evaluation of Agentic Capabilities in LLM Compression.pdf", "retrieved_at": "2025-11-12T03:22:08.195778Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Reconstruction-Guided Policy: Enhancing Decision-Making through Agent-Wise State Consistency", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Liang Qifan", "Yixiang Shan", "Haipeng Liu", "Zhengbang Zhu", "Ting Long", "Weinan Zhang", "Yuan Tian"], "affinity_score": 0.6449, "link": "https://openreview.net/pdf/93889fa7a9600b0947adac903f86072a53ee146f.pdf", "abstract": "An important challenge in multi-agent reinforcement learning is partial observability, where agents cannot access the global state of the environment during execution and can only receive observations within their field of view. To address this issue, previous works typically use the dimensional-wise state, which is obtained by applying MLP or dimensional-based attention on the global state, for decision-making during training and relying on a reconstructed dimensional-wise state during execution. However, dimensional-wise states tend to divert agent attention to specific features, neglecting potential dependencies between agents, making it difficult to make optimal decisions. Moreover, the inconsistency between the states used in training and execution further increases additional errors. To resolve these issues, we propose a method called Reconstruction-Guided Policy (RGP) to reconstruct the agent-wise state, which represents the information of inter-agent relationships, as input for decision-making during both training and execution. This not only preserves the potential dependencies between agents but also ensures consistency between the states used in training and execution. We conducted extensive experiments on both discrete and continuous action environments to evaluate RGP, and the results demonstrates its superior effectiveness. Our code is public in https://anonymous.4open.science/r/RGP-9F79", "bibtex": "@inproceedings{\nqifan2025reconstructionguided,\ntitle={Reconstruction-Guided Policy: Enhancing Decision-Making through Agent-Wise State Consistency},\nauthor={Liang Qifan and Yixiang Shan and Haipeng Liu and Zhengbang Zhu and Ting Long and Weinan Zhang and Yuan Tian},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=Y8L5RB4GWb}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Reconstruction-Guided Policy_ Enhancing Decision-Making through Agent-Wise State Consistency.pdf", "retrieved_at": "2025-11-12T03:22:10.312571Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "DSBench: How Far Are Data Science Agents from Becoming Data Science Experts?", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Liqiang Jing", "Zhehui Huang", "Xiaoyang Wang", "Wenlin Yao", "Wenhao Yu", "Kaixin Ma", "Hongming Zhang", "Xinya Du", "Dong Yu"], "affinity_score": 0.6448, "link": "https://openreview.net/pdf/c7598f99c29d589965e824c0fc1c1d64fc079c1e.pdf", "abstract": "Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) have demonstrated impressive language/vision reasoning abilities, igniting the recent trend of building agents for targeted applications such as shopping assistants or AI software engineers. Recently, many data science benchmarks have been proposed to investigate their performance in the data science domain. However, existing data science benchmarks still fall short when compared to real-world data science applications due to their simplified settings. To bridge this gap, we introduce DSBench, a comprehensive benchmark designed to evaluate data science agents with realistic tasks. This benchmark includes 466 data analysis tasks and 74 data modeling tasks, sourced from Eloquence and Kaggle competitions. DSBench offers a realistic setting by encompassing long contexts, multimodal task backgrounds, reasoning with large data files and multi-table structures, and performing end-to-end data modeling tasks. Our evaluation of state-of-the-art LLMs, LVLMs, and agents shows that they struggle with most tasks, with the best agent solving only 34.12% of data analysis tasks and achieving a 34.74% Relative Performance Gap (RPG). These findings underscore the need for further advancements in developing more practical, intelligent, and autonomous data science agents.", "bibtex": "@inproceedings{\njing2025dsbench,\ntitle={{DSB}ench: How Far Are Data Science Agents from Becoming Data Science Experts?},\nauthor={Liqiang Jing and Zhehui Huang and Xiaoyang Wang and Wenlin Yao and Wenhao Yu and Kaixin Ma and Hongming Zhang and Xinya Du and Dong Yu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=DSsSPr0RZJ}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster DSBench_ How Far Are Data Science Agents from Becoming Data Science Experts_.pdf", "retrieved_at": "2025-11-12T03:22:11.276442Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Hao Li", "Yu-Hao Huang", "Chang Xu", "Viktor Schlegel", "Renhe Jiang", "Riza Batista-Navarro", "Goran Nenadic", "Jiang Bian"], "affinity_score": 0.6447, "link": "https://openreview.net/pdf/c9eebe9ec79971c3504b2a13413d34dfc66ede75.pdf", "abstract": "Time-series Generation (TSG) is a prominent research area with broad applications in simulations, data augmentation, and counterfactual analysis. While existing methods have shown promise in unconditional single-domain TSG, real-world applications demand for cross-domain approaches capable of controlled generation tailored to domain-specific constraints and instance-level requirements. \nIn this paper, we argue that text can provide semantic insights, domain information and instance-specific temporal patterns, to guide and improve TSG.  We introduce ``Text-Controlled TSG'', a task focused on generating realistic time series by incorporating textual descriptions.\nTo address data scarcity in this setting, we propose a novel LLM-based Multi-Agent framework that synthesizes diverse, realistic text-to-TS datasets. Furthermore, we introduce Bridge, a hybrid text-controlled TSG framework that integrates semantic prototypes with text description for supporting domain-level guidance. This approach achieves state-of-the-art generation fidelity on 11 of 12 datasets, and improves controllability by up to 12% on MSE and 6% MAE compared to no text input generation, highlighting its potential for generating tailored time-series data.", "bibtex": "@inproceedings{\nli2025bridge,\ntitle={{BRIDGE}: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling},\nauthor={Hao Li and Yu-Hao Huang and Chang Xu and Viktor Schlegel and Renhe Jiang and Riza Batista-Navarro and Goran Nenadic and Jiang Bian},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=uRD6wkqulN}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster BRIDGE_ Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modeling.pdf", "retrieved_at": "2025-11-12T03:22:11.899301Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Fair Cooperation in Mixed-Motive Games via Conflict-Aware Gradient Adjustment", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Woojun Kim", "Katia P. Sycara"], "affinity_score": 0.6446, "link": "https://openreview.net/pdf/04273649fd0b3f8d9420d37287be398822e205a9.pdf", "abstract": "Multi-agent reinforcement learning in mixed-motive settings presents a fundamental challenge: agents must balance individual interests with collective goals, which are neither fully aligned nor strictly opposed. To address this, reward restructuring methods such as gifting and intrinsic motivation have been proposed. However, these approaches primarily focus on promoting cooperation by managing the trade-off between individual and collective returns, without explicitly addressing fairness with respect to agents’ task-specific rewards. In this paper, we propose an adaptive conflict-aware gradient adjustment method that promotes cooperation while ensuring fairness in individual rewards. The proposed method dynamically balances policy gradients derived from individual and collective objectives in situations where the two objectives are in conflict. By explicitly resolving such conflicts, our method improves collective performance while preserving fairness across agents. We provide theoretical results that guarantee monotonic non-decreasing improvement in both the collective and individual objectives and ensure fairness. Empirical results in sequential social dilemma environments demonstrate that our approach outperforms baselines in terms of social welfare, while maintaining fairness.", "bibtex": "@inproceedings{\nkim2025fair,\ntitle={Fair Cooperation in Mixed-Motive Games via Conflict-Aware Gradient Adjustment},\nauthor={Woojun Kim and Katia P. Sycara},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=yPsJ1PKiAi}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Spotlight Fair Cooperation in Mixed-Motive Games via Conflict-Aware Gradient Adjustment.pdf", "retrieved_at": "2025-11-12T03:22:12.642940Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AgentTTS: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Fali Wang", "Hui Liu", "Zhenwei DAI", "Jingying Zeng", "Zhiwei Zhang", "Zongyu Wu", "Chen Luo", "Zhen Li", "Xianfeng Tang", "Qi He", "Suhang Wang"], "affinity_score": 0.6445, "link": "https://openreview.net/pdf/13ea5abf7135c2269571122e956e24009565de1f.pdf", "abstract": "Test-time scaling (TTS) enhances the performance of large language models (LLMs) by allocating additional compute resources during inference. However, existing research primarily investigates TTS in single-stage tasks; while many real-world problems are multi-stage complex tasks, composed of a sequence of heterogeneous subtasks with each subtask requires LLM of specific capability. Therefore, we study a novel problem: the test-time compute-optimal scaling in multi-stage complex tasks, aiming to select suitable models and allocate budgets per subtask to maximize overall performance. TTS in multi-stage tasks introduces two fundamental challenges: (i) The combinatorial search space of model and budget allocations, combined with the high cost of inference, makes brute-force search impractical. (ii) The optimal model and budget allocations across subtasks are interdependent, increasing the complexity of the compute-optimal search. To address this gap, we conduct extensive pilot experiments on four tasks across six datasets, deriving three empirical insights characterizing the behavior of LLMs in multi-stage complex tasks. Informed by these insights, we propose AgentTTS, an LLM-agent-based framework that autonomously searches for compute-optimal allocations through iterative feedback-driven interactions with the execution environment. Experimental results demonstrate that AgentTTS significantly outperforms traditional and other LLM-based baselines in search efficiency, and shows improved robustness to varying training set sizes and enhanced interpretability.", "bibtex": "@inproceedings{\nwang2025agenttts,\ntitle={Agent{TTS}: Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks},\nauthor={Fali Wang and Hui Liu and Zhenwei DAI and Jingying Zeng and Zhiwei Zhang and Zongyu Wu and Chen Luo and Zhen Li and Xianfeng Tang and Qi He and Suhang Wang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=BuYtcTUMyA}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster AgentTTS_ Large Language Model Agent for Test-time Compute-optimal Scaling Strategy in Complex Tasks.pdf", "retrieved_at": "2025-11-12T03:22:13.395182Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Yaxi Lu", "Shenzhi Yang", "Cheng Qian", "Guirong Chen", "Qinyu Luo", "Yesai Wu", "Huadong Wang", "Xin Cong", "Zhong Zhang", "Yankai Lin", "Weiwen Liu", "Yasheng Wang", "Zhiyuan Liu", "Fangming Liu", "Maosong Sun"], "affinity_score": 0.6444, "link": "https://openreview.net/pdf/ba670e591dd33509822a7a0360e6a84be1debcd5.pdf", "abstract": "Agents powered by large language models have shown remarkable abilities in solving complex tasks. However, most agent systems remain reactive, limiting their effectiveness in scenarios requiring foresight and autonomous decision-making. In this paper, we tackle the challenge of developing proactive agents capable of anticipating and initiating tasks without explicit human instructions. We propose a novel data-driven approach for this problem. Firstly, we collect real-world human activities to generate proactive task predictions. These predictions are then labeled by human annotators as either accepted or rejected. The labeled data is used to train a reward model that simulates human judgment and serves as an automatic evaluator of the proactiveness of LLM agents. Building on this, we develop a comprehensive data generation pipeline to create a diverse dataset, ProactiveBench, containing 6,790 events. Finally, we demonstrate that fine-tuning models with the proposed ProactiveBench can significantly elicit the proactiveness of LLM agents. Experimental results show that our fine-tuned model achieves an F1-Score of 66.47% in proactively offering assistance, outperforming all open-source and close-source models. These results highlight the potential of our method in creating more proactive and effective agent systems, paving the way for future advancements in human-agent collaboration.", "bibtex": "@inproceedings{\nlu2025proactive,\ntitle={Proactive Agent: Shifting {LLM} Agents from Reactive Responses to Active Assistance},\nauthor={Yaxi Lu and Shenzhi Yang and Cheng Qian and Guirong Chen and Qinyu Luo and Yesai Wu and Huadong Wang and Xin Cong and Zhong Zhang and Yankai Lin and Weiwen Liu and Yasheng Wang and Zhiyuan Liu and Fangming Liu and Maosong Sun},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=sRIU6k2TcU}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Proactive Agent_ Shifting LLM Agents from Reactive Responses to Active Assistance.pdf", "retrieved_at": "2025-11-12T03:22:14.878720Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Dolphin: Moving Towards Closed-loop Auto-research through Thinking, Practice, and Feedback", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Jiakang Yuan", "Xiangchao Yan", "Bo Zhang (波章", ")", "Tao Chen", "Botian Shi", "Wanli Ouyang", "Yu Qiao", "Lei Bai", "Bowen Zhou"], "affinity_score": 0.6442, "link": "https://aclanthology.org/2025.acl-long.1056/", "abstract": "The scientific research paradigm is undergoing a profound transformation owing to the development of Artificial Intelligence (AI). Recent works demonstrate that various AI-assisted research methods can largely improve research efficiency by improving data analysis, accelerating computation, and fostering novel idea generation. To further move towards the ultimate goal (i.e., automatic scientific research), in this paper, we introduce Dolphin, a closed-loop LLM-driven framework to enhance the automation level of scientific research. Dolphin first generates novel ideas based on feedback from previous experiments and relevant papers ranked by the topic and task attributes. Then, the generated ideas can be implemented using a code template refined and debugged with the designed exception-traceback-guided local code structure. Finally, Dolphin automatically analyzes the results of each idea and feeds the results back to the next round of idea generation. Experiments are conducted on the benchmark datasets of different topics and a subset of MLE-bench. Results show that Dolphin can continuously improve the performance of the input topic in a loop. We highlight that Dolphin can automatically propose methods that are comparable to the state-of-the-art in some tasks such as 3D point classification.", "bibtex": "@inproceedings{yuan-etal-2025-dolphin,\n    title = \"Dolphin: Moving Towards Closed-loop Auto-research through Thinking, Practice, and Feedback\",\n    author = \"Yuan, Jiakang  and\n      Yan, Xiangchao  and\n      Zhang, Bo  and\n      Chen, Tao  and\n      Shi, Botian  and\n      Ouyang, Wanli  and\n      Qiao, Yu  and\n      Bai, Lei  and\n      Zhou, Bowen\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1056/\",\n    doi = \"10.18653/v1/2025.acl-long.1056\",\n    pages = \"21768--21789\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Dolphin_ Moving Towards Closed-loop Auto-research through Thinking, Practice, and Feedback.pdf", "retrieved_at": "2025-11-12T03:22:15.133452Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ChemAgent: Self-updating Memories in Large Language Models Improves Chemical Reasoning", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Xiangru Tang", "Tianyu Hu", "Muyang Ye", "Yanjun Shao", "Xunjian Yin", "Siru Ouyang", "Wangchunshu Zhou", "Pan Lu", "Zhuosheng Zhang", "Yilun Zhao", "Arman Cohan", "Mark Gerstein"], "affinity_score": 0.644, "link": "https://openreview.net/pdf/f072f5a9e65a8bb918caeaa9fdf7a78732984cba.pdf", "abstract": "Chemical reasoning usually involves complex, multi-step processes that demand precise calculations, where even minor errors can lead to cascading failures. Furthermore, large language models (LLMs) encounter difficulties handling domain-specific formulas, executing reasoning steps accurately, and integrating code ef- effectively when tackling chemical reasoning tasks. To address these challenges, we present ChemAgent, a novel framework designed to improve the performance of LLMs through a dynamic, self-updating library. This library is developed by decomposing chemical tasks into sub-tasks and compiling these sub-tasks into a structured collection that can be referenced for future queries. Then, when presented with a new problem, ChemAgent retrieves and refines pertinent information from the library, which we call memory, facilitating effective task decomposition and the generation of solutions. Our method designs three types of memory and a library-enhanced reasoning component, enabling LLMs to improve over time through experience. Experimental results on four chemical reasoning datasets from SciBench demonstrate that ChemAgent achieves performance gains of up to 46% (GPT-4), significantly outperforming existing methods. Our findings suggest substantial potential for future applications, including tasks such as drug discovery and materials science. Our code can be found at https://github.com/gersteinlab/ChemAgent.", "bibtex": "@inproceedings{\ntang2025chemagent,\ntitle={ChemAgent: Self-updating Memories in Large Language Models Improves Chemical Reasoning},\nauthor={Xiangru Tang and Tianyu Hu and Muyang Ye and Yanjun Shao and Xunjian Yin and Siru Ouyang and Wangchunshu Zhou and Pan Lu and Zhuosheng Zhang and Yilun Zhao and Arman Cohan and Mark Gerstein},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=kuhIqeVg0e}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster ChemAgent_ Self-updating Memories in Large Language Models Improves Chemical Reasoning.pdf", "retrieved_at": "2025-11-12T03:22:16.340617Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Wanxin Tian", "Shijie Zhang", "Kevin Zhang", "Xiaowei Chi", "Chun-Kai Fan", "Junyu Lu", "Yulin Luo", "Qiang Zhou", "Yiming Zhao", "Ning Liu", "Siyu Lin", "Zhiyuan Qin", "Xiaozhu Ju", "Shanghang Zhang", "Jian Tang"], "affinity_score": 0.6437, "link": "https://openreview.net/pdf/d934e1858b206a0ba8fe1fb5281ee9f117238785.pdf", "abstract": "Self-evolution, the ability of agents to autonomously improve their reasoning and behavior, is essential for the embodied domain with long-horizon, real-world tasks. Despite current advancements in reinforcement fine-tuning (RFT) showing strong performance in enhancing reasoning in LLMs, its potential to enable self-evolving embodied intelligence with multi-modal interactions remains largely unexplored. Specifically, reinforcement fine-tuning faces two fundamental obstacles in embodied settings: (i) the lack of accessible intermediate rewards in multi-step reasoning tasks limits effective learning signals, and (ii) reliance on hand-crafted reward functions restricts generalization to novel tasks and environments. To address these challenges, we present\nSelf-Evolving Embodied Agents-R1\n,\nSEEA-R1\n, the first RFT framework designed for enabling the self-evolving capabilities of embodied agents. Specifically, to convert sparse delayed rewards into denser intermediate signals that improve multi-step reasoning, we propose Tree-based group relative policy optimization (\nTree-GRPO\n) integrates Monte Carlo Tree Search into GRPO. To generalize reward estimation across tasks and scenes, supporting autonomous adaptation and reward-driven self-evolution, we further introduce Multi-modal Generative Reward Model (\nMGRM\n). To holistically evaluate the effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing state-of-the-art methods with scores of 85.07\\% (textual) and 46.27\\% (multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also achieves scores of 80.3\\% (textual) and 44.03\\% (multi-modal) without ground truth reward, surpassing all open-source baselines and highlighting its scalability as a self-evolving embodied agent. Additional experiments and qualitative analysis further support the potential of SEEA-R1 for future research in scalable embodied intelligence. Project page is at https://seea-r1.github.io/.", "bibtex": "@inproceedings{\ntian2025seear,\ntitle={{SEEA}-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents},\nauthor={Wanxin Tian and Shijie Zhang and Kevin Zhang and Xiaowei Chi and Chun-Kai Fan and Junyu Lu and Yulin Luo and Qiang Zhou and Yiming Zhao and Ning Liu and Siyu Lin and Zhiyuan Qin and Xiaozhu Ju and Shanghang Zhang and Jian Tang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=dAwKePZvcN}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster SEEA-R1_ Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents.pdf", "retrieved_at": "2025-11-12T03:22:17.855743Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Chengye Wang", "Yifei Shen", "Zexi Kuang", "Arman Cohan", "Yilun Zhao"], "affinity_score": 0.6437, "link": "https://aclanthology.org/2025.acl-long.420/", "abstract": "We introduce SciVer, the first benchmark specifically designed to evaluate the ability of foundation models to verify claims within a multimodal scientific context.SciVer consists of 3,000 expert-annotated examples over 1,113 scientific papers, covering four subsets, each representing a common reasoning type in multimodal scientific claim verification. To enable fine-grained evaluation, each example includes expert-annotated supporting evidence.We assess the performance of 21 state-of-the-art multimodal foundation models, including o4-mini, Gemini-2.5-Flash, Llama-3.2-Vision, and Qwen2.5-VL. Our experiment reveals a substantial performance gap between these models and human experts on SciVer.Through an in-depth analysis of retrieval-augmented generation (RAG), and human-conducted error evaluations, we identify critical limitations in current open-source models, offering key insights to advance models’ comprehension and reasoning in multimodal scientific literature tasks.", "bibtex": "@inproceedings{wang-etal-2025-sciver,\n    title = \"{S}ci{V}er: Evaluating Foundation Models for Multimodal Scientific Claim Verification\",\n    author = \"Wang, Chengye  and\n      Shen, Yifei  and\n      Kuang, Zexi  and\n      Cohan, Arman  and\n      Zhao, Yilun\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.420/\",\n    doi = \"10.18653/v1/2025.acl-long.420\",\n    pages = \"8562--8579\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long SciVer_ Evaluating Foundation Models for Multimodal Scientific Claim Verification.pdf", "retrieved_at": "2025-11-12T03:22:18.179343Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Do as We Do, Not as You Think: the Conformity of Large Language Models", "venue": "ICLR 2025 Oral", "year": "2025", "authors": ["Zhiyuan Weng", "Guikun Chen", "Wenguan Wang"], "affinity_score": 0.6437, "link": "https://openreview.net/pdf/cefcfec072e2db0f4b2196da7ea26a99d12a19a7.pdf", "abstract": "Recent advancements in large language models (LLMs) revolutionize the field of intelligent agents, enabling collaborative multi-agent systems capable of tackling complex problems across various domains. However, the potential of conformity within these systems, analogous to phenomena like conformity bias and group-think in human group dynamics, remains largely unexplored, raising concerns about their collective problem-solving capabilities and possible ethical implications. This paper presents a comprehensive study on conformity in LLM-driven multi-agent systems, focusing on three aspects: the existence of conformity, the factors influencing conformity, and potential mitigation strategies. In particular, we introduce BenchForm, a new conformity-oriented benchmark, featuring reasoning-intensive tasks and five distinct interaction protocols designed to probe LLMs’ behavior in collaborative scenarios. Several representative LLMs are evaluated on BenchForm, using metrics such as conformity rate and independence rate to quantify conformity’s impact. Our analysis delves into factors influencing conformity, including interaction time and majority size, and examines how the subject agent rationalize its conforming behavior. Furthermore, we explore two strategies to mitigate conformity effects, i.e., developing enhanced persona and implementing a reflection mechanism. Several interesting findings regarding LLMs’ conformity are derived from empirical results and case studies. We hope that these insights can pave the way for more robust and ethically-aligned collaborative AI systems. Our benchmark and code are available at BenchForm.", "bibtex": "@inproceedings{\nweng2025do,\ntitle={Do as We Do, Not as You Think: the Conformity of Large Language Models},\nauthor={Zhiyuan Weng and Guikun Chen and Wenguan Wang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=st77ShxP1K}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Oral Do as We Do, Not as You Think_ the Conformity of Large Language Models.pdf", "retrieved_at": "2025-11-12T03:22:18.812350Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Ad Hoc Teamwork via Offline Goal-Based Decision Transformers", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Xinzhi Zhang", "Hohei Chan", "Deheng Ye", "Yi Cai", "Mengchen Zhao"], "affinity_score": 0.6437, "link": "https://openreview.net/pdf/5a5bbf1f929c37537b614aa6bfbe6de1b7924960.pdf", "abstract": "The ability of agents to collaborate with previously unknown teammates on the fly, known as ad hoc teamwork (AHT), is crucial in many real-world applications. Existing approaches to AHT require online interactions with the environment and some carefully designed teammates. However, these prerequisites can be infeasible in practice. In this work, we extend the AHT problem to the offline setting, where the policy of the ego agent is directly learned from a multi-agent interaction dataset. We propose a hierarchical sequence modeling framework called TAGET that addresses critical challenges in the offline setting, including limited data, partial observability and online adaptation. The core idea of TAGET is to dynamically predict teammate-aware rewards-to-go and sub-goals, so that the ego agent can adapt to the changes of teammates’ behaviors in real time. Extensive experimental results show that TAGET significantly outperforms existing solutions to AHT in the offline setting.", "bibtex": "@inproceedings{\nzhang2025ad,\ntitle={Ad Hoc Teamwork via Offline Goal-Based Decision Transformers},\nauthor={Xinzhi Zhang and Hohei Chan and Deheng Ye and Yi Cai and Mengchen Zhao},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=tl3FlgWScA}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster Ad Hoc Teamwork via Offline Goal-Based Decision Transformers.pdf", "retrieved_at": "2025-11-12T03:22:19.555933Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "TriageAgent: Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Meng Lu", "Brandon Ho", "Dennis Ren", "Xuan Wang"], "affinity_score": 0.6436, "link": "https://aclanthology.org/2024.findings-emnlp.329/", "abstract": "The global escalation in emergency department patient visits poses significant challenges to efficient clinical management, particularly in clinical triage. Traditionally managed by human professionals, clinical triage is susceptible to substantial variability and high workloads. Although large language models (LLMs) demonstrate promising reasoning and understanding capabilities, directly applying them to clinical triage remains challenging due to the complex and dynamic nature of the clinical triage task. To address these issues, we introduce TriageAgent, a novel heterogeneous multi-agent framework designed to enhance collaborative decision-making in clinical triage. TriageAgent leverages LLMs for role-playing, incorporating self-confidence and early-stopping mechanisms in multi-round discussions to improve document reasoning and classification precision for triage tasks. In addition, TriageAgent employs the medical Emergency Severity Index (ESI) handbook through a retrieval-augmented generation (RAG) approach to provide precise clinical knowledge and integrates both coarse- and fine-grained ESI-level predictions in the decision-making process. Extensive experiments demonstrate that TriageAgent outperforms state-of-the-art LLM-based methods on three clinical triage test sets. Furthermore, we have released the first public benchmark dataset for clinical triage with corresponding ESI levels and human expert performance for comparison.", "bibtex": "@inproceedings{lu-etal-2024-triageagent,\n    title = \"{T}riage{A}gent: Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage\",\n    author = \"Lu, Meng  and\n      Ho, Brandon  and\n      Ren, Dennis  and\n      Wang, Xuan\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.329/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.329\",\n    pages = \"5747--5764\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings TriageAgent_ Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage.pdf", "retrieved_at": "2025-11-12T03:22:19.806604Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "M2PA: A Multi-Memory Planning Agent for Open Worlds Inspired by Cognitive Theory", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Yanfang Zhou", "Xiaodong Li", "Yuntao Liu", "Yongqiang Zhao", "Xintong Wang", "Zhenyu Li", "Jinlong Tian", "Xinhai Xu"], "affinity_score": 0.6434, "link": "https://aclanthology.org/2025.findings-acl.1191/", "abstract": "Open-world planning poses a significant challenge for general artificial intelligence due to environmental complexity and task diversity, especially in long-term tasks and lifelong learning. Inspired by cognitive theories, we propose M2PA, an open-world multi-memory planning agent. M2PA innovates by combining Large Language Models (LLMs) with human-like multi-memory systems, aiming to fully leverage the strengths of both while mitigating their respective limitations. By integrating the expansive world knowledge and language processing capabilities of LLMs with the perception and experience accumulation abilities of the human memory system, M2PA exhibits situation awareness, and experience generalization capabilities, as well as the potential for lifelong learning. In experiments, M2PA significantly outperforms current state-of-the-art agents across 50 Minecraft tasks in zero-shot learning. In exploratory lifelong learning experiments, M2PA demonstrates its continuous learning ability, achieving a 38.33% success rate in the “ObtainDiamond” task. Our findings provide a novel paradigm for constructing more effective agents in open-world environments.", "bibtex": "@inproceedings{yanfangzhou-etal-2025-m2pa,\n    title = \"{M}2{PA}: A Multi-Memory Planning Agent for Open Worlds Inspired by Cognitive Theory\",\n    author = \"Zhou, Yanfang  and\n      Li, Xiaodong  and\n      Liu, Yuntao  and\n      Zhao, Yongqiang  and\n      Wang, Xintong  and\n      Li, Zhenyu  and\n      Tian, Jinlong  and\n      Xu, Xinhai\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1191/\",\n    doi = \"10.18653/v1/2025.findings-acl.1191\",\n    pages = \"23204--23220\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings M2PA_ A Multi-Memory Planning Agent for Open Worlds Inspired by Cognitive Theory.pdf", "retrieved_at": "2025-11-12T03:22:20.176256Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Improving Retrospective Language Agents via Joint Policy Gradient Optimization", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Xueyang Feng", "Bo Lan", "Quanyu Dai", "Lei Wang (王雷)", "Jiakai Tang", "Xu Chen (陈旭)", "Zhenhua Dong", "Ji-Rong Wen"], "affinity_score": 0.6432, "link": "https://aclanthology.org/2025.naacl-long.6/", "abstract": "In recent research advancements within the community, large language models (LLMs) have sparked great interest in creating autonomous agents. However, current prompt-based agents often heavily rely on large-scale LLMs. Meanwhile, although fine-tuning methods significantly enhance the capabilities of smaller LLMs, the fine-tuned agents often lack the potential for self-reflection and self-improvement. To address these challenges, we introduce a novel agent framework named RetroAct, which is a framework that jointly optimizes both task-planning and self-reflective evolution capabilities in language agents. Specifically, we develop a two-stage joint optimization process that integrates imitation learning and reinforcement learning, and design an off-policy joint policy gradient optimization algorithm with imitation learning regularization to enhance the data efficiency and training stability in agent tasks. RetroAct significantly improves the performance of open-source models, reduces dependency on closed-source LLMs, and enables fine-tuned agents to learn and evolve continuously. We conduct extensive experiments across various testing environments, demonstrating RetroAct has substantial improvements in task performance and decision-making processes.", "bibtex": "@inproceedings{feng-etal-2025-improving,\n    title = \"Improving Retrospective Language Agents via Joint Policy Gradient Optimization\",\n    author = \"Feng, Xueyang  and\n      Lan, Bo  and\n      Dai, Quanyu  and\n      Wang, Lei  and\n      Tang, Jiakai  and\n      Chen, Xu  and\n      Dong, Zhenhua  and\n      Wen, Ji-Rong\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.6/\",\n    doi = \"10.18653/v1/2025.naacl-long.6\",\n    pages = \"112--141\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long Improving Retrospective Language Agents via Joint Policy Gradient Optimization.pdf", "retrieved_at": "2025-11-12T03:22:20.403484Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Tool-Planner: Task Planning with Clusters across Multiple Tools", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Yanming Liu", "Xinyue Peng", "Jiannan Cao", "Shi Bo", "Yuwei Zhang", "Xuhong Zhang", "Sheng Cheng", "Xun Wang", "Jianwei Yin", "Tianyu Du"], "affinity_score": 0.643, "link": "https://openreview.net/pdf/60305c49e9c179b0b6d6201aca2de8a489d664a5.pdf", "abstract": "Large language models (LLMs) have demonstrated exceptional reasoning capabilities, enabling them to solve various complex problems. Recently, this ability has been applied to the paradigm of tool learning. Tool learning involves providing examples of tool usage and their corresponding functions, allowing LLMs to formulate plans and demonstrate the process of invoking and executing each tool. LLMs can address tasks that they cannot complete independently, thereby enhancing their potential across different tasks. However, this approach faces two key challenges. First, redundant error correction leads to unstable planning and long execution time. Additionally, designing a correct plan among multiple tools is also a challenge in tool learning. To address these issues, we propose Tool-Planner, a task-processing framework based on toolkits. Tool-Planner groups tools based on the API functions with the same function into a toolkit and allows LLMs to implement planning across the various toolkits. When a tool error occurs, the language model can reselect and adjust tools based on the toolkit. Experiments show that our approach demonstrates a high pass and win rate across different datasets and optimizes the planning scheme for tool learning in models such as GPT-4 and Claude 3, showcasing the potential of our method. Our code is public at\n https://github.com/OceannTwT/Tool-Planner.", "bibtex": "@inproceedings{\nliu2025toolplanner,\ntitle={Tool-Planner: Task Planning with Clusters across Multiple Tools},\nauthor={Yanming Liu and Xinyue Peng and Jiannan Cao and Shi Bo and Yuwei Zhang and Xuhong Zhang and Sheng Cheng and Xun Wang and Jianwei Yin and Tianyu Du},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=dRz3cizftU}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Tool-Planner_ Task Planning with Clusters across Multiple Tools.pdf", "retrieved_at": "2025-11-12T03:22:21.980832Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Multi-agent cooperation through learning-aware policy gradients", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Alexander Meulemans", "Seijin Kobayashi", "Johannes von Oswald", "Nino Scherrer", "Eric Elmoznino", "Blake Aaron Richards", "Guillaume Lajoie", "Blaise Aguera y Arcas", "Joao Sacramento"], "affinity_score": 0.6428, "link": "https://openreview.net/pdf/285e1b9dad7e2cc3ca878820b61f9e4c7a3d7c97.pdf", "abstract": "Self-interested individuals often fail to cooperate, posing a fundamental challenge for multi-agent learning. How can we achieve cooperation among self-interested, independent learning agents? Promising recent work has shown that in certain tasks cooperation can be established between ``learning-aware\" agents who model the learning dynamics of each other. Here, we present the first unbiased, higher-derivative-free policy gradient algorithm for learning-aware reinforcement learning, which takes into account that other agents are themselves learning through trial and error based on multiple noisy trials. We then leverage efficient sequence models to condition behavior on long observation histories that contain traces of the learning dynamics of other agents. Training long-context policies with our algorithm leads to cooperative behavior and high returns on standard social dilemmas, including a challenging environment where temporally-extended action coordination is required. Finally, we derive from the iterated prisoner's dilemma a novel explanation for how and when cooperation arises among self-interested learning-aware agents.", "bibtex": "@inproceedings{\nmeulemans2025multiagent,\ntitle={Multi-agent cooperation through learning-aware policy gradients},\nauthor={Alexander Meulemans and Seijin Kobayashi and Johannes von Oswald and Nino Scherrer and Eric Elmoznino and Blake Aaron Richards and Guillaume Lajoie and Blaise Aguera y Arcas and Joao Sacramento},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=GkWA6NjePN}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Multi-agent cooperation through learning-aware policy gradients.pdf", "retrieved_at": "2025-11-12T03:22:23.203043Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Xuan Long Do", "Duong Ngoc Yen", "Luu Anh Tuan", "Kenji Kawaguchi", "Min-Yen Kan", "Nancy Chen"], "affinity_score": 0.6426, "link": "https://aclanthology.org/2024.emnlp-main.1135/", "abstract": "We present Multi-expert Prompting, a novel enhancement of ExpertPrompting (Xu et al., 2023), designed to improve the large language model (LLM) generation. Specifically, it guides an LLM to fulfill an input instruction by simulating multiple experts, aggregating their responses, and selecting the best among individual and aggregated responses. This process is performed in a single chain of thoughts through our seven carefully designed subtasks derived from the Nominal Group Technique (Ven and Delbecq, 1974), a well-established decision-making framework. Our evaluations demonstrate that Multi-expert Prompting significantly outperforms ExpertPrompting and comparable baselines in enhancing the truthfulness, factuality, informativeness, and usefulness of responses while reducing toxicity and hurtfulness. It further achieves state-of-the-art truthfulness by outperforming the best baseline by 8.69% with ChatGPT. Multi-expert Prompting is efficient, explainable, and highly adaptable to diverse scenarios, eliminating the need for manual prompt construction.", "bibtex": "@inproceedings{long-etal-2024-multi-expert,\n    title = \"Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models\",\n    author = \"Long, Do Xuan  and\n      Yen, Duong Ngoc  and\n      Luu, Anh Tuan  and\n      Kawaguchi, Kenji  and\n      Kan, Min-Yen  and\n      Chen, Nancy F.\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.1135/\",\n    doi = \"10.18653/v1/2024.emnlp-main.1135\",\n    pages = \"20370--20401\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main Multi-expert Prompting Improves Reliability, Safety and Usefulness of Large Language Models.pdf", "retrieved_at": "2025-11-12T03:22:23.636785Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Multiverse: Your Language Models Secretly Decide How to Parallelize and Merge Generation", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Xinyu Yang", "Yuwei An", "Hongyi Liu", "Tianqi Chen", "Beidi Chen"], "affinity_score": 0.6426, "link": "https://openreview.net/pdf/5f50a250befd3553dd40112c1a440f86b36737da.pdf", "abstract": "Autoregressive Large Language Models (AR-LLMs) frequently exhibit implicit parallelism in sequential generation. Inspired by this, we introduce Multiverse, a new generative model enabling natively parallel generation. Multiverse internalizes a MapReduce paradigm, generating automatically through three stages: (i) a Map stage for adaptive task decomposition, (ii) a Process stage for parallel subtask execution, and (iii) a Reduce stage for lossless result synthesis. Next, we build a real-world Multiverse reasoning model with co-design of data, algorithm, and system, enabling rapid and seamless transfer from frontier AR-LLMs. For data creation, we develop Multiverse Curator, an automated LLM-assisted pipeline that transforms sequential reasoning chains into structured training data, avoiding costly human annotations. Algorithmically, we design Multiverse Attention to separate parallel reasoning steps while keeping compatibility with causal attention for efficient training. Systematically, we implement Multiverse Engine to support parallel inference. It features a dedicated interpreter that dynamically switches between sequential and parallel generation, triggered directly by the model. After a 3-hour fine-tuning with 1K examples, our Multiverse-32B stands as the only open-sourced non-AR model achieving performance on par with leading AR-LLMs of the same scale, evidenced by AIME24 & 25 scores of 54% and 46%, respectively. Moreover, our budget control experiments show that Multiverse-32B exhibits superior scaling, outperforming AR-LLMs by 1.87% on average using the same context length. Such scaling further leads to practical efficiency gain, achieving up to 2x speedup across varying batch sizes. We have open-sourced the entire Multiverse ecosystem, including data, model weights, serving system, supporting tools, as well as data curation prompts and detailed training and evaluation recipes.", "bibtex": "@inproceedings{\nyang2025multiverse,\ntitle={Multiverse: Your Language Models Secretly Decide How to Parallelize and Merge Generation},\nauthor={Xinyu Yang and Yuwei An and Hongyi Liu and Tianqi Chen and Beidi Chen},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=r9YDEErKXU}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Spotlight Multiverse_ Your Language Models Secretly Decide How to Parallelize and Merge Generation.pdf", "retrieved_at": "2025-11-12T03:22:24.599162Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Retrieval Models Aren’t Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Zhengliang Shi", "Yuhan Wang", "Lingyong Yan", "Pengjie Ren", "Shuaiqiang Wang", "Dawei Yin", "Zhaochun Ren"], "affinity_score": 0.6424, "link": "https://aclanthology.org/2025.findings-acl.1258/", "abstract": "Tool learning aims to augment large language models (LLMs) with diverse tools, enabling them to act as agents for solving practical tasks. Due to the limited context length of tool-using LLMs, adopting information retrieval (IR) models to select useful tools from large toolsets is a critical initial step. However, the performance of IR models in tool retrieval tasks remains underexplored and unclear. Most tool-use benchmarks simplify this step by manually pre-annotating a small set of relevant tools for each task, which is far from the real-world scenarios. In this paper, we propose ToolRet, a heterogeneous tool retrieval benchmark comprising 7.6k diverse retrieval tasks, and a corpus of 43k tools, collected from existing datasets. We benchmark six types of models on ToolRet. Surprisingly, even the models with strong performance in conventional IR benchmarks, exhibit poor performance on ToolRet. This low retrieval quality degrades the task pass rate of tool-use LLMs. As a further step, we contribute a large-scale training dataset with over 200k instances, which substantially optimizes the tool retrieval ability of IR models.", "bibtex": "@inproceedings{shi-etal-2025-retrieval,\n    title = \"Retrieval Models Aren{'}t Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models\",\n    author = \"Shi, Zhengliang  and\n      Wang, Yuhan  and\n      Yan, Lingyong  and\n      Ren, Pengjie  and\n      Wang, Shuaiqiang  and\n      Yin, Dawei  and\n      Ren, Zhaochun\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.1258/\",\n    doi = \"10.18653/v1/2025.findings-acl.1258\",\n    pages = \"24497--24524\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings Retrieval Models Aren’t Tool-Savvy_ Benchmarking Tool Retrieval for Large Language Models.pdf", "retrieved_at": "2025-11-12T03:22:24.870988Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Thought Communication in Multiagent Collaboration", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Yujia Zheng", "Zhuokai Zhao", "Zijian Li", "Yaqi Xie", "Mingze Gao", "Lizhu Zhang", "Kun Zhang"], "affinity_score": 0.6422, "link": "https://openreview.net/pdf/7e84ecbda8064983f20c395751d38019a0ab3981.pdf", "abstract": "Natural language has long enabled human cooperation, but its lossy, ambiguous, and indirect nature limits the potential of collective intelligence. While machines are not subject to these constraints, most LLM-based multi-agent systems still rely solely on natural language, exchanging tokens or their embeddings. To go beyond language, we introduce a new paradigm,\nthought communication\n, which enables agents to interact directly mind-to-mind, akin to telepathy. To uncover these latent thoughts in a principled way, we formalize the process as a general latent variable model, where agent states are generated by an unknown function of underlying thoughts. We prove that, in a nonparametric setting without auxiliary information, both shared and private latent thoughts between any pair of agents can be identified. Moreover, the global structure of thought sharing, including which agents share which thoughts and how these relationships are structured, can also be recovered with theoretical guarantees. Guided by the established theory, we develop a framework that extracts latent thoughts from all agents prior to communication and assigns each agent the relevant thoughts, along with their sharing patterns. This paradigm naturally extends beyond LLMs to all modalities, as most observational data arise from hidden generative processes. Experiments on both synthetic and real-world benchmarks validate the theory and demonstrate the collaborative advantages of thought communication. We hope this work illuminates the potential of leveraging the hidden world, as many challenges remain unsolvable through surface-level observation alone, regardless of compute or data scale.", "bibtex": "@inproceedings{\nzheng2025thought,\ntitle={Thought Communication in Multiagent Collaboration},\nauthor={Yujia Zheng and Zhuokai Zhao and Zijian Li and Yaqi Xie and Mingze Gao and Lizhu Zhang and Kun Zhang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=tq9lyV9Cml}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Spotlight Thought Communication in Multiagent Collaboration.pdf", "retrieved_at": "2025-11-12T03:22:25.530886Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "LLM Agents for Coordinating Multi-User Information Gathering", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Harsh Jhamtani", "Jacob Andreas", "Benjamin Van Durme"], "affinity_score": 0.6421, "link": "https://aclanthology.org/2025.findings-acl.916/", "abstract": "This paper introduces PeopleJoin, a benchmark for evaluating LM-mediated collaborative problem solving. Given a user request, PeopleJoin agents must identify teammates who might be able to assist, converse with these teammates to gather information, and finally compile a useful answer or summary for the original user. PeopleJoin comprises two evaluation domains: PeopleJoin-QA, focused on questions about tabular data, and PeopleJoin-DocCreation, focused on document creation tasks. The two domains are adapted from existing NLP benchmarks for database question answering and multi-document summarization; here, however, the information needed to complete these tasks is distributed across synthetic “organizations” of 2–20 users, simulating natural multi-user collaboration scenarios. We implemented several popular LM agent architectures, evaluating their accuracy and efficiency at completing tasks, and highlight new research questions that can be studied using PeopleJoin.", "bibtex": "@inproceedings{jhamtani-etal-2025-llm,\n    title = \"{LLM} Agents for Coordinating Multi-User Information Gathering\",\n    author = \"Jhamtani, Harsh  and\n      Andreas, Jacob  and\n      Van Durme, Benjamin\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.916/\",\n    doi = \"10.18653/v1/2025.findings-acl.916\",\n    pages = \"17800--17826\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings LLM Agents for Coordinating Multi-User Information Gathering.pdf", "retrieved_at": "2025-11-12T03:22:25.757882Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Ruixuan Xiao", "Wentao Ma", "Ke Wang", "Yuchuan Wu", "Junbo Zhao", "Haobo Wang", "Fei Huang", "Yongbin Li"], "affinity_score": 0.6419, "link": "https://aclanthology.org/2024.findings-emnlp.638/", "abstract": "LLM-based agents have emerged as promising tools, which are crafted to fulfill complex tasks by iterative planning and action. However, these agents are susceptible to undesired planning hallucinations when lacking specific knowledge for expertise-intensive tasks. To address this, preliminary attempts are made to enhance planning reliability by incorporating external workflow-related knowledge. Despite the promise, such infused knowledge is mostly disorganized and diverse in formats, lacking rigorous formalization and comprehensive comparisons. Motivated by this, we formalize different formats of workflow knowledge and present FlowBench, the first benchmark for workflow-guided planning. FlowBench covers 51 different scenarios from 6 domains, with knowledge presented in diverse formats. To assess different LLMs on FlowBench, we design a multi-tiered evaluation framework. We evaluate the efficacy of workflow knowledge across multiple formats, and the results indicate that current LLM agents need considerable improvements for satisfactory planning. We hope that our challenging benchmark can pave the way for future agent planning research.", "bibtex": "@inproceedings{xiao-etal-2024-flowbench,\n    title = \"{F}low{B}ench: Revisiting and Benchmarking Workflow-Guided Planning for {LLM}-based Agents\",\n    author = \"Xiao, Ruixuan  and\n      Ma, Wentao  and\n      Wang, Ke  and\n      Wu, Yuchuan  and\n      Zhao, Junbo  and\n      Wang, Haobo  and\n      Huang, Fei  and\n      Li, Yongbin\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.638/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.638\",\n    pages = \"10883--10900\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings FlowBench_ Revisiting and Benchmarking Workflow-Guided Planning for LLM-based Agents.pdf", "retrieved_at": "2025-11-12T03:22:26.247494Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "RiOSWorld: Benchmarking the Risk of Multimodal Computer-Use Agents", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Yang JingYi", "Shuai Shao", "Dongrui Liu", "Jing Shao"], "affinity_score": 0.6419, "link": "https://openreview.net/pdf/11ac207fff4f7439cb345f2e79ef2a6fb5611910.pdf", "abstract": "With the rapid development of multimodal large language models (MLLMs), they are increasingly deployed as autonomous computer-use agents capable of accomplishing complex computer tasks. However, a pressing issue arises: Can the safety risk principles designed and aligned for general MLLMs in dialogue scenarios be effectively transferred to real-world computer-use scenarios? \nExisting research on evaluating the safety risks of MLLM-based computer-use agents suffers from several limitations: it either lacks realistic interactive environments, or narrowly focuses on one or a few specific risk types. These limitations ignore the complexity, variability, and diversity of real-world environments, thereby restricting comprehensive risk evaluation for computer-use agents.\nTo this end, we introduce\nRiOSWorld\n, a benchmark designed to evaluate the potential risks of MLLM-based agents during real-world computer manipulations. Our benchmark includes 492 risky tasks spanning various computer applications, involving web, social media, multimedia, os, email, and office software. We categorize these risks into two major classes based on their risk source: (i) User-originated risks and (ii) Environmental risks. For the evaluation, we evaluate safety risks from two perspectives: (i) Risk goal intention and (ii) Risk goal completion. Extensive experiments with multimodal agents on\nRiOSWorld\ndemonstrate that current computer-use agents confront significant safety risks in real-world scenarios. Our findings highlight the necessity and urgency of safety alignment for computer-use agents in real-world computer manipulation, providing valuable insights for developing trustworthy computer-use agents.", "bibtex": "@inproceedings{\njingyi2025riosworld,\ntitle={Ri{OSW}orld: Benchmarking the Risk of Multimodal Computer-Use Agents},\nauthor={Yang JingYi and Shuai Shao and Dongrui Liu and Jing Shao},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=aPBBkHDK4W}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster RiOSWorld_ Benchmarking the Risk of Multimodal Computer-Use Agents.pdf", "retrieved_at": "2025-11-12T03:22:28.140275Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ReachAgent: Enhancing Mobile Agent via Page Reaching and Operation", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Qinzhuo Wu", "Wei Liu", "Jian Luan", "Bin Wang"], "affinity_score": 0.6418, "link": "https://aclanthology.org/2025.naacl-long.244/", "abstract": "Recently, mobile AI agents have gained increasing attention. Given a task, mobile AI agents can interact with mobile devices in multiple steps and finally form a GUI flow that solves the task. However, existing agents tend to focus on most task-relevant elements at each step, leading to local optimal solutions and ignoring the overall GUI flow. To address this issue, we constructed a training dataset called MobileReach, which breaks the task into page reaching and operation subtasks. Furthermore, we propose ReachAgent, a two-stage framework that focuses on improving its task-completion abilities. It utilizes the page reaching and page operation subtasks, along with reward-based preference GUI flows, to further enhance the agent. Experimental results show that ReachAgent significantly improves the Intersection over Union (IoU) Accuracy and Text Accuracy by 7.12% and 7.69% on the step-level and 4.72% and 4.63% on the task-level compared to the SOTA agent. Our data and code will be released upon acceptance.", "bibtex": "@inproceedings{wu-etal-2025-reachagent,\n    title = \"{R}each{A}gent: Enhancing Mobile Agent via Page Reaching and Operation\",\n    author = \"Wu, Qinzhuo  and\n      Liu, Wei  and\n      Luan, Jian  and\n      Wang, Bin\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.244/\",\n    doi = \"10.18653/v1/2025.naacl-long.244\",\n    pages = \"4760--4775\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long ReachAgent_ Enhancing Mobile Agent via Page Reaching and Operation.pdf", "retrieved_at": "2025-11-12T03:22:28.414755Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "The Power of Many: Multi-Agent Multimodal Models for Cultural Image Captioning", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Longju Bai", "Angana Borah", "Oana Ignat", "Rada Mihalcea"], "affinity_score": 0.6416, "link": "https://aclanthology.org/2025.naacl-long.152/", "abstract": "Large Multimodal Models (LMMs) exhibit impressive performance across various multimodal tasks. However, their effectiveness in cross-cultural contexts remains limited due to the predominantly Western-centric nature of most data and models. Conversely, multi-agent models have shown significant capability in solving complex tasks. Our study evaluates the collective performance of LMMs in a multi-agent interaction setting for the novel task of cultural image captioning. Our contributions are as follows: (1) We introduce MosAIC, a Multi-Agent framework to enhance cross-cultural Image Captioning using LMMs with distinct cultural personas; (2) We provide a dataset of culturally enriched image captions in English for images from China, India, and Romania across three datasets: GeoDE, GD-VCR, CVQA; (3) We propose a culture-adaptable metric for evaluating cultural information within image captions; and (4) We show that the multi-agent interaction outperforms single-agent models across different metrics, and offer valuable insights for future research.", "bibtex": "@inproceedings{bai-etal-2025-power,\n    title = \"The Power of Many: Multi-Agent Multimodal Models for Cultural Image Captioning\",\n    author = \"Bai, Longju  and\n      Borah, Angana  and\n      Ignat, Oana  and\n      Mihalcea, Rada\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.152/\",\n    doi = \"10.18653/v1/2025.naacl-long.152\",\n    pages = \"2970--2993\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long The Power of Many_ Multi-Agent Multimodal Models for Cultural Image Captioning.pdf", "retrieved_at": "2025-11-12T03:22:30.075857Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Multi-agent KTO: Enhancing Strategic Interactions of Large Language Model in Language Game", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Rong Ye", "Yongxin Zhang", "Yikai Zhang", "Haoyu Kuang", "peng sun", "zhongyu wei"], "affinity_score": 0.6415, "link": "https://openreview.net/pdf/bbabefb823eddcdd5f1f54b70067773456bacdbd.pdf", "abstract": "Achieving Artificial General Intelligence (AGI) requires AI agents that can not only make strategic decisions but also engage in flexible and meaningful communication. Inspired by Wittgenstein's language game theory, we propose that language agents can learn through in-context interaction rather than traditional multi-stage frameworks that separate decision-making from language expression. Using Werewolf, a social deduction game that tests language understanding, strategic interaction, and adaptability, as a test bed, we develop the Multi-agent Kahneman-Tversky's Optimization (MaKTO). MaKTO engages diverse models in extensive gameplay to generate unpaired desirable and unacceptable responses, then employs KTO to refine the model's decision-making process. In 9-player Werewolf games, MaKTO achieves a 61% average win rate across various models, outperforming GPT-4o and two-stage RL agents by relative improvements of 23.0% and 10.9%, respectively. Notably, MaKTO also demonstrates human-like performance, winning 60% against expert players and showing only 48.9% detectability in Turing-style blind tests. Code and data are available at project page https://reneeye.github.io/MaKTO.html.", "bibtex": "@inproceedings{\nye2025multiagent,\ntitle={Multi-agent {KTO}: Enhancing Strategic Interactions of Large Language Model in Language Game},\nauthor={Rong Ye and Yongxin Zhang and Yikai Zhang and Haoyu Kuang and peng sun and zhongyu wei},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=WPHpBnKvdq}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Multi-agent KTO_ Enhancing Strategic Interactions of Large Language Model in Language Game.pdf", "retrieved_at": "2025-11-12T03:22:30.739989Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Agentic Knowledgeable Self-awareness", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Shuofei Qiao", "Zhisong Qiu", "Baochang Ren", "Xiaobin Wang", "Xiangyuan Ru", "Ningyu Zhang", "Xiang Chen", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Huajun Chen"], "affinity_score": 0.6414, "link": "https://aclanthology.org/2025.acl-long.619/", "abstract": "Large Language Models (LLMs) have achieved considerable performance across various agentic planning tasks. However, traditional approaches adopt a “flood irrigation” methodology that indiscriminately injects gold trajectories, external feedback, and domain knowledge into agent models. This practice overlooks the fundamental human cognitive principle of self-awareness - the ability to dynamically assess situational demands and strategically employ resources during decision-making. We propose Agentic Knowledgeable Self-awareness to address this gap, a novel paradigm enabling LLM-based agents to autonomously regulate knowledge utilization. Specifically, we propose KnowSelf , a data-centric approach that applies agents with know ledgeable self -awareness like humans. Concretely, we devise a heuristic situation judgement criterion to mark special tokens on the agent’s self-explored trajectories for collecting training data. Through a two-stage training process, the agent model can switch between different situations by generating specific special tokens, achieving optimal planning effects with minimal costs. Our experiments demonstrate that can outperform various strong baselines on different tasks and models with minimal use of external knowledge.", "bibtex": "@inproceedings{qiao-etal-2025-agentic,\n    title = \"Agentic Knowledgeable Self-awareness\",\n    author = \"Qiao, Shuofei  and\n      Qiu, Zhisong  and\n      Ren, Baochang  and\n      Wang, Xiaobin  and\n      Ru, Xiangyuan  and\n      Zhang, Ningyu  and\n      Chen, Xiang  and\n      Jiang, Yong  and\n      Xie, Pengjun  and\n      Huang, Fei  and\n      Chen, Huajun\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.619/\",\n    doi = \"10.18653/v1/2025.acl-long.619\",\n    pages = \"12601--12625\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Agentic Knowledgeable Self-awareness.pdf", "retrieved_at": "2025-11-12T03:22:31.112147Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MAPS: Advancing Multi-Modal Reasoning in Expert-Level Physical Science", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Erle Zhu", "Yadi Liu", "Zhe Zhang", "Xujun Li", "JinZhou", "Xinjie Yu", "Minlie Huang", "Hongning Wang"], "affinity_score": 0.6412, "link": "https://openreview.net/pdf/c84516a8e4b9a68b710453218bcaa36dee327176.pdf", "abstract": "Pre-trained on extensive text and image corpora, current Multi-Modal Large Language Models (MLLM) have shown strong capabilities in general visual reasoning tasks. \nHowever, their performance is still lacking in physical domains that require understanding diagrams with complex physical structures and quantitative analysis based on multi-modal information. \nTo address this, we develop a new framework, named\nM\nulti-Modal Scientific Re\nA\nsoning with\nP\nhysics Perception and\nS\nimulation (\nMAPS\n) based on an MLLM. \nMAPS decomposes expert-level multi-modal reasoning task into physical diagram understanding via a Physical Perception Model (PPM) and reasoning with physical knowledge via a simulator. \nThe PPM module is obtained by fine-tuning a visual language model using carefully designed synthetic data with paired physical diagrams and corresponding simulation language descriptions. \nAt the inference stage, MAPS integrates the simulation language description of the input diagram provided by PPM and results obtained through a Chain-of-Simulation process with MLLM to derive the underlying rationale and the final answer. \nValidated using our collected college-level circuit analysis problems, MAPS significantly improves reasoning accuracy of MLLM and outperforms all existing models. \nThe results confirm MAPS offers a promising direction for enhancing multi-modal scientific reasoning ability of MLLMs. \nWe will release our code, model and dataset used for our experiments upon publishing of this paper.", "bibtex": "@inproceedings{\nzhu2025maps,\ntitle={{MAPS}: Advancing Multi-Modal Reasoning in Expert-Level Physical Science},\nauthor={Erle Zhu and Yadi Liu and Zhe Zhang and Xujun Li and JinZhou and Xinjie Yu and Minlie Huang and Hongning Wang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=GR0y0F3Ipd}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster MAPS_ Advancing Multi-Modal Reasoning in Expert-Level Physical Science.pdf", "retrieved_at": "2025-11-12T03:22:32.000013Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "R3DM: Enabling Role Discovery and Diversity Through Dynamics Models in Multi-agent Reinforcement Learning", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Harsh Goel", "Mohammad Omama", "Behdad Chalaki", "Vaishnav Tadiparthi", "Ehsan Moradi Pari", "Sandeep P. Chinchali"], "affinity_score": 0.6411, "link": "https://openreview.net/pdf/857ab7d68934c04396d35f8beabafd85af467833.pdf", "abstract": "Multi-agent reinforcement learning (MARL) has achieved significant progress in large-scale traffic control, autonomous vehicles, and robotics. Drawing inspiration from biological systems where roles naturally emerge to enable coordination, role-based MARL methods have been proposed to enhance cooperation learning for complex tasks. However, existing methods exclusively derive roles from an agent's past experience during training, neglecting their influence on its future trajectories. This paper introduces a key insight: an agent’s role should shape its future behavior to enable effective coordination. Hence, we propose Role Discovery and Diversity through Dynamics Models (R3DM), a novel role-based MARL framework that learns emergent roles by maximizing the mutual information between agents' roles, observed trajectories, and expected future behaviors. R3DM optimizes the proposed objective through contrastive learning on past trajectories to first derive intermediate roles that shape intrinsic rewards to promote diversity in future behaviors across different roles through a learned dynamics model. Benchmarking on SMAC and SMACv2 environments demonstrates that R3DM outperforms state-of-the-art MARL approaches, improving multi-agent coordination to increase win rates by up to 20%. The code is available at https://github.com/UTAustin-SwarmLab/R3DM.", "bibtex": "@inproceedings{\ngoel2025rdm,\ntitle={R3{DM}: Enabling Role Discovery and Diversity Through Dynamics Models in Multi-agent Reinforcement Learning},\nauthor={Harsh Goel and Mohammad Omama and Behdad Chalaki and Vaishnav Tadiparthi and Ehsan Moradi Pari and Sandeep P. Chinchali},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=VSIjdKPGp8}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster R3DM_ Enabling Role Discovery and Diversity Through Dynamics Models in Multi-agent Reinforcement Learning.pdf", "retrieved_at": "2025-11-12T03:22:32.706328Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Curious Causality-Seeking Agents Learn Meta Causal World", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Zhiyu Zhao", "Haoxuan Li", "Haifeng Zhang", "Jun Wang", "Francesco Faccio", "Jürgen Schmidhuber", "Mengyue Yang"], "affinity_score": 0.641, "link": "https://openreview.net/pdf/4445ec123339778db9f6d34f44f2fcdc927ebd3d.pdf", "abstract": "When building a world model, a common assumption is that the environment has a single, unchanging underlying causal rule, like applying Newton's laws to every situation. However, in truly open-ended environments, the apparent causal mechanism may drift over time because the agent continually encounters novel contexts and operates within a limited observational window. This brings about a problem that, when building a world model, even subtle shifts in policy or environment states can alter the very observed causal mechanisms.\nIn this work, we introduce the Meta-Causal Graph as world models for open-ended environments, a minimal unified representation that efficiently encodes the transformation rules governing how causal structures shift across different latent world states. A single Meta-Causal Graph is composed of multiple causal subgraphs, each triggered by meta state, which is in the latent state space. Building on this representation, we introduce a Causality-Seeking Agent whose objectives are to (1) identify the meta states that trigger each subgraph, (2) discover the corresponding causal relationships by agent curiosity-driven intervention policy, and (3) iteratively refine the Meta-Causal Graph through ongoing curiosity-driven exploration and agent experiences. Experiments on both synthetic tasks and a challenging robot arm manipulation task demonstrate that our method robustly captures shifts in causal dynamics and generalizes effectively to previously unseen contexts.", "bibtex": "@inproceedings{\nzhao2025curious,\ntitle={Curious Causality-Seeking Agents Learn Meta Causal World},\nauthor={Zhiyu Zhao and Haoxuan Li and Haifeng Zhang and Jun Wang and Francesco Faccio and J{\\\"u}rgen Schmidhuber and Mengyue Yang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=sdK5Ufoo2d}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Curious Causality-Seeking Agents Learn Meta Causal World.pdf", "retrieved_at": "2025-11-12T03:22:33.455757Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Graph Diffusion for Robust Multi-Agent Coordination", "venue": "ICML 2025 Spotlightposter", "year": "2025", "authors": ["Xianghua Zeng", "Hang Su", "Zhengyi Wang", "Zhiyuan LIN"], "affinity_score": 0.6408, "link": "https://openreview.net/pdf/79f3d75d3322bdd5bddcd896cfb54793f6e97e57.pdf", "abstract": "Offline multi-agent reinforcement learning (MARL) struggles to estimate out-of-distribution states and actions due to the absence of real-time environmental feedback. While diffusion models show promise in addressing these challenges, their application primarily focuses on independently diffusing the historical trajectories of individual agents, neglecting crucial multi-agent coordination dynamics and reducing policy robustness in dynamic environments. In this paper, we propose MCGD, a novel Multi-agent Coordination framework based on Graph Diffusion models to improve the effectiveness and robustness of collaborative policies. Specifically, we begin by constructing a sparse coordination graph that includes continuous node attributes and discrete edge attributes to effectively identify the underlying dynamics of multi-agent interactions. Next, we derive transition probabilities between edge categories and present adaptive categorical diffusion to capture the structure diversity of multi-agent coordination. Leveraging this coordination structure, we define neighbor-dependent forward noise and develop anisotropic diffusion to enhance the action diversity of each agent. Extensive experiments across various multi-agent environments demonstrate that MCGD significantly outperforms existing state-of-the-art baselines in coordination performance and policy robustness in dynamic environments.", "bibtex": "@inproceedings{\nzeng2025graph,\ntitle={Graph Diffusion for Robust Multi-Agent Coordination},\nauthor={Xianghua Zeng and Hang Su and Zhengyi Wang and Zhiyuan LIN},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=T5IZ32ImAB}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Spotlightposter Graph Diffusion for Robust Multi-Agent Coordination.pdf", "retrieved_at": "2025-11-12T03:22:34.031304Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "ToolCoder: A Systematic Code-Empowered Tool Learning Framework for Large Language Models", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Hanxing Ding", "Shuchang Tao", "Liang Pang (庞亮)", "Zihao Wei", "Jinyang Gao", "Bolin Ding", "Huawei Shen (沈华伟)", "Xueqi Cheng (程学旗)"], "affinity_score": 0.6406, "link": "https://aclanthology.org/2025.acl-long.874/", "abstract": "Tool learning has emerged as a crucial capability for large language models (LLMs) to solve complex real-world tasks through interaction with external tools. Existing approaches face significant challenges, including reliance on hand-crafted prompts, difficulty in multi-step planning, and lack of precise error diagnosis and reflection mechanisms. We propose ToolCoder , a novel framework that reformulates tool learning as a code generation task. Inspired by software engineering principles, ToolCoder transforms natural language queries into structured Python function scaffold and systematically breaks down tasks with descriptive comments, enabling LLMs to leverage coding paradigms for complex reasoning and planning. It then generates and executes function implementations to obtain final responses. Additionally, ToolCoder stores successfully executed functions in a repository to promote code reuse, while leveraging error traceback mechanisms for systematic debugging, optimizing both execution efficiency and robustness. Experiments demonstrate that ToolCoder achieves superior performance in task completion accuracy and execution reliability compared to existing approaches, establishing the effectiveness of code-centric approaches in tool learning.", "bibtex": "@inproceedings{ding-etal-2025-toolcoder,\n    title = \"{T}ool{C}oder: A Systematic Code-Empowered Tool Learning Framework for Large Language Models\",\n    author = \"Ding, Hanxing  and\n      Tao, Shuchang  and\n      Pang, Liang  and\n      Wei, Zihao  and\n      Gao, Jinyang  and\n      Ding, Bolin  and\n      Shen, Huawei  and\n      Cheng, Xueqi\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.874/\",\n    doi = \"10.18653/v1/2025.acl-long.874\",\n    pages = \"17876--17891\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long ToolCoder_ A Systematic Code-Empowered Tool Learning Framework for Large Language Models.pdf", "retrieved_at": "2025-11-12T03:22:34.272707Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "IntersectionZoo: Eco-driving for Benchmarking Multi-Agent Contextual Reinforcement Learning", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Vindula Jayawardana", "Baptiste Freydt", "Ao Qu", "Cameron Hickert", "Zhongxia Yan", "Cathy Wu"], "affinity_score": 0.6405, "link": "https://openreview.net/pdf/a5755be074036a2b8b2c406d877735d28896ba68.pdf", "abstract": "Despite the popularity of multi-agent reinforcement learning (RL) in simulated and two-player applications, its success in messy real-world applications has been limited. A key challenge lies in its generalizability across problem variations, a common necessity for many real-world problems. Contextual reinforcement learning (CRL) formalizes learning policies that generalize across problem variations. However, the lack of standardized benchmarks for multi-agent CRL has hindered progress in the field. Such benchmarks are desired to be based on real-world applications to naturally capture the many open challenges of real-world problems that affect generalization. To bridge this gap, we propose IntersectionZoo, a comprehensive benchmark suite for multi-agent CRL through the real-world application of cooperative eco-driving in urban road networks. The task of cooperative eco-driving is to control a fleet of vehicles to reduce fleet-level vehicular emissions. By grounding IntersectionZoo in a real-world application, we naturally capture real-world problem characteristics, such as partial observability and multiple competing objectives. IntersectionZoo is built on data-informed simulations of 16,334 signalized intersections derived from 10 major US cities, modeled in an open-source industry-grade microscopic traffic simulator. By modeling factors affecting vehicular exhaust emissions (e.g., temperature, road conditions, travel demand), IntersectionZoo provides one million data-driven traffic scenarios. Using these traffic scenarios, we benchmark popular multi-agent RL and human-like driving algorithms and demonstrate that the popular multi-agent RL algorithms struggle to generalize in CRL settings.", "bibtex": "@inproceedings{\njayawardana2025intersectionzoo,\ntitle={IntersectionZoo: Eco-driving for Benchmarking Multi-Agent Contextual Reinforcement Learning},\nauthor={Vindula Jayawardana and Baptiste Freydt and Ao Qu and Cameron Hickert and Zhongxia Yan and Cathy Wu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=XoulHHQGFi}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster IntersectionZoo_ Eco-driving for Benchmarking Multi-Agent Contextual Reinforcement Learning.pdf", "retrieved_at": "2025-11-12T03:22:35.343253Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "NeSyC: A Neuro-symbolic Continual Learner For Complex Embodied Tasks In Open Domains", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Wonje Choi", "Jinwoo Park", "Sanghyun Ahn", "Daehee Lee", "Honguk Woo"], "affinity_score": 0.6404, "link": "https://openreview.net/pdf/c8d2430bc59b081b9da93330e0d70ee7eba1729b.pdf", "abstract": "We explore neuro-symbolic approaches to generalize actionable knowledge, enabling embodied agents to tackle complex tasks more effectively in open-domain environments. A key challenge for embodied agents is the generalization of knowledge across diverse environments and situations, as limited experiences often confine them to their prior knowledge. To address this issue, we introduce a novel framework, NeSyC, a neuro-symbolic continual learner that emulates the hypothetico-deductive model by continually formulating and validating knowledge from limited experiences through the combined use of Large Language Models (LLMs) and symbolic tools. Specifically, we devise a contrastive generality improvement scheme within NeSyC, which iteratively generates hypotheses using LLMs and conducts contrastive validation via symbolic tools. This scheme reinforces the justification for admissible actions while minimizing the inference of inadmissible ones. Additionally, we incorporate a memory-based monitoring scheme that efficiently detects action errors and triggers the knowledge refinement process across domains. Experiments conducted on diverse embodied task benchmarks—including ALFWorld, VirtualHome, Minecraft, RLBench, and a real-world robotic scenario—demonstrate that NeSyC is highly effective in solving complex embodied tasks across a range of open-domain environments.", "bibtex": "@inproceedings{\nchoi2025nesyc,\ntitle={NeSyC: A Neuro-symbolic Continual Learner For Complex Embodied Tasks in Open Domains},\nauthor={Wonje Choi and Jinwoo Park and Sanghyun Ahn and Daehee Lee and Honguk Woo},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=VoayJihXra}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster NeSyC_ A Neuro-symbolic Continual Learner For Complex Embodied Tasks In Open Domains.pdf", "retrieved_at": "2025-11-12T03:22:36.888296Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "MASTER: A Multi-Agent System with LLM Specialized MCTS", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Bingzheng Gan", "Yufan Zhao", "Tianyi Zhang", "Jing Huang", "Li Yusu", "Shu Xian Teo", "Changwang Zhang", "Wei Shi"], "affinity_score": 0.6402, "link": "https://aclanthology.org/2025.naacl-long.476/", "abstract": "Large Language Models (LLM) are increasingly being explored for problem-solving tasks. However, their strategic planning capability is often viewed with skepticism. Recent studies have incorporated the Monte Carlo Tree Search (MCTS) algorithm to augment the planning capacity of LLM. Despite its potential, MCTS relies on extensive sampling simulations to approximate the true reward distribution, which leads to two primary issues. Firstly, MCTS is effective for tasks like the Game of Go, where simulation results can yield objective rewards (e.g., 1 for a win and 0 for a loss). However, for tasks such as question answering, the result of a simulation is the answer to the question, which cannot yield an objective reward without the ground truth. Secondly, obtaining statistically significant reward estimations typically requires a sample size exceeding 30 simulations, resulting in excessive token usage and time consumption. To address these challenges, we present Multi-Agent System with Tactical Execution and Reasoning using LLM Specialized MCTS (MASTER), a novel framework that coordinates agent recruitment and communication through LLM specialized MCTS. This system autonomously adjusts the number of agents based on task complexity and ensures focused communication among them. Comprehensive experiments across various tasks demonstrate the effectiveness of our proposed framework. It achieves 76% accuracy on HotpotQA and 80% on WebShop, setting new state of-the-art performance on these datasets.", "bibtex": "@inproceedings{gan-etal-2025-master,\n    title = \"{MASTER}: A Multi-Agent System with {LLM} Specialized {MCTS}\",\n    author = \"Gan, Bingzheng  and\n      Zhao, Yufan  and\n      Zhang, Tianyi  and\n      Huang, Jing  and\n      Yusu, Li  and\n      Teo, Shu Xian  and\n      Zhang, Changwang  and\n      Shi, Wei\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.476/\",\n    doi = \"10.18653/v1/2025.naacl-long.476\",\n    pages = \"9409--9426\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Long MASTER_ A Multi-Agent System with LLM Specialized MCTS.pdf", "retrieved_at": "2025-11-12T03:22:37.988512Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "AMEX: Android Multi-annotation Expo Dataset for Mobile GUI Agents", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Yuxiang Chai", "Siyuan Huang", "Yazhe Niu", "Han Xiao", "Liang Liu (陆亮)", "Guozhi Wang", "Dingyu Zhang", "Shuai Ren", "Hongsheng Li"], "affinity_score": 0.6401, "link": "https://aclanthology.org/2025.findings-acl.110/", "abstract": "AI agents have drawn increasing attention mostly on their ability to perceive environments, understand tasks, and autonomously achieve goals. To advance research on AI agents in mobile scenarios, we introduce the Android Multi-annotation EXpo (AMEX), a comprehensive, large-scale dataset designed for generalist mobile GUI-control agents which are capable of completing tasks by directly interacting with the graphical user interface (GUI) on mobile devices. AMEX comprises over 104K high-resolution screenshots from popular mobile applications, which are annotated at multiple levels. Unlike existing GUI-related datasets, e.g., Rico, AitW, etc., AMEX includes three levels of annotations: GUI interactive element grounding, GUI screen and element functionality descriptions, and complex natural language instructions with stepwise GUI-action chains. We develop this dataset from a more instructive and detailed perspective, complementing the general settings of existing datasets. Additionally, we finetune a baseline model SPHINX Agent and illustrate the effectiveness of AMEX.", "bibtex": "@inproceedings{chai-etal-2025-amex,\n    title = \"{AMEX}: Android Multi-annotation Expo Dataset for Mobile {GUI} Agents\",\n    author = \"Chai, Yuxiang  and\n      Huang, Siyuan  and\n      Niu, Yazhe  and\n      Xiao, Han  and\n      Liu, Liang  and\n      Wang, Guozhi  and\n      Zhang, Dingyu  and\n      Ren, Shuai  and\n      Li, Hongsheng\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.110/\",\n    doi = \"10.18653/v1/2025.findings-acl.110\",\n    pages = \"2138--2156\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings AMEX_ Android Multi-annotation Expo Dataset for Mobile GUI Agents.pdf", "retrieved_at": "2025-11-12T03:22:38.604355Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Exponential Topology-enabled Scalable Communication in Multi-agent Reinforcement Learning", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Xinran Li", "Xiaolu Wang", "Chenjia Bai", "Jun Zhang"], "affinity_score": 0.64, "link": "https://openreview.net/pdf/099ca577bb4201168ce2fb973ae5e94e0a9074cd.pdf", "abstract": "In cooperative multi-agent reinforcement learning (MARL), well-designed communication protocols can effectively facilitate consensus among agents, thereby enhancing task performance. Moreover, in large-scale multi-agent systems commonly found in real-world applications, effective communication plays an even more critical role due to the escalated challenge of partial observability compared to smaller-scale setups. In this work, we endeavor to develop a scalable communication protocol for MARL. Unlike previous methods that focus on selecting optimal pairwise communication links—a task that becomes increasingly complex as the number of agents grows—we adopt a global perspective on communication topology design. Specifically, we propose utilizing the exponential topology to enable rapid information dissemination among agents by leveraging its small-diameter and small-size properties. This approach leads to a scalable communication protocol, named ExpoComm. To fully unlock the potential of exponential graphs as communication topologies, we employ memory-based message processors and auxiliary tasks to ground messages, ensuring that they reflect global information and benefit decision-making. Extensive experiments on large-scale cooperative benchmarks, including MAgent and Infrastructure Management Planning, demonstrate the superior performance and robust zero-shot transferability of ExpoComm compared to existing communication strategies. The\ncode is publicly available at\nhttps://github.com/LXXXXR/ExpoComm\n.", "bibtex": "@inproceedings{\nli2025exponential,\ntitle={Exponential Topology-enabled Scalable Communication in Multi-agent Reinforcement Learning},\nauthor={Xinran Li and Xiaolu Wang and Chenjia Bai and Jun Zhang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=CL3U0GxFRD}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Exponential Topology-enabled Scalable Communication in Multi-agent Reinforcement Learning.pdf", "retrieved_at": "2025-11-12T03:22:39.370829Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "LLM-Based Multi-Agent Systems are Scalable Graph Generative Models", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Jiarui Ji", "Runlin Lei", "Jialing Bi", "Zhewei Wei", "Xu Chen (陈旭)", "Yankai Lin (林衍凯)", "Xuchen Pan", "Yaliang Li", "Bolin Ding"], "affinity_score": 0.64, "link": "https://aclanthology.org/2025.findings-acl.78/", "abstract": "The structural properties of naturally arising social graphs are extensively studied to understand their evolution. Prior approaches for modeling network dynamics typically rely on rule-based models, which lack realism and generalizability, or deep learning-based models, which require large-scale training datasets. As abstract graph representations of entity-wise interactions, social graphs present an opportunity to explore network evolution mechanisms through realistic simulations of human-item interactions. Leveraging the pre-trained social consensus knowledge embedded in large language models (LLMs), we present GraphAgent-Generator (GAG), a novel simulation-based framework for dynamic, text-attributed social graph generation. GAG simulates the temporal node and edge generation processes for zero-shot social graph generation. The resulting graphs adhere to seven key macroscopic network properties, achieving an 11% improvement in microscopic graph structure metrics. Through the node classification benchmarking task, we validate that GAG effectively captures the intricate text-structure correlations in graph generation. Furthermore, GAG supports generating graphs with up to nearly 100,000 nodes or 10 million edges through large-scale LLM-based agent simulation with parallel acceleration, achieving a minimum speed-up of 90.4%. The source code is available at https://github.com/Ji-Cather/GraphAgent.", "bibtex": "@inproceedings{ji-etal-2025-llm,\n    title = \"{LLM}-Based Multi-Agent Systems are Scalable Graph Generative Models\",\n    author = \"Ji, Jiarui  and\n      Lei, Runlin  and\n      Bi, Jialing  and\n      Wei, Zhewei  and\n      Chen, Xu  and\n      Lin, Yankai  and\n      Pan, Xuchen  and\n      Li, Yaliang  and\n      Ding, Bolin\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.78/\",\n    doi = \"10.18653/v1/2025.findings-acl.78\",\n    pages = \"1492--1523\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings LLM-Based Multi-Agent Systems are Scalable Graph Generative Models.pdf", "retrieved_at": "2025-11-12T03:22:39.708239Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Xuehang Guo", "Xingyao Wang", "Yangyi Chen", "Sha Li", "Chi Han", "Manling Li", "Heng Ji"], "affinity_score": 0.6397, "link": "https://openreview.net/pdf/459416e63ca7008561801619a22a7a580c87df95.pdf", "abstract": "Software engineering (SE) is increasingly collaborative, with developers working together on shared complex codebases. Effective collaboration in shared environments requires participants---whether humans or AI agents---to stay on the same page as their environment evolves. When a collaborator's understanding diverges from the current state---what we term the\nout-of-sync\nchallenge---the collaborator's actions may fail, leading to integration issues. In this work, we introduce\nSyncMind\n, a framework that systematically defines the\nout-of-sync\nproblem faced by large language model (LLM) agents in collaborative software engineering (CSE). Based on\nSyncMind\n, we create\nSyncBench\n, a benchmark featuring 24,332 instances of agent\nout-of-sync\nscenarios in real-world CSE derived from 21 popular\nGitHub\nrepositories with executable verification tests. Experiments on\nSyncBench\nuncover critical insights into existing LLM agents' capabilities and limitations. Besides substantial performance gaps among agents (from\nLlama-3.1\nagents $\\leq 3.33\\%$ to\nClaude-3.5-Sonnet\n$\\geq 28.18\\%$), their consistently low collaboration willingness ($\\le 4.86\\%$) suggests fundamental limitations of existing LLM in CSE. However, when collaboration occurs, it positively correlates with\nout-of-sync\nrecovery success. Minimal performance differences in agents' resource-aware\nout-of-sync\nrecoveries further reveal their significant lack of resource awareness and adaptability, shedding light on future development of resource-efficient collaborative systems. Our code and data are openly available on our project website: https://xhguo7.github.io/SyncMind/.", "bibtex": "@inproceedings{\nguo2025syncmind,\ntitle={SyncMind: Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering},\nauthor={Xuehang Guo and Xingyao Wang and Yangyi Chen and Sha Li and Chi Han and Manling Li and Heng Ji},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=6TDSDdgP7Z}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICML 2025 Poster SyncMind_ Measuring Agent Out-of-Sync Recovery in Collaborative Software Engineering.pdf", "retrieved_at": "2025-11-12T03:22:40.769731Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Yihuai Lan", "Zhiqiang Hu", "Lei Wang (王雷)", "Yang Wang", "Deheng Ye", "Peilin Zhao", "Ee-Peng Lim", "Hui Xiong", "Hao Wang (汪浩", "王昊", "王浩)"], "affinity_score": 0.6397, "link": "https://aclanthology.org/2024.emnlp-main.7/", "abstract": "This paper explores the open research problem of understanding the social behaviors of LLM-based agents. Using Avalon as a testbed, we employ system prompts to guide LLM agents in gameplay. While previous studies have touched on gameplay with LLM agents, research on their social behaviors is lacking. We propose a novel framework, tailored for Avalon, features a multi-agent system facilitating efficient communication and interaction. We evaluate its performance based on game success and analyze LLM agents’ social behaviors. Results affirm the framework’s effectiveness in creating adaptive agents and suggest LLM-based agents’ potential in navigating dynamic social interactions. By examining collaboration and confrontation behaviors, we offer insights into this field’s research and applications.", "bibtex": "@inproceedings{lan-etal-2024-llm,\n    title = \"{LLM}-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay\",\n    author = \"Lan, Yihuai  and\n      Hu, Zhiqiang  and\n      Wang, Lei  and\n      Wang, Yang  and\n      Ye, Deheng  and\n      Zhao, Peilin  and\n      Lim, Ee-Peng  and\n      Xiong, Hui  and\n      Wang, Hao\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.7/\",\n    doi = \"10.18653/v1/2024.emnlp-main.7\",\n    pages = \"128--145\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Main LLM-Based Agent Society Investigation_ Collaboration and Confrontation in Avalon Gameplay.pdf", "retrieved_at": "2025-11-12T03:22:41.073290Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "FlickerFusion: Intra-trajectory Domain Generalizing Multi-agent Reinforcement Learning", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Woosung Koh", "Wonbeen Oh", "Siyeol Kim", "Suhin Shin", "Hyeongjin Kim", "Jaein Jang", "Junghyun Lee", "Se-Young Yun"], "affinity_score": 0.6397, "link": "https://openreview.net/pdf/2967188815daed9df1c0d1dc55c40445a96ceb35.pdf", "abstract": "Multi-agent reinforcement learning has demonstrated significant potential in addressing complex cooperative tasks across various real-world applications. However, existing MARL approaches often rely on the restrictive assumption that the number of entities (e.g., agents, obstacles) remains constant between training and inference. This overlooks scenarios where entities are dynamically removed or $\\textit{added}$ $\\textit{during}$ the inference trajectory—a common occurrence in real-world environments like search and rescue missions and dynamic combat situations. In this paper, we tackle the challenge of intra-trajectory dynamic entity composition under zero-shot out-of-domain (OOD) generalization, where such dynamic changes cannot be anticipated beforehand. Our empirical studies reveal that existing MARL methods suffer $\\textit{significant}$ performance degradation and increased uncertainty in these scenarios. In response, we propose FlickerFusion, a novel OOD generalization method that acts as a $\\textit{universally}$ applicable augmentation technique for MARL backbone methods. FlickerFusion stochastically drops out parts of the observation space, emulating being in-domain when inferenced OOD. The results show that FlickerFusion not only achieves superior inference rewards but also $\\textit{uniquely}$ reduces uncertainty vis-à-vis the backbone, compared to existing methods. Benchmarks, implementations, and  model weights are organized and open-sourced at $\\texttt{\\href{flickerfusion305.github.io}{\\textbf{flickerfusion305.github.io}}}$, accompanied by ample demo video renderings.", "bibtex": "@inproceedings{\nkoh2025flickerfusion,\ntitle={FlickerFusion: Intra-trajectory Domain Generalizing Multi-agent Reinforcement Learning},\nauthor={Woosung Koh and Wonbeen Oh and Siyeol Kim and Suhin Shin and Hyeongjin Kim and Jaein Jang and Junghyun Lee and Se-Young Yun},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=MRYyOaNxh3}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster FlickerFusion_ Intra-trajectory Domain Generalizing Multi-agent Reinforcement Learning.pdf", "retrieved_at": "2025-11-12T03:22:43.272254Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Progressive Multimodal Reasoning via Active Retrieval", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Guanting Dong", "Chenghao Zhang", "Mengjie Deng", "Yutao Zhu (朱余韬)", "Zhicheng Dou (窦志成)", "Ji-Rong Wen"], "affinity_score": 0.6392, "link": "https://aclanthology.org/2025.acl-long.180/", "abstract": "Multi-step multimodal reasoning tasks pose significant challenges for multimodal large language models (MLLMs), and finding effective ways to enhance their performance in such scenarios remains an unresolved issue. In this paper, we propose AR-MCTS, a universal framework designed to progressively improve the reasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo Tree Search (MCTS). AR-MCTS follows the MCTS algorithm and heuristically integrates an active retrieval mechanism during the expansion stage to automatically acquire high-quality step-wise reasoning annotations. Moreover, we further introduce curriculum training objectives to progressively align with a process reward model, ultimately achieving process-level multimodal reasoning verification. Experimental results across three complex multimodal reasoning benchmarks confirm the effectiveness of AR-MCTS. Further analysis demonstrates that it can optimize sampling diversity and accuracy, yielding reliable multimodal reasoning.", "bibtex": "@inproceedings{dong-etal-2025-progressive,\n    title = \"Progressive Multimodal Reasoning via Active Retrieval\",\n    author = \"Dong, Guanting  and\n      Zhang, Chenghao  and\n      Deng, Mengjie  and\n      Zhu, Yutao  and\n      Dou, Zhicheng  and\n      Wen, Ji-Rong\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.180/\",\n    doi = \"10.18653/v1/2025.acl-long.180\",\n    pages = \"3579--3602\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Long Progressive Multimodal Reasoning via Active Retrieval.pdf", "retrieved_at": "2025-11-12T03:22:43.595150Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Can Agent Fix Agent Issues?", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Alfin Wijaya Rahardja", "Junwei Liu", "Weitong Chen", "Zhenpeng Chen", "Yiling Lou"], "affinity_score": 0.6391, "link": "https://openreview.net/pdf/ab4c234adba0d835dbb64828e87b465d8983cecd.pdf", "abstract": "LLM-based agent systems are emerging as a new software paradigm and have been widely adopted across diverse domains such as medicine, robotics, and programming. However, maintaining these systems requires substantial effort, as they are inevitably prone to bugs and continually evolve to meet changing external requirements. Therefore, automatically resolving agent issues (i.e.,bug reports or feature requests) is a crucial and challenging task.  While recent software engineering (SE) agents (e.g., SWE-agent) have shown promise in addressing issues in traditional software systems, it remains unclear how effectively they can resolve real-world issues in agent systems, which differ significantly from traditional software. To fill this gap, we first manually analyze 201 real-world agent issues and identify common categories of agent issues. We then spend 500 person-hours constructing AgentIssue-bench, a reproducible benchmark comprising 50 agent issue resolution tasks (each with an executable environment and failure-triggering tests). We further evaluate state-of-the-art SE agents on AgentIssue-bench and reveal their limited effectiveness (.e., with only 0.67% - 4.67% resolution rates). These results underscore the unique challenges of maintaining agent systems compared to traditional software, highlighting the need for further research to develop advanced SE agents for resolving agent issues.", "bibtex": "@inproceedings{\nrahardja2025can,\ntitle={Can Agent Fix Agent Issues?},\nauthor={Alfin Wijaya Rahardja and Junwei Liu and Weitong Chen and Zhenpeng Chen and Yiling Lou},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=N9HLe9iPhj}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Can Agent Fix Agent Issues_.pdf", "retrieved_at": "2025-11-12T03:22:44.296293Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Spyridon Mouselinos", "Henryk Michalewski", "Mateusz Malinowski"], "affinity_score": 0.6391, "link": "https://aclanthology.org/2024.findings-emnlp.360/", "abstract": "Large Language Models (LLMs) demonstrate ever-increasing abilities in mathematical and algorithmic tasks, yet their geometric reasoning skills are underexplored. We investigate LLMs’ abilities in constructive geometric problem-solving, – one of the most fundamental steps in developing human mathematical reasoning, revealing notable challenges in this domain. LLMs exhibit biases in variable names, struggle with 2D spatial relationships and planning, and hallucinate object placements. To this end, we introduce a framework that enhances LLMs’ reasoning potential through a multi-agent system conducting internal dialogue. This work underscores LLMs’ limitations in geometric reasoning and improves their capabilities through self-correction, collaboration, and diverse role specializations.", "bibtex": "@inproceedings{mouselinos-etal-2024-beyond,\n    title = \"Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models\",\n    author = \"Mouselinos, Spyridon  and\n      Michalewski, Henryk  and\n      Malinowski, Mateusz\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.360/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.360\",\n    pages = \"6192--6222\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings Beyond Lines and Circles_ Unveiling the Geometric Reasoning Gap in Large Language Models.pdf", "retrieved_at": "2025-11-12T03:22:44.545689Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Chuhan Li", "Ziyao Shangguan", "Yilun Zhao", "Deyuan Li", "Yixin Liu", "Arman Cohan"], "affinity_score": 0.6388, "link": "https://aclanthology.org/2024.findings-emnlp.904/", "abstract": "Existing evaluation benchmarks for foundation models in understanding scientific literature predominantly focus on single-document, text-only tasks. Such benchmarks often do not adequately represent the complexity of research workflows, which typically also involve interpreting non-textual data, such as figures and tables, and gathering information across multiple documents and related literature. To address this gap, we introduce M3SciQA, a multi-modal, multi-document scientific question answering benchmark designed for a more comprehensive evaluation of foundation models. M3Sci QA consists of 1452 expert-annotated questions spanning 70 natural language processing paper clusters, where each cluster represents a primary paper along with all its cited documents, mirroring the workflow of comprehending a single paper by requiring multi-modal and multi-document data. With M3SciQA, we conduct a comprehensive evaluation of 18 frontier foundation models. Our results indicate that current foundation models still significantly underperform compared to human experts in multi-modal information retrieval and in reasoning across multiple scientific documents. Additionally, we explore the implications of these findings for the future advancement of applying foundation models in multi-modal scientific literature analysis.", "bibtex": "@inproceedings{li-etal-2024-m3sciqa,\n    title = \"{M}3{S}ci{QA}: A Multi-Modal Multi-Document Scientific {QA} Benchmark for Evaluating Foundation Models\",\n    author = \"Li, Chuhan  and\n      Shangguan, Ziyao  and\n      Zhao, Yilun  and\n      Li, Deyuan  and\n      Liu, Yixin  and\n      Cohan, Arman\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.904/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.904\",\n    pages = \"15419--15446\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/EMNLP 2024 Findings M3SciQA_ A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models.pdf", "retrieved_at": "2025-11-12T03:22:45.900475Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Bi-Level Knowledge Transfer for Multi-Task Multi-Agent Reinforcement Learning", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Junkai Zhang", "Jinmin He", "Yifan Zhang", "Yifan Zang", "Ning Xu", "Jian Cheng"], "affinity_score": 0.6387, "link": "https://openreview.net/pdf/2b86cc9f576d8abadc37889762dbb565bf235fe1.pdf", "abstract": "Multi-Agent Reinforcement Learning (MARL) has achieved remarkable success in various real-world scenarios, but its high cost of online training makes it impractical to learn each task from scratch. \nTo enable effective policy reuse, we consider the problem of zero-shot generalization from offline data across multiple tasks. \nWhile prior work focuses on transferring individual skills of agents, we argue that the effective policy transfer across tasks should also capture the team-level coordination knowledge.\nIn this paper, we propose Bi-Level Knowledge Transfer (BiKT) for Multi-Task MARL, which performs knowledge transfer at both the individual and team levels. \nAt the individual level, we extract transferable individual skill embeddings from offline MARL trajectories.\nAt the team level, we define tactics as coordinated patterns of skill combinations and capture them by leveraging the learned skill embeddings. \nWe map skill combinations into compact tactic embeddings and then construct a tactic codebook.\nTo incorporate both skills and tactics into decision-making, we design a bi-level decision transformer that infers them in sequence.\nOur BiKT leverages both the generalizability of individual skills and the diversity of tactics, enabling the learned policy to perform effectively across multiple tasks.\nExtensive experiments on SMAC and MPE benchmarks demonstrate that BiKT achieves strong generalization to previously unseen tasks.", "bibtex": "@inproceedings{\nzhang2025bilevel,\ntitle={Bi-Level Knowledge Transfer for Multi-Task Multi-Agent Reinforcement Learning},\nauthor={Junkai Zhang and Jinmin He and Yifan Zhang and Yifan Zang and Ning Xu and Jian Cheng},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=6jKed3sx4f}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Bi-Level Knowledge Transfer for Multi-Task Multi-Agent Reinforcement Learning.pdf", "retrieved_at": "2025-11-12T03:22:46.907793Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Breaking Mental Set to Improve Reasoning through Diverse Multi-Agent Debate", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Yexiang Liu", "Jie Cao", "Zekun Li", "Ran He", "Tieniu Tan"], "affinity_score": 0.6387, "link": "https://openreview.net/pdf/d67d70de207899a21f78262107dd3b5ec2d940b6.pdf", "abstract": "Large Language Models (LLMs) have seen significant progress but continue to struggle with persistent reasoning mistakes.\nPrevious methods of\nself-reflection\nhave been proven limited due to the models’ inherent fixed thinking patterns. \nWhile Multi-Agent Debate (MAD) attempts to mitigate this by incorporating multiple agents, it often employs the same reasoning methods, even though assigning different personas to models. This leads to a \"fixed mental set\", where models rely on homogeneous thought processes without exploring alternative perspectives.\nIn this paper, we introduce Diverse Multi-Agent Debate (DMAD), a method that encourages agents to think with distinct reasoning approaches. By leveraging diverse problem-solving strategies, each agent can gain insights from different perspectives, refining its responses through discussion and collectively arriving at the optimal solution. DMAD effectively breaks the limitations of fixed mental sets. We evaluate DMAD against various prompting techniques, including\nself-reflection\nand traditional MAD, across multiple benchmarks using both LLMs and Multimodal LLMs. Our experiments show that DMAD consistently outperforms other methods, delivering better results than MAD in fewer rounds. Code is available at https://github.com/MraDonkey/DMAD.", "bibtex": "@inproceedings{\nliu2025breaking,\ntitle={Breaking Mental Set to Improve Reasoning through Diverse Multi-Agent Debate},\nauthor={Yexiang Liu and Jie Cao and Zekun Li and Ran He and Tieniu Tan},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=t6QHYUOQL7}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Breaking Mental Set to Improve Reasoning through Diverse Multi-Agent Debate.pdf", "retrieved_at": "2025-11-12T03:22:47.961097Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Heterogeneous Graph Transformers for Simultaneous Mobile Multi-Robot Task Allocation and Scheduling under Temporal Constraints", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Batuhan Altundas", "Shengkang Chen", "Shivika Singh", "Shivangi Deo", "Minwoo Cho", "Matthew Craig Gombolay"], "affinity_score": 0.6382, "link": "https://openreview.net/pdf/c132589a72ce5fd8c489d67b73b34261d138def2.pdf", "abstract": "Coordinating large teams of heterogeneous mobile agents to perform complex tasks efficiently has scalability bottlenecks in feasible and optimal task scheduling, with critical applications in logistics, manufacturing, and disaster response. Existing task allocation and scheduling methods, including heuristics and optimization-based solvers, often fail to scale and overlook inter-task dependencies and agent heterogeneity. We propose a novel Simultaneous Decision-Making model for Heterogeneous Multi-Agent Task Allocation and Scheduling (HM-MATAS), built on a Residual Heterogeneous Graph Transformer with edge and node-level attention. Our model encodes agent capabilities, travel times, and temporospatial constraints into a rich graph representation and is trainable via reinforcement learning. Trained on small-scale problems (10 agents, 20 tasks), our model generalizes effectively to significantly larger scenarios (up to 40 agents and 200 tasks), enabling fast, one-shot task assignment and scheduling. Our simultaneous model outperforms classical heuristics by assigning 164.10\\% more feasible tasks given temporal constraints in 3.83\\% of the time, metaheuristics by 201.54\\% in 0.01\\% of the time and exact solver by 231.73\\% in 0.03\\% of the time, while achieving $20\\times$-to-$250\\times$ speedup from prior graph-based methods across scales.", "bibtex": "@inproceedings{\naltundas2025heterogeneous,\ntitle={Heterogeneous Graph Transformers for Simultaneous Mobile Multi-Robot Task Allocation and Scheduling under Temporal Constraints},\nauthor={Batuhan Altundas and Shengkang Chen and Shivika Singh and Shivangi Deo and Minwoo Cho and Matthew Craig Gombolay},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=k1fbdnwjCH}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Heterogeneous Graph Transformers for Simultaneous Mobile Multi-Robot Task Allocation and Scheduling under Temporal Constraints.pdf", "retrieved_at": "2025-11-12T03:22:48.732716Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Time-aware ReAct Agent for Temporal Knowledge Graph Question Answering", "venue": "NAACL 2025 Findings", "year": "2025", "authors": ["Qianyi Hu", "Xinhui Tu (涂新辉)", "Cong Guo", "Shunping Zhang"], "affinity_score": 0.6381, "link": "https://aclanthology.org/2025.findings-naacl.334/", "abstract": "Temporal knowledge graph question answering (TKGQA) addresses time-sensitive queries using knowledge bases. Although large language models (LLMs) and LLM-based agents such as ReAct have shown potential for TKGQA, they often lack sufficient temporal constraints in the retrieval process. To tackle this challenge, we propose TempAgent, a novel autonomous agent framework built on LLMs that enhances their ability to conduct temporal reasoning and comprehension. By integrating temporal constraints into information retrieval, TempAgent effectively discards irrelevant material and concentrates on extracting pertinent temporal and factual information. We evaluate our framework on the MultiTQ dataset, a real-world multi-granularity TKGQA benchmark, using a fully automated setup. Our experimental results reveal the remarkable effectiveness of our approach: TempAgent achieves a 41.3% improvement over the baseline model and a 32.2% gain compared to the Abstract Reasoning Induction (ARI) method. Moreover, our method attains an accuracy of 70.2% on the @hit1 metric, underscoring its substantial advantage in addressing time-aware TKGQA tasks.", "bibtex": "@inproceedings{qianyihu-etal-2025-time,\n    title = \"Time-aware {R}e{A}ct Agent for Temporal Knowledge Graph Question Answering\",\n    author = \"Hu, Qianyi  and\n      Tu, Xinhui  and\n      Guo, Cong  and\n      Zhang, Shunping\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Findings of the Association for Computational Linguistics: NAACL 2025\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-naacl.334/\",\n    doi = \"10.18653/v1/2025.findings-naacl.334\",\n    pages = \"6013--6024\",\n    ISBN = \"979-8-89176-195-7\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NAACL 2025 Findings Time-aware ReAct Agent for Temporal Knowledge Graph Question Answering.pdf", "retrieved_at": "2025-11-12T03:22:49.103036Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "VideoWebArena:  Evaluating Long Context Multimodal Agents with Video Understanding Web Tasks", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Lawrence Keunho Jang", "Yinheng Li", "Dan Zhao", "Charles Ding", "Justin Lin", "Paul Pu Liang", "Rogerio Bonatti", "Kazuhito Koishida"], "affinity_score": 0.6381, "link": "https://openreview.net/pdf/0665a611105a080d57247da2317726273a86a222.pdf", "abstract": "Videos are often used to learn or extract the necessary information to complete\ntasks in ways different than what text or static imagery can provide. However, many\nexisting agent benchmarks neglect long-context video understanding, instead focus-\ning on text or static image inputs. To bridge this gap, we introduce VideoWebArena\n(VideoWA), a benchmark for evaluating the capabilities of long-context multimodal\nagents for video understanding. VideoWA consists of 2,021 web agent tasks based\non manually crafted video tutorials, which total almost four hours of content. For\nour benchmark, we define a taxonomy of long-context video-based agent tasks with\ntwo main areas of focus: skill retention and factual retention. While skill retention\ntasks evaluate whether an agent can use a given human demonstration to complete\na task efficiently, the factual retention task evaluates whether an agent can retrieve\ninstruction-relevant information from a video to complete a task. We find that the\nbest model achieves a 13.3% success rate on factual retention tasks and 45.8% on\nfactual retention QA pairs—far below human success rates of 73.9% and 79.3%,\nrespectively. On skill retention tasks, long-context models perform worse with\ntutorials than without, exhibiting a 5% performance decrease in WebArena tasks\nand a 10.3% decrease in VisualWebArena tasks. Our work highlights performance\ngaps in the agentic abilities of long-context multimodal models and provides as a\ntestbed for the future development of long-context video agents.", "bibtex": "@inproceedings{\njang2025videowebarena,\ntitle={VideoWebArena:  Evaluating Long Context Multimodal Agents with Video Understanding Web Tasks},\nauthor={Lawrence Keunho Jang and Yinheng Li and Dan Zhao and Charles Ding and Justin Lin and Paul Pu Liang and Rogerio Bonatti and Kazuhito Koishida},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=unDQOUah0F}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster VideoWebArena_ Evaluating Long Context Multimodal Agents with Video Understanding Web Tasks.pdf", "retrieved_at": "2025-11-12T03:22:49.711004Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Weize Chen", "Jiarui Yuan", "Chen Qian", "Cheng Yang", "Zhiyuan Liu", "Maosong Sun (孙茂松)"], "affinity_score": 0.6381, "link": "https://aclanthology.org/2025.findings-acl.601/", "abstract": "Large Language Model (LLM) based multi-agent systems (MAS) show remarkable potential in collaborative problem-solving, yet they still face critical challenges: low communication efficiency, poor scalability, and a lack of effective parameter-updating optimization methods. We present Optima, a novel framework that addresses these issues by significantly enhancing both communication efficiency and task effectiveness in LLM-based MAS through training. Optima employs an iterative generate, rank, select, and train paradigm with a reward function balancing task performance, token efficiency, and communication readability. We explore various algorithms, including Supervised Fine-Tuning, Direct Preference Optimization, and their hybrid approaches, providing insights into their effectiveness-efficiency trade-offs. We integrate Monte Carlo Tree Search-inspired techniques for DPO data generation, treating conversation turns as tree nodes to explore diverse interaction paths. Evaluated on common multi-agent tasks, including information-asymmetric question answering and complex reasoning, Optimashows consistent and substantial improvements over single-agent baselines and vanilla MAS based on Llama 3 8B / 3.2 3B, achieving up to 2.8x performance gain with less than 10% tokens on tasks requiring heavy information exchange. Moreover, Optima’s efficiency gains enable more effective compute utilization during inference, leading to improved inference-time scaling laws. By addressing fundamental challenges in LLM-based MAS, Optima shows the potential towards scalable, efficient, and effective MAS.", "bibtex": "@inproceedings{chen-etal-2025-optima,\n    title = \"Optima: Optimizing Effectiveness and Efficiency for {LLM}-Based Multi-Agent System\",\n    author = \"Chen, Weize  and\n      Yuan, Jiarui  and\n      Qian, Chen  and\n      Yang, Cheng  and\n      Liu, Zhiyuan  and\n      Sun, Maosong\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.601/\",\n    doi = \"10.18653/v1/2025.findings-acl.601\",\n    pages = \"11534--11557\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ACL 2025 Findings Optima_ Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System.pdf", "retrieved_at": "2025-11-12T03:22:49.997251Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Facilitating Multi-turn Function Calling for LLMs via Compositional Instruction Tuning", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Mingyang Chen", "sunhaoze", "Tianpeng Li", "Fan Yang", "Hao Liang", "KeerLu", "Bin CUI", "Wentao Zhang", "Zenan Zhou", "weipeng chen"], "affinity_score": 0.6376, "link": "https://openreview.net/pdf/bddc07777716e293010f1c92044e3f7cc25fb4aa.pdf", "abstract": "Large Language Models (LLMs) have exhibited significant potential in performing diverse tasks, including the ability to call functions or use external tools to enhance their performance. While current research on function calling by LLMs primarily focuses on single-turn interactions, this paper addresses the overlooked necessity for LLMs to engage in multi-turn function calling—critical for handling compositional, real-world queries that require planning with functions but not only use functions. To facilitate this, we introduce an approach, BUTTON, which generates synthetic compositional instruction tuning data via bottom-up instruction construction and top-down trajectory generation. In the bottom-up phase, we generate simple atomic tasks based on real-world scenarios and build compositional tasks using heuristic strategies based on atomic tasks. Corresponding function definitions are then synthesized for these compositional tasks. The top-down phase features a multi-agent environment where interactions among simulated humans, assistants, and tools are utilized to gather multi-turn function calling trajectories. This approach ensures task compositionality and allows for effective function and trajectory generation by examining atomic tasks within compositional tasks. We produce a dataset BUTTONInstruct comprising 8k data points and demonstrate its effectiveness through extensive experiments across various LLMs.", "bibtex": "@inproceedings{\nchen2025facilitating,\ntitle={Facilitating Multi-turn Function Calling for {LLM}s via Compositional Instruction Tuning},\nauthor={Mingyang Chen and sunhaoze and Tianpeng Li and Fan Yang and Hao Liang and KeerLu and Bin CUI and Wentao Zhang and Zenan Zhou and weipeng chen},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=owP2mymrTD}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Poster Facilitating Multi-turn Function Calling for LLMs via Compositional Instruction Tuning.pdf", "retrieved_at": "2025-11-12T03:22:50.441304Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "Partner Modelling Emerges in Recurrent Agents (But Only When It Matters)", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Ruaridh Mon-Williams", "Max Taylor-Davies", "Elizabeth Mieczkowski", "Natalia Vélez", "Neil R Bramley", "Yanwei Wang", "Thomas L. Griffiths", "Christopher G. Lucas"], "affinity_score": 0.6376, "link": "https://openreview.net/pdf/ce9e0e5f6bb446a8103ef0fb8f4c67e47b7972d0.pdf", "abstract": "Humans are remarkably adept at collaboration, able to infer the strengths and weaknesses of new partners in order to work successfully towards shared goals. To build AI systems with this capability, we must first understand its building blocks: does such flexibility require explicit, dedicated mechanisms for modelling others—or can it emerge spontaneously from the pressures of open-ended cooperative interaction? To investigate this question, we train simple model-free RNN agents to collaborate with a population of diverse partners. Using the 'Overcooked-AI' environment, we collect data from thousands of collaborative teams, and analyse agents' internal hidden states. Despite a lack of additional architectural features, inductive biases, or auxiliary objectives, the agents nevertheless develop structured internal representations of their partners' task abilities, enabling rapid adaptation and generalisation to novel collaborators. We investigated these internal models through probing techniques, and large-scale behavioural analysis. Notably, we find that structured partner modelling emerges when agents can influence partner behaviour by controlling task allocation. Our results show that partner modelling can arise spontaneously in model-free agents—but only under environmental conditions that impose the right kind of social pressure.", "bibtex": "@inproceedings{\nmon-williams2025partner,\ntitle={Partner Modelling Emerges in Recurrent Agents (But Only When It Matters)},\nauthor={Ruaridh Mon-Williams and Max Taylor-Davies and Elizabeth Mieczkowski and Natalia V{\\'e}lez and Neil R Bramley and Yanwei Wang and Thomas L. Griffiths and Christopher G. Lucas},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=WydxWM2xNb}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/NeurIPS 2025 Poster Partner Modelling Emerges in Recurrent Agents (But Only When It Matters).pdf", "retrieved_at": "2025-11-12T03:22:51.160078Z"}
{"search_index": 1, "query": "multiagent tool science", "title": "From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions", "venue": "ICLR 2025 Oral", "year": "2025", "authors": ["Changle Qu", "Sunhao Dai", "Xiaochi Wei", "Hengyi Cai", "Shuaiqiang Wang", "Dawei Yin", "Jun Xu", "Ji-Rong Wen"], "affinity_score": 0.6375, "link": "https://openreview.net/pdf/316eeebf4b438f0f482c02184e1b2316f3800805.pdf", "abstract": "Tool learning enables Large Language Models (LLMs) to interact with external environments by invoking tools, serving as an effective strategy to mitigate the limitations inherent in their pre-training data. In this process, tool documentation plays a crucial role by providing usage instructions for LLMs, thereby facilitating effective tool utilization. This paper concentrates on the critical challenge of bridging the comprehension gap between LLMs and external tools due to the inadequacies and inaccuracies inherent in existing human-centric tool documentation. We propose a novel framework, DRAFT, aimed at Dynamically Refining tool documentation through the Analysis of Feedback and Trials emanating from LLMs' interactions with external tools. This methodology pivots on an innovative trial-and-error approach, consisting of three distinct learning phases: experience gathering, learning from experience, and documentation rewriting, to iteratively enhance the tool documentation. This process is further optimized by implementing a diversity-promoting exploration strategy to ensure explorative diversity and a tool-adaptive termination mechanism to prevent overfitting while enhancing efficiency. Extensive experiments on multiple datasets demonstrate that DRAFT's iterative, feedback-based refinement significantly ameliorates documentation quality, fostering a deeper comprehension and more effective utilization of tools by LLMs. Notably, our analysis reveals that the tool documentation refined via our approach demonstrates robust cross-model generalization capabilities.", "bibtex": "@inproceedings{\nqu2025from,\ntitle={From Exploration to Mastery: Enabling {LLM}s to Master Tools via Self-Driven Interactions},\nauthor={Changle Qu and Sunhao Dai and Xiaochi Wei and Hengyi Cai and Shuaiqiang Wang and Dawei Yin and Jun Xu and Ji-Rong Wen},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=QKBu1BOAwd}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_science/ICLR 2025 Oral From Exploration to Mastery_ Enabling LLMs to Master Tools via Self-Driven Interactions.pdf", "retrieved_at": "2025-11-12T03:22:51.712635Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Ziru Chen", "Shijie Chen", "Yuting Ning", "Qianheng Zhang", "Boshi Wang", "Botao Yu", "Yifei Li", "Zeyi Liao", "Chen Wei", "Zitong Lu", "Vishal Dey", "Mingyi Xue", "Frazier N. Baker", "Benjamin Burns", "Daniel Adu-Ampratwum", "Xuhui Huang", "Xia Ning", "Song Gao", "Yu Su", "Huan Sun"], "affinity_score": 0.6136, "link": "https://openreview.net/pdf/01bb45041a6c8c75021cdf0e1835d645398f660d.pdf", "abstract": "The advancements of language language models (LLMs) have piqued growing interest in developing LLM-based language agents to automate scientific discovery end-to-end, which has sparked both excitement and skepticism about the true capabilities of such agents. In this work, we argue that for an agent to fully automate scientific discovery, it must be able to complete all essential tasks in the workflow. Thus, we call for rigorous assessment of agents on individual tasks in a scientific workflow before making bold claims on end-to-end automation. To this end, we present ScienceAgentBench, a new benchmark for evaluating language agents for data-driven scientific discovery. To ensure the scientific authenticity and real-world relevance of our benchmark, we extract 102 tasks from 44 peer-reviewed publications in four disciplines and engage nine subject matter experts to validate them. We unify the target output for every task to a self-contained Python program file and employ an array of evaluation metrics to examine the generated programs, execution results, and costs. Each task goes through multiple rounds of manual validation by annotators and subject matter experts to ensure its annotation quality and scientific plausibility. We also propose two effective strategies to mitigate data contamination concerns. Using our benchmark, we evaluate five open-weight and proprietary LLMs, each with three frameworks: direct prompting, OpenHands, and self-debug. Given three attempts for each task, the best-performing agent can only solve 32.4% of the tasks independently and 34.3% with expert-provided knowledge. These results underscore the limited capacities of current language agents in generating code for data-driven discovery, let alone end-to-end automation for scientific research.", "bibtex": "@inproceedings{\nchen2025scienceagentbench,\ntitle={ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery},\nauthor={Ziru Chen and Shijie Chen and Yuting Ning and Qianheng Zhang and Boshi Wang and Botao Yu and Yifei Li and Zeyi Liao and Chen Wei and Zitong Lu and Vishal Dey and Mingyi Xue and Frazier N. Baker and Benjamin Burns and Daniel Adu-Ampratwum and Xuhui Huang and Xia Ning and Song Gao and Yu Su and Huan Sun},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=6z4YKr0GK6}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:33.561085Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Yubo Ma", "Zhibin Gou", "Junheng Hao", "Ruochen Xu", "Shuohang Wang", "Liangming Pan", "Yujiu Yang", "Yixin Cao", "Aixin Sun"], "affinity_score": 0.6135, "link": "https://aclanthology.org/2024.emnlp-main.880/", "abstract": "Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and shifts the focus from pursuing an omniscient problem solver to a proficient tool-user. To facilitate the research of such setting, we construct a tool-augmented training corpus named MathFunc which encompasses over 30,000 samples and roughly 6,000 tools. Building on MathFunc, we develop SciAgent to retrieve, understand and, if necessary, tool scientific problem solving. Additionally, we craft a benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs’ abilities with tool assistance. Extensive experiments on SciToolBench confirm the effectiveness of SciAgent. Notably, SciAgent-Llama3-8B surpasses other LLMs with the comparable size by more than 8.0% in absolute accuracy. Furthermore, SciAgent-DeepMath-7B shows much superior performance than ChatGPT.", "bibtex": "@inproceedings{ma-etal-2024-sciagent,\n    title = \"{S}ci{A}gent: Tool-augmented Language Models for Scientific Reasoning\",\n    author = \"Ma, Yubo  and\n      Gou, Zhibin  and\n      Hao, Junheng  and\n      Xu, Ruochen  and\n      Wang, Shuohang  and\n      Pan, Liangming  and\n      Yang, Yujiu  and\n      Cao, Yixin  and\n      Sun, Aixin\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.880/\",\n    doi = \"10.18653/v1/2024.emnlp-main.880\",\n    pages = \"15701--15736\"\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:33.561116Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Jinheon Baek", "Sujay Kumar Jauhar", "Silviu Cucerzan", "Sung Ju Hwang"], "affinity_score": 0.5989, "link": "https://aclanthology.org/2025.naacl-long.342/", "abstract": "The pace of scientific research, vital for improving human life, is complex, slow, and needs specialized expertise. Meanwhile, novel, impactful research often stems from both a deep understanding of prior work, and a cross-pollination of ideas across domains and fields. To enhance the productivity of researchers, we propose ResearchAgent, which leverages the encyclopedic knowledge and linguistic reasoning capabilities of Large Language Models (LLMs) to assist them in their work. This system automatically defines novel problems, proposes methods and designs experiments, while iteratively refining them based on the feedback from collaborative LLM-powered reviewing agents. Specifically, starting with a core scientific paper, ResearchAgent is augmented not only with relevant publications by connecting information over an academic graph but also entities retrieved from a knowledge store derived from shared underlying concepts mined across numerous papers. Then, mimicking a scientific approach to improving ideas with peer discussions, we leverage multiple LLM-based ReviewingAgents that provide reviews and feedback via iterative revision processes. These reviewing agents are instantiated with human preference-aligned LLMs whose criteria for evaluation are elicited from actual human judgments via LLM prompting. We experimentally validate our ResearchAgent on scientific publications across multiple disciplines, showing its effectiveness in generating novel, clear, and valid ideas based on both human and model-based evaluation results. Our initial foray into AI-mediated scientific research has important implications for the development of future systems aimed at supporting researchers in their ideation and operationalization of novel work.", "bibtex": "@inproceedings{baek-etal-2025-researchagent,\n    title = \"{R}esearch{A}gent: Iterative Research Idea Generation over Scientific Literature with Large Language Models\",\n    author = \"Baek, Jinheon  and\n      Jauhar, Sujay Kumar  and\n      Cucerzan, Silviu  and\n      Hwang, Sung Ju\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.342/\",\n    doi = \"10.18653/v1/2025.naacl-long.342\",\n    pages = \"6709--6738\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:33.561124Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Yusuf H Roohani", "Andrew H. Lee", "Qian Huang", "Jian Vora", "Zachary Steinhart", "Kexin Huang", "Alexander Marson", "Percy Liang", "Jure Leskovec"], "affinity_score": 0.5959, "link": "https://openreview.net/pdf/dcfab1feaba7d38761a21e709247e9d97d4b98e2.pdf", "abstract": "Agents based on large language models have shown great potential in accelerating scientific discovery by leveraging their rich background knowledge and reasoning capabilities. In this paper, we introduce BioDiscoveryAgent, an agent that designs new experiments, reasons about their outcomes, and efficiently navigates the hypothesis space to reach desired solutions. We demonstrate our agent on the problem of designing genetic perturbation experiments, where the aim is to find a small subset out of many possible genes that, when perturbed, result in a specific phenotype (e.g., cell growth). Utilizing its biological knowledge, BioDiscoveryAgent can uniquely design new experiments without the need to train a machine learning model or explicitly design an acquisition function as in Bayesian optimization. Moreover, BioDiscoveryAgent using Claude 3.5 Sonnet achieves an average of 21% improvement in predicting relevant genetic perturbations across six datasets, and a 46% improvement in the harder task of non-essential gene perturbation, compared to existing Bayesian optimization baselines specifically trained for this task. Our evaluation includes one dataset that is unpublished, ensuring it is not part of the language model's training data. Additionally, BioDiscoveryAgent predicts gene combinations to perturb more than twice as accurately as a random baseline, a task so far not explored in the context of closed-loop experiment design. The agent also has access to tools for searching the biomedical literature, executing code to analyze biological datasets, and prompting another agent to critically evaluate its predictions. Overall, BioDiscoveryAgent is interpretable at every stage, representing an accessible new paradigm in the computational design of biological experiments with the potential to augment scientists' efficacy.", "bibtex": "@inproceedings{\nroohani2025biodiscoveryagent,\ntitle={BioDiscoveryAgent: An {AI} Agent for Designing Genetic Perturbation Experiments},\nauthor={Yusuf H Roohani and Andrew H. Lee and Qian Huang and Jian Vora and Zachary Steinhart and Kexin Huang and Alexander Marson and Percy Liang and Jure Leskovec},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=HAwZGLcye3}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:33.561130Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "CFP-Gen: Combinatorial Functional Protein Generation via Diffusion Language Models", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Junbo Yin", "Chao Zha", "Wenjia He", "Chencheng Xu", "Xin Gao"], "affinity_score": 0.5891, "link": "https://openreview.net/pdf/569318484c672a4bfddea91c3e6c323f86db7f28.pdf", "abstract": "Existing PLMs generate protein sequences based on a single-condition constraint from a specific modality, struggling to simultaneously satisfy multiple constraints across different modalities. In this work, we introduce CFP-GEN, a novel diffusion language model for Combinatorial Functional Protein GENeration. CFP-GEN facilitates the de novo protein design by integrating multimodal conditions with functional, sequence, and structural constraints. Specifically, an Annotation-Guided Feature Modulation (AGFM) module is introduced to dynamically adjust the protein feature distribution based on composable functional annotations, e.g., GO terms, IPR domains and EC numbers. Meanwhile, the ResidueControlled Functional Encoding (RCFE) module captures residue-wise interaction to ensure more precise control. Additionally, off-the-shelf 3D structure encoders can be seamlessly integrated to impose geometric constraints. We demonstrate that CFP-GEN enables high-throughput generation of novel proteins with functionality comparable to natural proteins, while achieving a high success rate in designing multifunctional proteins.", "bibtex": "@inproceedings{\nyin2025cfpgen,\ntitle={{CFP}-Gen: Combinatorial Functional Protein Generation via Diffusion Language Models},\nauthor={Junbo Yin and Chao Zha and Wenjia He and Chencheng Xu and Xin Gao},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=EiM163eZyg}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:33.561135Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ProteinBench: A Holistic Evaluation of Protein Foundation Models", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Fei YE", "Zaixiang Zheng", "Dongyu Xue", "Yuning Shen", "Lihao Wang", "Yiming Ma", "Yan Wang", "Xinyou Wang", "Xiangxin Zhou", "Quanquan Gu"], "affinity_score": 0.5736, "link": "https://openreview.net/pdf/3544ce00631e6c89a866f5f9ff2ba3d59149c0d7.pdf", "abstract": "Recent years have witnessed a surge in the development of protein foundation models, significantly improving performance in protein prediction and generative tasks ranging from 3D structure prediction and protein design to conformational dynamics. However, the capabilities and limitations associated with these models remain poorly understood due to the absence of a unified evaluation framework. To fill this gap, we introduce ProteinBench, a holistic evaluation framework designed to enhance the transparency of protein foundation models. Our approach consists of three key components: (i) A taxonomic classification of tasks that broadly encompass the main challenges in the protein domain, based on the relationships between different protein modalities; (ii) A multi-metric evaluation approach that assesses performance across four key dimensions: quality, novelty, diversity, and robustness; and (iii) In-depth analyses from various user objectives, providing a holistic view of model performance. Our comprehensive evaluation of protein foundation models reveals several key findings that shed light on their current capabilities and limitations. To promote transparency and facilitate further research, we release the evaluation dataset, code, and a public leaderboard publicly for further analysis and a general modular toolkit. We intend for ProteinBench to be a living benchmark for establishing a standardized, in-depth evaluation framework for protein foundation models, driving their development and application while fostering collaboration within the field.", "bibtex": "@inproceedings{\nye2025proteinbench,\ntitle={ProteinBench: A Holistic Evaluation of Protein Foundation Models},\nauthor={Fei YE and Zaixiang Zheng and Dongyu Xue and Yuning Shen and Lihao Wang and Yiming Ma and Yan Wang and Xinyou Wang and Xiangxin Zhou and Quanquan Gu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=BksqWM8737}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:33.561139Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Protein Design with Dynamic Protein Vocabulary", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Nuowei Liu", "Jiahao Kuang", "Yanting Liu", "Tao Ji", "Changzhi Sun", "Man Lan", "Yuanbin Wu"], "affinity_score": 0.5704, "link": "https://openreview.net/pdf/e184433c0869edcdccef239e20dfb9420d27b9f8.pdf", "abstract": "Protein design is a fundamental challenge in biotechnology, aiming to design novel sequences with specific functions within the vast space of possible proteins. Recent advances in deep generative models have enabled function-based protein design from textual descriptions, yet struggle with structural plausibility. Inspired by classical protein design methods that leverage natural protein structures, we explore whether incorporating fragments from natural proteins can enhance foldability in generative models. Our empirical results show that even random incorporation of fragments improves foldability. Building on this insight, we introduce ProDVa, a novel protein design approach that integrates a text encoder for functional descriptions, a protein language model for designing proteins, and a fragment encoder to dynamically retrieve protein fragments based on textual functional descriptions. Experimental results demonstrate that our approach effectively designs protein sequences that are both functionally aligned and structurally plausible. Compared to state-of-the-art models, ProDVa achieves comparable function alignment using less than 0.04% of the training data, while designing significantly more well-folded proteins, with the proportion of proteins having pLDDT above 70 increasing by 7.38% and those with PAE below 10 increasing by 9.62%.", "bibtex": "@inproceedings{\nliu2025protein,\ntitle={Protein Design with Dynamic Protein Vocabulary},\nauthor={Nuowei Liu and Jiahao Kuang and Yanting Liu and Tao Ji and Changzhi Sun and Man Lan and Yuanbin Wu},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=MpJkAzwUtl}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:33.561144Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ProtPainter: Draw or Drag Protein via Topology-guided Diffusion", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Zhengxi Lu", "Shizhuo Cheng", "Tintin Jiang", "Yan Zhang", "Min Zhang"], "affinity_score": 0.5593, "link": "https://openreview.net/pdf/e4eaf619ab5c208b6e210bc9af270af499eda7c5.pdf", "abstract": "Recent advances in protein backbone generation have achieved promising results under structural, functional, or physical constraints. However, existing methods lack the flexibility for precise topology control, limiting navigation of the backbone space. We present $\\textbf{ProtPainter}$, a diffusion-based approach for generating protein backbones conditioned on 3D curves. ProtPainter follows a two-stage process: curve-based sketching and sketch-guided backbone generation. For the first stage, we propose $\\textbf{CurveEncoder}$, which predicts secondary structure annotations from a curve to parametrize sketch generation. For the second stage, the sketch guides the generative process in Denoising Diffusion Probabilistic Modeling (DDPM) to generate backbones. During the process, we further introduce a fusion scheduling scheme, Helix-Gating, to control the scaling factors. To evaluate, we propose the first benchmark for topology-conditioned protein generation, introducing Protein Restoration Task and a new metric, self-consistency Topology Fitness (scTF). Experiments demonstrate ProtPainter's ability to generate topology-fit (scTF $>$ 0.8) and designable (scTM $>$ 0.5) backbones, with drawing and dragging tasks showcasing its flexibility and versatility.", "bibtex": "@inproceedings{\nlu2025protpainter,\ntitle={ProtPainter: Draw or Drag Protein via Topology-guided Diffusion},\nauthor={Zhengxi Lu and Shizhuo Cheng and Tintin Jiang and Yan Zhang and Min Zhang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=Nq7yKYL0Bp}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:33.561148Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Prot2Text-V2: protein-function Prediction with Multimodal Contrastive Alignment", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Xiao Fei", "Michail Chatzianastasis", "Sarah Almeida Carneiro", "Hadi Abdine", "Lawrence Paul Petalidis", "Michalis Vazirgiannis"], "affinity_score": 0.5567, "link": "https://openreview.net/pdf/b02004d99f8f2dea970dfefc2a557e7c05782a38.pdf", "abstract": "Predicting protein-function from sequence is a central challenge in computational biology. While existing methods rely heavily on structured ontologies or similarity-based techniques, they often lack the flexibility to express structure-free functional descriptions and novel biological functions. In this work, we introduce Prot2Text-V2, a novel multimodal sequence-to-text model that generates free-form natural language descriptions of protein-function directly from amino acid sequences. Our method combines a protein language model as a sequence encoder (ESM-3B) and a decoder-only language model (LLaMA-3.1-8B-Instruct) through a lightweight nonlinear modality projector.\nA key innovation is our Hybrid Sequence-level Contrastive Alignment Learning (H-SCALE), which improves cross-modal learning by matching mean- and std-pooled protein embeddings with text representations via contrastive loss. After the alignment phase, we apply instruction-based fine-tuning using LoRA on the decoder to teach the model how to generate accurate protein-function descriptions conditioned on the protein sequence. We train Prot2Text-V2 on about 250K curated entries from SwissProt and evaluate it under low-homology conditions, where test sequences have low similarity with training samples. Prot2Text-V2 consistently outperforms traditional and LLM-based baselines across various metrics.", "bibtex": "@inproceedings{\nfei2025prottextv,\ntitle={Prot2Text-V2: protein-function Prediction with Multimodal Contrastive Alignment},\nauthor={Xiao Fei and Michail Chatzianastasis and Sarah Almeida Carneiro and Hadi Abdine and Lawrence Paul Petalidis and Michalis Vazirgiannis},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=w1FUXt3ujK}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:33.561153Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "An All-Atom Generative Model for Designing Protein Complexes", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Ruizhe Chen", "Dongyu Xue", "Xiangxin Zhou", "Zaixiang Zheng", "xiangxiang Zeng", "Quanquan Gu"], "affinity_score": 0.5484, "link": "https://openreview.net/pdf/097aa805ed5da2cc0d4fc09c1cfaab111789b078.pdf", "abstract": "Proteins typically exist in complexes, interacting with other proteins or biomolecules to perform their specific biological roles. Research on single-chain protein modeling has been extensively and deeply explored, with advancements seen in models like the series of ESM and AlphaFold2. Despite these developments, the study and modeling of multi-chain proteins remain largely uncharted, though they are vital for understanding biological functions. Recognizing the importance of these interactions, we introduce APM (all-Atom Protein generative Model), a model specifically designed for modeling multi-chain proteins. By integrating atom-level information and leveraging data on multi-chain proteins, APM is capable of precisely modeling inter-chain interactions and designing protein complexes with binding capabilities from scratch. It also performs folding and inverse-folding tasks for multi-chain proteins. Moreover, APM demonstrates versatility in downstream applications: it achieves enhanced performance through supervised fine-tuning (SFT) while also supporting zero-shot sampling in certain tasks, achieving state-of-the-art results. We released our code at https://github.com/bytedance/apm.", "bibtex": "@inproceedings{\nchen2025an,\ntitle={An All-Atom Generative Model for Designing Protein Complexes},\nauthor={Ruizhe Chen and Dongyu Xue and Xiangxin Zhou and Zaixiang Zheng and xiangxiang Zeng and Quanquan Gu},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=Afmi28vgIf}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:33.561157Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Joint Design of Protein Surface and Backbone Using a Diffusion Bridge Model", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Guanlue Li", "Xufeng Zhao", "Fang Wu", "Sören Laue"], "affinity_score": 0.5463, "link": "https://openreview.net/pdf/f1279f7d02db36b5fa80332e4f86e4a98dc23ef7.pdf", "abstract": "Protein-protein interactions (PPIs) are governed by surface complementarity and hydrophobic interactions at protein interfaces. However, designing diverse and physically realistic protein structure and surfaces that precisely complement target receptors remains a significant challenge in computational protein design. In this work, we introduce PepBridge, a novel framework for the joint design of protein surface and structure that seamlessly integrates receptor surface geometry and biochemical properties. Starting with a receptor surface represented as a 3D point cloud, PepBridge generates complete protein structures through a multi-step process. First, it employs denoising diffusion bridge models (DDBMs) to map receptor surfaces to ligand surfaces. Next, a multi-model diffusion model predicts the corresponding structure, while Shape-Frame Matching Networks ensure alignment between surface geometry and backbone architecture. This integrated approach facilitates surface complementarity, conformational stability, and chemical feasibility. Extensive validation across diverse protein design scenarios demonstrates PepBridge's efficacy in generating structurally viable proteins, representing a significant advancement in the joint design of top-down protein structure.", "bibtex": "@inproceedings{\nli2025joint,\ntitle={Joint Design of Protein Surface and Backbone Using a Diffusion Bridge Model},\nauthor={Guanlue Li and Xufeng Zhao and Fang Wu and S{\\\"o}ren Laue},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=QqCv9SI0X3}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:34.550906Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Steering Protein Family Design through Profile Bayesian Flow", "venue": "ICLR 2025 Oral", "year": "2025", "authors": ["Jingjing Gong", "Yu Pei", "Siyu Long", "Yuxuan Song", "Zhe Zhang", "Wenhao Huang", "Ziyao Cao", "Shuyi Zhang", "Hao Zhou", "Wei-Ying Ma"], "affinity_score": 0.5356, "link": "https://openreview.net/pdf/43bf9f0b2762a450d02b6845e2f7fa85988bf860.pdf", "abstract": "Protein family design emerges as a promising alternative by combining the advantages of de novo protein design and mutation-based directed evolution.In this paper, we propose ProfileBFN, the Profile Bayesian Flow Networks, for specifically generative modeling of protein families. ProfileBFN extends the discrete Bayesian Flow Network from an MSA profile perspective, which can be trained on single protein sequences by regarding it as a degenerate profile, thereby achieving efficient protein family design by avoiding large-scale MSA data construction and training. Empirical results show that ProfileBFN has a profound understanding of proteins. When generating diverse and novel family proteins, it can accurately capture the structural characteristics of the family. The enzyme produced by this method is more likely than the previous approach to have the corresponding function, offering better odds of generating diverse proteins with the desired functionality.", "bibtex": "@inproceedings{\ngong2025steering,\ntitle={Steering Protein Family Design through Profile Bayesian Flow},\nauthor={Jingjing Gong and Yu Pei and Siyu Long and Yuxuan Song and Zhe Zhang and Wenhao Huang and Ziyao Cao and Shuyi Zhang and Hao Zhou and Wei-Ying Ma},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=PSiijdQjNU}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:34.550919Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "TEMPO: Temporal Multi-scale Autoregressive Generation of Protein Conformational Ensembles", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Yaoyao Xu", "Di Wang", "Zihan Zhou", "Tianshu Yu", "Mingchen Chen"], "affinity_score": 0.5333, "link": "https://openreview.net/pdf/91f410ff9dcb163d0ffe652491a71fba886e94d9.pdf", "abstract": "Understanding the dynamic behavior of proteins is critical to elucidating their functional mechanisms, yet generating realistic, temporally coherent trajectories of protein ensembles remains a significant challenge. In this work, we introduce a novel hierarchical autoregressive framework for modeling protein dynamics that leverages the intrinsic multi-scale organization of molecular motions. Unlike existing methods that focus on generating static conformational ensembles or treat dynamic sampling as an independent process, our approach characterizes protein dynamics as a Markovian process. The framework employs a two-scale architecture: a low-resolution model captures slow, collective motions driving major conformational transitions, while a high-resolution model generates detailed local fluctuations conditioned on these large-scale movements. This hierarchical design ensures that the causal dependencies inherent in protein dynamics are preserved, enabling the generation of temporally coherent and physically realistic trajectories. By bridging high-level biophysical principles with state-of-the-art generative modeling, our approach provides an efficient framework for simulating protein dynamics that balances computational efficiency with physical accuracy.", "bibtex": "@inproceedings{\nxu2025tempo,\ntitle={{TEMPO}: Temporal Multi-scale Autoregressive Generation of Protein Conformational Ensembles},\nauthor={Yaoyao Xu and Di Wang and Zihan Zhou and Tianshu Yu and Mingchen Chen},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=0wV5HR7M4P}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:34.550923Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Bridging Protein Sequences and Microscopy Images with Unified Diffusion Models", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Dihan Zheng", "Bo Huang"], "affinity_score": 0.5324, "link": "https://openreview.net/pdf/f447029f83b094b6b90f0c5043453e975c659aa2.pdf", "abstract": "Fluorescence microscopy is ubiquitously used in cell biology research to characterize the cellular role of a protein. To help elucidate the relationship between the amino acid sequence of a protein and its cellular function, we introduce CELL-Diff, a unified diffusion model facilitating bidirectional transformations between protein sequences and their corresponding microscopy images. Utilizing reference cell morphology images and a protein sequence, CELL-Diff efficiently generates corresponding protein images. Conversely, given a protein image, the model outputs protein sequences. CELL-Diff integrates continuous and diffusion models within a unified framework and is implemented using a transformer-based network. We train CELL-Diff on the Human Protein Atlas (HPA) dataset and fine-tune it on the OpenCell dataset. Experimental results demonstrate that CELL-Diff outperforms existing methods in generating high-fidelity protein images, making it a practical tool for investigating subcellular protein localization and interactions.", "bibtex": "@inproceedings{\nzheng2025bridging,\ntitle={Bridging Protein Sequences and Microscopy Images with Unified Diffusion Models},\nauthor={Dihan Zheng and Bo Huang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=r4XfIgD77g}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:34.550926Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "From Mechanistic Interpretability to Mechanistic Biology: Training, Evaluating, and Interpreting Sparse Autoencoders on Protein Language Models", "venue": "ICML 2025 Spotlightposter", "year": "2025", "authors": ["Etowah Adams", "Liam Bai", "Minji Lee", "Yiyang Yu", "Mohammed AlQuraishi"], "affinity_score": 0.5323, "link": "https://openreview.net/pdf/9f17c03cb8b900c8987d0efd2edda7945a8224c9.pdf", "abstract": "Protein language models (pLMs) are powerful predictors of protein structure and function, learning through unsupervised training on millions of protein sequences. pLMs are thought to capture common motifs in protein sequences, but the specifics of pLM features are not well understood. Identifying these features would not only shed light on how pLMs work, but potentially uncover novel protein biology––studying the model to study the biology. Motivated by this, we train sparse autoencoders (SAEs) on the residual stream of a pLM, ESM-2. By characterizing SAE features, we determine that pLMs use a combination of generic features and family-specific features to represent a protein. In addition, we demonstrate how known sequence determinants of properties such as thermostability and subcellular localization can be identified by linear probing of SAE features. For predictive features without known functional associations, we hypothesize their role in unknown mechanisms and provide visualization tools to aid their interpretation. Our study gives a better understanding of the limitations of pLMs, and demonstrates how SAE features can be used to help generate hypotheses for biological mechanisms. We release our code, model weights, and feature visualizer.", "bibtex": "@inproceedings{\nadams2025from,\ntitle={From Mechanistic Interpretability to Mechanistic Biology: Training, Evaluating, and Interpreting Sparse Autoencoders on Protein Language Models},\nauthor={Etowah Adams and Liam Bai and Minji Lee and Yiyang Yu and Mohammed AlQuraishi},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=zdOGBRQEbz}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:34.550929Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Steering Generative Models with Experimental Data for Protein Fitness Optimization", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Jason Yang", "Wenda Chu", "Daniel Khalil", "Raul Astudillo", "Bruce James Wittmann", "Frances H. Arnold", "Yisong Yue"], "affinity_score": 0.5313, "link": "https://openreview.net/pdf/81aade662c48049d5fd1adafcb6cb2d72d21cf70.pdf", "abstract": "Protein fitness optimization involves finding a protein sequence that maximizes desired quantitative properties in a combinatorially large design space of possible sequences. Recent advances in steering protein generative models (e.g., diffusion models and language models) with labeled data offer a promising approach. However, most previous studies have optimized surrogate rewards and/or utilized large amounts of labeled data for steering, making it unclear how well existing methods perform and compare to each other in real-world optimization campaigns where fitness is measured through low-throughput wet-lab assays. In this study, we explore fitness optimization using small amounts (hundreds) of labeled sequence-fitness pairs and comprehensively evaluate strategies such as classifier guidance and posterior sampling for guiding generation from different discrete diffusion models of protein sequences. We also demonstrate how guidance can be integrated into adaptive sequence selection akin to Thompson sampling in Bayesian optimization, showing that plug-and-play guidance strategies offer advantages over alternatives such as reinforcement learning with protein language models. Overall, we provide practical insights into how to effectively steer modern generative models for next-generation protein fitness optimization.", "bibtex": "@inproceedings{\nyang2025steering,\ntitle={Steering Generative Models with Experimental Data for Protein Fitness Optimization},\nauthor={Jason Yang and Wenda Chu and Daniel Khalil and Raul Astudillo and Bruce James Wittmann and Frances H. Arnold and Yisong Yue},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=Ice2BHIumz}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:34.550932Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "BLADE: Benchmarking Language Model Agents for Data-Driven Science", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Ken Gu", "Ruoxi Shang", "Ruien Jiang", "Keying Kuang", "Richard-John Lin", "Donghe Lyu", "Yue Mao", "Youran Pan", "Teng Wu", "Jiaqian Yu", "Yikun Zhang", "Tianmai M. Zhang", "Lanyi Zhu", "Mike A Merrill", "Jeffrey Heer", "Tim Althoff"], "affinity_score": 0.5296, "link": "https://aclanthology.org/2024.findings-emnlp.815/", "abstract": "Data-driven scientific discovery requires the iterative integration of scientific domain knowledge, statistical expertise, and an understanding of data semantics to make nuanced analytical decisions, e.g., about which variables, transformations, and statistical models to consider. LM-based agents equipped with planning, memory, and code execution capabilities have the potential to support data-driven science. However, evaluating agents on such open-ended tasks is challenging due to multiple valid approaches, partially correct steps, and different ways to express the same decisions. To address these challenges, we present BLADE, a benchmark to automatically evaluate agents’ multifaceted approaches to open-ended research questions. BLADE consists of 12 datasets and research questions drawn from existing scientific literature, with ground truth collected from independent analyses by expert data scientists and researchers. To automatically evaluate agent responses, we developed corresponding computational methods to match different representations of analyses to this ground truth. Though language models possess considerable world knowledge, our evaluation shows that they are often limited to basic analyses. However, agents capable of interacting with the underlying data demonstrate improved, but still non-optimal, diversity in their analytical decision making. Our work enables the evaluation of agents for data-driven science and provides researchers deeper insights into agents’ analysis approaches.", "bibtex": "@inproceedings{gu-etal-2024-blade,\n    title = \"{BLADE}: Benchmarking Language Model Agents for Data-Driven Science\",\n    author = \"Gu, Ken  and\n      Shang, Ruoxi  and\n      Jiang, Ruien  and\n      Kuang, Keying  and\n      Lin, Richard-John  and\n      Lyu, Donghe  and\n      Mao, Yue  and\n      Pan, Youran  and\n      Wu, Teng  and\n      Yu, Jiaqian  and\n      Zhang, Yikun  and\n      Zhang, Tianmai M.  and\n      Zhu, Lanyi  and\n      Merrill, Mike A  and\n      Heer, Jeffrey  and\n      Althoff, Tim\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.815/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.815\",\n    pages = \"13936--13971\"\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:34.550935Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Retrieval-Augmented Language Model for Knowledge-aware Protein Encoding", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Jiasheng Zhang", "Delvin Ce Zhang", "Shuang Liang", "Zhengpin Li", "Rex Ying", "Jie Shao"], "affinity_score": 0.5292, "link": "https://openreview.net/pdf/5f63c05b47d681f0a59195523a2fc09dac1bedee.pdf", "abstract": "Protein language models often struggle to capture biological functions due to their lack of factual knowledge (e.g., gene descriptions). Existing solutions leverage protein knowledge graphs (PKGs) as auxiliary pre-training objectives, but lack explicit integration of task-oriented knowledge, making them suffer from limited knowledge exploitation and catastrophic forgetting. The root cause is that they fail to align PKGs with task-specific data, forcing their knowledge modeling to adapt to the knowledge-isolated nature of downstream tasks. In this paper, we propose Knowledge-aware retrieval augmented protein language model (Kara), achieving the first task-oriented and explicit integration of PKGs and protein language models. With a knowledge retriever learning to predict linkages between PKG and task proteins, Kara unifies the knowledge integration of the pre-training and fine-tuning stages with a structure-based regularization, mitigating catastrophic forgetting. To ensure task-oriented integration, Kara uses contextualized virtual tokens to extract graph context as task-specific knowledge for new proteins. Experiments show that Kara outperforms existing knowledge-enhanced models in 6 representative tasks, achieving on average 5.1% improvements.", "bibtex": "@inproceedings{\nzhang2025retrievalaugmented,\ntitle={Retrieval-Augmented Language Model for Knowledge-aware Protein Encoding},\nauthor={Jiasheng Zhang and Delvin Ce Zhang and Shuang Liang and Zhengpin Li and Rex Ying and Jie Shao},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=TJHhXzTcQe}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:34.550937Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "LLM Agents Making Agent Tools", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Georg Wölflein", "Dyke Ferber", "Daniel Truhn", "Ognjen Arandjelovic", "Jakob Nikolas Kather"], "affinity_score": 0.5288, "link": "https://aclanthology.org/2025.acl-long.1266/", "abstract": "Tool use has turned large language models (LLMs) into powerful agents that can perform complex multi-step tasks by dynamically utilising external software components. However, these tools must be implemented in advance by human developers, hindering the applicability of LLM agents in domains demanding large numbers of highly specialised tools, like in life sciences and medicine. Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose ToolMaker, an agentic framework that autonomously transforms papers with code into LLM-compatible tools. Given a GitHub URL and short task description, ToolMaker autonomously installs dependencies and generates code to perform the task, using a closed-loop self-correction mechanism for debugging. To evaluate our approach, we introduce a benchmark comprising 15 complex computational tasks spanning various domains with over 100 unit tests to assess correctness and robustness. Our method correctly implements 80% of the tasks, substantially outperforming current state-of-the-art software engineering agents. ToolMaker therefore is a step towards fully autonomous agent-based scientific workflows.", "bibtex": "@inproceedings{wolflein-etal-2025-llm,\n    title = \"{LLM} Agents Making Agent Tools\",\n    author = {W{\\\"o}lflein, Georg  and\n      Ferber, Dyke  and\n      Truhn, Daniel  and\n      Arandjelovic, Ognjen  and\n      Kather, Jakob Nikolas},\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1266/\",\n    doi = \"10.18653/v1/2025.acl-long.1266\",\n    pages = \"26092--26130\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:34.550941Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "UniZyme: A Unified Protein Cleavage Site Predictor Enhanced with Enzyme Active-Site Knowledge", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Chenao Li", "Shuo Yan", "Enyan Dai"], "affinity_score": 0.5281, "link": "https://openreview.net/pdf/b89909c20ceaa10621ab93b7b6694fbdb824f04d.pdf", "abstract": "Enzyme-catalyzed protein cleavage is essential for many biological functions. Accurate prediction of cleavage sites can facilitate various applications such as drug development, enzyme design, and a deeper understanding of biological mechanisms. However, most existing models are restricted to an individual enzyme, which neglects shared knowledge of enzymes and fails to generalize to novel enzymes. Thus, we introduce a unified protein cleavage site predictor named UniZyme, which can generalize across diverse enzymes. To enhance the enzyme encoding for the protein cleavage site prediction, UniZyme employs a novel biochemically-informed model architecture along with active-site knowledge of proteolytic enzymes.  Extensive experiments demonstrate that UniZyme achieves high accuracy in predicting cleavage sites across a range of proteolytic enzymes, including unseen enzymes. The code is available in  https://github.com/Ao-LiChen/UniZyme", "bibtex": "@inproceedings{\nli2025unizyme,\ntitle={UniZyme: A Unified Protein Cleavage Site Predictor Enhanced with Enzyme Active-Site Knowledge},\nauthor={Chenao Li and Shuo Yan and Enyan Dai},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=5cgm5dV5hr}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:34.550944Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Yuhao Wang", "Keyan Ding", "Kehua Feng", "Zeyuan Wang", "Ming Qin", "Xiaotong Li", "Qiang Zhang", "Huajun Chen"], "affinity_score": 0.5271, "link": "https://aclanthology.org/2025.acl-long.616/", "abstract": "Protein language models have emerged as powerful tools for sequence generation, offering substantial advantages in functional optimization and\ndenovo\ndesign. However, these models also present significant risks of generating harmful protein sequences, such as those that enhance viral transmissibility or evade immune responses. These concerns underscore critical biosafety and ethical challenges. To address these issues, we propose a Knowledge-guided Preference Optimization (KPO) framework that integrates prior knowledge via a Protein Safety Knowledge Graph. This framework utilizes an efficient graph pruning strategy to identify preferred sequences and employs reinforcement learning to minimize the risk of generating harmful proteins. Experimental results demonstrate that KPO effectively reduces the likelihood of producing hazardous sequences while maintaining high functionality, offering a robust safety assurance framework for applying generative models in biotechnology.", "bibtex": "@inproceedings{wang-etal-2025-enhancing-safe,\n    title = \"Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization\",\n    author = \"Wang, Yuhao  and\n      Ding, Keyan  and\n      Feng, Kehua  and\n      Wang, Zeyuan  and\n      Qin, Ming  and\n      Li, Xiaotong  and\n      Zhang, Qiang  and\n      Chen, Huajun\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.616/\",\n    doi = \"10.18653/v1/2025.acl-long.616\",\n    pages = \"12553--12569\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:35.413020Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Steering Protein Language Models", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Long-Kai Huang", "Rongyi Zhu", "Bing He", "Jianhua Yao"], "affinity_score": 0.5267, "link": "https://openreview.net/pdf/a837cc69557d144870d59bb17ba9cec8627e9546.pdf", "abstract": "Protein Language Models (PLMs), pre-trained on extensive evolutionary data from natural proteins, have emerged as indispensable tools for protein design. While powerful, PLMs often struggle to produce proteins with precisely specified functionalities or properties due to inherent challenges in controlling their outputs. \nIn this work, we investigate the potential of Activation Steering, a technique originally developed for controlling text generation in Large Language Models (LLMs), to direct PLMs toward generating protein sequences with targeted properties. We propose a simple yet effective method that employs activation editing to steer PLM outputs, and extend this approach to protein optimization through a novel editing site identification module. Through comprehensive experiments on lysozyme-like sequence generation and optimization, we demonstrate that our methods can be seamlessly integrated into both auto-encoding and autoregressive PLMs without requiring additional training. These results highlight a promising direction for precise protein engineering using foundation models.\nCode is available at\nhttps://github.com/Long-Kai/Steering-PLMs\n.", "bibtex": "@inproceedings{\nhuang2025steering,\ntitle={Steering Protein Language Models},\nauthor={Long-Kai Huang and Rongyi Zhu and Bing He and Jianhua Yao},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=pu2aw2zwMx}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:35.413041Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "AI-Researcher: Autonomous Scientific Innovation", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Jiabin Tang", "Lianghao Xia", "Zhonghang Li", "Chao Huang"], "affinity_score": 0.5266, "link": "https://openreview.net/pdf/a1c63cdd0495de94664b1513f7d95a3aedcb483a.pdf", "abstract": "The powerful reasoning capabilities of Large Language Models (LLMs) in mathematics and coding, combined with their ability to automate complex tasks through agentic frameworks, present unprecedented opportunities for accelerating scientific innovation. In this paper, we introduce AI-Researcher, a fully autonomous research system that transforms how AI-driven scientific discovery is conducted and evaluated. Our framework seamlessly orchestrates the complete research pipeline--from literature review and hypothesis generation to algorithm implementation and publication-ready manuscript preparation--with minimal human intervention. To rigorously assess autonomous research capabilities, we develop Scientist-Bench, a comprehensive benchmark comprising state-of-the-art papers across diverse AI research domains, featuring both guided innovation and open-ended exploration tasks. Through extensive experiments, we demonstrate that AI-Researcher achieves remarkable implementation success rates and produces research papers that approach human-level quality. This work establishes new foundations for autonomous scientific innovation that can complement human researchers by systematically exploring solution spaces beyond cognitive limitations.", "bibtex": "@inproceedings{\ntang2025airesearcher,\ntitle={{AI}-Researcher: Autonomous Scientific Innovation},\nauthor={Jiabin Tang and Lianghao Xia and Zhonghang Li and Chao Huang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=kQWyOYUAC4}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:35.413047Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Data Distillation for extrapolative protein design through exact preference optimization", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Mostafa Karimi", "Sharmi Banerjee", "Tommi Jaakkola", "Bella Dubrov", "Shang Shang", "Ron Benson"], "affinity_score": 0.526, "link": "https://openreview.net/pdf/021d9166b13a2e7722c47febaf5741466a713b4d.pdf", "abstract": "The goal of protein design typically involves increasing fitness (extrapolating) beyond what is seen during training (e.g., towards higher stability, stronger binding affinity, etc.). State-of-the-art methods assume that one can safely steer proteins towards such extrapolated regions by learning from pairs alone. We hypothesize that noisy training pairs are not sufficiently informative to capture the fitness gradient and that models learned from pairs specifically may fail to capture three-way relations important for search, e.g., how two alternatives fair relative to a seed. Building on the success of preference alignment models in large language models, we introduce a progressive search method for extrapolative protein design by directly distilling into the model relevant triplet relations. We evaluated our model's performance in designing AAV and GFP proteins and demonstrated that the proposed framework significantly improves effectiveness in extrapolation tasks.", "bibtex": "@inproceedings{\nkarimi2025data,\ntitle={Data Distillation for extrapolative protein design through exact preference optimization},\nauthor={Mostafa Karimi and Sharmi Banerjee and Tommi Jaakkola and Bella Dubrov and Shang Shang and Ron Benson},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=ua5MHdsbck}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:35.413052Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "PPDiff: Diffusing in Hybrid Sequence-Structure Space for Protein-Protein Complex Design", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Zhenqiao Song", "Tianxiao Li", "Lei Li", "Martin Renqiang Min"], "affinity_score": 0.5253, "link": "https://openreview.net/pdf/c1d0093e12471abf1eedc91b20aa16373243a7b7.pdf", "abstract": "Designing protein-binding proteins with high affinity is critical in biomedical research and biotechnology. Despite recent advancements targeting specific proteins, the ability to create high-affinity binders for arbitrary protein targets on demand, without extensive rounds of wet-lab testing, remains a significant challenge. Here, we introduce PPDiff, a diffusion model to jointly design the sequence and structure of binders for arbitrary protein targets in a non-autoregressive manner. PPDiff builds upon our developed Sequence Structure Interleaving Network with Causal attention layers (SSINC), which integrates interleaved self-attention layers to capture global amino acid correlations, $k$-nearest neighbor ($k$NN) equivariant graph convolutional layers to model local interactions in three-dimensional (3D) space, and causal attention layers to simplify the intricate interdependencies within the protein sequence. To assess PPDiff, we curate PPBench, a general protein-protein complex dataset comprising 706,360 complexes from the Protein Data Bank (PDB). The model is pretrained on PPBench and finetuned on two real-world applications: target-protein mini-binder complex design and antigen-antibody complex design. PPDiff consistently surpasses baseline methods, achieving success rates of 50.00\\%, 23.16\\%, and 16.89\\% for the pretraining task and the two downstream applications, respectively.", "bibtex": "@inproceedings{\nsong2025ppdiff,\ntitle={{PPD}iff: Diffusing in Hybrid Sequence-Structure Space for Protein-Protein Complex Design},\nauthor={Zhenqiao Song and Tianxiao Li and Lei Li and Martin Renqiang Min},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=gTYzm0Qchr}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:35.413056Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Latent Retrieval Augmented Generation of Cross-Domain Protein Binders", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Zishen Zhang", "Xiangzhe Kong", "Wenbing Huang", "Yang Liu"], "affinity_score": 0.5246, "link": "https://openreview.net/pdf/9ddd71a1025703ddb55d20ba5a51370138b4915e.pdf", "abstract": "Designing protein binders targeting specific sites, which requires to generate realistic and functional interaction patterns, is a fundamental challenge in drug discovery. Current structure-based generative models are limited in generating nterfaces with sufficient rationality and interpretability. In this paper, we propose\nR\netrieval-\nA\nugmented\nDi\nffusion for\nA\nlig\nn\ned interfa\nce\n(\nRADiAnce\n), a new framework that leverages known interfaces to guide the design of novel binders. By unifying retrieval and generation in a shared contrastive latent space, our model efficiently identifies relevant interfaces for a given binding site and seamlessly integrates them through a conditional latent diffusion generator, enabling cross-domain interface transfer. Extensive exeriments show that\nRADiAnce\nsignificantly outperforms baseline models across multiple metrics, including binding affinity and recovery of geometries and interactions.\nAdditional experimental results validate cross-domain generalization, demonstrating that retrieving interfaces from diverse domains, such as peptides, antibodies, and protein fragments, enhances the generation performance of binders for other domains. Our work establishes a new paradigm for protein binder design that successfully bridges retrieval-based knowledge and generative AI, opening new possibilities for drug discovery.", "bibtex": "@inproceedings{\nzhang2025latent,\ntitle={Latent Retrieval Augmented Generation of Cross-Domain Protein Binders},\nauthor={Zishen Zhang and Xiangzhe Kong and Wenbing Huang and Yang Liu},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=B7Bc9xzl2o}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:35.413061Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ChemAgent: Self-updating Memories in Large Language Models Improves Chemical Reasoning", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Xiangru Tang", "Tianyu Hu", "Muyang Ye", "Yanjun Shao", "Xunjian Yin", "Siru Ouyang", "Wangchunshu Zhou", "Pan Lu", "Zhuosheng Zhang", "Yilun Zhao", "Arman Cohan", "Mark Gerstein"], "affinity_score": 0.5245, "link": "https://openreview.net/pdf/f072f5a9e65a8bb918caeaa9fdf7a78732984cba.pdf", "abstract": "Chemical reasoning usually involves complex, multi-step processes that demand precise calculations, where even minor errors can lead to cascading failures. Furthermore, large language models (LLMs) encounter difficulties handling domain-specific formulas, executing reasoning steps accurately, and integrating code ef- effectively when tackling chemical reasoning tasks. To address these challenges, we present ChemAgent, a novel framework designed to improve the performance of LLMs through a dynamic, self-updating library. This library is developed by decomposing chemical tasks into sub-tasks and compiling these sub-tasks into a structured collection that can be referenced for future queries. Then, when presented with a new problem, ChemAgent retrieves and refines pertinent information from the library, which we call memory, facilitating effective task decomposition and the generation of solutions. Our method designs three types of memory and a library-enhanced reasoning component, enabling LLMs to improve over time through experience. Experimental results on four chemical reasoning datasets from SciBench demonstrate that ChemAgent achieves performance gains of up to 46% (GPT-4), significantly outperforming existing methods. Our findings suggest substantial potential for future applications, including tasks such as drug discovery and materials science. Our code can be found at https://github.com/gersteinlab/ChemAgent.", "bibtex": "@inproceedings{\ntang2025chemagent,\ntitle={ChemAgent: Self-updating Memories in Large Language Models Improves Chemical Reasoning},\nauthor={Xiangru Tang and Tianyu Hu and Muyang Ye and Yanjun Shao and Xunjian Yin and Siru Ouyang and Wangchunshu Zhou and Pan Lu and Zhuosheng Zhang and Yilun Zhao and Arman Cohan and Mark Gerstein},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=kuhIqeVg0e}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:35.413066Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Simultaneous Modeling of Protein Conformation and Dynamics via Autoregression", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Yuning Shen", "Lihao Wang", "Huizhuo Yuan", "Yan Wang", "Bangji Yang", "Quanquan Gu"], "affinity_score": 0.5237, "link": "https://openreview.net/pdf/8049776790397ae4bd55dbc09aa3105a978e06ea.pdf", "abstract": "Understanding protein dynamics is critical for elucidating their biological functions. \nThe increasing availability of molecular dynamics (MD) data enables the training of deep generative models to efficiently explore the conformational space of proteins.\nHowever, existing approaches either fail to explicitly capture the temporal dependencies between conformations or do not support direct generation of time-independent samples.\nTo address these limitations, we introduce\nConfRover\n, an autoregressive model that simultaneously learns protein conformation and dynamics from MD trajectory data, supporting both time-dependent and time-independent sampling.\nAt the core of our model is a modular architecture comprising: (i) an\nencoding layer\n, adapted from protein folding models, that embeds protein-specific information and conformation at each time frame into a latent space; (ii) a\ntemporal module\n, a sequence model that captures conformational dynamics across frames; and (iii) an SE(3) diffusion model as the\nstructure decoder\n, generating conformations in continuous space.\nExperiments on ATLAS, a large-scale protein MD dataset of diverse structures, demonstrate the effectiveness of our model in learning conformational dynamics and supporting a wide range of downstream tasks.\nConfRover\nis the first model to sample both protein conformations and trajectories within a single framework, offering a novel and flexible approach for learning from protein MD data.", "bibtex": "@inproceedings{\nshen2025simultaneous,\ntitle={Simultaneous Modeling of Protein Conformation and Dynamics via Autoregression},\nauthor={Yuning Shen and Lihao Wang and Huizhuo Yuan and Yan Wang and Bangji Yang and Quanquan Gu},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=jj0nJQYFlW}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:35.413070Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "DPLM-2: A Multimodal Diffusion Protein Language Model", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Xinyou Wang", "Zaixiang Zheng", "Fei YE", "Dongyu Xue", "Shujian Huang", "Quanquan Gu"], "affinity_score": 0.5228, "link": "https://openreview.net/pdf/13c6bc9b904922e7352e690eae7cad8a2d4526f7.pdf", "abstract": "Proteins are essential macromolecules defined by their amino acid sequences, which determine their three-dimensional structures and, consequently, their functions in all living organisms. Therefore, generative protein modeling necessitates a multimodal approach to simultaneously model, understand, and generate both sequences and structures. However, existing methods typically use separate models for each modality, limiting their ability to capture the intricate relationships between sequence and structure. This results in suboptimal performance in tasks that requires joint understanding and generation of both modalities.\nIn this paper, we introduce DPLM-2, a multimodal protein foundation model that extends discrete diffusion protein language model (DPLM) to accommodate both sequences and structures.\nTo enable structural learning with the language model, 3D coordinates are converted to discrete tokens using a lookup-free quantization-based tokenizer.\nBy training on both experimental and high-quality synthetic structures, DPLM-2 learns the joint distribution of sequence and structure, as well as their marginals and conditionals.\nWe also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models.\nEmpirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach.\nMoreover, DPLM-2 demonstrates competitive performance in various conditional generation tasks, including folding, inverse folding, and scaffolding with multimodal motif inputs.", "bibtex": "@inproceedings{\nwang2025dplm,\ntitle={{DPLM}-2: A Multimodal Diffusion Protein Language Model},\nauthor={Xinyou Wang and Zaixiang Zheng and Fei YE and Dongyu Xue and Shujian Huang and Quanquan Gu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=5z9GjHgerY}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:35.413075Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Inverse problems with experiment-guided AlphaFold", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Sai Advaith Maddipatla", "Nadav Bojan", "Meital Bojan", "Sanketh Vedula", "Paul Schanda", "Ailie Marx", "Alexander Bronstein"], "affinity_score": 0.5211, "link": "https://openreview.net/pdf/4851973ad7a0af3ee84445f1dc248b20a01234be.pdf", "abstract": "Proteins exist as a dynamic ensemble of multiple conformations, and these motions are often crucial for their functions. However, current structure prediction methods predominantly yield a single  conformation, overlooking the conformational heterogeneity revealed by diverse experimental modalities. Here, we present a framework for building experiment-grounded protein structure generative models that infer conformational ensembles consistent with measured experimental data. The key idea is to treat state-of-the-art protein structure predictors (e.g., AlphaFold3) as sequence-conditioned structural priors, and cast ensemble modeling as posterior inference of protein structures given experimental measurements. Through extensive real-data experiments, we demonstrate the generality of our method to incorporate a variety of experimental measurements. In particular, our framework uncovers previously unmodeled conformational heterogeneity from crystallographic densities, generates high-accuracy NMR ensembles orders of magnitude faster than status quo, and incorporates pairwise cross-link constraints. Notably, we demonstrate that our ensembles outperform AlphaFold3 and sometimes better fit experimental data than publicly deposited structures to the protein database (PDB). We believe that this approach will unlock building predictive models that fully embrace experimentally observed conformational diversity.", "bibtex": "@inproceedings{\nmaddipatla2025inverse,\ntitle={Inverse problems with experiment-guided AlphaFold},\nauthor={Sai Advaith Maddipatla and Nadav Bojan and Meital Bojan and Sanketh Vedula and Paul Schanda and Ailie Marx and Alexander Bronstein},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=qzM37nOy3N}\n}", "pdf_path": null, "retrieved_at": "2025-11-12T19:52:35.413079Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Yubo Ma", "Zhibin Gou", "Junheng Hao", "Ruochen Xu", "Shuohang Wang", "Liangming Pan", "Yujiu Yang", "Yixin Cao", "Aixin Sun"], "affinity_score": 0.7669, "link": "https://aclanthology.org/2024.emnlp-main.880/", "abstract": "Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and shifts the focus from pursuing an omniscient problem solver to a proficient tool-user. To facilitate the research of such setting, we construct a tool-augmented training corpus named MathFunc which encompasses over 30,000 samples and roughly 6,000 tools. Building on MathFunc, we develop SciAgent to retrieve, understand and, if necessary, tool scientific problem solving. Additionally, we craft a benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs’ abilities with tool assistance. Extensive experiments on SciToolBench confirm the effectiveness of SciAgent. Notably, SciAgent-Llama3-8B surpasses other LLMs with the comparable size by more than 8.0% in absolute accuracy. Furthermore, SciAgent-DeepMath-7B shows much superior performance than ChatGPT.", "bibtex": "@inproceedings{ma-etal-2024-sciagent,\n    title = \"{S}ci{A}gent: Tool-augmented Language Models for Scientific Reasoning\",\n    author = \"Ma, Yubo  and\n      Gou, Zhibin  and\n      Hao, Junheng  and\n      Xu, Ruochen  and\n      Wang, Shuohang  and\n      Pan, Liangming  and\n      Yang, Yujiu  and\n      Cao, Yixin  and\n      Sun, Aixin\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.880/\",\n    doi = \"10.18653/v1/2024.emnlp-main.880\",\n    pages = \"15701--15736\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/EMNLP 2024 Main SciAgent_ Tool-augmented Language Models for Scientific Reasoning.pdf", "retrieved_at": "2025-11-12T03:28:32.494233Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Yaolun Zhang", "Xiaogeng Liu", "Chaowei Xiao"], "affinity_score": 0.7663, "link": "https://openreview.net/pdf/34ab3426aaf31798b2df911672d4e1e4643a631d.pdf", "abstract": "Large Language Models (LLMs) have demonstrated the ability to solve a wide range of practical tasks within multi-agent systems. However, existing human-designed multi-agent frameworks are typically limited to a small set of pre-defined scenarios, while current automated design methods suffer from several limitations, such as the lack of tool integration, dependence on external training data, and rigid communication structures. In this paper, we propose \\textbf{MetaAgent}, a  \\textbf{finite state machine} based framework that can automatically generate a multi-agent system. Given a task description, MetaAgent will design a multi-agent system and polish it through an optimization algorithm. When the multi-agent system is deployed, the finite state machine will control the agent's actions and the state transitions. To evaluate our framework, we conduct experiments on both text-based tasks and practical tasks. The results indicate that the generated multi-agent system surpasses other auto-designed methods and can achieve a comparable performance with the human-designed multi-agent system, which is optimized for those specific tasks.", "bibtex": "@inproceedings{\nzhang2025metaagent,\ntitle={MetaAgent: Automatically Constructing Multi-Agent Systems Based on Finite State Machines},\nauthor={Yaolun Zhang and Xiaogeng Liu and Chaowei Xiao},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=vOxaD3hhPt}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ICML 2025 Poster MetaAgent_ Automatically Constructing Multi-Agent Systems Based on Finite State Machines.pdf", "retrieved_at": "2025-11-12T03:28:32.494249Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Spyridon Mouselinos", "Henryk Michalewski", "Mateusz Malinowski"], "affinity_score": 0.7631, "link": "https://aclanthology.org/2024.findings-emnlp.360/", "abstract": "Large Language Models (LLMs) demonstrate ever-increasing abilities in mathematical and algorithmic tasks, yet their geometric reasoning skills are underexplored. We investigate LLMs’ abilities in constructive geometric problem-solving, – one of the most fundamental steps in developing human mathematical reasoning, revealing notable challenges in this domain. LLMs exhibit biases in variable names, struggle with 2D spatial relationships and planning, and hallucinate object placements. To this end, we introduce a framework that enhances LLMs’ reasoning potential through a multi-agent system conducting internal dialogue. This work underscores LLMs’ limitations in geometric reasoning and improves their capabilities through self-correction, collaboration, and diverse role specializations.", "bibtex": "@inproceedings{mouselinos-etal-2024-beyond,\n    title = \"Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large Language Models\",\n    author = \"Mouselinos, Spyridon  and\n      Michalewski, Henryk  and\n      Malinowski, Mateusz\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.360/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.360\",\n    pages = \"6192--6222\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/EMNLP 2024 Findings Beyond Lines and Circles_ Unveiling the Geometric Reasoning Gap in Large Language Models.pdf", "retrieved_at": "2025-11-12T03:30:25.876163Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Multi-agent Architecture Search via Agentic Supernet", "venue": "ICML 2025 Oral", "year": "2025", "authors": ["Guibin Zhang", "Luyang Niu", "Junfeng Fang", "Kun Wang", "LEI BAI", "Xiang Wang"], "affinity_score": 0.7605, "link": "https://openreview.net/pdf/46a781e93da44fdacc085588e4eeb8edc5f20439.pdf", "abstract": "Large Language Model (LLM)-empowered multi-agent systems extend the cognitive boundaries of individual agents through disciplined collaboration and interaction, while constructing these systems often requires labor-intensive manual designs. Despite the availability of methods to automate the design of agentic workflows, they typically seek to identify a static, complex, one-size-fits-all system, which, however, fails to dynamically allocate inference resources based on the difficulty and domain of each query. To address this challenge, we shift away from the pursuit of a monolithic agentic system, instead optimizing the \\textbf{agentic supernet}, a probabilistic and continuous distribution of agentic architectures. We introduce \\textbf{MaAS}, an automated framework that samples query-dependent agentic systems from the supernet, delivering high-quality solutions and tailored resource allocation (\\textit{e.g.}, LLM calls, tool calls, token cost). Comprehensive evaluation across six benchmarks demonstrates that MaAS \\textbf{(I)} requires only $6\\sim45\\%$ of the inference costs of existing handcrafted or automated multi-agent systems, \\textbf{(II)} surpasses them by $0.54\\%\\sim11.82\\%$, and \\textbf{(III)} enjoys superior cross-dataset and cross-LLM-backbone transferability.", "bibtex": "@inproceedings{\nzhang2025multiagent,\ntitle={Multi-agent Architecture Search via Agentic Supernet},\nauthor={Guibin Zhang and Luyang Niu and Junfeng Fang and Kun Wang and LEI BAI and Xiang Wang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=imcyVlzpXh}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ICML 2025 Oral Multi-agent Architecture Search via Agentic Supernet.pdf", "retrieved_at": "2025-11-12T03:30:25.876190Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "MultiAgentBench : Evaluating the Collaboration and Competition of LLM agents", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Kunlun Zhu", "Hongyi Du", "Zhaochen Hong", "Xiaocheng Yang", "Shuyi Guo", "Daisy Zhe Wang", "Zhenhailong Wang", "Cheng Qian", "Robert Tang", "Heng Ji", "Jiaxuan You"], "affinity_score": 0.7572, "link": "https://aclanthology.org/2025.acl-long.421/", "abstract": "Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents; yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition. In this paper, we introduce MultiAgentBench, a comprehensive benchmark designed to evaluate LLM-based multi-agent systems across diverse, interactive scenarios. Our framework measures not only task completion but also the quality of collaboration and competition using novel, milestone-based key performance indicators. Moreover, we evaluate various coordination protocols (including star, chain, tree, and graph topologies) and innovative strategies such as group discussion and cognitive planning. Notably, cognitive planning improves milestone achievement rates by 3%. Code and dataset will be made publicly available. Code and datasets are publicavailable at https://github.com/ulab-uiuc/MARBLE", "bibtex": "@inproceedings{zhu-etal-2025-multiagentbench,\n    title = \"{M}ulti{A}gent{B}ench : Evaluating the Collaboration and Competition of {LLM} agents\",\n    author = \"Zhu, Kunlun  and\n      Du, Hongyi  and\n      Hong, Zhaochen  and\n      Yang, Xiaocheng  and\n      Guo, Shuyi  and\n      Wang, Zhe  and\n      Wang, Zhenhailong  and\n      Qian, Cheng  and\n      Tang, Robert  and\n      Ji, Heng  and\n      You, Jiaxuan\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.421/\",\n    doi = \"10.18653/v1/2025.acl-long.421\",\n    pages = \"8580--8622\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ACL 2025 Long MultiAgentBench _ Evaluating the Collaboration and Competition of LLM agents.pdf", "retrieved_at": "2025-11-12T03:30:25.876199Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "LeanAgent: Lifelong Learning for Formal Theorem Proving", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Adarsh Kumarappan", "Mo Tiwari", "Peiyang Song", "Robert Joseph George", "Chaowei Xiao", "Anima Anandkumar"], "affinity_score": 0.7502, "link": "https://openreview.net/pdf/c4bbf8256507953aff546765903d08e3fe6d16a4.pdf", "abstract": "Large Language Models (LLMs) have been successful in mathematical reasoning tasks such as formal theorem proving when integrated with interactive proof assistants like Lean. Existing approaches involve training or fine-tuning an LLM on a specific dataset to perform well on particular domains, such as undergraduate-level mathematics. These methods struggle with generalizability to advanced mathematics. A fundamental limitation is that these approaches operate on static domains, failing to capture how mathematicians often work across multiple domains and projects simultaneously or cyclically. We present LeanAgent, a novel lifelong learning framework for formal theorem proving that continuously generalizes to and improves on ever-expanding mathematical knowledge without forgetting previously learned knowledge. LeanAgent introduces several key innovations, including a curriculum learning strategy that optimizes the learning trajectory in terms of mathematical difficulty, a dynamic database for efficient management of evolving mathematical knowledge, and progressive training to balance stability and plasticity. LeanAgent successfully generates formal proofs for 155 theorems across 23 diverse Lean repositories where formal proofs were previously missing, many from advanced mathematics. It performs significantly better than the static LLM baseline, proving challenging theorems in domains like abstract algebra and algebraic topology while showcasing a clear progression of learning from basic concepts to advanced topics. In addition, we analyze LeanAgent's superior performance on key lifelong learning metrics. LeanAgent achieves exceptional scores in stability and backward transfer, where learning new tasks improves performance on previously learned tasks. This emphasizes LeanAgent's continuous generalizability and improvement, explaining its superior theorem-proving performance.", "bibtex": "@inproceedings{\nkumarappan2025leanagent,\ntitle={LeanAgent: Lifelong Learning for Formal Theorem Proving},\nauthor={Adarsh Kumarappan and Mo Tiwari and Peiyang Song and Robert Joseph George and Chaowei Xiao and Anima Anandkumar},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=Uo4EHT4ZZ8}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ICLR 2025 Poster LeanAgent_ Lifelong Learning for Formal Theorem Proving.pdf", "retrieved_at": "2025-11-12T03:30:25.876205Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "ACT: Knowledgeable Agents to Design and Perform Complex Tasks", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Makoto Nakatsuji", "Shuhei Tateishi", "Yasuhiro Fujiwara", "Ayaka Matsumoto", "Narichika Nomoto", "Yoshihide Kato"], "affinity_score": 0.7502, "link": "https://aclanthology.org/2025.acl-long.823/", "abstract": "Large language models enhance collaborative task execution in multi-agent systems. Current studies break complex task into manageable tasks, but agents lack understanding of the overall task and how others approach their tasks, hindering synergy and integration.We propose a method called knowledgeable A gents to design and perform C omplex T asks (ACT), where: (1) Agents independently manage their knowledge and tasks while collaboratively design the complex task into a more comprehensible form. In parallel, each agent also acquires knowledge of others, defined as a structured description of how other agents approach their tasks based on the agent’s own task resolution. (2) Each agent updates its knowledge and refines its task through interactions with others. By referencing structured knowledge, they effectively integrate their tasks to collaboratively solve the complex task.Three evaluations including creative writing and tool utilization, show that ACT accurately outperforms existing methods in solving complex tasks.", "bibtex": "@inproceedings{nakatsuji-etal-2025-act,\n    title = \"{ACT}: Knowledgeable Agents to Design and Perform Complex Tasks\",\n    author = \"Nakatsuji, Makoto  and\n      Tateishi, Shuhei  and\n      Fujiwara, Yasuhiro  and\n      Matsumoto, Ayaka  and\n      Nomoto, Narichika  and\n      Sato, Yoshihide\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.823/\",\n    doi = \"10.18653/v1/2025.acl-long.823\",\n    pages = \"16831--16861\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ACL 2025 Long ACT_ Knowledgeable Agents to Design and Perform Complex Tasks.pdf", "retrieved_at": "2025-11-12T03:30:25.876211Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Haochun Wang", "Sendong Zhao", "Jingbo Wang", "Zewen Qiang", "Bing Qin (秦兵)", "Ting Liu (刘挺)"], "affinity_score": 0.7476, "link": "https://aclanthology.org/2025.acl-long.1037/", "abstract": "Multi-agent collaboration has emerged as a pivotal paradigm for addressing complex, distributed tasks in large language model (LLM)-driven applications. While prior research has focused on high-level architectural frameworks, the granular mechanisms governing agents—critical to performance and scalability—remain underexplored. This study systematically investigates four dimensions of collaboration strategies: (1) agent governance, (2) participation control, (3) interaction dynamics, and (4) dialogue history management. Through rigorous experimentation under two context-dependent scenarios—Distributed Evidence Integration (DEI) and Structured Evidence Synthesis (SES)—we quantify the impact of these strategies on both task accuracy and computational efficiency. Our findings reveal that centralized governance, instructor-led participation, ordered interaction patterns, and instructor-curated context summarization collectively optimize the trade-off between decision quality and resource utilization with the support of the proposed Token-Accuracy Ratio (TAR). This work establishes a foundation for designing adaptive, scalable multi-agent systems, shifting the focus from structural novelty to strategic interaction mechanics.", "bibtex": "@inproceedings{wang-etal-2025-beyond,\n    title = \"Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems\",\n    author = \"Wang, Haochun  and\n      Zhao, Sendong  and\n      Wang, Jingbo  and\n      Qiang, Zewen  and\n      Qin, Bing  and\n      Liu, Ting\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1037/\",\n    doi = \"10.18653/v1/2025.acl-long.1037\",\n    pages = \"21361--21375\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ACL 2025 Long Beyond Frameworks_ Unpacking Collaboration Strategies in Multi-Agent Systems.pdf", "retrieved_at": "2025-11-12T03:30:25.876216Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Yibo Yan", "Jiamin Su", "Jianxiang He", "Fangteng Fu", "Xu Zheng", "Yuanhuiyi Lyu", "Kun Wang", "Shen Wang", "Qingsong Wen", "Xuming Hu"], "affinity_score": 0.747, "link": "https://aclanthology.org/2025.findings-acl.614/", "abstract": "Mathematical reasoning, a core aspect of human cognition, is vital across many domains, from educational problem-solving to scientific advancements. As artificial general intelligence (AGI) progresses, integrating large language models (LLMs) with mathematical reasoning tasks is becoming increasingly significant. This survey provides\nthe first comprehensive analysis of mathematical reasoning in the era of multimodal large language models (MLLMs)\n. We review over 200 studies published since 2021, and examine the state-of-the-art developments in Math-LLMs, with a focus on multimodal settings. We categorize the field into three dimensions: benchmarks, methodologies, and challenges. In particular, we explore multimodal mathematical reasoning pipeline, as well as the role of (M)LLMs and the associated methodologies. Finally, we identify five major challenges hindering the realization of AGI in this domain, offering insights into the future direction for enhancing multimodal reasoning capabilities. This survey serves as a critical resource for the research community in advancing the capabilities of LLMs to tackle complex multimodal reasoning tasks.", "bibtex": "@inproceedings{yan-etal-2025-survey,\n    title = \"A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method {\\&} Challenges\",\n    author = \"Yan, Yibo  and\n      Su, Jiamin  and\n      He, Jianxiang  and\n      Fu, Fangteng  and\n      Zheng, Xu  and\n      Lyu, Yuanhuiyi  and\n      Wang, Kun  and\n      Wang, Shen  and\n      Wen, Qingsong  and\n      Hu, Xuming\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.614/\",\n    doi = \"10.18653/v1/2025.findings-acl.614\",\n    pages = \"11798--11827\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ACL 2025 Findings A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model_ Benchmark, Method & Challenges.pdf", "retrieved_at": "2025-11-12T03:30:25.876220Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "LLM-Based Explicit Models of Opponents for Multi-Agent Games", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["XiaoPeng Yu", "Wanpeng Zhang", "Zongqing Lu"], "affinity_score": 0.7418, "link": "https://aclanthology.org/2025.naacl-long.41/", "abstract": "In multi-agent scenarios, the ability to anticipate and respond to opponents is essential, particularly in environments involving adversarial and collaborative interactions. In this paper, we introduce Explicit Models of Opponents (EMO) based on Large Language Models (LLMs), enabling agents to better predict and adapt to diverse, dynamic multi-agent interactions. Unlike traditional methods that often simplify multi-agent interactions using a single opponent model, EMO constructs an individual model for each opponent and aligns these models working in synergy through a bi-level feedback-refinement framework. We test EMO alongside several reasoning methods in multi-player deduction games, where agents must infer hidden information about their opponents. The results show that EMO significantly enhances agents’ decision-making, outperforming traditional single-model approaches. Our findings demonstrate that EMO can be a powerful tool for enhancing LLM-based agents in complex multi-agent systems.", "bibtex": "@inproceedings{yu-etal-2025-llm,\n    title = \"{LLM}-Based Explicit Models of Opponents for Multi-Agent Games\",\n    author = \"Yu, XiaoPeng  and\n      Zhang, Wanpeng  and\n      Lu, Zongqing\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.41/\",\n    doi = \"10.18653/v1/2025.naacl-long.41\",\n    pages = \"892--911\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/NAACL 2025 Long LLM-Based Explicit Models of Opponents for Multi-Agent Games.pdf", "retrieved_at": "2025-11-12T03:30:25.876224Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Learning to Use Tools via Cooperative and Interactive Agents", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Zhengliang Shi", "Shen Gao", "Xiuyi Chen", "Yue Feng", "Lingyong Yan", "Haibo Shi", "Dawei Yin", "Pengjie Ren", "Suzan Verberne", "Zhaochun Ren"], "affinity_score": 0.741, "link": "https://aclanthology.org/2024.findings-emnlp.624/", "abstract": "Tool learning empowers large language models (LLMs) as agents to use external tools and extend their utility. Existing methods employ one single LLM-based agent to iteratively select and execute tools, thereafter incorporating execution results into the next action prediction. Despite their progress, these methods suffer from performance degradation when addressing practical tasks due to: (1) the pre-defined pipeline with restricted flexibility to calibrate incorrect actions, and (2) the struggle to adapt a general LLM-based agent to perform a variety of specialized actions. To mitigate these problems, we propose ConAgents, a Cooperative and interactive Agents framework, which coordinates three specialized agents for tool selection, tool execution, and action calibration separately. ConAgents introduces two communication protocols to enable the flexible cooperation of agents. To effectively generalize the ConAgents into open-source models, we also propose specialized action distillation, enhancing their ability to perform specialized actions in our framework. Our extensive experiments on three datasets show that the LLMs, when equipped with the ConAgents, outperform baselines with substantial improvement (i.e., up to 14% higher success rate).", "bibtex": "@inproceedings{shi-etal-2024-learning,\n    title = \"Learning to Use Tools via Cooperative and Interactive Agents\",\n    author = \"Shi, Zhengliang  and\n      Gao, Shen  and\n      Chen, Xiuyi  and\n      Feng, Yue  and\n      Yan, Lingyong  and\n      Shi, Haibo  and\n      Yin, Dawei  and\n      Ren, Pengjie  and\n      Verberne, Suzan  and\n      Ren, Zhaochun\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.624/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.624\",\n    pages = \"10642--10657\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/EMNLP 2024 Findings Learning to Use Tools via Cooperative and Interactive Agents.pdf", "retrieved_at": "2025-11-12T03:30:26.834276Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Fan Liu", "Zhe-Rui Yang", "Cancheng Liu", "Tianrui SONG", "Xiaofeng Gao", "Hao Liu"], "affinity_score": 0.7392, "link": "https://openreview.net/pdf/e01a39be0de98c2f808394f7affa2bfb004c68a5.pdf", "abstract": "Mathematical modeling is a cornerstone of scientific discovery and engineering practice, enabling the translation of real-world problems into formal systems across domains such as physics, biology, and economics. Unlike mathematical reasoning, which assumes a predefined formulation, modeling requires open-ended problem analysis, abstraction, and principled formalization. While Large Language Models (LLMs) have shown strong reasoning capabilities, they fall short in rigorous model construction, limiting their utility in real-world problem-solving. To this end, we formalize the task of LLM-powered real-world mathematical modeling, where agents must analyze problems, construct domain-appropriate formulations, and generate complete end-to-end solutions.We introduce MM-Bench, a curated benchmark of 111 problems from the Mathematical Contest in Modeling (MCM/ICM), spanning the years 2000 to 2025 and across ten diverse domains such as physics, biology, and economics.  To tackle this task, we propose MM-Agent, an expert-inspired framework that decomposes mathematical modeling into four stages: open-ended problem analysis, structured model formulation, computational problem solving, and report generation.Experiments on MM-Bench show that MM-Agent significantly outperforms baseline agents, achieving an 11.88\\% improvement over human expert solutions while requiring only 15 minutes and \\$0.88 per task using GPT-4o. Furthermore, under official MCM/ICM protocols, MM-Agent assisted two undergraduate teams in winning the Finalist Award (\\textbf{top 2.0\\% among 27,456 teams}) in MCM/ICM 2025, demonstrating its practical effectiveness as a modeling copilot.", "bibtex": "@inproceedings{\nliu2025mmagent,\ntitle={{MM}-Agent: {LLM} as Agents for Real-world Mathematical Modeling Problem},\nauthor={Fan Liu and Zhe-Rui Yang and Cancheng Liu and Tianrui SONG and Xiaofeng Gao and Hao Liu},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=o8n5oNDsiq}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/NeurIPS 2025 Poster MM-Agent_ LLM as Agents for Real-world Mathematical Modeling Problem.pdf", "retrieved_at": "2025-11-12T03:30:26.834305Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Assessing and Verifying Task Utility in LLM-Powered Applications", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Negar Arabzadeh", "Siqing Huo", "Nikhil Mehta", "Qingyun Wu", "Chi Wang", "Ahmed Hassan", "Charles L. A. Clarke", "Julia Kiseleva"], "affinity_score": 0.7371, "link": "https://aclanthology.org/2024.emnlp-main.1219/", "abstract": "The rapid development of Large Language Models (LLMs) has led to a surge in applications that facilitate collaboration among multiple agents, assisting humans in their daily tasks. However, a significant gap remains in assessing to what extent LLM-powered applications genuinely enhance user experience and task execution efficiency. This highlights the need to verify utility of LLM-powered applications, particularly by ensuring alignment between the application’s functionality and end-user needs. We introduce AgentEval, a novel framework designed to simplify the utility verification process by automatically proposing a set of criteria tailored to the unique purpose of any given application. This allows for a comprehensive assessment, quantifying the utility of an application against the suggested criteria. We present a comprehensive analysis of the effectiveness and robustness of AgentEval for two open source datasets including Math Problem solving and ALFWorld House-hold related tasks. For reproducibility purposes, we make the data, code and all the logs publicly available at https://github.com/Narabzad/AgentEval", "bibtex": "@inproceedings{arabzadeh-etal-2024-assessing,\n    title = \"Assessing and Verifying Task Utility in {LLM}-Powered Applications\",\n    author = \"Arabzadeh, Negar  and\n      Huo, Siqing  and\n      Mehta, Nikhil  and\n      Wu, Qingyun  and\n      Wang, Chi  and\n      Awadallah, Ahmed Hassan  and\n      Clarke, Charles L. A.  and\n      Kiseleva, Julia\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.1219/\",\n    doi = \"10.18653/v1/2024.emnlp-main.1219\",\n    pages = \"21868--21888\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/EMNLP 2024 Main Assessing and Verifying Task Utility in LLM-Powered Applications.pdf", "retrieved_at": "2025-11-12T03:30:26.834311Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Tools Fail: Detecting Silent Errors in Faulty Tools", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Jimin Sun", "So Yeon Min", "Yingshan Chang", "Yonatan Bisk"], "affinity_score": 0.7365, "link": "https://aclanthology.org/2024.emnlp-main.790/", "abstract": "Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not in their weights, to perform tasks on the web, and even to control robots. However, most ontologies and surveys of tool-use have assumed the core challenge for LLMs is choosing the tool. Instead, we introduce a framework for tools more broadly which guides us to explore a model’s ability to detect “silent” tool errors, and reflect on how to plan. This more directly aligns with the increasingly popular use of models as tools. We provide an initial approach to failure recovery with promising results both on a controlled calculator setting and embodied agent planning.", "bibtex": "@inproceedings{sun-etal-2024-tools,\n    title = \"Tools Fail: Detecting Silent Errors in Faulty Tools\",\n    author = \"Sun, Jimin  and\n      Min, So Yeon  and\n      Chang, Yingshan  and\n      Bisk, Yonatan\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.790/\",\n    doi = \"10.18653/v1/2024.emnlp-main.790\",\n    pages = \"14272--14289\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/EMNLP 2024 Main Tools Fail_ Detecting Silent Errors in Faulty Tools.pdf", "retrieved_at": "2025-11-12T03:30:26.834316Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Improving Multi-Agent Debate with Sparse Communication Topology", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Yunxuan Li", "Yibing Du", "Jiageng Zhang", "Le Hou", "Peter Grabowski", "Yeqing Li", "Eugene Ie"], "affinity_score": 0.7351, "link": "https://aclanthology.org/2024.findings-emnlp.427/", "abstract": "Multi-agent debate has proven effective in improving large language models quality for reasoning and factuality tasks. While various role-playing strategies in multi-agent debates have been explored, in terms of the communication among agents, existing approaches adopt a brute force algorithm – each agent can communicate with all other agents. In this paper, we systematically investigate the effect of communication connectivity in multi-agent systems. Our experiments on GPT and Mistral models reveal that multi-agent debates leveraging sparse communication topology can achieve comparable or superior performance while significantly reducing computational costs. Furthermore, we extend the multi-agent debate framework to multi-modal reasoning and alignment labeling tasks, showcasing its broad applicability and effectiveness. Our findings underscore the importance of communication connectivity on enhancing the efficiency and effectiveness of the “society of minds” approach.", "bibtex": "@inproceedings{li-etal-2024-improving-multi,\n    title = \"Improving Multi-Agent Debate with Sparse Communication Topology\",\n    author = \"Li, Yunxuan  and\n      Du, Yibing  and\n      Zhang, Jiageng  and\n      Hou, Le  and\n      Grabowski, Peter  and\n      Li, Yeqing  and\n      Ie, Eugene\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.427/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.427\",\n    pages = \"7281--7294\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/EMNLP 2024 Findings Improving Multi-Agent Debate with Sparse Communication Topology.pdf", "retrieved_at": "2025-11-12T03:30:26.834320Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Agent-Oriented Planning in Multi-Agent Systems", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Ao Li", "Yuexiang Xie", "Songze Li", "Fugee Tsung", "Bolin Ding", "Yaliang Li"], "affinity_score": 0.7348, "link": "https://openreview.net/pdf/82bac503b8ff6352c48f82986a318160a941b2a4.pdf", "abstract": "Through the collaboration of multiple LLM-empowered agents possessing diverse expertise and tools, multi-agent systems achieve impressive progress in solving real-world problems. Given the user queries, the meta-agents, serving as the brain within multi-agent systems, are required to decompose the queries into multiple sub-tasks that can be allocated to suitable agents capable of solving them, so-called agent-oriented planning. In this study, we identify three critical design principles of agent-oriented planning, including solvability, completeness, and non-redundancy, to ensure that each sub-task can be effectively resolved, resulting in satisfactory responses to user queries. These principles further inspire us to propose AOP, a novel framework for agent-oriented planning in multi-agent systems, leveraging a fast task decomposition and allocation process followed by an effective and efficient evaluation via a reward model. According to the evaluation results, the meta-agent is also responsible for promptly making necessary adjustments to sub-tasks and scheduling. Besides, we integrate a feedback loop into AOP to further enhance the effectiveness and robustness of such a problem-solving process. Extensive experiments demonstrate the advancement of AOP in solving real-world problems compared to both single-agent systems and existing planning strategies for multi-agent systems. The source code is available at https://github.com/lalaliat/Agent-Oriented-Planning", "bibtex": "@inproceedings{\nli2025agentoriented,\ntitle={Agent-Oriented Planning in Multi-Agent Systems},\nauthor={Ao Li and Yuexiang Xie and Songze Li and Fugee Tsung and Bolin Ding and Yaliang Li},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=EqcLAU6gyU}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ICLR 2025 Poster Agent-Oriented Planning in Multi-Agent Systems.pdf", "retrieved_at": "2025-11-12T03:30:26.834325Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Efficient Multi-Agent Collaboration with Tool Use for Online Planning in Complex Table Question Answering", "venue": "NAACL 2025 Findings", "year": "2025", "authors": ["Wei Zhou", "Mohsen Mesgar", "Annemarie Friedrich", "Heike Adel"], "affinity_score": 0.7336, "link": "https://aclanthology.org/2025.findings-naacl.54/", "abstract": "Complex table question answering (TQA) aims to answer questions that require complex reasoning, such as multi-step or multi-category reasoning, over data represented in tabular form. Previous approaches demonstrate notable performance by leveraging either closed-source large language models (LLMs) or fine-tuned open-weight LLMs. However, fine-tuning LLMs requires high-quality training data, which is costly to obtain. The use of closed-source LLMs poses accessibility challenges and leads to reproducibility issues. In this paper, we propose Multi Agent Collaboration with Tool use (MACT), a framework that requires neither fine-tuning nor closed-source models. In MACT, a planning agent and a coding agent that also make use of tools collaborate for TQA. MACT outperforms previous SoTA systems on three out of four benchmarks and performs comparably to the larger and more expensive closed-source model GPT-4 on two benchmarks, even when using only open-weight models without any fine-tuning. Our extensive analyses prove the effectiveness of MACT’s multi-agent collaboration in TQA. We release our code publicly.", "bibtex": "@inproceedings{zhou-etal-2025-efficient,\n    title = \"Efficient Multi-Agent Collaboration with Tool Use for Online Planning in Complex Table Question Answering\",\n    author = \"Zhou, Wei  and\n      Mesgar, Mohsen  and\n      Friedrich, Annemarie  and\n      Adel, Heike\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Findings of the Association for Computational Linguistics: NAACL 2025\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-naacl.54/\",\n    doi = \"10.18653/v1/2025.findings-naacl.54\",\n    pages = \"945--968\",\n    ISBN = \"979-8-89176-195-7\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/NAACL 2025 Findings Efficient Multi-Agent Collaboration with Tool Use for Online Planning in Complex Table Question Answering.pdf", "retrieved_at": "2025-11-12T03:30:26.834330Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool Usage", "venue": "ICLR 2025 Spotlight", "year": "2025", "authors": ["Zhi Gao", "Bofei Zhang", "Pengxiang Li", "Xiaojian Ma", "Tao Yuan", "Yue Fan", "Yuwei Wu", "Yunde Jia", "Song-Chun Zhu", "Qing Li"], "affinity_score": 0.7316, "link": "https://openreview.net/pdf/5023fe68ab67d9e72385045030a9d62d49bf747d.pdf", "abstract": "The advancement of large language models (LLMs) prompts the development of multi-modal agents, which are used as a controller to call external tools, providing a feasible way to solve practical tasks. In this paper, we propose a multi-modal agent tuning method that automatically generates multi-modal tool-usage data and tunes a vision-language model (VLM) as the controller for powerful tool-usage reasoning. To preserve the data quality, we prompt the GPT-4o mini model to generate queries, files, and trajectories, followed by query-file and trajectory verifiers. Based on the data synthesis pipeline, we collect the MM-Traj dataset that contains 20K tasks with trajectories of tool usage. Then, we develop the T3-Agent via Trajectory Tuning on VLMs for Tool usage using MM-Traj. Evaluations on the GTA and GAIA benchmarks show that the T3-Agent consistently achieves improvements on two popular VLMs: MiniCPM-V-8.5B and Qwen2-VL-7B, which outperforms untrained VLMs by 20%, showing the effectiveness of the proposed data synthesis pipeline, leading to high-quality data for tool-usage capabilities.", "bibtex": "@inproceedings{\ngao2025multimodal,\ntitle={Multi-modal Agent Tuning: Building a {VLM}-Driven Agent for Efficient Tool Usage},\nauthor={Zhi Gao and Bofei Zhang and Pengxiang Li and Xiaojian Ma and Tao Yuan and Yue Fan and Yuwei Wu and Yunde Jia and Song-Chun Zhu and Qing Li},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=0bmGL4q7vJ}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ICLR 2025 Spotlight Multi-modal Agent Tuning_ Building a VLM-Driven Agent for Efficient Tool Usage.pdf", "retrieved_at": "2025-11-12T03:30:26.834335Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "CogMath: Assessing LLMs' Authentic Mathematical Ability from a Human Cognitive Perspective", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Jiayu Liu", "Zhenya Huang", "Wei Dai", "Cheng Cheng", "Jinze Wu", "Jing Sha", "Song Li", "Qi Liu", "Shijin Wang", "Enhong Chen"], "affinity_score": 0.7302, "link": "https://openreview.net/pdf/7255cc5f87c2df39cc1873f4f82d8033ca416a7e.pdf", "abstract": "Although large language models (LLMs) show promise in solving complex mathematical tasks, existing evaluation paradigms rely solely on a coarse measure of overall answer accuracy, which are insufficient for assessing their authentic capabilities. In this paper, we propose \\textbf{CogMath}, which comprehensively assesses LLMs' mathematical abilities through the lens of human cognition. Specifically, inspired by psychological theories, CogMath formalizes human reasoning process into 3 stages: \\emph{problem comprehension}, \\emph{problem solving}, and \\emph{solution summarization}. Within these stages, we investigate perspectives such as numerical calculation, knowledge, and counterfactuals, and design a total of 9 fine-grained evaluation dimensions. In each dimension, we develop an ``\\emph{Inquiry}-\\emph{Judge}-\\emph{Reference}'' multi-agent system to generate inquiries that assess LLMs' mastery from this dimension. An LLM is considered to truly master a problem only when excelling in all inquiries from the 9 dimensions. By applying CogMath on three benchmarks, we reveal that the mathematical capabilities of 7 mainstream LLMs are overestimated by 30\\%-40\\%. Moreover, we locate their strengths and weaknesses across specific stages/dimensions, offering in-depth insights to further enhance their reasoning abilities.", "bibtex": "@inproceedings{\nliu2025cogmath,\ntitle={CogMath: Assessing {LLM}s' Authentic Mathematical Ability from a Human Cognitive Perspective},\nauthor={Jiayu Liu and Zhenya Huang and Wei Dai and Cheng Cheng and Jinze Wu and Jing Sha and Song Li and Qi Liu and Shijin Wang and Enhong Chen},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=mqY0X3Yoy9}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ICML 2025 Poster CogMath_ Assessing LLMs' Authentic Mathematical Ability from a Human Cognitive Perspective.pdf", "retrieved_at": "2025-11-12T03:30:26.834341Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Weizhou Shen", "Chenliang Li", "Hongzhan Chen", "Ming Yan", "Xiaojun Quan", "Hehong Chen", "Ji Zhang", "Fei Huang"], "affinity_score": 0.7292, "link": "https://aclanthology.org/2024.emnlp-main.929/", "abstract": "Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete various tasks in a self-directed fashion. The challenge of tool use demands that LLMs not only understand user queries and generate answers accurately but also excel in task planning, tool invocation, and result summarization. While traditional works focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models. To overcome these challenges, we propose a novel approach that decomposes the aforementioned capabilities into a planner, caller, and summarizer. Each component is implemented by a single LLM that focuses on a specific capability and collaborates with others to accomplish the task. This modular framework facilitates individual updates and the potential use of smaller LLMs for building each capability. To effectively train this framework, we introduce a two-stage training paradigm. First, we fine-tune a backbone LLM on the entire dataset without discriminating sub-tasks, providing the model with a comprehensive understanding of the task. Second, the fine-tuned LLM is used to instantiate the planner, caller, and summarizer respectively, which are continually fine-tuned on respective sub-tasks. Evaluation across various tool-use benchmarks illustrates that our proposed multi-LLM framework surpasses the traditional single-LLM approach, highlighting its efficacy and advantages in tool learning.", "bibtex": "@inproceedings{shen-etal-2024-small,\n    title = \"Small {LLM}s Are Weak Tool Learners: A Multi-{LLM} Agent\",\n    author = \"Shen, Weizhou  and\n      Li, Chenliang  and\n      Chen, Hongzhan  and\n      Yan, Ming  and\n      Quan, Xiaojun  and\n      Chen, Hehong  and\n      Zhang, Ji  and\n      Huang, Fei\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.929/\",\n    doi = \"10.18653/v1/2024.emnlp-main.929\",\n    pages = \"16658--16680\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/EMNLP 2024 Main Small LLMs Are Weak Tool Learners_ A Multi-LLM Agent.pdf", "retrieved_at": "2025-11-12T03:30:26.834346Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Iterative Tool Usage Exploration for Multimodal Agents via Step-wise Preference Tuning", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Pengxiang Li", "Zhi Gao", "Bofei Zhang", "Yapeng Mi", "Xiaojian Ma", "Chenrui Shi", "Tao Yuan", "Yuwei Wu", "Yunde Jia", "Song-Chun Zhu", "Qing Li"], "affinity_score": 0.7272, "link": "https://openreview.net/pdf/a3ae43bcdfe712b2361e4ab5254bbce2bcc0dd95.pdf", "abstract": "Multimodal agents, which integrate a controller (e.g., a vision language model) with external tools, have demonstrated remarkable capabilities in tackling complex multimodal tasks.\nExisting approaches for training these agents, both supervised fine-tuning and reinforcement learning, depend on extensive human-annotated task-answer pairs and tool trajectories.\nHowever, for complex multimodal tasks, such annotations are prohibitively expensive or impractical to obtain.\nIn this paper, we propose an iterative tool usage exploration method for multimodal agents without any pre-collected data, namely SPORT, via step-wise preference optimization to refine the trajectories of tool usage. Our method enables multimodal agents to autonomously discover effective tool usage strategies through self-exploration and optimization, eliminating the bottleneck of human annotation.\nSPORT has four iterative components: task synthesis, step sampling, step verification, and preference tuning.\nWe first synthesize multimodal tasks using language models. \nThen, we introduce a novel trajectory exploration scheme, where step sampling and step verification are executed alternately to solve synthesized tasks.\nIn step sampling, the agent tries different tools and obtains corresponding results. \nIn step verification, we employ a verifier to provide AI feedback to construct step-wise preference data. \nThe data is subsequently used to update the controller for tool usage through preference tuning, producing a SPORT agent.\nBy interacting with real environments, the SPORT agent gradually evolves into a more refined and capable system.\nEvaluation in the GTA and GAIA benchmarks shows that the SPORT agent achieves 6.41% and  3.64% improvements, underscoring the generalization and effectiveness introduced by our method.", "bibtex": "@inproceedings{\nli2025iterative,\ntitle={Iterative Tool Usage Exploration for Multimodal Agents via Step-wise Preference Tuning},\nauthor={Pengxiang Li and Zhi Gao and Bofei Zhang and Yapeng Mi and Xiaojian Ma and Chenrui Shi and Tao Yuan and Yuwei Wu and Yunde Jia and Song-Chun Zhu and Qing Li},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=yKUwkihcsi}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/NeurIPS 2025 Poster Iterative Tool Usage Exploration for Multimodal Agents via Step-wise Preference Tuning.pdf", "retrieved_at": "2025-11-12T03:30:27.838474Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "LLM Agents Making Agent Tools", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Georg Wölflein", "Dyke Ferber", "Daniel Truhn", "Ognjen Arandjelovic", "Jakob Nikolas Kather"], "affinity_score": 0.7266, "link": "https://aclanthology.org/2025.acl-long.1266/", "abstract": "Tool use has turned large language models (LLMs) into powerful agents that can perform complex multi-step tasks by dynamically utilising external software components. However, these tools must be implemented in advance by human developers, hindering the applicability of LLM agents in domains demanding large numbers of highly specialised tools, like in life sciences and medicine. Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose ToolMaker, an agentic framework that autonomously transforms papers with code into LLM-compatible tools. Given a GitHub URL and short task description, ToolMaker autonomously installs dependencies and generates code to perform the task, using a closed-loop self-correction mechanism for debugging. To evaluate our approach, we introduce a benchmark comprising 15 complex computational tasks spanning various domains with over 100 unit tests to assess correctness and robustness. Our method correctly implements 80% of the tasks, substantially outperforming current state-of-the-art software engineering agents. ToolMaker therefore is a step towards fully autonomous agent-based scientific workflows.", "bibtex": "@inproceedings{wolflein-etal-2025-llm,\n    title = \"{LLM} Agents Making Agent Tools\",\n    author = {W{\\\"o}lflein, Georg  and\n      Ferber, Dyke  and\n      Truhn, Daniel  and\n      Arandjelovic, Ognjen  and\n      Kather, Jakob Nikolas},\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1266/\",\n    doi = \"10.18653/v1/2025.acl-long.1266\",\n    pages = \"26092--26130\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ACL 2025 Long LLM Agents Making Agent Tools.pdf", "retrieved_at": "2025-11-12T03:30:27.838494Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "SMART: Self-Aware Agent for Tool Overuse Mitigation", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Cheng Qian", "Emre Can Acikgoz", "Hongru Wang", "Xiusi Chen", "Avirup Sil", "Dilek Hakkani-Tur", "Gokhan Tur", "Heng Ji"], "affinity_score": 0.7265, "link": "https://aclanthology.org/2025.findings-acl.239/", "abstract": "Current Large Language Model (LLM) agents demonstrate strong reasoning and tool use capabilities, but often lack self-awareness, failing to balance these approaches effectively. This imbalance leads to\nTool Overuse\n, where models unnecessarily rely on external tools for tasks solvable with parametric knowledge, increasing computational overhead. Inspired by human metacognition, we introduce\nSMART\n(Strategic Model-Aware Reasoning with Tools), a paradigm that enhances an agent’s self-awareness to optimize task handling and reduce tool overuse. To support this paradigm, we introduce\nSMART-ER\n, a dataset spanning three domains, where reasoning alternates between parametric knowledge and tool-dependent steps, with each step enriched by rationales explaining when tools are necessary. Through supervised training, we develop\nSMARTAgent\n, a family of models that dynamically balance parametric knowledge and tool use. Evaluations show that SMARTAgent reduces tool use by 24% while improving performance by over 37%, enabling 7B-scale models to match its 70B counterpart and GPT-4. Additionally, SMARTAgent generalizes to out-of-distribution test data like GSM8K and MINTQA, maintaining accuracy with just one-fifth the tool calls. These highlight the potential of strategic tool use to enhance reasoning, mitigate overuse, and bridge the gap between model size and performance, advancing intelligent and resource-efficient agent designs.", "bibtex": "@inproceedings{qian-etal-2025-smart,\n    title = \"{SMART}: Self-Aware Agent for Tool Overuse Mitigation\",\n    author = {Qian, Cheng  and\n      Acikgoz, Emre Can  and\n      Wang, Hongru  and\n      Chen, Xiusi  and\n      Sil, Avirup  and\n      Hakkani-T{\\\"u}r, Dilek  and\n      Tur, Gokhan  and\n      Ji, Heng},\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.239/\",\n    doi = \"10.18653/v1/2025.findings-acl.239\",\n    pages = \"4604--4621\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ACL 2025 Findings SMART_ Self-Aware Agent for Tool Overuse Mitigation.pdf", "retrieved_at": "2025-11-12T03:30:27.838500Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "An Evaluation Mechanism of LLM-based Agents on Manipulating APIs", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Bing Liu", "Zhou Jianxiang", "Dan Meng", "Haonan Lu"], "affinity_score": 0.7262, "link": "https://aclanthology.org/2024.findings-emnlp.267/", "abstract": "LLM-based agents can greatly extend the abilities of LLMs and thus attract sharply increased studies. An ambitious vision – serving users by manipulating massive API-based tools – has been proposed and explored. However, we find a widely accepted evaluation mechanism for generic agents is still missing. This work aims to fill this gap. We decompose tool use capability into seven aspects and form a thorough evaluation schema. In addition, we design and release an instruction dataset and a toolset – the two sides that the agents bridge between – following the principle of reflecting real-world challenges. Furthermore, we evaluate multiple generic agents. Our findings can inspire future research in improving LLM-based agents and rethink the philosophy of API design.", "bibtex": "@inproceedings{liu-etal-2024-evaluation-mechanism,\n    title = \"An Evaluation Mechanism of {LLM}-based Agents on Manipulating {API}s\",\n    author = \"Liu, Bing  and\n      Jianxiang, Zhou  and\n      Meng, Dan  and\n      Lu, Haonan\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.267/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.267\",\n    pages = \"4649--4662\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/EMNLP 2024 Findings An Evaluation Mechanism of LLM-based Agents on Manipulating APIs.pdf", "retrieved_at": "2025-11-12T03:30:27.838505Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence", "venue": "ICLR 2025 Spotlight", "year": "2025", "authors": ["Weize Chen", "Ziming You", "Ran Li", "yitong guan", "Chen Qian", "Chenyang Zhao", "Cheng Yang", "Ruobing Xie", "Zhiyuan Liu", "Maosong Sun"], "affinity_score": 0.7248, "link": "https://openreview.net/pdf/1006483e763807a740f78d0096898fc8d8a8424b.pdf", "abstract": "The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents. However, existing multi-agent frameworks often struggle with integrating diverse capable third-party agents due to reliance on agents defined within their own ecosystems. They also face challenges in simulating distributed environments, as most frameworks are limited to single-device setups. Furthermore, these frameworks often rely on hard-coded communication pipelines, limiting their adaptability to dynamic task requirements. Inspired by the concept of the Internet, we propose the Internet of Agents (IoA), a novel framework that addresses these limitations by providing a flexible and scalable platform for LLM-based multi-agent collaboration. IoA introduces an agent integration protocol, an instant-messaging-like architecture design, and dynamic mechanisms for agent teaming and conversation flow control. Through extensive experiments on general assistant tasks, embodied AI tasks, and retrieval-augmented generation benchmarks, we demonstrate that IoA consistently outperforms state-of-the-art baselines, showcasing its ability to facilitate effective collaboration among heterogeneous agents. IoA represents a step towards linking diverse agents in an Internet-like environment, where agents can seamlessly collaborate to achieve greater intelligence and capabilities. We will release our code to facilitate further research.", "bibtex": "@inproceedings{\nchen2025internet,\ntitle={Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence},\nauthor={Weize Chen and Ziming You and Ran Li and yitong guan and Chen Qian and Chenyang Zhao and Cheng Yang and Ruobing Xie and Zhiyuan Liu and Maosong Sun},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=o1Et3MogPw}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ICLR 2025 Spotlight Internet of Agents_ Weaving a Web of Heterogeneous Agents for Collaborative Intelligence.pdf", "retrieved_at": "2025-11-12T03:30:27.838509Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks", "venue": "ICML 2025 Spotlightposter", "year": "2025", "authors": ["Guibin Zhang", "Yanwei Yue", "Xiangguo Sun", "Guancheng Wan", "Miao Yu", "Junfeng Fang", "Kun Wang", "Tianlong Chen", "Dawei Cheng"], "affinity_score": 0.7229, "link": "https://openreview.net/pdf/ac2d69ee4852bf5e47910fa3e4da09a7322def18.pdf", "abstract": "Recent advancements in large language model (LLM)-based agents have demonstrated that collective intelligence can significantly surpass the capabilities of individual agents, primarily due to well-crafted inter-agent communication topologies. Despite the diverse and high-performing designs available, practitioners often face confusion when selecting the most effective pipeline for their specific task: \\textit{Which topology is the best choice for my task, avoiding unnecessary communication token overhead while ensuring high-quality solution?} In response to this dilemma, we introduce G-Designer, an adaptive, efficient, and robust solution for multi-agent deployment, which dynamically designs task-aware, customized communication topologies. Specifically, G-Designer models the multi-agent system as a multi-agent network, leveraging a variational graph auto-encoder to encode both the nodes (agents) and a task-specific virtual node, and decodes a task-adaptive and high-performing communication topology. Extensive experiments on six benchmarks showcase that G-Designer is: \\textbf{(1) high-performing}, achieving superior results on MMLU with accuracy at $84.50\\%$ and on HumanEval with pass@1 at $89.90\\%$; \\textbf{(2) task-adaptive}, architecting communication protocols tailored to task difficulty, reducing token consumption by up to $95.33\\%$ on HumanEval; and \\textbf{(3) adversarially robust}, defending against agent adversarial attacks with merely $0.3\\%$ accuracy drop.", "bibtex": "@inproceedings{\nzhang2025gdesigner,\ntitle={G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks},\nauthor={Guibin Zhang and Yanwei Yue and Xiangguo Sun and Guancheng Wan and Miao Yu and Junfeng Fang and Kun Wang and Tianlong Chen and Dawei Cheng},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=LpE54NUnmO}\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ICML 2025 Spotlightposter G-Designer_ Architecting Multi-agent Communication Topologies via Graph Neural Networks.pdf", "retrieved_at": "2025-11-12T03:30:27.838513Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "Smurfs: Multi-Agent System using Context-Efficient DFSDT for Tool Planning", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Junzhi Chen", "Juhao Liang", "Benyou Wang"], "affinity_score": 0.7228, "link": "https://aclanthology.org/2025.naacl-long.169/", "abstract": "Teaching large language models (LLMs) to tool solving complex problems can grant them human-like reasoning abilities. ReAct and its variants are popular frameworks for tool use in both single-agent and multi-agent systems. To address issues like error propagation and limited exploration in ReAct, the Deep First Search Decision Tree (DFSDT) was proposed, but it faces challenges such as rollback instability, redundant context, and premature termination in single-agent settings. We introduce “Smurfs,” a novel multi-agent system (MAS) that enhances DFSDT with a modular, context-efficient, and training-free design. Smurfs surpasses baseline methods in both the open-ended StableToolBench and the closed-ended HotpotQA tasks, reducing token usage by 60.9% compared to DFSDT and enabling Mistral-7b to perform on par with GPT-4-DFSDT. Extensive ablation studies confirm the effectiveness of Smurfs’ core components, offering valuable insights for the construction and interpretation of MAS, and paving the way for future exploration. We release the code at https://github.com/FreedomIntelligence/Smurfs.", "bibtex": "@inproceedings{chen-etal-2025-smurfs,\n    title = \"Smurfs: Multi-Agent System using Context-Efficient {DFSDT} for Tool Planning\",\n    author = \"Chen, Junzhi  and\n      Liang, Juhao  and\n      Wang, Benyou\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.169/\",\n    doi = \"10.18653/v1/2025.naacl-long.169\",\n    pages = \"3281--3298\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/NAACL 2025 Long Smurfs_ Multi-Agent System using Context-Efficient DFSDT for Tool Planning.pdf", "retrieved_at": "2025-11-12T03:30:27.838518Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Shuo Yin", "Weihao You", "Zhilong Ji", "Guoqiang Zhong", "Jinfeng Bai"], "affinity_score": 0.7217, "link": "https://aclanthology.org/2024.emnlp-main.274/", "abstract": "The tool-use Large Language Models (LLMs) that integrate with external Python interpreters have significantly enhanced mathematical reasoning capabilities for open-source LLMs, while tool-free methods chose another track: augmenting math reasoning data. However, a great method to integrate the above two research paths and combine their advantages remains to be explored. In this work, we firstly include new math questions via\nmu\nlti-perspective data augmenting methods and then synthesize\ncode\n-nested solutions to them. The open LLMs (e.g., Llama-2) are finetuned on the augmented dataset to get the resulting models,\nMuMath-Code\n( 𝜇 -Math-Code). During the inference phase, our MuMath-Code generates code and interacts with the external python interpreter to get the execution results. Therefore, MuMath-Code leverages the advantages of both the external tool and data augmentation. To fully leverage the advantages of our augmented data, we propose a two-stage training strategy: In Stage-1, we finetune Llama-2 on pure CoT data to get an intermediate model, which then is trained on the code-nested data in Stage-2 to get the resulting MuMath-Code.Our MuMath-Code-7B achieves 83.8% on GSM8K and 52.4% on MATH, while MuMath-Code-70B model achieves new state-of-the-art performance among open methods—achieving 90.7% on GSM8K and 55.1% on MATH. Extensive experiments validate the combination of tool use and data augmentation, as well as our two-stage training strategy.We release the proposed dataset along with the associated code for public use: https://github.com/youweihao-tal/MuMath-Code.", "bibtex": "@inproceedings{yin-etal-2024-mumath,\n    title = \"{M}u{M}ath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning\",\n    author = \"Yin, Shuo  and\n      You, Weihao  and\n      Ji, Zhilong  and\n      Zhong, Guoqiang  and\n      Bai, Jinfeng\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.274/\",\n    doi = \"10.18653/v1/2024.emnlp-main.274\",\n    pages = \"4770--4785\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/EMNLP 2024 Main MuMath-Code_ Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning.pdf", "retrieved_at": "2025-11-12T03:30:27.838523Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "AgentDropout: Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Zhexuan Wang", "Yutong Wang", "Xuebo Liu", "Liang Ding", "Miao Zhang", "Jie Liu (刘杰)", "Min Zhang (张民)"], "affinity_score": 0.7209, "link": "https://aclanthology.org/2025.acl-long.1170/", "abstract": "Multi-agent systems (MAS) based on large language models (LLMs) have demonstrated significant potential in collaborative problem-solving. However, they still face substantial challenges of low communication efficiency and suboptimal task performance, making the careful design of the agents’ communication topologies particularly important. Inspired by the management theory that roles in an efficient team are often dynamically adjusted, we propose AgentDropout , which identifies redundant agents and communication across different communication rounds by optimizing the adjacency matrices of the communication graphs and eliminates them to enhance both token efficiency and task performance. Compared to state-of-the-art methods, AgentDropout achieves an average reduction of 21.6% in prompt token consumption and 18.4% in completion token consumption, along with a performance improvement of 1.14 on the tasks. Furthermore, the extended experiments demonstrate that AgentDropout achieves notable domain transferability and structure robustness, revealing its reliability and effectiveness. We release our code at https://github.com/wangzx1219/AgentDropout.", "bibtex": "@inproceedings{wang-etal-2025-agentdropout,\n    title = \"{A}gent{D}ropout: Dynamic Agent Elimination for Token-Efficient and High-Performance {LLM}-Based Multi-Agent Collaboration\",\n    author = \"Wang, Zhexuan  and\n      Wang, Yutong  and\n      Liu, Xuebo  and\n      Ding, Liang  and\n      Zhang, Miao  and\n      Liu, Jie  and\n      Zhang, Min\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1170/\",\n    doi = \"10.18653/v1/2025.acl-long.1170\",\n    pages = \"24013--24035\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ACL 2025 Long AgentDropout_ Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration.pdf", "retrieved_at": "2025-11-12T03:30:27.838528Z"}
{"search_index": 1, "query": "multiagent tool mathematics", "title": "AgentStore: Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant", "venue": "ACL 2025 Findings", "year": "2025", "authors": ["Chengyou Jia", "Minnan Luo (罗敏楠)", "Zhuohang Dang", "Qiushi Sun", "Fangzhi Xu", "Junlin Hu", "Tianbao Xie", "Zhiyong Wu"], "affinity_score": 0.7204, "link": "https://aclanthology.org/2025.findings-acl.466/", "abstract": "Digital agents capable of automating complex computer tasks have attracted considerable attention. However, existing agent methods exhibit deficiencies in their generalization and specialization capabilities, especially in handling open-ended computer tasks in real-world environments. Inspired by the rich functionality of the App store, we present AgentStore, a scalable platform designed to dynamically integrate heterogeneous agents for automating computer tasks. AgentStore allows the system to continuously enrich its capabilities and adapt to rapidly evolving operating systems. Additionally, we propose a novel core MetaAgent with the AgentToken strategy to efficiently manage diverse agents and utilize their specialized and generalist abilities for both domain-specific and system-wide tasks. Extensive experiments on three interactive real-world benchmarks demonstrate that AgentStore significantly expands the capability boundaries of agent systems in both generalization and specialization, underscoring its potential for developing the specialized generalist computer assistant.", "bibtex": "@inproceedings{jia-etal-2025-agentstore,\n    title = \"{A}gent{S}tore: Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant\",\n    author = \"Jia, Chengyou  and\n      Luo, Minnan  and\n      Dang, Zhuohang  and\n      Sun, Qiushi  and\n      Xu, Fangzhi  and\n      Hu, Junlin  and\n      Xie, Tianbao  and\n      Wu, Zhiyong\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2025\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-acl.466/\",\n    doi = \"10.18653/v1/2025.findings-acl.466\",\n    pages = \"8908--8934\",\n    ISBN = \"979-8-89176-256-5\"\n}", "pdf_path": "/Users/lingzhi/Downloads/Agent-Bio/plan+notes/tools/paper-finder/multiagent_use_tools_for_mathematics/ACL 2025 Findings AgentStore_ Scalable Integration of Heterogeneous Agents As Specialized Generalist Computer Assistant.pdf", "retrieved_at": "2025-11-12T03:30:27.838535Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Ziru Chen", "Shijie Chen", "Yuting Ning", "Qianheng Zhang", "Boshi Wang", "Botao Yu", "Yifei Li", "Zeyi Liao", "Chen Wei", "Zitong Lu", "Vishal Dey", "Mingyi Xue", "Frazier N. Baker", "Benjamin Burns", "Daniel Adu-Ampratwum", "Xuhui Huang", "Xia Ning", "Song Gao", "Yu Su", "Huan Sun"], "affinity_score": 0.6136, "link": "https://openreview.net/pdf/01bb45041a6c8c75021cdf0e1835d645398f660d.pdf", "abstract": "The advancements of language language models (LLMs) have piqued growing interest in developing LLM-based language agents to automate scientific discovery end-to-end, which has sparked both excitement and skepticism about the true capabilities of such agents. In this work, we argue that for an agent to fully automate scientific discovery, it must be able to complete all essential tasks in the workflow. Thus, we call for rigorous assessment of agents on individual tasks in a scientific workflow before making bold claims on end-to-end automation. To this end, we present ScienceAgentBench, a new benchmark for evaluating language agents for data-driven scientific discovery. To ensure the scientific authenticity and real-world relevance of our benchmark, we extract 102 tasks from 44 peer-reviewed publications in four disciplines and engage nine subject matter experts to validate them. We unify the target output for every task to a self-contained Python program file and employ an array of evaluation metrics to examine the generated programs, execution results, and costs. Each task goes through multiple rounds of manual validation by annotators and subject matter experts to ensure its annotation quality and scientific plausibility. We also propose two effective strategies to mitigate data contamination concerns. Using our benchmark, we evaluate five open-weight and proprietary LLMs, each with three frameworks: direct prompting, OpenHands, and self-debug. Given three attempts for each task, the best-performing agent can only solve 32.4% of the tasks independently and 34.3% with expert-provided knowledge. These results underscore the limited capacities of current language agents in generating code for data-driven discovery, let alone end-to-end automation for scientific research.", "bibtex": "@inproceedings{\nchen2025scienceagentbench,\ntitle={ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery},\nauthor={Ziru Chen and Shijie Chen and Yuting Ning and Qianheng Zhang and Boshi Wang and Botao Yu and Yifei Li and Zeyi Liao and Chen Wei and Zitong Lu and Vishal Dey and Mingyi Xue and Frazier N. Baker and Benjamin Burns and Daniel Adu-Ampratwum and Xuhui Huang and Xia Ning and Song Gao and Yu Su and Huan Sun},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=6z4YKr0GK6}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:46.461865Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "SciAgent: Tool-augmented Language Models for Scientific Reasoning", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Yubo Ma", "Zhibin Gou", "Junheng Hao", "Ruochen Xu", "Shuohang Wang", "Liangming Pan", "Yujiu Yang", "Yixin Cao", "Aixin Sun"], "affinity_score": 0.6135, "link": "https://aclanthology.org/2024.emnlp-main.880/", "abstract": "Scientific reasoning poses an excessive challenge for even the most advanced Large Language Models (LLMs). To make this task more practical and solvable for LLMs, we introduce a new task setting named tool-augmented scientific reasoning. This setting supplements LLMs with scalable toolsets, and shifts the focus from pursuing an omniscient problem solver to a proficient tool-user. To facilitate the research of such setting, we construct a tool-augmented training corpus named MathFunc which encompasses over 30,000 samples and roughly 6,000 tools. Building on MathFunc, we develop SciAgent to retrieve, understand and, if necessary, tool scientific problem solving. Additionally, we craft a benchmark, SciToolBench, spanning five scientific domains to evaluate LLMs’ abilities with tool assistance. Extensive experiments on SciToolBench confirm the effectiveness of SciAgent. Notably, SciAgent-Llama3-8B surpasses other LLMs with the comparable size by more than 8.0% in absolute accuracy. Furthermore, SciAgent-DeepMath-7B shows much superior performance than ChatGPT.", "bibtex": "@inproceedings{ma-etal-2024-sciagent,\n    title = \"{S}ci{A}gent: Tool-augmented Language Models for Scientific Reasoning\",\n    author = \"Ma, Yubo  and\n      Gou, Zhibin  and\n      Hao, Junheng  and\n      Xu, Ruochen  and\n      Wang, Shuohang  and\n      Pan, Liangming  and\n      Yang, Yujiu  and\n      Cao, Yixin  and\n      Sun, Aixin\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.880/\",\n    doi = \"10.18653/v1/2024.emnlp-main.880\",\n    pages = \"15701--15736\"\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:46.461894Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Jinheon Baek", "Sujay Kumar Jauhar", "Silviu Cucerzan", "Sung Ju Hwang"], "affinity_score": 0.5989, "link": "https://aclanthology.org/2025.naacl-long.342/", "abstract": "The pace of scientific research, vital for improving human life, is complex, slow, and needs specialized expertise. Meanwhile, novel, impactful research often stems from both a deep understanding of prior work, and a cross-pollination of ideas across domains and fields. To enhance the productivity of researchers, we propose ResearchAgent, which leverages the encyclopedic knowledge and linguistic reasoning capabilities of Large Language Models (LLMs) to assist them in their work. This system automatically defines novel problems, proposes methods and designs experiments, while iteratively refining them based on the feedback from collaborative LLM-powered reviewing agents. Specifically, starting with a core scientific paper, ResearchAgent is augmented not only with relevant publications by connecting information over an academic graph but also entities retrieved from a knowledge store derived from shared underlying concepts mined across numerous papers. Then, mimicking a scientific approach to improving ideas with peer discussions, we leverage multiple LLM-based ReviewingAgents that provide reviews and feedback via iterative revision processes. These reviewing agents are instantiated with human preference-aligned LLMs whose criteria for evaluation are elicited from actual human judgments via LLM prompting. We experimentally validate our ResearchAgent on scientific publications across multiple disciplines, showing its effectiveness in generating novel, clear, and valid ideas based on both human and model-based evaluation results. Our initial foray into AI-mediated scientific research has important implications for the development of future systems aimed at supporting researchers in their ideation and operationalization of novel work.", "bibtex": "@inproceedings{baek-etal-2025-researchagent,\n    title = \"{R}esearch{A}gent: Iterative Research Idea Generation over Scientific Literature with Large Language Models\",\n    author = \"Baek, Jinheon  and\n      Jauhar, Sujay Kumar  and\n      Cucerzan, Silviu  and\n      Hwang, Sung Ju\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.342/\",\n    doi = \"10.18653/v1/2025.naacl-long.342\",\n    pages = \"6709--6738\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:46.461901Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Yusuf H Roohani", "Andrew H. Lee", "Qian Huang", "Jian Vora", "Zachary Steinhart", "Kexin Huang", "Alexander Marson", "Percy Liang", "Jure Leskovec"], "affinity_score": 0.5959, "link": "https://openreview.net/pdf/dcfab1feaba7d38761a21e709247e9d97d4b98e2.pdf", "abstract": "Agents based on large language models have shown great potential in accelerating scientific discovery by leveraging their rich background knowledge and reasoning capabilities. In this paper, we introduce BioDiscoveryAgent, an agent that designs new experiments, reasons about their outcomes, and efficiently navigates the hypothesis space to reach desired solutions. We demonstrate our agent on the problem of designing genetic perturbation experiments, where the aim is to find a small subset out of many possible genes that, when perturbed, result in a specific phenotype (e.g., cell growth). Utilizing its biological knowledge, BioDiscoveryAgent can uniquely design new experiments without the need to train a machine learning model or explicitly design an acquisition function as in Bayesian optimization. Moreover, BioDiscoveryAgent using Claude 3.5 Sonnet achieves an average of 21% improvement in predicting relevant genetic perturbations across six datasets, and a 46% improvement in the harder task of non-essential gene perturbation, compared to existing Bayesian optimization baselines specifically trained for this task. Our evaluation includes one dataset that is unpublished, ensuring it is not part of the language model's training data. Additionally, BioDiscoveryAgent predicts gene combinations to perturb more than twice as accurately as a random baseline, a task so far not explored in the context of closed-loop experiment design. The agent also has access to tools for searching the biomedical literature, executing code to analyze biological datasets, and prompting another agent to critically evaluate its predictions. Overall, BioDiscoveryAgent is interpretable at every stage, representing an accessible new paradigm in the computational design of biological experiments with the potential to augment scientists' efficacy.", "bibtex": "@inproceedings{\nroohani2025biodiscoveryagent,\ntitle={BioDiscoveryAgent: An {AI} Agent for Designing Genetic Perturbation Experiments},\nauthor={Yusuf H Roohani and Andrew H. Lee and Qian Huang and Jian Vora and Zachary Steinhart and Kexin Huang and Alexander Marson and Percy Liang and Jure Leskovec},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=HAwZGLcye3}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:46.461907Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "CFP-Gen: Combinatorial Functional Protein Generation via Diffusion Language Models", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Junbo Yin", "Chao Zha", "Wenjia He", "Chencheng Xu", "Xin Gao"], "affinity_score": 0.5891, "link": "https://openreview.net/pdf/569318484c672a4bfddea91c3e6c323f86db7f28.pdf", "abstract": "Existing PLMs generate protein sequences based on a single-condition constraint from a specific modality, struggling to simultaneously satisfy multiple constraints across different modalities. In this work, we introduce CFP-GEN, a novel diffusion language model for Combinatorial Functional Protein GENeration. CFP-GEN facilitates the de novo protein design by integrating multimodal conditions with functional, sequence, and structural constraints. Specifically, an Annotation-Guided Feature Modulation (AGFM) module is introduced to dynamically adjust the protein feature distribution based on composable functional annotations, e.g., GO terms, IPR domains and EC numbers. Meanwhile, the ResidueControlled Functional Encoding (RCFE) module captures residue-wise interaction to ensure more precise control. Additionally, off-the-shelf 3D structure encoders can be seamlessly integrated to impose geometric constraints. We demonstrate that CFP-GEN enables high-throughput generation of novel proteins with functionality comparable to natural proteins, while achieving a high success rate in designing multifunctional proteins.", "bibtex": "@inproceedings{\nyin2025cfpgen,\ntitle={{CFP}-Gen: Combinatorial Functional Protein Generation via Diffusion Language Models},\nauthor={Junbo Yin and Chao Zha and Wenjia He and Chencheng Xu and Xin Gao},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=EiM163eZyg}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:46.461912Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ProteinBench: A Holistic Evaluation of Protein Foundation Models", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Fei YE", "Zaixiang Zheng", "Dongyu Xue", "Yuning Shen", "Lihao Wang", "Yiming Ma", "Yan Wang", "Xinyou Wang", "Xiangxin Zhou", "Quanquan Gu"], "affinity_score": 0.5736, "link": "https://openreview.net/pdf/3544ce00631e6c89a866f5f9ff2ba3d59149c0d7.pdf", "abstract": "Recent years have witnessed a surge in the development of protein foundation models, significantly improving performance in protein prediction and generative tasks ranging from 3D structure prediction and protein design to conformational dynamics. However, the capabilities and limitations associated with these models remain poorly understood due to the absence of a unified evaluation framework. To fill this gap, we introduce ProteinBench, a holistic evaluation framework designed to enhance the transparency of protein foundation models. Our approach consists of three key components: (i) A taxonomic classification of tasks that broadly encompass the main challenges in the protein domain, based on the relationships between different protein modalities; (ii) A multi-metric evaluation approach that assesses performance across four key dimensions: quality, novelty, diversity, and robustness; and (iii) In-depth analyses from various user objectives, providing a holistic view of model performance. Our comprehensive evaluation of protein foundation models reveals several key findings that shed light on their current capabilities and limitations. To promote transparency and facilitate further research, we release the evaluation dataset, code, and a public leaderboard publicly for further analysis and a general modular toolkit. We intend for ProteinBench to be a living benchmark for establishing a standardized, in-depth evaluation framework for protein foundation models, driving their development and application while fostering collaboration within the field.", "bibtex": "@inproceedings{\nye2025proteinbench,\ntitle={ProteinBench: A Holistic Evaluation of Protein Foundation Models},\nauthor={Fei YE and Zaixiang Zheng and Dongyu Xue and Yuning Shen and Lihao Wang and Yiming Ma and Yan Wang and Xinyou Wang and Xiangxin Zhou and Quanquan Gu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=BksqWM8737}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:46.461916Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Protein Design with Dynamic Protein Vocabulary", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Nuowei Liu", "Jiahao Kuang", "Yanting Liu", "Tao Ji", "Changzhi Sun", "Man Lan", "Yuanbin Wu"], "affinity_score": 0.5704, "link": "https://openreview.net/pdf/e184433c0869edcdccef239e20dfb9420d27b9f8.pdf", "abstract": "Protein design is a fundamental challenge in biotechnology, aiming to design novel sequences with specific functions within the vast space of possible proteins. Recent advances in deep generative models have enabled function-based protein design from textual descriptions, yet struggle with structural plausibility. Inspired by classical protein design methods that leverage natural protein structures, we explore whether incorporating fragments from natural proteins can enhance foldability in generative models. Our empirical results show that even random incorporation of fragments improves foldability. Building on this insight, we introduce ProDVa, a novel protein design approach that integrates a text encoder for functional descriptions, a protein language model for designing proteins, and a fragment encoder to dynamically retrieve protein fragments based on textual functional descriptions. Experimental results demonstrate that our approach effectively designs protein sequences that are both functionally aligned and structurally plausible. Compared to state-of-the-art models, ProDVa achieves comparable function alignment using less than 0.04% of the training data, while designing significantly more well-folded proteins, with the proportion of proteins having pLDDT above 70 increasing by 7.38% and those with PAE below 10 increasing by 9.62%.", "bibtex": "@inproceedings{\nliu2025protein,\ntitle={Protein Design with Dynamic Protein Vocabulary},\nauthor={Nuowei Liu and Jiahao Kuang and Yanting Liu and Tao Ji and Changzhi Sun and Man Lan and Yuanbin Wu},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=MpJkAzwUtl}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:46.461920Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Robust Optimization in Protein Fitness Landscapes Using Reinforcement Learning in Latent Space", "venue": "ICML 2024 Spotlight", "year": "2024", "authors": ["Minji Lee", "Luiz Felipe Vecchietti", "Hyunkyu Jung", "Hyun Joo Ro", "Meeyoung Cha", "Ho Min Kim"], "affinity_score": 0.5649, "link": "https://openreview.net/pdf/a6ef2163b0c8e9627e5c526fc4d73fb2e9eec207.pdf", "abstract": "Proteins are complex molecules responsible for different functions in nature. Enhancing the functionality of proteins and cellular fitness can significantly impact various industries. However, protein optimization using computational methods remains challenging, especially when starting from low-fitness sequences. We propose LatProtRL, an optimization method to efficiently traverse a latent space learned by an encoder-decoder leveraging a large protein language model. To escape local optima, our optimization is modeled as a Markov decision process using reinforcement learning acting directly in latent space. We evaluate our approach on two important fitness optimization tasks, demonstrating its ability to achieve comparable or superior fitness over baseline methods. Our findings and in vitro evaluation show that the generated sequences can reach high-fitness regions, suggesting a substantial potential of LatProtRL in lab-in-the-loop scenarios.", "bibtex": "@inproceedings{\nlee2024robust,\ntitle={Robust Optimization in Protein Fitness Landscapes Using Reinforcement Learning in Latent Space},\nauthor={Minji Lee and Luiz Felipe Vecchietti and Hyunkyu Jung and Hyun Joo Ro and Meeyoung Cha and Ho Min Kim},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=0zbxwvJqwf}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:46.461925Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "InstructProtein: Aligning Human and Protein Language via Knowledge Instruction", "venue": "ACL 2024 Long", "year": "2024", "authors": ["Zeyuan Wang", "Qiang Zhang", "Keyan Ding", "Ming Qin", "Xiang Zhuang", "Xiaotong Li", "Huajun Chen"], "affinity_score": 0.5624, "link": "https://aclanthology.org/2024.acl-long.62/", "abstract": "Large Language Models (LLMs) have revolutionized the field of natural language processing, but they fall short in comprehending biological sequences such as proteins. To address this challenge, we propose InstructProtein, an innovative LLM that possesses bidirectional generation capabilities in both human and protein languages: (i) taking a protein sequence as input to predict its textual function description and (ii) using natural language to prompt protein sequence generation. To achieve this, we first pre-train an LLM on both protein and natural language corpora, enabling it to comprehend individual languages. Then supervised instruction tuning is employed to facilitate the alignment of these two distinct languages. Herein, we introduce a knowledge graph-based instruction generation framework to construct a high-quality instruction dataset, addressing the annotation imbalance and the absence of instructional signals in the existing protein-text corpus. In particular, the instructions inherit the structural relations between proteins and function annotations in knowledge graphs, which empowers our model to engage in the causal modeling of protein-functions, akin to the chain-of-thought processes in natural languages. Extensive experiments on bidirectional protein-text generation tasks show that InstructProtein outperforms state-of-the-art LLMs by a large margin.", "bibtex": "@inproceedings{wang-etal-2024-instructprotein,\n    title = \"{I}nstruct{P}rotein: Aligning Human and Protein Language via Knowledge Instruction\",\n    author = \"Wang, Zeyuan  and\n      Zhang, Qiang  and\n      Ding, Keyan  and\n      Qin, Ming  and\n      Zhuang, Xiang  and\n      Li, Xiaotong  and\n      Chen, Huajun\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.62/\",\n    doi = \"10.18653/v1/2024.acl-long.62\",\n    pages = \"1114--1136\"\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:46.461929Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "SurfPro: Functional Protein Design Based on Continuous Surface", "venue": "ICML 2024 Poster", "year": "2024", "authors": ["Zhenqiao Song", "Tinglin Huang", "Lei Li", "Wengong Jin"], "affinity_score": 0.5599, "link": "https://openreview.net/pdf/e20d4e2dc0e1eec6b208ec275b34023987e7f976.pdf", "abstract": "How can we design proteins with desired functions? We are motivated by a chemical intuition that both geometric structure and biochemical properties are critical to a protein's function. In this paper, we propose SurfPro, a new method to generate functional proteins given a desired surface and its associated biochemical properties. SurfPro comprises a hierarchical encoder that progressively models the geometric shape and biochemical features of a protein surface, and an autoregressive decoder to produce an amino acid sequence. We evaluate SurfPro on a standard inverse folding benchmark CATH 4.2 and two functional protein design tasks: protein binder design and enzyme design. Our SurfPro consistently surpasses previous state-of-the-art inverse folding methods, achieving a recovery rate of 57.78% on CATH 4.2 and higher success rates in terms of protein-protein binding and enzyme-substrate interaction scores", "bibtex": "@inproceedings{\nsong2024surfpro,\ntitle={SurfPro: Functional Protein Design Based on Continuous Surface},\nauthor={Zhenqiao Song and Tinglin Huang and Lei Li and Wengong Jin},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=a8QpoEJCRI}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:46.461933Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ProtPainter: Draw or Drag Protein via Topology-guided Diffusion", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Zhengxi Lu", "Shizhuo Cheng", "Tintin Jiang", "Yan Zhang", "Min Zhang"], "affinity_score": 0.5593, "link": "https://openreview.net/pdf/e4eaf619ab5c208b6e210bc9af270af499eda7c5.pdf", "abstract": "Recent advances in protein backbone generation have achieved promising results under structural, functional, or physical constraints. However, existing methods lack the flexibility for precise topology control, limiting navigation of the backbone space. We present $\\textbf{ProtPainter}$, a diffusion-based approach for generating protein backbones conditioned on 3D curves. ProtPainter follows a two-stage process: curve-based sketching and sketch-guided backbone generation. For the first stage, we propose $\\textbf{CurveEncoder}$, which predicts secondary structure annotations from a curve to parametrize sketch generation. For the second stage, the sketch guides the generative process in Denoising Diffusion Probabilistic Modeling (DDPM) to generate backbones. During the process, we further introduce a fusion scheduling scheme, Helix-Gating, to control the scaling factors. To evaluate, we propose the first benchmark for topology-conditioned protein generation, introducing Protein Restoration Task and a new metric, self-consistency Topology Fitness (scTF). Experiments demonstrate ProtPainter's ability to generate topology-fit (scTF $>$ 0.8) and designable (scTM $>$ 0.5) backbones, with drawing and dragging tasks showcasing its flexibility and versatility.", "bibtex": "@inproceedings{\nlu2025protpainter,\ntitle={ProtPainter: Draw or Drag Protein via Topology-guided Diffusion},\nauthor={Zhengxi Lu and Shizhuo Cheng and Tintin Jiang and Yan Zhang and Min Zhang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=Nq7yKYL0Bp}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:47.453232Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Prot2Text-V2: protein-function Prediction with Multimodal Contrastive Alignment", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Xiao Fei", "Michail Chatzianastasis", "Sarah Almeida Carneiro", "Hadi Abdine", "Lawrence Paul Petalidis", "Michalis Vazirgiannis"], "affinity_score": 0.5567, "link": "https://openreview.net/pdf/b02004d99f8f2dea970dfefc2a557e7c05782a38.pdf", "abstract": "Predicting protein-function from sequence is a central challenge in computational biology. While existing methods rely heavily on structured ontologies or similarity-based techniques, they often lack the flexibility to express structure-free functional descriptions and novel biological functions. In this work, we introduce Prot2Text-V2, a novel multimodal sequence-to-text model that generates free-form natural language descriptions of protein-function directly from amino acid sequences. Our method combines a protein language model as a sequence encoder (ESM-3B) and a decoder-only language model (LLaMA-3.1-8B-Instruct) through a lightweight nonlinear modality projector.\nA key innovation is our Hybrid Sequence-level Contrastive Alignment Learning (H-SCALE), which improves cross-modal learning by matching mean- and std-pooled protein embeddings with text representations via contrastive loss. After the alignment phase, we apply instruction-based fine-tuning using LoRA on the decoder to teach the model how to generate accurate protein-function descriptions conditioned on the protein sequence. We train Prot2Text-V2 on about 250K curated entries from SwissProt and evaluate it under low-homology conditions, where test sequences have low similarity with training samples. Prot2Text-V2 consistently outperforms traditional and LLM-based baselines across various metrics.", "bibtex": "@inproceedings{\nfei2025prottextv,\ntitle={Prot2Text-V2: protein-function Prediction with Multimodal Contrastive Alignment},\nauthor={Xiao Fei and Michail Chatzianastasis and Sarah Almeida Carneiro and Hadi Abdine and Lawrence Paul Petalidis and Michalis Vazirgiannis},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=w1FUXt3ujK}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:47.453249Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Pre-training Sequence, Structure, and Surface Features for Comprehensive Protein Representation Learning", "venue": "ICLR 2024 Poster", "year": "2024", "authors": ["Youhan Lee", "Hasun Yu", "Jaemyung Lee", "Jaehoon Kim"], "affinity_score": 0.5518, "link": "https://openreview.net/pdf/d85441e5f968c9ae883e09ec5a06e9f9eda773c2.pdf", "abstract": "Proteins can be represented in various ways, including their sequences, 3D structures, and surfaces. While recent studies have successfully employed sequence- or structure-based representations to address multiple tasks in protein science, there has been significant oversight in incorporating protein surface information, a critical factor for protein-function. In this paper, we present a pre-training strategy that incorporates information from protein sequences, 3D structures, and surfaces to improve protein representation learning. Specifically, we utilize Implicit Neural Representations (INRs) for learning surface characteristics, and name it ProteinINR. We confirm that ProteinINR successfully reconstructs protein surfaces, and integrate this surface learning into the existing pre-training strategy of sequences and structures. Our results demonstrate that our approach can enhance performance in various downstream tasks, thereby underscoring the importance of including surface attributes in protein representation learning. These findings underline the importance of understanding protein surfaces for generating effective protein representations.", "bibtex": "@inproceedings{\nlee2024pretraining,\ntitle={Pre-training Sequence, Structure, and Surface Features for Comprehensive Protein Representation Learning},\nauthor={Youhan Lee and Hasun Yu and Jaemyung Lee and Jaehoon Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BEH4mGo7zP}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:47.453253Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Protein Conformation Generation via Force-Guided SE(3) Diffusion Models", "venue": "ICML 2024 Poster", "year": "2024", "authors": ["YanWang", "Lihao Wang", "Yuning Shen", "Yiqun Wang", "Huizhuo Yuan", "Yue Wu", "Quanquan Gu"], "affinity_score": 0.5501, "link": "https://openreview.net/pdf/e517c97a7e9d4f13dca2fb7971865e8d5fb0194a.pdf", "abstract": "The conformational landscape of proteins is crucial to understanding their functionality in complex biological processes. Traditional physics-based computational methods, such as molecular dynamics (MD) simulations, suffer from rare event sampling and long equilibration time problems, hindering their applications in general protein systems. Recently, deep generative modeling techniques, especially diffusion models, have been employed to generate novel protein conformations. However, existing score-based diffusion methods cannot properly incorporate important physical prior knowledge to guide the generation process, causing large deviations in the sampled protein conformations from the equilibrium distribution. In this paper, to overcome these limitations, we propose a force-guided $\\mathrm{SE}(3)$ diffusion model, ConfDiff, for protein conformation generation. By incorporating a force-guided network with a mixture of data-based score models, ConfDiff can generate protein conformations with rich diversity while preserving high fidelity. Experiments on a variety of protein conformation prediction tasks, including 12 fast-folding proteins and the Bovine Pancreatic Trypsin Inhibitor (BPTI), demonstrate that our method surpasses the state-of-the-art method.", "bibtex": "@inproceedings{\nyanwang2024protein,\ntitle={Protein Conformation Generation via Force-Guided {SE}(3) Diffusion Models},\nauthor={YanWang and Lihao Wang and Yuning Shen and Yiqun Wang and Huizhuo Yuan and Yue Wu and Quanquan Gu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=aC1LSa4nXs}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:47.453256Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "An All-Atom Generative Model for Designing Protein Complexes", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Ruizhe Chen", "Dongyu Xue", "Xiangxin Zhou", "Zaixiang Zheng", "xiangxiang Zeng", "Quanquan Gu"], "affinity_score": 0.5484, "link": "https://openreview.net/pdf/097aa805ed5da2cc0d4fc09c1cfaab111789b078.pdf", "abstract": "Proteins typically exist in complexes, interacting with other proteins or biomolecules to perform their specific biological roles. Research on single-chain protein modeling has been extensively and deeply explored, with advancements seen in models like the series of ESM and AlphaFold2. Despite these developments, the study and modeling of multi-chain proteins remain largely uncharted, though they are vital for understanding biological functions. Recognizing the importance of these interactions, we introduce APM (all-Atom Protein generative Model), a model specifically designed for modeling multi-chain proteins. By integrating atom-level information and leveraging data on multi-chain proteins, APM is capable of precisely modeling inter-chain interactions and designing protein complexes with binding capabilities from scratch. It also performs folding and inverse-folding tasks for multi-chain proteins. Moreover, APM demonstrates versatility in downstream applications: it achieves enhanced performance through supervised fine-tuning (SFT) while also supporting zero-shot sampling in certain tasks, achieving state-of-the-art results. We released our code at https://github.com/bytedance/apm.", "bibtex": "@inproceedings{\nchen2025an,\ntitle={An All-Atom Generative Model for Designing Protein Complexes},\nauthor={Ruizhe Chen and Dongyu Xue and Xiangxin Zhou and Zaixiang Zheng and xiangxiang Zeng and Quanquan Gu},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=Afmi28vgIf}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:47.453258Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Sequence-Augmented SE(3)-Flow Matching For Conditional Protein Generation", "venue": "NeurIPS 2024 Poster", "year": "2024", "authors": ["Guillaume Huguet", "James Vuckovic", "Kilian FATRAS", "Eric Thibodeau-Laufer", "Pablo Lemos", "Riashat Islam", "Cheng-Hao Liu", "Jarrid Rector-Brooks", "Tara Akhound-Sadegh", "Michael M. Bronstein", "Alexander Tong", "Joey Bose"], "affinity_score": 0.5478, "link": "https://openreview.net/pdf/503e86547852b43509aa82eecef8210d45232c5b.pdf", "abstract": "Proteins are essential for almost all biological processes and derive their diverse functions from complex $3 \\rm D$ structures, which are in turn determined by their amino acid sequences. \nIn this paper, we exploit the rich biological inductive bias of amino acid sequences and introduce FoldFlow++, a novel sequence-conditioned $\\text{SE}(3)$-equivariant flow matching model for protein structure generation. FoldFlow++ presents substantial new architectural features over the previous FoldFlow family of models including a protein large language model to encode sequence, a new multi-modal fusion trunk that combines structure and sequence representations, and a geometric transformer based decoder. To increase \ndiversity and novelty of generated samples -- crucial for de-novo drug design -- we\ntrain FoldFlow++ at scale on a new dataset \nthat is an order of magnitude \nlarger than PDB datasets of prior works, containing both known proteins in PDB and high-quality synthetic structures achieved through filtering. We further demonstrate the ability to align FoldFlow++ to arbitrary rewards, e.g. increasing secondary structures diversity, by introducing a Reinforced Finetuning (ReFT) objective. We empirically observe that FoldFlow++ outperforms previous state-of-the-art protein structure-based generative models, improving over RFDiffusion in terms of unconditional generation across all metrics including designability, diversity, and novelty across all protein lengths, as well as exhibiting generalization on the task of equilibrium conformation sampling. Finally, we demonstrate that a fine-tuned FoldFlow++ makes progress on challenging conditional design tasks such as designing scaffolds for the VHH nanobody.", "bibtex": "@inproceedings{\nhuguet2024sequenceaugmented,\ntitle={Sequence-Augmented {SE}(3)-Flow Matching For Conditional Protein Generation},\nauthor={Guillaume Huguet and James Vuckovic and Kilian FATRAS and Eric Thibodeau-Laufer and Pablo Lemos and Riashat Islam and Cheng-Hao Liu and Jarrid Rector-Brooks and Tara Akhound-Sadegh and Michael M. Bronstein and Alexander Tong and Joey Bose},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=paYwtPBpyZ}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:47.453261Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Proteus: Exploring Protein Structure Generation for Enhanced Designability and Efficiency", "venue": "ICML 2024 Poster", "year": "2024", "authors": ["Chentong Wang", "Yannan Qu", "Zhangzhi Peng", "Yukai Wang", "Hongli Zhu", "Dachuan Chen", "Longxing Cao"], "affinity_score": 0.5474, "link": "https://openreview.net/pdf/c0e3630d2c44de576cfbb58426802f4a8b71c9db.pdf", "abstract": "Diffusion-based generative models have been successfully employed to create proteins with novel structures and functions. However, the construction of such models typically depends on large, pre-trained structure prediction networks, like RFdiffusion. In contrast, alternative models that are trained from scratch, such as FrameDiff, still fall short in performance. In this context, we introduce Proteus, an innovative deep diffusion network that incorporates graph-based triangle methods and a multi-track interaction network, eliminating the dependency on structure prediction pre-training with superior efficiency. We have validated our model's performance on de novo protein backbone generation through comprehensive in silico evaluations and experimental characterizations, which demonstrate a remarkable success rate. These promising results underscore Proteus's ability to generate highly designable protein backbones efficiently. This capability, achieved without reliance on pre-training techniques, has the potential to significantly advance the field of protein design.", "bibtex": "@inproceedings{\nwang2024proteus,\ntitle={Proteus: Exploring Protein Structure Generation for Enhanced Designability and Efficiency},\nauthor={Chentong Wang and Yannan Qu and Zhangzhi Peng and Yukai Wang and Hongli Zhu and Dachuan Chen and Longxing Cao},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=IckJCzsGVS}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:47.453264Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "LLM and Simulation as Bilevel Optimizers: A New Paradigm to Advance Physical Scientific Discovery", "venue": "ICML 2024 Poster", "year": "2024", "authors": ["Pingchuan Ma", "Tsun-Hsuan Wang", "Minghao Guo", "Zhiqing Sun", "Joshua B. Tenenbaum", "Daniela Rus", "Chuang Gan", "Wojciech Matusik"], "affinity_score": 0.5465, "link": "https://openreview.net/pdf/8e1aee641dee0dc2d14eb58b4c9d0f25392e7047.pdf", "abstract": "Large Language Models have recently gained significant attention in scientific discovery for their extensive knowledge and advanced reasoning capabilities. However, they encounter challenges in effectively simulating observational feedback and grounding it with language to propel advancements in physical scientific discovery. Conversely, human scientists undertake scientific discovery by formulating hypotheses, conducting experiments, and revising theories through observational analysis. Inspired by this, we propose to enhance the knowledge-driven, abstract reasoning abilities of LLMs with the computational strength of simulations. We introduce Scientific Generative Agent (SGA), a bilevel optimization framework: LLMs act as knowledgeable and versatile thinkers, proposing scientific hypotheses and reason about discrete components, such as physics equations or molecule structures; meanwhile, simulations function as experimental platforms, providing observational feedback and optimizing via differentiability for continuous parts, such as physical parameters. We conduct extensive experiments to demonstrate our framework's efficacy in constitutive law discovery and molecular design, unveiling novel solutions that differ from conventional human expectations yet remain coherent upon analysis.", "bibtex": "@inproceedings{\nma2024llm,\ntitle={{LLM} and Simulation as Bilevel Optimizers: A New Paradigm to Advance Physical Scientific Discovery},\nauthor={Pingchuan Ma and Tsun-Hsuan Wang and Minghao Guo and Zhiqing Sun and Joshua B. Tenenbaum and Daniela Rus and Chuang Gan and Wojciech Matusik},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=hz8cFsdz7P}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:47.453267Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Joint Design of Protein Surface and Backbone Using a Diffusion Bridge Model", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Guanlue Li", "Xufeng Zhao", "Fang Wu", "Sören Laue"], "affinity_score": 0.5463, "link": "https://openreview.net/pdf/f1279f7d02db36b5fa80332e4f86e4a98dc23ef7.pdf", "abstract": "Protein-protein interactions (PPIs) are governed by surface complementarity and hydrophobic interactions at protein interfaces. However, designing diverse and physically realistic protein structure and surfaces that precisely complement target receptors remains a significant challenge in computational protein design. In this work, we introduce PepBridge, a novel framework for the joint design of protein surface and structure that seamlessly integrates receptor surface geometry and biochemical properties. Starting with a receptor surface represented as a 3D point cloud, PepBridge generates complete protein structures through a multi-step process. First, it employs denoising diffusion bridge models (DDBMs) to map receptor surfaces to ligand surfaces. Next, a multi-model diffusion model predicts the corresponding structure, while Shape-Frame Matching Networks ensure alignment between surface geometry and backbone architecture. This integrated approach facilitates surface complementarity, conformational stability, and chemical feasibility. Extensive validation across diverse protein design scenarios demonstrates PepBridge's efficacy in generating structurally viable proteins, representing a significant advancement in the joint design of top-down protein structure.", "bibtex": "@inproceedings{\nli2025joint,\ntitle={Joint Design of Protein Surface and Backbone Using a Diffusion Bridge Model},\nauthor={Guanlue Li and Xufeng Zhao and Fang Wu and S{\\\"o}ren Laue},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=QqCv9SI0X3}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:47.453277Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Dynamics-Informed Protein Design with Structure Conditioning", "venue": "ICLR 2024 Poster", "year": "2024", "authors": ["Urszula Julia Komorowska", "Simon V Mathis", "Kieran Didi", "Francisco Vargas", "Pietro Lio", "Mateja Jamnik"], "affinity_score": 0.5414, "link": "https://openreview.net/pdf/0ffbbb38174d8802162c0bef4914451f67318f38.pdf", "abstract": "Current protein generative models are able to design novel backbones with desired shapes or functional motifs. However, despite the importance of a protein’s dynamical properties for its function, conditioning on dynamical properties remains elusive. We present a new approach to protein generative modeling by leveraging Normal Mode Analysis that enables us to capture dynamical properties too. We introduce a method for conditioning the diffusion probabilistic models on protein dynamics, specifically on the lowest non-trivial normal mode of oscillation. Our method, similar to the classifier guidance conditioning, formulates the sampling process as being driven by conditional and unconditional terms. However, unlike previous works, we approximate the conditional term with a simple analytical function rather than an external neural network, thus making the eigenvector calculations approachable. We present the corresponding SDE theory as a formal justification of our approach. We extend our framework to conditioning on structure and dynamics at the same time, enabling scaffolding of the dynamical motifs. We demonstrate the empirical effectiveness of our method by turning the open-source unconditional protein diffusion model Genie into the conditional model with no retraining. Generated proteins exhibit the desired dynamical and structural properties while still being biologically plausible. Our work represents a first step towards incorporating dynamical behaviour in protein design and may open the door to designing more flexible and functional proteins in the future.", "bibtex": "@inproceedings{\nkomorowska2024dynamicsinformed,\ntitle={Dynamics-Informed Protein Design with Structure Conditioning},\nauthor={Urszula Julia Komorowska and Simon V Mathis and Kieran Didi and Francisco Vargas and Pietro Lio and Mateja Jamnik},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jZPqf2G9Sw}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:47.453279Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ProtGO: Function-Guided Protein Modeling for Unified Representation Learning", "venue": "NeurIPS 2024 Poster", "year": "2024", "authors": ["Bozhen Hu", "Cheng Tan", "Yongjie Xu", "Zhangyang Gao", "Jun Xia", "Lirong Wu", "Stan Z. Li"], "affinity_score": 0.5384, "link": "https://openreview.net/pdf/4c612b62ad07fff120769db3671c70a742345427.pdf", "abstract": "Protein representation learning is indispensable for various downstream applications of artificial intelligence for bio-medicine research, such as drug design and function prediction. However, achieving effective representation learning for proteins poses challenges due to the diversity of data modalities involved, including sequence, structure, and function annotations. Despite the impressive capabilities of large language models in biomedical text modelling, there remains a pressing need for a framework that seamlessly integrates these diverse modalities, particularly focusing on the three critical aspects of protein information: sequence, structure, and function. Moreover, addressing the inherent data scale differences among these modalities is essential. To tackle these challenges, we introduce ProtGO, a unified model that harnesses a teacher network equipped with a customized graph neural network (GNN) and a Gene Ontology (GO) encoder to learn hybrid embeddings. Notably, our approach eliminates the need for additional functions as input for the student network, which shares the same GNN module. Importantly, we utilize a domain adaptation method to facilitate distribution approximation for guiding the training of the teacher-student framework. This approach leverages distributions learned from latent representations to avoid the alignment of individual samples. Benchmark experiments highlight that ProtGO significantly outperforms state-of-the-art baselines, clearly demonstrating the advantages of the proposed unified framework.", "bibtex": "@inproceedings{\nhu2024protgo,\ntitle={Prot{GO}: Function-Guided Protein Modeling for Unified Representation Learning},\nauthor={Bozhen Hu and Cheng Tan and Yongjie Xu and Zhangyang Gao and Jun Xia and Lirong Wu and Stan Z. Li},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=0oUutV92YF}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:49.409104Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Steering Protein Family Design through Profile Bayesian Flow", "venue": "ICLR 2025 Oral", "year": "2025", "authors": ["Jingjing Gong", "Yu Pei", "Siyu Long", "Yuxuan Song", "Zhe Zhang", "Wenhao Huang", "Ziyao Cao", "Shuyi Zhang", "Hao Zhou", "Wei-Ying Ma"], "affinity_score": 0.5356, "link": "https://openreview.net/pdf/43bf9f0b2762a450d02b6845e2f7fa85988bf860.pdf", "abstract": "Protein family design emerges as a promising alternative by combining the advantages of de novo protein design and mutation-based directed evolution.In this paper, we propose ProfileBFN, the Profile Bayesian Flow Networks, for specifically generative modeling of protein families. ProfileBFN extends the discrete Bayesian Flow Network from an MSA profile perspective, which can be trained on single protein sequences by regarding it as a degenerate profile, thereby achieving efficient protein family design by avoiding large-scale MSA data construction and training. Empirical results show that ProfileBFN has a profound understanding of proteins. When generating diverse and novel family proteins, it can accurately capture the structural characteristics of the family. The enzyme produced by this method is more likely than the previous approach to have the corresponding function, offering better odds of generating diverse proteins with the desired functionality.", "bibtex": "@inproceedings{\ngong2025steering,\ntitle={Steering Protein Family Design through Profile Bayesian Flow},\nauthor={Jingjing Gong and Yu Pei and Siyu Long and Yuxuan Song and Zhe Zhang and Wenhao Huang and Ziyao Cao and Shuyi Zhang and Hao Zhou and Wei-Ying Ma},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=PSiijdQjNU}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:49.409120Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Knowledge-aware Reinforced Language Models for Protein Directed Evolution", "venue": "ICML 2024 Poster", "year": "2024", "authors": ["Yuhao Wang", "Qiang Zhang", "Ming Qin", "Xiang Zhuang", "Xiaotong Li", "Zhichen Gong", "Zeyuan Wang", "Yu Zhao", "Jianhua Yao", "Keyan Ding", "Huajun Chen"], "affinity_score": 0.5341, "link": "https://openreview.net/pdf/71ce8b48d7bf2425e056b8ff930df961125d4a43.pdf", "abstract": "Directed evolution, a cornerstone of protein optimization, is to harness natural mutational processes to enhance protein-functionality. Existing Machine Learning-assisted Directed Evolution (MLDE) methodologies typically rely on data-driven strategies and often overlook the profound domain knowledge in biochemical fields. In this paper, we introduce a novel Knowledge-aware Reinforced Language Model (KnowRLM) for MLDE. An Amino Acid Knowledge Graph (AAKG) is constructed to represent the intricate biochemical relationships among amino acids. We further propose a Protein Language Model (PLM)-based policy network that iteratively samples mutants through preferential random walks on the AAKG using a dynamic sliding window mechanism. The novel mutants are actively sampled to fine-tune a fitness predictor as the reward model, providing feedback to the knowledge-aware policy. Finally, we optimize the whole system in an active learning approach that mimics biological settings in practice.KnowRLM stands out for its ability to utilize contextual amino acid information from knowledge graphs, thus attaining advantages from both statistical patterns of protein sequences and biochemical properties of amino acids.Extensive experiments demonstrate the superior performance of KnowRLM in more efficiently identifying high-fitness mutants compared to existing methods.", "bibtex": "@inproceedings{\nwang2024knowledgeaware,\ntitle={Knowledge-aware Reinforced Language Models for Protein Directed Evolution},\nauthor={Yuhao Wang and Qiang Zhang and Ming Qin and Xiang Zhuang and Xiaotong Li and Zhichen Gong and Zeyuan Wang and Yu Zhao and Jianhua Yao and Keyan Ding and Huajun Chen},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=MikandLqtW}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:49.409125Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "TEMPO: Temporal Multi-scale Autoregressive Generation of Protein Conformational Ensembles", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Yaoyao Xu", "Di Wang", "Zihan Zhou", "Tianshu Yu", "Mingchen Chen"], "affinity_score": 0.5333, "link": "https://openreview.net/pdf/91f410ff9dcb163d0ffe652491a71fba886e94d9.pdf", "abstract": "Understanding the dynamic behavior of proteins is critical to elucidating their functional mechanisms, yet generating realistic, temporally coherent trajectories of protein ensembles remains a significant challenge. In this work, we introduce a novel hierarchical autoregressive framework for modeling protein dynamics that leverages the intrinsic multi-scale organization of molecular motions. Unlike existing methods that focus on generating static conformational ensembles or treat dynamic sampling as an independent process, our approach characterizes protein dynamics as a Markovian process. The framework employs a two-scale architecture: a low-resolution model captures slow, collective motions driving major conformational transitions, while a high-resolution model generates detailed local fluctuations conditioned on these large-scale movements. This hierarchical design ensures that the causal dependencies inherent in protein dynamics are preserved, enabling the generation of temporally coherent and physically realistic trajectories. By bridging high-level biophysical principles with state-of-the-art generative modeling, our approach provides an efficient framework for simulating protein dynamics that balances computational efficiency with physical accuracy.", "bibtex": "@inproceedings{\nxu2025tempo,\ntitle={{TEMPO}: Temporal Multi-scale Autoregressive Generation of Protein Conformational Ensembles},\nauthor={Yaoyao Xu and Di Wang and Zihan Zhou and Tianshu Yu and Mingchen Chen},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=0wV5HR7M4P}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:49.409130Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Bridging Protein Sequences and Microscopy Images with Unified Diffusion Models", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Dihan Zheng", "Bo Huang"], "affinity_score": 0.5324, "link": "https://openreview.net/pdf/f447029f83b094b6b90f0c5043453e975c659aa2.pdf", "abstract": "Fluorescence microscopy is ubiquitously used in cell biology research to characterize the cellular role of a protein. To help elucidate the relationship between the amino acid sequence of a protein and its cellular function, we introduce CELL-Diff, a unified diffusion model facilitating bidirectional transformations between protein sequences and their corresponding microscopy images. Utilizing reference cell morphology images and a protein sequence, CELL-Diff efficiently generates corresponding protein images. Conversely, given a protein image, the model outputs protein sequences. CELL-Diff integrates continuous and diffusion models within a unified framework and is implemented using a transformer-based network. We train CELL-Diff on the Human Protein Atlas (HPA) dataset and fine-tune it on the OpenCell dataset. Experimental results demonstrate that CELL-Diff outperforms existing methods in generating high-fidelity protein images, making it a practical tool for investigating subcellular protein localization and interactions.", "bibtex": "@inproceedings{\nzheng2025bridging,\ntitle={Bridging Protein Sequences and Microscopy Images with Unified Diffusion Models},\nauthor={Dihan Zheng and Bo Huang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=r4XfIgD77g}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:49.409134Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "From Mechanistic Interpretability to Mechanistic Biology: Training, Evaluating, and Interpreting Sparse Autoencoders on Protein Language Models", "venue": "ICML 2025 Spotlightposter", "year": "2025", "authors": ["Etowah Adams", "Liam Bai", "Minji Lee", "Yiyang Yu", "Mohammed AlQuraishi"], "affinity_score": 0.5323, "link": "https://openreview.net/pdf/9f17c03cb8b900c8987d0efd2edda7945a8224c9.pdf", "abstract": "Protein language models (pLMs) are powerful predictors of protein structure and function, learning through unsupervised training on millions of protein sequences. pLMs are thought to capture common motifs in protein sequences, but the specifics of pLM features are not well understood. Identifying these features would not only shed light on how pLMs work, but potentially uncover novel protein biology––studying the model to study the biology. Motivated by this, we train sparse autoencoders (SAEs) on the residual stream of a pLM, ESM-2. By characterizing SAE features, we determine that pLMs use a combination of generic features and family-specific features to represent a protein. In addition, we demonstrate how known sequence determinants of properties such as thermostability and subcellular localization can be identified by linear probing of SAE features. For predictive features without known functional associations, we hypothesize their role in unknown mechanisms and provide visualization tools to aid their interpretation. Our study gives a better understanding of the limitations of pLMs, and demonstrates how SAE features can be used to help generate hypotheses for biological mechanisms. We release our code, model weights, and feature visualizer.", "bibtex": "@inproceedings{\nadams2025from,\ntitle={From Mechanistic Interpretability to Mechanistic Biology: Training, Evaluating, and Interpreting Sparse Autoencoders on Protein Language Models},\nauthor={Etowah Adams and Liam Bai and Minji Lee and Yiyang Yu and Mohammed AlQuraishi},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=zdOGBRQEbz}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:49.409139Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Steering Generative Models with Experimental Data for Protein Fitness Optimization", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Jason Yang", "Wenda Chu", "Daniel Khalil", "Raul Astudillo", "Bruce James Wittmann", "Frances H. Arnold", "Yisong Yue"], "affinity_score": 0.5313, "link": "https://openreview.net/pdf/81aade662c48049d5fd1adafcb6cb2d72d21cf70.pdf", "abstract": "Protein fitness optimization involves finding a protein sequence that maximizes desired quantitative properties in a combinatorially large design space of possible sequences. Recent advances in steering protein generative models (e.g., diffusion models and language models) with labeled data offer a promising approach. However, most previous studies have optimized surrogate rewards and/or utilized large amounts of labeled data for steering, making it unclear how well existing methods perform and compare to each other in real-world optimization campaigns where fitness is measured through low-throughput wet-lab assays. In this study, we explore fitness optimization using small amounts (hundreds) of labeled sequence-fitness pairs and comprehensively evaluate strategies such as classifier guidance and posterior sampling for guiding generation from different discrete diffusion models of protein sequences. We also demonstrate how guidance can be integrated into adaptive sequence selection akin to Thompson sampling in Bayesian optimization, showing that plug-and-play guidance strategies offer advantages over alternatives such as reinforcement learning with protein language models. Overall, we provide practical insights into how to effectively steer modern generative models for next-generation protein fitness optimization.", "bibtex": "@inproceedings{\nyang2025steering,\ntitle={Steering Generative Models with Experimental Data for Protein Fitness Optimization},\nauthor={Jason Yang and Wenda Chu and Daniel Khalil and Raul Astudillo and Bruce James Wittmann and Frances H. Arnold and Yisong Yue},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=Ice2BHIumz}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:49.409143Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning", "venue": "ICML 2024 Poster", "year": "2024", "authors": ["Siyuan Guo", "Cheng Deng", "Ying Wen", "Hechang Chen", "Yi Chang", "Jun Wang"], "affinity_score": 0.5301, "link": "https://openreview.net/pdf/ca6f6e07e47b268198c00cca4b58903bd015c219.pdf", "abstract": "In this work, we investigate the potential of large language models (LLMs) based agents to automate data science tasks, with the goal of comprehending task requirements, then building and training the best-fit machine learning models. Despite their widespread success, existing LLM agents are hindered by generating unreasonable experiment plans within this scenario. To this end, we present DS-Agent, a novel automatic framework that harnesses LLM agent and case-based reasoning (CBR). In the development stage, DS-Agent follows the CBR framework to structure an automatic iteration pipeline, which can flexibly capitalize on the expert knowledge from Kaggle, and facilitate consistent performance improvement through the feedback mechanism. Moreover, DS-Agent implements a low-resource deployment stage with a simplified CBR paradigm to adapt past successful solutions from the development stage for direct code generation, significantly reducing the demand on foundational capabilities of LLMs. Empirically, DS-Agent with GPT-4 achieves 100% success rate in the development stage, while attaining 36% improvement on average one pass rate across alternative LLMs in the deployment stage. In both stages, DS-Agent achieves the best rank in performance, costing \n$1.60 and \\$0.13 per run with GPT-4, respectively. Our data and code are open-sourced at https://github.com/guosyjlu/DS-Agent.", "bibtex": "@inproceedings{\nguo2024dsagent,\ntitle={{DS}-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning},\nauthor={Siyuan Guo and Cheng Deng and Ying Wen and Hechang Chen and Yi Chang and Jun Wang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=LfJgeBNCFI}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:49.409147Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ESM All-Atom: Multi-Scale Protein Language Model for Unified Molecular Modeling", "venue": "ICML 2024 Poster", "year": "2024", "authors": ["Kangjie Zheng", "Siyu Long", "Tianyu Lu", "Junwei Yang", "Xinyu Dai", "Ming Zhang", "Zaiqing Nie", "Wei-Ying Ma", "Hao Zhou"], "affinity_score": 0.5298, "link": "https://openreview.net/pdf/a701e753389a226ace8e293f2f5d53cabc38f484.pdf", "abstract": "Protein language models have demonstrated significant potential in the field of protein engineering. However, current protein language models primarily operate at the residue scale, which limits their ability to provide information at the atom level. This limitation prevents us from fully exploiting the capabilities of protein language models for applications involving both proteins and small molecules. In this paper, we propose ESM-AA (ESM All-Atom), a novel approach that enables atom-scale and residue-scale unified molecular modeling. ESM-AA achieves this by pre-training on multi-scale code-switch protein sequences and utilizing a multi-scale position encoding to capture relationships among residues and atoms. Experimental results indicate that ESM-AA surpasses previous methods in protein-molecule tasks, demonstrating the full utilization of protein language models. Further investigations reveal that through unified molecular modeling, ESM-AA not only gains molecular knowledge but also retains its understanding of proteins.", "bibtex": "@inproceedings{\nzheng2024esm,\ntitle={{ESM} All-Atom: Multi-Scale Protein Language Model for Unified Molecular Modeling},\nauthor={Kangjie Zheng and Siyu Long and Tianyu Lu and Junwei Yang and Xinyu Dai and Ming Zhang and Zaiqing Nie and Wei-Ying Ma and Hao Zhou},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=283cGgWfM2}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:49.409151Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "BLADE: Benchmarking Language Model Agents for Data-Driven Science", "venue": "EMNLP 2024 Findings", "year": "2024", "authors": ["Ken Gu", "Ruoxi Shang", "Ruien Jiang", "Keying Kuang", "Richard-John Lin", "Donghe Lyu", "Yue Mao", "Youran Pan", "Teng Wu", "Jiaqian Yu", "Yikun Zhang", "Tianmai M. Zhang", "Lanyi Zhu", "Mike A Merrill", "Jeffrey Heer", "Tim Althoff"], "affinity_score": 0.5296, "link": "https://aclanthology.org/2024.findings-emnlp.815/", "abstract": "Data-driven scientific discovery requires the iterative integration of scientific domain knowledge, statistical expertise, and an understanding of data semantics to make nuanced analytical decisions, e.g., about which variables, transformations, and statistical models to consider. LM-based agents equipped with planning, memory, and code execution capabilities have the potential to support data-driven science. However, evaluating agents on such open-ended tasks is challenging due to multiple valid approaches, partially correct steps, and different ways to express the same decisions. To address these challenges, we present BLADE, a benchmark to automatically evaluate agents’ multifaceted approaches to open-ended research questions. BLADE consists of 12 datasets and research questions drawn from existing scientific literature, with ground truth collected from independent analyses by expert data scientists and researchers. To automatically evaluate agent responses, we developed corresponding computational methods to match different representations of analyses to this ground truth. Though language models possess considerable world knowledge, our evaluation shows that they are often limited to basic analyses. However, agents capable of interacting with the underlying data demonstrate improved, but still non-optimal, diversity in their analytical decision making. Our work enables the evaluation of agents for data-driven science and provides researchers deeper insights into agents’ analysis approaches.", "bibtex": "@inproceedings{gu-etal-2024-blade,\n    title = \"{BLADE}: Benchmarking Language Model Agents for Data-Driven Science\",\n    author = \"Gu, Ken  and\n      Shang, Ruoxi  and\n      Jiang, Ruien  and\n      Kuang, Keying  and\n      Lin, Richard-John  and\n      Lyu, Donghe  and\n      Mao, Yue  and\n      Pan, Youran  and\n      Wu, Teng  and\n      Yu, Jiaqian  and\n      Zhang, Yikun  and\n      Zhang, Tianmai M.  and\n      Zhu, Lanyi  and\n      Merrill, Mike A  and\n      Heer, Jeffrey  and\n      Althoff, Tim\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Findings of the Association for Computational Linguistics: EMNLP 2024\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-emnlp.815/\",\n    doi = \"10.18653/v1/2024.findings-emnlp.815\",\n    pages = \"13936--13971\"\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:49.409156Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "DePLM: Denoising Protein Language Models for Property Optimization", "venue": "NeurIPS 2024 Poster", "year": "2024", "authors": ["Zeyuan Wang", "Keyan Ding", "Ming Qin", "Xiaotong Li", "Xiang Zhuang", "Yu Zhao", "Jianhua Yao", "Qiang Zhang", "Huajun Chen"], "affinity_score": 0.5295, "link": "https://openreview.net/pdf/8f9fddc96bbfe2d55f21a3238ba386cb0b43d243.pdf", "abstract": "Protein optimization is a fundamental biological task aimed at enhancing theperformance of proteins by modifying their sequences. Computational methodsprimarily rely on evolutionary information (EI) encoded by protein languagemodels (PLMs) to predict fitness landscape for optimization. However, thesemethods suffer from a few limitations. (1) Evolutionary processes involve thesimultaneous consideration of multiple functional properties, often overshadowingthe specific property of interest. (2) Measurements of these properties tend to betailored to experimental conditions, leading to reduced generalizability of trainedmodels to novel proteins. To address these limitations, we introduce DenoisingProtein Language Models (DePLM), a novel approach that refines the evolutionaryinformation embodied in PLMs for improved protein optimization. Specifically, weconceptualize EI as comprising both property-relevant and irrelevant information,with the latter acting as “noise” for the optimization task at hand. Our approachinvolves denoising this EI in PLMs through a diffusion process conducted in therank space of property values, thereby enhancing model generalization and ensuringdataset-agnostic learning. Extensive experimental results have demonstrated thatDePLM not only surpasses the state-of-the-art in mutation effect prediction butalso exhibits strong generalization capabilities for novel proteins.", "bibtex": "@inproceedings{\nwang2024deplm,\ntitle={De{PLM}: Denoising Protein Language Models for Property Optimization},\nauthor={Zeyuan Wang and Keyan Ding and Ming Qin and Xiaotong Li and Xiang Zhuang and Yu Zhao and Jianhua Yao and Qiang Zhang and Huajun Chen},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=MU27zjHBcW}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:50.361800Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Retrieval-Augmented Language Model for Knowledge-aware Protein Encoding", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Jiasheng Zhang", "Delvin Ce Zhang", "Shuang Liang", "Zhengpin Li", "Rex Ying", "Jie Shao"], "affinity_score": 0.5292, "link": "https://openreview.net/pdf/5f63c05b47d681f0a59195523a2fc09dac1bedee.pdf", "abstract": "Protein language models often struggle to capture biological functions due to their lack of factual knowledge (e.g., gene descriptions). Existing solutions leverage protein knowledge graphs (PKGs) as auxiliary pre-training objectives, but lack explicit integration of task-oriented knowledge, making them suffer from limited knowledge exploitation and catastrophic forgetting. The root cause is that they fail to align PKGs with task-specific data, forcing their knowledge modeling to adapt to the knowledge-isolated nature of downstream tasks. In this paper, we propose Knowledge-aware retrieval augmented protein language model (Kara), achieving the first task-oriented and explicit integration of PKGs and protein language models. With a knowledge retriever learning to predict linkages between PKG and task proteins, Kara unifies the knowledge integration of the pre-training and fine-tuning stages with a structure-based regularization, mitigating catastrophic forgetting. To ensure task-oriented integration, Kara uses contextualized virtual tokens to extract graph context as task-specific knowledge for new proteins. Experiments show that Kara outperforms existing knowledge-enhanced models in 6 representative tasks, achieving on average 5.1% improvements.", "bibtex": "@inproceedings{\nzhang2025retrievalaugmented,\ntitle={Retrieval-Augmented Language Model for Knowledge-aware Protein Encoding},\nauthor={Jiasheng Zhang and Delvin Ce Zhang and Shuang Liang and Zhengpin Li and Rex Ying and Jie Shao},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=TJHhXzTcQe}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:50.361811Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "LLM Agents Making Agent Tools", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Georg Wölflein", "Dyke Ferber", "Daniel Truhn", "Ognjen Arandjelovic", "Jakob Nikolas Kather"], "affinity_score": 0.5288, "link": "https://aclanthology.org/2025.acl-long.1266/", "abstract": "Tool use has turned large language models (LLMs) into powerful agents that can perform complex multi-step tasks by dynamically utilising external software components. However, these tools must be implemented in advance by human developers, hindering the applicability of LLM agents in domains demanding large numbers of highly specialised tools, like in life sciences and medicine. Motivated by the growing trend of scientific studies accompanied by public code repositories, we propose ToolMaker, an agentic framework that autonomously transforms papers with code into LLM-compatible tools. Given a GitHub URL and short task description, ToolMaker autonomously installs dependencies and generates code to perform the task, using a closed-loop self-correction mechanism for debugging. To evaluate our approach, we introduce a benchmark comprising 15 complex computational tasks spanning various domains with over 100 unit tests to assess correctness and robustness. Our method correctly implements 80% of the tasks, substantially outperforming current state-of-the-art software engineering agents. ToolMaker therefore is a step towards fully autonomous agent-based scientific workflows.", "bibtex": "@inproceedings{wolflein-etal-2025-llm,\n    title = \"{LLM} Agents Making Agent Tools\",\n    author = {W{\\\"o}lflein, Georg  and\n      Ferber, Dyke  and\n      Truhn, Daniel  and\n      Arandjelovic, Ognjen  and\n      Kather, Jakob Nikolas},\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1266/\",\n    doi = \"10.18653/v1/2025.acl-long.1266\",\n    pages = \"26092--26130\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:50.361816Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "UniZyme: A Unified Protein Cleavage Site Predictor Enhanced with Enzyme Active-Site Knowledge", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Chenao Li", "Shuo Yan", "Enyan Dai"], "affinity_score": 0.5281, "link": "https://openreview.net/pdf/b89909c20ceaa10621ab93b7b6694fbdb824f04d.pdf", "abstract": "Enzyme-catalyzed protein cleavage is essential for many biological functions. Accurate prediction of cleavage sites can facilitate various applications such as drug development, enzyme design, and a deeper understanding of biological mechanisms. However, most existing models are restricted to an individual enzyme, which neglects shared knowledge of enzymes and fails to generalize to novel enzymes. Thus, we introduce a unified protein cleavage site predictor named UniZyme, which can generalize across diverse enzymes. To enhance the enzyme encoding for the protein cleavage site prediction, UniZyme employs a novel biochemically-informed model architecture along with active-site knowledge of proteolytic enzymes.  Extensive experiments demonstrate that UniZyme achieves high accuracy in predicting cleavage sites across a range of proteolytic enzymes, including unseen enzymes. The code is available in  https://github.com/Ao-LiChen/UniZyme", "bibtex": "@inproceedings{\nli2025unizyme,\ntitle={UniZyme: A Unified Protein Cleavage Site Predictor Enhanced with Enzyme Active-Site Knowledge},\nauthor={Chenao Li and Shuo Yan and Enyan Dai},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=5cgm5dV5hr}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:50.361821Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Yuhao Wang", "Keyan Ding", "Kehua Feng", "Zeyuan Wang", "Ming Qin", "Xiaotong Li", "Qiang Zhang", "Huajun Chen"], "affinity_score": 0.5271, "link": "https://aclanthology.org/2025.acl-long.616/", "abstract": "Protein language models have emerged as powerful tools for sequence generation, offering substantial advantages in functional optimization and\ndenovo\ndesign. However, these models also present significant risks of generating harmful protein sequences, such as those that enhance viral transmissibility or evade immune responses. These concerns underscore critical biosafety and ethical challenges. To address these issues, we propose a Knowledge-guided Preference Optimization (KPO) framework that integrates prior knowledge via a Protein Safety Knowledge Graph. This framework utilizes an efficient graph pruning strategy to identify preferred sequences and employs reinforcement learning to minimize the risk of generating harmful proteins. Experimental results demonstrate that KPO effectively reduces the likelihood of producing hazardous sequences while maintaining high functionality, offering a robust safety assurance framework for applying generative models in biotechnology.", "bibtex": "@inproceedings{wang-etal-2025-enhancing-safe,\n    title = \"Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization\",\n    author = \"Wang, Yuhao  and\n      Ding, Keyan  and\n      Feng, Kehua  and\n      Wang, Zeyuan  and\n      Qin, Ming  and\n      Li, Xiaotong  and\n      Zhang, Qiang  and\n      Chen, Huajun\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.616/\",\n    doi = \"10.18653/v1/2025.acl-long.616\",\n    pages = \"12553--12569\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:50.361826Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Steering Protein Language Models", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Long-Kai Huang", "Rongyi Zhu", "Bing He", "Jianhua Yao"], "affinity_score": 0.5267, "link": "https://openreview.net/pdf/a837cc69557d144870d59bb17ba9cec8627e9546.pdf", "abstract": "Protein Language Models (PLMs), pre-trained on extensive evolutionary data from natural proteins, have emerged as indispensable tools for protein design. While powerful, PLMs often struggle to produce proteins with precisely specified functionalities or properties due to inherent challenges in controlling their outputs. \nIn this work, we investigate the potential of Activation Steering, a technique originally developed for controlling text generation in Large Language Models (LLMs), to direct PLMs toward generating protein sequences with targeted properties. We propose a simple yet effective method that employs activation editing to steer PLM outputs, and extend this approach to protein optimization through a novel editing site identification module. Through comprehensive experiments on lysozyme-like sequence generation and optimization, we demonstrate that our methods can be seamlessly integrated into both auto-encoding and autoregressive PLMs without requiring additional training. These results highlight a promising direction for precise protein engineering using foundation models.\nCode is available at\nhttps://github.com/Long-Kai/Steering-PLMs\n.", "bibtex": "@inproceedings{\nhuang2025steering,\ntitle={Steering Protein Language Models},\nauthor={Long-Kai Huang and Rongyi Zhu and Bing He and Jianhua Yao},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=pu2aw2zwMx}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:50.361830Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "AI-Researcher: Autonomous Scientific Innovation", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Jiabin Tang", "Lianghao Xia", "Zhonghang Li", "Chao Huang"], "affinity_score": 0.5266, "link": "https://openreview.net/pdf/a1c63cdd0495de94664b1513f7d95a3aedcb483a.pdf", "abstract": "The powerful reasoning capabilities of Large Language Models (LLMs) in mathematics and coding, combined with their ability to automate complex tasks through agentic frameworks, present unprecedented opportunities for accelerating scientific innovation. In this paper, we introduce AI-Researcher, a fully autonomous research system that transforms how AI-driven scientific discovery is conducted and evaluated. Our framework seamlessly orchestrates the complete research pipeline--from literature review and hypothesis generation to algorithm implementation and publication-ready manuscript preparation--with minimal human intervention. To rigorously assess autonomous research capabilities, we develop Scientist-Bench, a comprehensive benchmark comprising state-of-the-art papers across diverse AI research domains, featuring both guided innovation and open-ended exploration tasks. Through extensive experiments, we demonstrate that AI-Researcher achieves remarkable implementation success rates and produces research papers that approach human-level quality. This work establishes new foundations for autonomous scientific innovation that can complement human researchers by systematically exploring solution spaces beyond cognitive limitations.", "bibtex": "@inproceedings{\ntang2025airesearcher,\ntitle={{AI}-Researcher: Autonomous Scientific Innovation},\nauthor={Jiabin Tang and Lianghao Xia and Zhonghang Li and Chao Huang},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=kQWyOYUAC4}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:50.361834Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Data Distillation for extrapolative protein design through exact preference optimization", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Mostafa Karimi", "Sharmi Banerjee", "Tommi Jaakkola", "Bella Dubrov", "Shang Shang", "Ron Benson"], "affinity_score": 0.526, "link": "https://openreview.net/pdf/021d9166b13a2e7722c47febaf5741466a713b4d.pdf", "abstract": "The goal of protein design typically involves increasing fitness (extrapolating) beyond what is seen during training (e.g., towards higher stability, stronger binding affinity, etc.). State-of-the-art methods assume that one can safely steer proteins towards such extrapolated regions by learning from pairs alone. We hypothesize that noisy training pairs are not sufficiently informative to capture the fitness gradient and that models learned from pairs specifically may fail to capture three-way relations important for search, e.g., how two alternatives fair relative to a seed. Building on the success of preference alignment models in large language models, we introduce a progressive search method for extrapolative protein design by directly distilling into the model relevant triplet relations. We evaluated our model's performance in designing AAV and GFP proteins and demonstrated that the proposed framework significantly improves effectiveness in extrapolation tasks.", "bibtex": "@inproceedings{\nkarimi2025data,\ntitle={Data Distillation for extrapolative protein design through exact preference optimization},\nauthor={Mostafa Karimi and Sharmi Banerjee and Tommi Jaakkola and Bella Dubrov and Shang Shang and Ron Benson},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=ua5MHdsbck}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:50.361838Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "PPDiff: Diffusing in Hybrid Sequence-Structure Space for Protein-Protein Complex Design", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Zhenqiao Song", "Tianxiao Li", "Lei Li", "Martin Renqiang Min"], "affinity_score": 0.5253, "link": "https://openreview.net/pdf/c1d0093e12471abf1eedc91b20aa16373243a7b7.pdf", "abstract": "Designing protein-binding proteins with high affinity is critical in biomedical research and biotechnology. Despite recent advancements targeting specific proteins, the ability to create high-affinity binders for arbitrary protein targets on demand, without extensive rounds of wet-lab testing, remains a significant challenge. Here, we introduce PPDiff, a diffusion model to jointly design the sequence and structure of binders for arbitrary protein targets in a non-autoregressive manner. PPDiff builds upon our developed Sequence Structure Interleaving Network with Causal attention layers (SSINC), which integrates interleaved self-attention layers to capture global amino acid correlations, $k$-nearest neighbor ($k$NN) equivariant graph convolutional layers to model local interactions in three-dimensional (3D) space, and causal attention layers to simplify the intricate interdependencies within the protein sequence. To assess PPDiff, we curate PPBench, a general protein-protein complex dataset comprising 706,360 complexes from the Protein Data Bank (PDB). The model is pretrained on PPBench and finetuned on two real-world applications: target-protein mini-binder complex design and antigen-antibody complex design. PPDiff consistently surpasses baseline methods, achieving success rates of 50.00\\%, 23.16\\%, and 16.89\\% for the pretraining task and the two downstream applications, respectively.", "bibtex": "@inproceedings{\nsong2025ppdiff,\ntitle={{PPD}iff: Diffusing in Hybrid Sequence-Structure Space for Protein-Protein Complex Design},\nauthor={Zhenqiao Song and Tianxiao Li and Lei Li and Martin Renqiang Min},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=gTYzm0Qchr}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:50.361843Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Latent Retrieval Augmented Generation of Cross-Domain Protein Binders", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Zishen Zhang", "Xiangzhe Kong", "Wenbing Huang", "Yang Liu"], "affinity_score": 0.5246, "link": "https://openreview.net/pdf/9ddd71a1025703ddb55d20ba5a51370138b4915e.pdf", "abstract": "Designing protein binders targeting specific sites, which requires to generate realistic and functional interaction patterns, is a fundamental challenge in drug discovery. Current structure-based generative models are limited in generating nterfaces with sufficient rationality and interpretability. In this paper, we propose\nR\netrieval-\nA\nugmented\nDi\nffusion for\nA\nlig\nn\ned interfa\nce\n(\nRADiAnce\n), a new framework that leverages known interfaces to guide the design of novel binders. By unifying retrieval and generation in a shared contrastive latent space, our model efficiently identifies relevant interfaces for a given binding site and seamlessly integrates them through a conditional latent diffusion generator, enabling cross-domain interface transfer. Extensive exeriments show that\nRADiAnce\nsignificantly outperforms baseline models across multiple metrics, including binding affinity and recovery of geometries and interactions.\nAdditional experimental results validate cross-domain generalization, demonstrating that retrieving interfaces from diverse domains, such as peptides, antibodies, and protein fragments, enhances the generation performance of binders for other domains. Our work establishes a new paradigm for protein binder design that successfully bridges retrieval-based knowledge and generative AI, opening new possibilities for drug discovery.", "bibtex": "@inproceedings{\nzhang2025latent,\ntitle={Latent Retrieval Augmented Generation of Cross-Domain Protein Binders},\nauthor={Zishen Zhang and Xiangzhe Kong and Wenbing Huang and Yang Liu},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=B7Bc9xzl2o}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:50.361847Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ChemAgent: Self-updating Memories in Large Language Models Improves Chemical Reasoning", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Xiangru Tang", "Tianyu Hu", "Muyang Ye", "Yanjun Shao", "Xunjian Yin", "Siru Ouyang", "Wangchunshu Zhou", "Pan Lu", "Zhuosheng Zhang", "Yilun Zhao", "Arman Cohan", "Mark Gerstein"], "affinity_score": 0.5245, "link": "https://openreview.net/pdf/f072f5a9e65a8bb918caeaa9fdf7a78732984cba.pdf", "abstract": "Chemical reasoning usually involves complex, multi-step processes that demand precise calculations, where even minor errors can lead to cascading failures. Furthermore, large language models (LLMs) encounter difficulties handling domain-specific formulas, executing reasoning steps accurately, and integrating code ef- effectively when tackling chemical reasoning tasks. To address these challenges, we present ChemAgent, a novel framework designed to improve the performance of LLMs through a dynamic, self-updating library. This library is developed by decomposing chemical tasks into sub-tasks and compiling these sub-tasks into a structured collection that can be referenced for future queries. Then, when presented with a new problem, ChemAgent retrieves and refines pertinent information from the library, which we call memory, facilitating effective task decomposition and the generation of solutions. Our method designs three types of memory and a library-enhanced reasoning component, enabling LLMs to improve over time through experience. Experimental results on four chemical reasoning datasets from SciBench demonstrate that ChemAgent achieves performance gains of up to 46% (GPT-4), significantly outperforming existing methods. Our findings suggest substantial potential for future applications, including tasks such as drug discovery and materials science. Our code can be found at https://github.com/gersteinlab/ChemAgent.", "bibtex": "@inproceedings{\ntang2025chemagent,\ntitle={ChemAgent: Self-updating Memories in Large Language Models Improves Chemical Reasoning},\nauthor={Xiangru Tang and Tianyu Hu and Muyang Ye and Yanjun Shao and Xunjian Yin and Siru Ouyang and Wangchunshu Zhou and Pan Lu and Zhuosheng Zhang and Yilun Zhao and Arman Cohan and Mark Gerstein},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=kuhIqeVg0e}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:51.318784Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Generalized Protein Pocket Generation with Prior-Informed Flow Matching", "venue": "NeurIPS 2024 Spotlight", "year": "2024", "authors": ["ZAIXI ZHANG", "Marinka Zitnik", "Qi Liu"], "affinity_score": 0.524, "link": "https://openreview.net/pdf/8e3258542a044155281d07e06f9bc062d4c9ec04.pdf", "abstract": "Designing ligand-binding proteins, such as enzymes and biosensors, is essential in bioengineering and protein biology. One critical step in this process involves designing protein pockets, the protein interface binding with the ligand. Current approaches to pocket generation often suffer from time-intensive physical computations or template-based methods, as well as compromised generation quality due to the overlooking of domain knowledge. To tackle these challenges, we propose PocketFlow, a generative model that incorporates protein-ligand interaction priors based on flow matching. During training, PocketFlow learns to model key types of protein-ligand interactions, such as hydrogen bonds. In the sampling, PocketFlow leverages multi-granularity guidance (overall binding affinity and interaction geometry constraints) to facilitate generating high-affinity and valid pockets. Extensive experiments show that PocketFlow outperforms baselines on multiple benchmarks, e.g., achieving an average improvement of 1.29 in Vina Score and 0.05 in scRMSD. Moreover, modeling interactions make PocketFlow a generalized generative model across multiple ligand modalities, including small molecules, peptides, and RNA.", "bibtex": "@inproceedings{\nzhang2024generalized,\ntitle={Generalized Protein Pocket Generation with Prior-Informed Flow Matching},\nauthor={ZAIXI ZHANG and Marinka Zitnik and Qi Liu},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=WyVTj77KEV}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:51.318805Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Simultaneous Modeling of Protein Conformation and Dynamics via Autoregression", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Yuning Shen", "Lihao Wang", "Huizhuo Yuan", "Yan Wang", "Bangji Yang", "Quanquan Gu"], "affinity_score": 0.5237, "link": "https://openreview.net/pdf/8049776790397ae4bd55dbc09aa3105a978e06ea.pdf", "abstract": "Understanding protein dynamics is critical for elucidating their biological functions. \nThe increasing availability of molecular dynamics (MD) data enables the training of deep generative models to efficiently explore the conformational space of proteins.\nHowever, existing approaches either fail to explicitly capture the temporal dependencies between conformations or do not support direct generation of time-independent samples.\nTo address these limitations, we introduce\nConfRover\n, an autoregressive model that simultaneously learns protein conformation and dynamics from MD trajectory data, supporting both time-dependent and time-independent sampling.\nAt the core of our model is a modular architecture comprising: (i) an\nencoding layer\n, adapted from protein folding models, that embeds protein-specific information and conformation at each time frame into a latent space; (ii) a\ntemporal module\n, a sequence model that captures conformational dynamics across frames; and (iii) an SE(3) diffusion model as the\nstructure decoder\n, generating conformations in continuous space.\nExperiments on ATLAS, a large-scale protein MD dataset of diverse structures, demonstrate the effectiveness of our model in learning conformational dynamics and supporting a wide range of downstream tasks.\nConfRover\nis the first model to sample both protein conformations and trajectories within a single framework, offering a novel and flexible approach for learning from protein MD data.", "bibtex": "@inproceedings{\nshen2025simultaneous,\ntitle={Simultaneous Modeling of Protein Conformation and Dynamics via Autoregression},\nauthor={Yuning Shen and Lihao Wang and Huizhuo Yuan and Yan Wang and Bangji Yang and Quanquan Gu},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=jj0nJQYFlW}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:51.318811Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Floating Anchor Diffusion Model for Multi-motif Scaffolding", "venue": "ICML 2024 Poster", "year": "2024", "authors": ["Ke Liu", "Weian Mao", "Shuaike Shen", "Xiaoran Jiao", "Zheng Sun", "Hao Chen", "Chunhua Shen"], "affinity_score": 0.523, "link": "https://openreview.net/pdf/4e958aee8348fd92514fdee57d46ba3667fee7e3.pdf", "abstract": "Motif scaffolding seeks to design scaffold structures for constructing proteins with functions derived from the desired motif, which is crucial for the design of vaccines and enzymes. Previous works approach the problem by inpainting or conditional generation. Both of them can only scaffold motifs with fixed positions, and the conditional generation cannot guarantee the presence of motifs. However, prior knowledge of the relative motif positions in a protein is not readily available, and constructing a protein with multiple functions in one protein is more general and significant because of the synergies between functions. We propose a Floating Anchor Diffusion (FADiff) model. FADiff allows motifs to float rigidly and independently in the process of diffusion, which guarantees the presence of motifs and automates the motif position design. Our experiments demonstrate the efficacy of FADiff with high success rates and designable novel scaffolds. To the best of our knowledge, FADiff is the first work to tackle the challenge of scaffolding multiple motifs without relying on the expertise of relative motif positions in the protein. Code is available at https://github.com/aim-uofa/FADiff.", "bibtex": "@inproceedings{\nliu2024floating,\ntitle={Floating Anchor Diffusion Model for Multi-motif Scaffolding},\nauthor={Ke Liu and Weian Mao and Shuaike Shen and Xiaoran Jiao and Zheng Sun and Hao Chen and Chunhua Shen},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=CtgJUQxmEo}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:51.318816Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "DPLM-2: A Multimodal Diffusion Protein Language Model", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Xinyou Wang", "Zaixiang Zheng", "Fei YE", "Dongyu Xue", "Shujian Huang", "Quanquan Gu"], "affinity_score": 0.5228, "link": "https://openreview.net/pdf/13c6bc9b904922e7352e690eae7cad8a2d4526f7.pdf", "abstract": "Proteins are essential macromolecules defined by their amino acid sequences, which determine their three-dimensional structures and, consequently, their functions in all living organisms. Therefore, generative protein modeling necessitates a multimodal approach to simultaneously model, understand, and generate both sequences and structures. However, existing methods typically use separate models for each modality, limiting their ability to capture the intricate relationships between sequence and structure. This results in suboptimal performance in tasks that requires joint understanding and generation of both modalities.\nIn this paper, we introduce DPLM-2, a multimodal protein foundation model that extends discrete diffusion protein language model (DPLM) to accommodate both sequences and structures.\nTo enable structural learning with the language model, 3D coordinates are converted to discrete tokens using a lookup-free quantization-based tokenizer.\nBy training on both experimental and high-quality synthetic structures, DPLM-2 learns the joint distribution of sequence and structure, as well as their marginals and conditionals.\nWe also implement an efficient warm-up strategy to exploit the connection between large-scale evolutionary data and structural inductive biases from pre-trained sequence-based protein language models.\nEmpirical evaluation shows that DPLM-2 can simultaneously generate highly compatible amino acid sequences and their corresponding 3D structures eliminating the need for a two-stage generation approach.\nMoreover, DPLM-2 demonstrates competitive performance in various conditional generation tasks, including folding, inverse folding, and scaffolding with multimodal motif inputs.", "bibtex": "@inproceedings{\nwang2025dplm,\ntitle={{DPLM}-2: A Multimodal Diffusion Protein Language Model},\nauthor={Xinyou Wang and Zaixiang Zheng and Fei YE and Dongyu Xue and Shujian Huang and Quanquan Gu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=5z9GjHgerY}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:51.318820Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Inverse problems with experiment-guided AlphaFold", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Sai Advaith Maddipatla", "Nadav Bojan", "Meital Bojan", "Sanketh Vedula", "Paul Schanda", "Ailie Marx", "Alexander Bronstein"], "affinity_score": 0.5211, "link": "https://openreview.net/pdf/4851973ad7a0af3ee84445f1dc248b20a01234be.pdf", "abstract": "Proteins exist as a dynamic ensemble of multiple conformations, and these motions are often crucial for their functions. However, current structure prediction methods predominantly yield a single  conformation, overlooking the conformational heterogeneity revealed by diverse experimental modalities. Here, we present a framework for building experiment-grounded protein structure generative models that infer conformational ensembles consistent with measured experimental data. The key idea is to treat state-of-the-art protein structure predictors (e.g., AlphaFold3) as sequence-conditioned structural priors, and cast ensemble modeling as posterior inference of protein structures given experimental measurements. Through extensive real-data experiments, we demonstrate the generality of our method to incorporate a variety of experimental measurements. In particular, our framework uncovers previously unmodeled conformational heterogeneity from crystallographic densities, generates high-accuracy NMR ensembles orders of magnitude faster than status quo, and incorporates pairwise cross-link constraints. Notably, we demonstrate that our ensembles outperform AlphaFold3 and sometimes better fit experimental data than publicly deposited structures to the protein database (PDB). We believe that this approach will unlock building predictive models that fully embrace experimentally observed conformational diversity.", "bibtex": "@inproceedings{\nmaddipatla2025inverse,\ntitle={Inverse problems with experiment-guided AlphaFold},\nauthor={Sai Advaith Maddipatla and Nadav Bojan and Meital Bojan and Sanketh Vedula and Paul Schanda and Ailie Marx and Alexander Bronstein},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=qzM37nOy3N}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:51.318825Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Diffusion on Language Model Encodings for Protein Sequence Generation", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Viacheslav Meshchaninov", "Pavel Strashnov", "Andrey Shevtsov", "Fedor Nikolaev", "Nikita Ivanisenko", "Olga Kardymon", "Dmitry Vetrov"], "affinity_score": 0.521, "link": "https://openreview.net/pdf/247bdc9c2a584f53f7defdfab8bd5e01da3316bc.pdf", "abstract": "Protein\nsequence\ndesign has seen significant advances through discrete diffusion and autoregressive approaches, yet the potential of continuous diffusion remains underexplored. Here, we present\nDiMA\n, a latent diffusion framework that operates on protein language model representations. Through systematic exploration of architectural choices and diffusion components, we develop a robust methodology that generalizes across multiple protein encoders ranging from 8M to 3B parameters. We demonstrate that our framework achieves consistently high performance across sequence-only (ESM-2, ESMc), dual-decodable (CHEAP), and multimodal (SaProt) representations using the same architecture and training approach. We conduct extensive evaluation of existing methods alongside\nDiMA\nusing multiple metrics across two protein modalities, covering quality, diversity, novelty, and distribution matching of generated proteins.\nDiMA\nconsistently produces novel, high-quality and diverse protein sequences and achieves strong results compared to baselines such as autoregressive, discrete diffusion and flow matching language models. The model demonstrates versatile functionality, supporting conditional generation tasks including protein family-generation, motif scaffolding and infilling, and fold-specific sequence design, despite being trained solely on sequence data. This work provides a universal continuous diffusion framework for protein sequence generation, offering both architectural insights and practical applicability across various protein design scenarios.  Code is released at\nGitHub\n.", "bibtex": "@inproceedings{\nmeshchaninov2025diffusion,\ntitle={Diffusion on Language Model Encodings for Protein Sequence Generation},\nauthor={Viacheslav Meshchaninov and Pavel Strashnov and Andrey Shevtsov and Fedor Nikolaev and Nikita Ivanisenko and Olga Kardymon and Dmitry Vetrov},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=xB9eROwBCB}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:51.318829Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Ambient Proteins - Training Diffusion Models on Noisy Structures", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Giannis Daras", "Jeffrey Ouyang-Zhang", "Krithika Ravishankar", "Constantinos Costis Daskalakis", "Adam Klivans", "Daniel Jesus Diaz"], "affinity_score": 0.5205, "link": "https://openreview.net/pdf/22b564f0323f02f1220e3bfac5d7226e465bad2c.pdf", "abstract": "We present Ambient Protein Diffusion, a framework for training protein diffusion models that generates structures with unprecedented diversity and quality. State-of-the-art generative models are trained on computationally derived structures from AlphaFold2 (AF), as experimentally determined structures are relatively scarce. The resulting models are therefore limited by the quality of synthetic datasets.  Since the accuracy of AF predictions degrades with increasing protein length and complexity, de novo generation of long, complex proteins remains challenging. Ambient Protein Diffusion overcomes this problem by treating low-confidence AF structures as corrupted data.  Rather than simply filtering out low-quality AF structures, our method adjusts the diffusion objective for each structure based on its corruption level, allowing the model to learn from both high and low quality structures. Empirically, ambient protein diffusion yields major improvements: on proteins with 700 residues, diversity increases from 45% to 85% from the previous state-of-the-art, and designability improves from 70% to 88%.", "bibtex": "@inproceedings{\ndaras2025ambient,\ntitle={Ambient Proteins - Training Diffusion Models on Noisy Structures},\nauthor={Giannis Daras and Jeffrey Ouyang-Zhang and Krithika Ravishankar and Constantinos Costis Daskalakis and Adam Klivans and Daniel Jesus Diaz},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=Xll01vw606}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:51.318834Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Antibody Design Using a Score-based Diffusion Model Guided by Evolutionary, Physical and Geometric Constraints", "venue": "ICML 2024 Poster", "year": "2024", "authors": ["Tian Zhu", "Milong Ren", "Haicang Zhang"], "affinity_score": 0.52, "link": "https://openreview.net/pdf/796235a4ba2d4cd37c4bd249f841f29243adf136.pdf", "abstract": "Antibodies are central proteins in adaptive immune responses, responsible for protecting against viruses and other pathogens. Rational antibody design has proven effective in the diagnosis and treatment of various diseases like cancers and virus infections. While recent diffusion-based generative models show promise in designing antigen-specific antibodies, the primary challenge lies in the scarcity of labeled antibody-antigen complex data and binding affinity data. We present AbX, a new score-based diffusion generative model guided by evolutionary, physical, and geometric constraints for antibody design. These constraints serve to narrow the search space and provide priors for plausible antibody sequences and structures. Specifically, we leverage a pre-trained protein language model as priors for evolutionary plausible antibodies and introduce additional training objectives for geometric and physical constraints like van der Waals forces. Furthermore, as far as we know, AbX is the first score-based diffusion model with continuous timesteps for antibody design, jointly modeling the discrete sequence space and the $\\mathrm{SE}(3)$ structure space. Evaluated on two independent testing sets, we show that AbX outperforms other published methods, achieving higher accuracy in sequence and structure generation and enhanced antibody-antigen binding affinity. Ablation studies highlight the clear contributions of the introduced constraints to antibody design.", "bibtex": "@inproceedings{\nzhu2024antibody,\ntitle={Antibody Design Using a Score-based Diffusion Model Guided by Evolutionary, Physical and Geometric Constraints},\nauthor={Tian Zhu and Milong Ren and Haicang Zhang},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=1YsQI04KaN}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:51.318839Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Tooling or Not Tooling? The Impact of Tools on Language Agents for Chemistry Problem Solving", "venue": "NAACL 2025 Findings", "year": "2025", "authors": ["Botao Yu", "Frazier N. Baker", "Ziru Chen", "Garrett Herb", "Boyu Gou", "Daniel Adu-Ampratwum", "Xia Ning", "Huan Sun"], "affinity_score": 0.5199, "link": "https://aclanthology.org/2025.findings-naacl.424/", "abstract": "To enhance large language models (LLMs) for chemistry problem solving, several LLM-based agents augmented with tools have been proposed, such as ChemCrow and Coscientist. However, their evaluations are narrow in scope, leaving a large gap in understanding the benefits of tools across diverse chemistry tasks. To bridge this gap, we develop ChemAgent, an enhanced chemistry agent over ChemCrow, and conduct a comprehensive evaluation of its performance on both specialized chemistry tasks and general chemistry questions. Surprisingly, ChemAgent does not consistently outperform its base LLMs without tools. Our error analysis with a chemistry expert suggests that: For specialized chemistry tasks, such as synthesis prediction, we should augment agents with specialized tools; however, for general chemistry questions like those in exams, agents’ ability to reason correctly with chemistry knowledge matters more, and tool augmentation does not always help.", "bibtex": "@inproceedings{yu-etal-2025-tooling,\n    title = \"Tooling or Not Tooling? The Impact of Tools on Language Agents for Chemistry Problem Solving\",\n    author = \"Yu, Botao  and\n      Baker, Frazier N.  and\n      Chen, Ziru  and\n      Herb, Garrett  and\n      Gou, Boyu  and\n      Adu-Ampratwum, Daniel  and\n      Ning, Xia  and\n      Sun, Huan\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Findings of the Association for Computational Linguistics: NAACL 2025\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.findings-naacl.424/\",\n    doi = \"10.18653/v1/2025.findings-naacl.424\",\n    pages = \"7620--7640\",\n    ISBN = \"979-8-89176-195-7\"\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:51.318843Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Proteina: Scaling Flow-based Protein Structure Generative Models", "venue": "ICLR 2025 Oral", "year": "2025", "authors": ["Tomas Geffner", "Kieran Didi", "Zuobai Zhang", "Danny Reidenbach", "Zhonglin Cao", "Jason Yim", "Mario Geiger", "Christian Dallago", "Emine Kucukbenli", "Arash Vahdat", "Karsten Kreis"], "affinity_score": 0.5194, "link": "https://openreview.net/pdf/4b7a263bc7986c92ded70f173e7809c3153445a2.pdf", "abstract": "Recently, diffusion- and flow-based generative models of protein structures have emerged as a powerful tool for de novo protein design. Here, we develop\nProteina\n, a new large-scale flow-based protein backbone generator that utilizes hierarchical fold class labels for conditioning and relies on a tailored scalable transformer architecture with up to $5\\times$ as many parameters as previous models. To meaningfully quantify performance, we introduce a new set of metrics that directly measure the distributional similarity of generated proteins with reference sets, complementing existing metrics. We further explore scaling training data to millions of synthetic protein structures and explore improved training and sampling recipes adapted to protein backbone generation. This includes fine-tuning strategies like LoRA for protein backbones, new guidance methods like classifier-free guidance and autoguidance for protein backbones, and new adjusted training objectives. Proteina achieves state-of-the-art performance on de novo protein backbone design and produces diverse and designable proteins at unprecedented length, up to 800 residues. The hierarchical conditioning offers novel control, enabling high-level secondary-structure guidance as well as low-level fold-specific generation.", "bibtex": "@inproceedings{\ngeffner2025proteina,\ntitle={Proteina: Scaling Flow-based Protein Structure Generative Models},\nauthor={Tomas Geffner and Kieran Didi and Zuobai Zhang and Danny Reidenbach and Zhonglin Cao and Jason Yim and Mario Geiger and Christian Dallago and Emine Kucukbenli and Arash Vahdat and Karsten Kreis},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=TVQLu34bdw}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:52.260553Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Retrieval Augmented Diffusion Model for Structure-informed Antibody Design and Optimization", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Zichen Wang", "Yaokun Ji", "Jianing Tian", "Shuangjia Zheng"], "affinity_score": 0.5194, "link": "https://openreview.net/pdf/f2d4951e515ad2b997b256831ed11bb5b5ce58b6.pdf", "abstract": "Antibodies are essential proteins responsible for immune responses in organisms, capable of specifically recognizing antigen molecules of pathogens. Recent advances in generative models have significantly enhanced rational antibody design. However, existing methods mainly create antibodies from scratch without template constraints, leading to model optimization challenges and unnatural sequences. To address these issues, we propose a retrieval-augmented diffusion framework, termed RADAb, for efficient antibody design. Our method leverages a set of structural homologous motifs that align with query structural constraints to guide the generative model in inversely optimizing antibodies according to desired design criteria. Specifically, we introduce a structure-informed retrieval mechanism that integrates these exemplar motifs with the input backbone through a novel dual-branch denoising module, utilizing both structural and evolutionary information. Additionally, we develop a conditional diffusion model that iteratively refines the optimization process by incorporating both global context and local evolutionary conditions. Our approach is agnostic to the choice of generative models. Empirical experiments demonstrate that our method achieves state-of-the-art performance in multiple antibody inverse folding and optimization tasks, offering a new perspective on biomolecular generative models.", "bibtex": "@inproceedings{\nwang2025retrieval,\ntitle={Retrieval Augmented Diffusion Model for Structure-informed Antibody Design and Optimization},\nauthor={Zichen Wang and Yaokun Ji and Jianing Tian and Shuangjia Zheng},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=a6U41REOa5}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:52.260567Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Rationalized All-Atom Protein Design with Unified Multi-Modal Bayesian Flow", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Hanlin Wu", "Yuxuan Song", "Zhe Zhang", "Zhilong Zhang", "Hao Zhou", "Wei-Ying Ma", "Jingjing Liu"], "affinity_score": 0.5193, "link": "https://openreview.net/pdf/5427b0c4461e72ab1d2de811fb8dc817639a8e83.pdf", "abstract": "Designing functional proteins is a critical yet challenging problem due to the intricate interplay between backbone structures, sequences, and side-chains. Current approaches often decompose protein design into separate tasks, which can lead to accumulated errors, while recent efforts increasingly focus on all-atom protein design. However, we observe that existing all-atom generation approaches suffering from an information shortcut issue, where models inadvertently infer sequences from side-chain information, compromising their ability to accurately learn sequence distributions. To address this, we introduce a novel rationalized information flow strategy to eliminate the information shortcut. Furthermore, motivated by the advantages of Bayesian flows over differential equation–based methods, we propose the first Bayesian flow formulation for protein backbone orientations by recasting orientation modeling as an equivalent hyperspherical generation problem with antipodal symmetry. To validate, our method delivers consistently exceptional performance in both peptide and antibody design tasks.", "bibtex": "@inproceedings{\nwu2025rationalized,\ntitle={Rationalized All-Atom Protein Design with Unified Multi-Modal Bayesian Flow},\nauthor={Hanlin Wu and Yuxuan Song and Zhe Zhang and Zhilong Zhang and Hao Zhou and Wei-Ying Ma and Jingjing Liu},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=3p4272zl7q}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:52.260571Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Str2Str: A Score-based Framework for Zero-shot Protein Conformation Sampling", "venue": "ICLR 2024 Poster", "year": "2024", "authors": ["Jiarui Lu", "Bozitao Zhong", "Zuobai Zhang", "Jian Tang"], "affinity_score": 0.5193, "link": "https://openreview.net/pdf/8af65d24f25a4b2e78702b1efb981126bd3bf160.pdf", "abstract": "The dynamic nature of proteins is crucial for determining their biological functions and properties, for which Monte Carlo (MC) and molecular dynamics (MD) simulations stand as predominant tools to study such phenomena. By utilizing empirically derived force fields, MC or MD simulations explore the conformational space through numerically evolving the system via Markov chain or Newtonian mechanics. However, the high-energy barrier of the force fields can hamper the exploration of both methods by the rare event, resulting in inadequately sampled ensemble without exhaustive running. Existing learning-based approaches perform direct sampling yet heavily rely on target-specific simulation data for training, which suffers from high data acquisition cost and poor generalizability. Inspired by simulated annealing, we propose Str2Str, a novel structure-to-structure translation framework capable of zero-shot conformation sampling with roto-translation equivariant property. Our method leverages an amortized denoising score matching objective trained on general crystal structures and has no reliance on simulation data during both training and inference. Experimental results across several benchmarking protein systems demonstrate that Str2Str outperforms previous state-of-the-art generative structure prediction models and can be orders of magnitude faster compared with long MD simulations.", "bibtex": "@inproceedings{\nlu2024strstr,\ntitle={Str2Str: A Score-based Framework for Zero-shot Protein Conformation Sampling},\nauthor={Jiarui Lu and Bozitao Zhong and Zuobai Zhang and Jian Tang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=C4BikKsgmK}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:52.260575Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ProtInvTree: Deliberate Protein Inverse Folding with Reward-guided Tree Search", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Mengdi Liu", "Xiaoxue Cheng", "Zhangyang Gao", "Hong Chang", "Cheng Tan", "Shiguang Shan", "Xilin Chen"], "affinity_score": 0.5183, "link": "https://openreview.net/pdf/b08774914ebce1eaef7904832504cd7677145d30.pdf", "abstract": "Designing protein sequences that fold into a target 3D structure—known as protein inverse folding—is a fundamental challenge in protein engineering. While recent deep learning methods have achieved impressive performance by recovering native sequences, they often overlook the one-to-many nature of the problem: multiple diverse sequences can fold into the same structure. This motivates the need for a generative model capable of designing diverse sequences while preserving structural consistency. To address this trade-off, we introduce ProtInvTree, the first reward-guided tree-search framework for protein inverse folding. ProtInvTree reformulates sequence generation as a deliberate, step-wise decision-making process, enabling the exploration of multiple design paths and exploitation of promising candidates through self-evaluation, lookahead, and backtracking. We propose a two-stage focus-and-grounding action mechanism that decouples position selection and residue generation. To efficiently evaluate intermediate states, we introduce a jumpy denoising strategy that avoids full rollouts. Built upon pretrained protein language models, ProtInvTree supports flexible test-time scaling by adjusting the search depth and breadth without retraining. Empirically, ProtInvTree outperforms state-of-the-art baselines across multiple benchmarks, generating structurally consistent yet diverse sequences, including those far from the native ground truth. The code is available at https://github.com/A4Bio/ProteinInvBench/.", "bibtex": "@inproceedings{\nliu2025protinvtree,\ntitle={ProtInvTree: Deliberate Protein Inverse Folding with Reward-guided Tree Search},\nauthor={Mengdi Liu and Xiaoxue Cheng and Zhangyang Gao and Hong Chang and Cheng Tan and Shiguang Shan and Xilin Chen},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=2uKVyGq5zK}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:52.260579Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Aligning Protein Conformation Ensemble Generation with Physical Feedback", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Jiarui Lu", "Xiaoyin Chen", "Stephen Zhewen Lu", "Aurelie Lozano", "Vijil Chenthamarakshan", "Payel Das", "Jian Tang"], "affinity_score": 0.5171, "link": "https://openreview.net/pdf/7edee416678ec73f1c03c4b207395eaed75298d3.pdf", "abstract": "Protein dynamics play a crucial role in protein biological functions and properties, and their traditional study typically relies on time-consuming molecular dynamics (MD) simulations conducted in silico. Recent advances in generative modeling, particularly denoising diffusion models, have enabled efficient accurate protein structure prediction and conformation sampling by learning distributions over crystallographic structures. However, effectively integrating physical supervision into these data-driven approaches remains challenging, as standard energy-based objectives often lead to intractable optimization. In this paper, we introduce Energy-based Alignment (EBA), a method that aligns generative models with feedback from physical models, efficiently calibrating them to appropriately balance conformational states based on their energy differences. Experimental results on the MD ensemble benchmark demonstrate that EBA achieves state-of-the-art performance in generating high-quality protein ensembles. By improving the physical plausibility of generated structures, our approach enhances model predictions and holds promise for applications in structural biology and drug discovery.", "bibtex": "@inproceedings{\nlu2025aligning,\ntitle={Aligning Protein Conformation Ensemble Generation with Physical Feedback},\nauthor={Jiarui Lu and Xiaoyin Chen and Stephen Zhewen Lu and Aurelie Lozano and Vijil Chenthamarakshan and Payel Das and Jian Tang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=Asr955jcuZ}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:52.260583Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Generative Enzyme Design Guided by Functionally Important Sites and Small-Molecule Substrates", "venue": "ICML 2024 Poster", "year": "2024", "authors": ["Zhenqiao Song", "Yunlong Zhao", "Wenxian Shi", "Wengong Jin", "Yang Yang", "Lei Li"], "affinity_score": 0.5168, "link": "https://openreview.net/pdf/b349f5504ef1e6143231064979e2e96feaf5a6a9.pdf", "abstract": "Enzymes are genetically encoded biocatalysts capable of accelerating chemical reactions. How can we automatically design functional enzymes? In this paper, we propose EnzyGen, an approach to learn a unified model to design enzymes across all functional families. Our key idea is to generate an enzyme's amino acid sequence and their three-dimensional (3D) coordinates based on functionally important sites and substrates corresponding to a desired catalytic function. These sites are automatically mined from enzyme databases. EnzyGen consists of a novel interleaving network of attention and neighborhood equivariant layers, which captures both long-range correlation in an entire protein sequence and local influence from nearest amino acids in 3D space. To learn the generative model, we devise a joint training objective, including a sequence generation loss, a position prediction loss and an enzyme-substrate interaction loss. We further construct EnzyBench, a dataset with 3157 enzyme families, covering all available enzymes within the protein data bank (PDB). Experimental results show that our EnzyGen consistently achieves the best performance across all 323 testing families, surpassing the best baseline by 10.79% in terms of substrate binding affinity. These findings demonstrate EnzyGen's superior capability in designing well-folded and effective enzymes binding to specific substrates with high affinities. Our code, model and dataset are provided at https://github.com/LeiLiLab/EnzyGen.", "bibtex": "@inproceedings{\nsong2024generative,\ntitle={Generative Enzyme Design Guided by Functionally Important Sites and Small-Molecule Substrates},\nauthor={Zhenqiao Song and Yunlong Zhao and Wenxian Shi and Wengong Jin and Yang Yang and Lei Li},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=ATvN9JnqZ8}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:52.260587Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ProtComposer: Compositional Protein Structure Generation with 3D Ellipsoids", "venue": "ICLR 2025 Oral", "year": "2025", "authors": ["Hannes Stark", "Bowen Jing", "Tomas Geffner", "Jason Yim", "Tommi Jaakkola", "Arash Vahdat", "Karsten Kreis"], "affinity_score": 0.5162, "link": "https://openreview.net/pdf/3cd76a5f12a43a2296132178c1a97bad7e141588.pdf", "abstract": "We develop ProtComposer to generate protein structures conditioned on spatial protein layouts that are specified via a set of 3D ellipsoids capturing substructure shapes and semantics. At inference time, we condition on ellipsoids that are hand-constructed, extracted from existing proteins, or from a statistical model, with each option unlocking new capabilities. Hand-specifying ellipsoids enables users to control the location, size, orientation, secondary structure, and approximate shape of protein substructures. Conditioning on ellipsoids of existing proteins enables redesigning their substructure's connectivity or editing substructure properties. By conditioning on novel and diverse ellipsoid layouts from a simple statistical model, we improve protein generation with expanded Pareto frontiers between designability, novelty, and diversity. Further, this enables sampling designable proteins with a helix-fraction that matches PDB proteins, unlike existing generative models that commonly oversample conceptually simple helix bundles. Code is available at https://github.com/NVlabs/protcomposer.", "bibtex": "@inproceedings{\nstark2025protcomposer,\ntitle={ProtComposer: Compositional Protein Structure Generation with 3D Ellipsoids},\nauthor={Hannes Stark and Bowen Jing and Tomas Geffner and Jason Yim and Tommi Jaakkola and Arash Vahdat and Karsten Kreis},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=0ctvBgKFgc}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:52.260591Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Implicitly Guided Design with PropEn: Match your Data to Follow the Gradient", "venue": "NeurIPS 2024 Poster", "year": "2024", "authors": ["Natasa Tagasovska", "Vladimir Gligorijevic", "Kyunghyun Cho", "Andreas Loukas"], "affinity_score": 0.5156, "link": "https://openreview.net/pdf/8a38f93e4d74653c3c0b602b283100aaa3519666.pdf", "abstract": "Across scientific domains, generating new models or optimizing existing ones while meeting specific criteria is crucial. Traditional machine learning frameworks for guided design use a generative model and a surrogate model (discriminator), requiring large datasets. However, real-world scientific applications often have limited data and complex landscapes, making data-hungry models inefficient or impractical. We propose a new framework, PropEn, inspired by ``matching'', which enables implicit guidance without training a discriminator. By matching each sample with a similar one that has a better property value, we create a larger training dataset that inherently indicates the direction of improvement. Matching, combined with an encoder-decoder architecture, forms a domain-agnostic generative framework for property enhancement. We show that training with a matched dataset approximates the gradient of the property of interest while remaining within the data distribution, allowing efficient design optimization. Extensive evaluations in toy problems and scientific applications, such as therapeutic protein design and airfoil optimization, demonstrate PropEn's advantages over common baselines. Notably, the protein design results are validated with wet lab experiments, confirming the competitiveness and effectiveness of our approach. Our code is available at https://github.com/prescient-design/propen.", "bibtex": "@inproceedings{\ntagasovska2024implicitly,\ntitle={Implicitly Guided Design with PropEn: Match your Data to Follow the Gradient},\nauthor={Natasa Tagasovska and Vladimir Gligorijevic and Kyunghyun Cho and Andreas Loukas},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=dhFHO90INk}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:52.260595Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Aditya Sengar", "Ali Hariri", "Daniel Probst", "PATRICK BARTH", "Pierre Vandergheynst"], "affinity_score": 0.5152, "link": "https://openreview.net/pdf/a98baeaa5867971c7e7ebb650d1d64686abf8c93.pdf", "abstract": "Generating diverse, all‐atom conformational ensembles of dynamic proteins such as G‐protein‐coupled receptors (GPCRs) is critical for understanding their function, yet most generative models simplify atomic detail or ignore conformational diversity altogether. We present latent diffusion for full protein generation (LD-FPG), a framework that constructs complete all‐atom protein structures, including every side‐chain heavy atom, directly from molecular dynamics (MD) trajectories. LD-FPG employs a Chebyshev graph neural network (ChebNet) to obtain low‐dimensional latent embeddings of protein conformations, which are processed using three pooling strategies: blind, sequential and residue‐based. A diffusion model trained on these latent representations generates new samples that a decoder, optionally regularized by dihedral‐angle losses, maps back to Cartesian coordinates. Using D2R-MD, a $2\\mu\\text{s}$ MD trajectory (12 000 frames) of the human dopamine D$2$ receptor in a membrane environment, the sequential and residue-based pooling strategies reproduce the reference ensemble with high structural fidelity (all‐atom lDDT \\~ $0.7$; $C\\alpha$-lDDT \\~ $0.8$) and recovers backbone and side‐chain dihedral‐angle distributions with a Jensen–Shannon divergence $<0.03$ compared to the MD data. LD-FPG thereby offers a practical route to system‐specific, all‐atom ensemble generation for large proteins, providing a promising tool for structure‐based therapeutic design on complex, dynamic targets. The D2R-MD dataset and our implementation are freely available to facilitate further research.", "bibtex": "@inproceedings{\nsengar2025generative,\ntitle={Generative Modeling of Full-Atom Protein Conformations using Latent Diffusion on Graph Embeddings},\nauthor={Aditya Sengar and Ali Hariri and Daniel Probst and PATRICK BARTH and Pierre Vandergheynst},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=JPjMXgQQxk}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:52.260598Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Learning to engineer protein flexibility", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Petr Kouba", "Joan Planas-Iglesias", "Jiri Damborsky", "Jiri Sedlar", "Stanislav Mazurenko", "Josef Sivic"], "affinity_score": 0.5136, "link": "https://openreview.net/pdf/f203c4b413d1e4b8ee51ba095228ec49eb548e2d.pdf", "abstract": "Generative machine learning models are increasingly being used to design novel proteins. However, their major limitation is the inability to account for protein flexibility, a property crucial for protein-function. Learning to engineer flexibility is difficult because the relevant data is scarce, heterogeneous, and costly to obtain using computational and experimental methods. Our contributions are three-fold. First, we perform a comprehensive comparison of methods for evaluating protein flexibility and identify relevant data for learning. Second, we overcome the data scarcity issue by leveraging a pre-trained protein language model. We design and train flexibility predictors utilizing either only sequential or both sequential and structural information on the input. Third, we introduce a method for fine-tuning a protein inverse folding model to make it steerable toward desired flexibility at specified regions. We demonstrate that our method Flexpert enables guidance of inverse folding models toward increased flexibility. This opens up a transformative possibility of engineering protein flexibility.", "bibtex": "@inproceedings{\nkouba2025learning,\ntitle={Learning to engineer protein flexibility},\nauthor={Petr Kouba and Joan Planas-Iglesias and Jiri Damborsky and Jiri Sedlar and Stanislav Mazurenko and Josef Sivic},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=L238BAx0wP}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:53.210365Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ProtT3: Protein-to-Text Generation for Text-based Protein Understanding", "venue": "ACL 2024 Long", "year": "2024", "authors": ["Zhiyuan Liu", "An Zhang", "Hao Fei", "Enzhi Zhang", "Xiang Wang", "Kenji Kawaguchi", "Tat-Seng Chua"], "affinity_score": 0.5129, "link": "https://aclanthology.org/2024.acl-long.324/", "abstract": "Language Models (LMs) excel in understanding textual descriptions of proteins, as evident in biomedical question-answering tasks. However, their capability falters with raw protein data, such as amino acid sequences, due to a deficit in pretraining on such data. Conversely, Protein Language Models (PLMs) can understand and convert protein data into high-quality representations, but struggle to process texts. To address their limitations, we introduce ProtT3, a framework for Protein-to-Text Generation for Text-based Protein Understanding. ProtT3 empowers an LM to understand protein sequences of amino acids by incorporating a PLM as its protein understanding module, enabling effective protein-to-text generation. This collaboration between PLM and LM is facilitated by a cross-modal projector (i.e., Q-Former) that bridges the modality gap between the PLM’s representation space and the LM’s input space. Unlike previous studies focusing on protein property prediction and protein-text retrieval, we delve into the largely unexplored field of protein-to-text generation. To facilitate comprehensive benchmarks and promote future research, we establish quantitative evaluations for protein-text modeling tasks, including protein captioning, protein question-answering, and protein-text retrieval. Our experiments show that ProtT3 substantially surpasses current baselines, with ablation studies further highlighting the efficacy of its core components. Our code is available at https://github.com/acharkq/ProtT3.", "bibtex": "@inproceedings{liu-etal-2024-prott3,\n    title = \"{P}rot{T}3: Protein-to-Text Generation for Text-based Protein Understanding\",\n    author = \"Liu, Zhiyuan  and\n      Zhang, An  and\n      Fei, Hao  and\n      Zhang, Enzhi  and\n      Wang, Xiang  and\n      Kawaguchi, Kenji  and\n      Chua, Tat-Seng\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.acl-long.324/\",\n    doi = \"10.18653/v1/2024.acl-long.324\",\n    pages = \"5949--5966\"\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:53.210377Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Edan Toledo", "Karen Hambardzumyan", "Martin Josifoski", "RISHI HAZRA", "Nicolas Baldwin", "Alexis Audran-Reiss", "Michael Kuchnik", "Despoina Magka", "Minqi Jiang", "Alisia Maria Lupidi", "Andrei Lupu", "Roberta Raileanu", "Tatiana Shavrina", "Kelvin Niu", "Jean-Christophe Gagnon-Audet", "Michael Shvartsman", "Shagun Sodhani", "Alexander H Miller", "Abhishek Charnalia", "Derek Dunfield", "Carole-Jean Wu", "Pontus Stenetorp", "Nicola Cancedda", "Jakob Nicolaus Foerster", "Yoram Bachrach"], "affinity_score": 0.512, "link": "https://openreview.net/pdf/a22e34894b1de174131d79168e9a32bf5fefd3a5.pdf", "abstract": "AI research agents are demonstrating great potential to accelerate scientific progress by automating the design, implementation, and training of machine learning models. We focus on methods for improving agents' performance on MLE-bench, a challenging benchmark where agents compete in Kaggle competitions to solve real-world machine learning problems. We formalize AI research agents as search policies that navigate a space of candidate solutions, iteratively modifying them using operators. By designing and systematically varying different operator sets and search policies (Greedy, MCTS, Evolutionary), we show that their interplay is critical for achieving high performance. Our best pairing of search strategy and operator set achieves a state-of-the-art result on MLE-bench lite, increasing the success rate of achieving a Kaggle medal from 39.6% to 47.7%. Our investigation underscores the importance of jointly considering the search strategy, operator design, and evaluation methodology in advancing automated machine learning.", "bibtex": "@inproceedings{\ntoledo2025ai,\ntitle={{AI} Research Agents for Machine Learning: Search, Exploration, and Generalization in {MLE}-bench},\nauthor={Edan Toledo and Karen Hambardzumyan and Martin Josifoski and RISHI HAZRA and Nicolas Baldwin and Alexis Audran-Reiss and Michael Kuchnik and Despoina Magka and Minqi Jiang and Alisia Maria Lupidi and Andrei Lupu and Roberta Raileanu and Tatiana Shavrina and Kelvin Niu and Jean-Christophe Gagnon-Audet and Michael Shvartsman and Shagun Sodhani and Alexander H Miller and Abhishek Charnalia and Derek Dunfield and Carole-Jean Wu and Pontus Stenetorp and Nicola Cancedda and Jakob Nicolaus Foerster and Yoram Bachrach},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=RwfrdKSgCE}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:53.210381Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Retrieved Sequence Augmentation for Protein Representation Learning", "venue": "EMNLP 2024 Main", "year": "2024", "authors": ["Chang Ma", "Haiteng Zhao", "Lin Zheng", "Jiayi Xin", "Qintong Li", "Lijun Wu", "Zhi-Hong Deng", "Yang Young Lu", "Qi Liu", "Sheng Wang", "Lingpeng Kong"], "affinity_score": 0.5113, "link": "https://aclanthology.org/2024.emnlp-main.104/", "abstract": "Protein Language Models traditionally depend on Multiple Sequence Alignments (MSA) to incorporate evolutionary knowledge. However, MSA-based approaches suffer from substantial computational overhead and generally underperform in generalizing to de novo proteins. This study reevaluates the role of MSA, proposing it as a retrieval augmentation method and questioning the necessity of sequence alignment. We show that a simple alternative, Retrieved Sequence Augmentation (RSA), can enhance protein representation learning without the need for alignment and cumbersome preprocessing. RSA surpasses MSA Transformer by an average of 5% in both structural and property prediction tasks while being 373 times faster. Additionally, RSA demonstrates enhanced transferability for predicting de novo proteins. This methodology addresses a critical need for efficiency in protein prediction and can be rapidly employed to identify homologous sequences, improve representation learning, and enhance the capacity of Large Language Models to interpret protein structures.", "bibtex": "@inproceedings{ma-etal-2024-retrieved,\n    title = \"Retrieved Sequence Augmentation for Protein Representation Learning\",\n    author = \"Ma, Chang  and\n      Zhao, Haiteng  and\n      Zheng, Lin  and\n      Xin, Jiayi  and\n      Li, Qintong  and\n      Wu, Lijun  and\n      Deng, Zhihong  and\n      Lu, Yang Young  and\n      Liu, Qi  and\n      Wang, Sheng  and\n      Kong, Lingpeng\",\n    editor = \"Al-Onaizan, Yaser  and\n      Bansal, Mohit  and\n      Chen, Yun-Nung\",\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\n    month = nov,\n    year = \"2024\",\n    address = \"Miami, Florida, USA\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.emnlp-main.104/\",\n    doi = \"10.18653/v1/2024.emnlp-main.104\",\n    pages = \"1738--1767\"\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:53.210384Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Scaling Unlocks Broader Generation and Deeper Functional Understanding of Proteins", "venue": "NeurIPS 2025 Spotlight", "year": "2025", "authors": ["Aadyot Bhatnagar", "Sarthak Jain", "Joel Beazer", "Samuel C. Curran", "Alexander M. Hoffnagle", "Kyle Shan Ching", "Michael Martyn", "Stephen Nayfach", "Jeffrey A. Ruffolo", "Ali Madani"], "affinity_score": 0.5107, "link": "https://openreview.net/pdf/e39feef56ff28883049bd1ddc3b506a53fcaba90.pdf", "abstract": "Generative protein language models (PLMs) are powerful tools for designing proteins purpose-built to solve problems in medicine, agriculture, and industrial processes.\nRecent work has trained ever larger language models, but there has been little systematic study of the optimal training distributions and the influence of model scale on the sequences generated by PLMs.\nWe introduce the ProGen3 family of sparse generative PLMs, and we develop compute-optimal scaling laws to scale up to a 46B-parameter model pre-trained on 1.5T amino acid tokens.\nProGen3's pre-training data is sampled from an optimized data distribution over the PPA v1, a carefully curated dataset of 3.4B full-length proteins. \nWe evaluate for the first time in the wet lab the influence of model scale on the sequences generated by PLMs, and we find that larger models generate viable proteins for a much wider diversity of protein families.\nFinally, we find both computationally and experimentally that larger models are more responsive to alignment with laboratory data, resulting in improved protein fitness prediction and sequence generation capabilities.\nThese results indicate that larger PLMs like ProGen3-46B trained on larger, well-curated datasets are powerful foundation models that push the frontier of protein design.", "bibtex": "@inproceedings{\nbhatnagar2025scaling,\ntitle={Scaling Unlocks Broader Generation and Deeper Functional Understanding of Proteins},\nauthor={Aadyot Bhatnagar and Sarthak Jain and Joel Beazer and Samuel C. Curran and Alexander M. Hoffnagle and Kyle Shan Ching and Michael Martyn and Stephen Nayfach and Jeffrey A. Ruffolo and Ali Madani},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=yvGL2HP7pU}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:53.210387Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Unified all-atom molecule generation with neural fields", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Matthieu Kirchmeyer", "Pedro O. Pinheiro", "Emma Willett", "Karolis Martinkus", "Joseph Kleinhenz", "Emily K. Makowski", "Andrew Martin Watkins", "Vladimir Gligorijevic", "Richard Bonneau", "Saeed Saremi"], "affinity_score": 0.5077, "link": "https://openreview.net/pdf/6635b183138e1f0d25dfd02911c6d87234a8b01e.pdf", "abstract": "Generative models for structure-based drug design are often limited to a specific modality, restricting their broader applicability. To address this challenge, we introduce FuncBind, a framework based on computer vision to generate target-conditioned, all-atom molecules across atomic systems. FuncBind uses neural fields to represent molecules as continuous atomic densities and employs score-based generative models with modern architectures adapted from the computer vision literature. This modality-agnostic representation allows a single unified model to be trained on diverse atomic systems, from small to large molecules, and handle variable atom/residue counts, including non-canonical amino acids. FuncBind achieves competitive in silico performance in generating small molecules, macrocyclic peptides, and antibody complementarity-determining region loops, conditioned on target structures. FuncBind also generated in vitro novel antibody binders via de novo redesign of the complementarity-determining region H3 loop of two chosen co-crystal structures. As a final contribution, we introduce a new dataset and benchmark for structure-conditioned macrocyclic peptide generation.", "bibtex": "@inproceedings{\nkirchmeyer2025unified,\ntitle={Unified all-atom molecule generation with neural fields},\nauthor={Matthieu Kirchmeyer and Pedro O. Pinheiro and Emma Willett and Karolis Martinkus and Joseph Kleinhenz and Emily K. Makowski and Andrew Martin Watkins and Vladimir Gligorijevic and Richard Bonneau and Saeed Saremi},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=JMq90N6lLe}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:53.210390Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Haoyang Su", "Renqi Chen", "Shixiang Tang", "Zhenfei Yin", "Xinzhe Zheng", "Jinzhe Li", "Biqing Qi", "Qi Wu", "Hui Li", "Wanli Ouyang", "Philip Torr", "Bowen Zhou", "Nanqing Dong"], "affinity_score": 0.5069, "link": "https://aclanthology.org/2025.acl-long.1368/", "abstract": "The rapid advancement of scientific progress requires innovative tools that can accelerate knowledge discovery. Although recent AI methods, particularly large language models (LLMs), have shown promise in tasks such as hypothesis generation and experimental design, they fall short of replicating the collaborative nature of real-world scientific practices, where diverse experts work together in teams to tackle complex problems. To address the limitations, we propose an LLM-based multi-agent system, i.e., Virtual Scientists (VIRSCI), designed to mimic the teamwork inherent in scientific research. VIRSCI organizes a team of agents to collaboratively generate, evaluate, and refine research ideas. Through comprehensive experiments, we demonstrate that this multi-agent approach outperforms the state-of-the-art method in producing novel scientific ideas. We further investigate the collaboration mechanisms that contribute to its tendency to produce ideas with higher novelty, offering valuable insights to guide future research and illuminating pathways toward building a robust system for autonomous scientific discovery. The code is available at https://github.com/open-sciencelab/Virtual-Scientists.", "bibtex": "@inproceedings{su-etal-2025-many,\n    title = \"Many Heads Are Better Than One: Improved Scientific Idea Generation by A {LLM}-Based Multi-Agent System\",\n    author = \"Su, Haoyang  and\n      Chen, Renqi  and\n      Tang, Shixiang  and\n      Yin, Zhenfei  and\n      Zheng, Xinzhe  and\n      Li, Jinzhe  and\n      Qi, Biqing  and\n      Wu, Qi  and\n      Li, Hui  and\n      Ouyang, Wanli  and\n      Torr, Philip  and\n      Zhou, Bowen  and\n      Dong, Nanqing\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1368/\",\n    doi = \"10.18653/v1/2025.acl-long.1368\",\n    pages = \"28201--28240\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:53.210393Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "MMSite: A Multi-modal Framework for the Identification of Active Sites in Proteins", "venue": "NeurIPS 2024 Poster", "year": "2024", "authors": ["Song Ouyang", "Huiyu Cai", "Yong Luo", "Kehua Su", "Lefei Zhang", "Bo Du"], "affinity_score": 0.5065, "link": "https://openreview.net/pdf/bed87ee8878ddba7d48aae1e57c504b09040e052.pdf", "abstract": "The accurate identification of active sites in proteins is essential for the advancement of life sciences and pharmaceutical development, as these sites are of critical importance for enzyme activity and drug design. Recent advancements in protein language models (PLMs), trained on extensive datasets of amino acid sequences, have significantly improved our understanding of proteins. However, compared to the abundant protein sequence data, functional annotations, especially precise per-residue annotations, are scarce, which limits the performance of PLMs. On the other hand, textual descriptions of proteins, which could be annotated by human experts or a pretrained protein sequence-to-text model, provide meaningful context that could assist in the functional annotations, such as the localization of active sites. This motivates us to construct a $\\textbf{ProT}$ein-$\\textbf{A}$ttribute text $\\textbf{D}$ataset ($\\textbf{ProTAD}$), comprising over 570,000 pairs of protein sequences and multi-attribute textual descriptions. Based on this dataset, we propose $\\textbf{MMSite}$, a multi-modal framework that improves the performance of PLMs to identify active sites by leveraging biomedical language models (BLMs). In particular, we incorporate manual prompting and design a MACross module to deal with the multi-attribute characteristics of textual descriptions. MMSite is a two-stage (\"First Align, Then Fuse\") framework: first aligns the textual modality with the sequential modality through soft-label alignment, and then identifies active sites via multi-modal fusion. Experimental results demonstrate that MMSite achieves state-of-the-art performance compared to existing protein representation learning methods. The dataset and code implementation are available at https://github.com/Gift-OYS/MMSite.", "bibtex": "@inproceedings{\nouyang2024mmsite,\ntitle={{MMS}ite: A Multi-modal Framework for the Identification of Active Sites in Proteins},\nauthor={Song Ouyang and Huiyu Cai and Yong Luo and Kehua Su and Lefei Zhang and Bo Du},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=XHdwlbNSVb}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:53.210396Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Boosting Protein Graph Representations through Static-Dynamic Fusion", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Pengkang Guo", "Bruno Correia", "Pierre Vandergheynst", "Daniel Probst"], "affinity_score": 0.5065, "link": "https://openreview.net/pdf/001945ff4d54a973e8ae12ca0b731eddfba38767.pdf", "abstract": "Machine learning for protein modeling faces significant challenges due to proteins' inherently dynamic nature, yet most graph-based machine learning methods rely solely on static structural information. Recently, the growing availability of molecular dynamics trajectories provides new opportunities for understanding the dynamic behavior of proteins; however, computational methods for utilizing this dynamic information remain limited. We propose a novel graph representation that integrates both static structural information and dynamic correlations from molecular dynamics trajectories, enabling more comprehensive modeling of proteins. By applying relational graph neural networks (RGNNs) to process this heterogeneous representation, we demonstrate significant improvements over structure-based approaches across three distinct tasks: atomic adaptability prediction, binding site detection, and binding affinity prediction. Our results validate that combining static and dynamic information provides complementary signals for understanding protein-ligand interactions, offering new possibilities for drug design and structural biology applications.", "bibtex": "@inproceedings{\nguo2025boosting,\ntitle={Boosting Protein Graph Representations through Static-Dynamic Fusion},\nauthor={Pengkang Guo and Bruno Correia and Pierre Vandergheynst and Daniel Probst},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=QbtBIE36Fd}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:53.210398Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Towards Stable Representations for Protein Interface Prediction", "venue": "NeurIPS 2024 Poster", "year": "2024", "authors": ["Ziqi Gao", "Zijing Liu", "Yu Li", "Jia Li"], "affinity_score": 0.5057, "link": "https://openreview.net/pdf/3bcb6350ee8d48b26c40ab54d9ccc40843ecc595.pdf", "abstract": "The knowledge of protein interactions is crucial but challenging for drug discovery applications. This work focuses on protein interface prediction, which aims to determine whether a pair of residues from different proteins interact. Existing data-driven methods have made significant progress in effectively learning protein structures. Nevertheless, they overlook the conformational changes (i.e., flexibility) within proteins upon binding, leading to poor generalization ability. In this paper, we regard the protein flexibility as an attack on the trained model and aim to defend against it for improved generalization. To fulfill this purpose, we propose ATProt, an adversarial training framework for protein representations to robustly defend against the attack of protein flexibility. ATProt can theoretically guarantee protein representation stability under complicated protein flexibility. Experiments on various benchmarks demonstrate that ATProt consistently improves the performance for protein interface prediction. Moreover, our method demonstrates broad applicability, performing the best even when provided with testing structures from structure prediction models like ESMFold and AlphaFold2.", "bibtex": "@inproceedings{\ngao2024towards,\ntitle={Towards Stable Representations for Protein Interface Prediction},\nauthor={Ziqi Gao and Zijing Liu and Yu Li and Jia Li},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=OEWBkLrRZu}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:53.210401Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Deep Signature: Characterization of Large-Scale Molecular Dynamics", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Tiexin Qin", "Mengxu ZHU", "Chunyang Li", "Terry Lyons", "Hong Yan", "Haoliang Li"], "affinity_score": 0.5037, "link": "https://openreview.net/pdf/1ec2cb7c6b2e39febe219118760ddcbcef3ee3a4.pdf", "abstract": "Understanding protein dynamics are essential for deciphering protein-functional mechanisms and developing molecular therapies. However, the complex high-dimensional dynamics and interatomic interactions of biological processes pose significant challenge for existing computational techniques. In this paper, we approach this problem for the first time by introducing Deep Signature, a novel computationally tractable framework that characterizes complex dynamics and interatomic interactions based on their evolving trajectories. Specifically, our approach incorporates soft spectral clustering that locally aggregates cooperative dynamics to reduce the size of the system, as well as signature transform that collects iterated integrals to provide a global characterization of the non-smooth interactive dynamics. Theoretical analysis demonstrates that Deep Signature exhibits several desirable properties, including invariance to translation, near invariance to rotation, equivariance to permutation of atomic coordinates, and invariance under time reparameterization. Furthermore, experimental results on three benchmarks of biological processes verify that our approach can achieve superior performance compared to baseline methods.", "bibtex": "@inproceedings{\nqin2025deep,\ntitle={Deep Signature: Characterization of Large-Scale Molecular Dynamics},\nauthor={Tiexin Qin and Mengxu ZHU and Chunyang Li and Terry Lyons and Hong Yan and Haoliang Li},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=xayT1nn8Mg}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:54.170624Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "De novo Protein Design Using Geometric Vector Field Networks", "venue": "ICLR 2024 Spotlight", "year": "2024", "authors": ["Weian Mao", "Muzhi Zhu", "Zheng Sun", "Shuaike Shen", "Lin Yuanbo Wu", "Hao Chen", "Chunhua Shen"], "affinity_score": 0.503, "link": "https://openreview.net/pdf/88687a41b251ea3e5018907ebe06860c15e31ff3.pdf", "abstract": "Advances like protein diffusion have marked revolutionary progress in $\\textit{de novo}$ protein design, a central topic in life science. These methods typically depend on protein structure encoders to model residue backbone frames, where atoms do not exist. Most prior encoders rely on atom-wise features, such as angles and distances between atoms, which are not available in this context. Only a few basic encoders, like IPA, have been proposed for this scenario, exposing the frame modeling as a bottleneck. In this work, we introduce the Vector Field Network (VFN), that enables network layers to perform learnable vector computations between coordinates of frame-anchored virtual atoms, thus achieving a higher capability for modeling frames. The vector computation operates in a manner similar to a linear layer, with each input channel receiving 3D virtual atom coordinates instead of scalar values. The multiple feature vectors output by the vector computation are then used to update the residue representations and virtual atom coordinates via attention aggregation. Remarkably, VFN also excels in modeling both frames and atoms, as the real atoms can be treated as the virtual atoms for modeling, positioning VFN as a potential $\\textit{universal encoder}$. In protein diffusion (frame modeling), VFN exhibits a impressive performance advantage over IPA, excelling in terms of both designability ($\\textbf{67.04}$\\% vs. 53.58\\%) and diversity ($\\textbf{66.54}$\\% vs. 51.98\\%). In inverse folding(frame and atom modeling), VFN outperforms the previous SoTA model, PiFold ($\\textbf{54.7}$\\% vs. 51.66\\%), on sequence recovery rate; we also propose a method of equipping VFN with the ESM model, which significantly surpasses the previous ESM-based SoTA ($\\textbf{62.67}$\\% vs. 55.65\\%), LM-Design, by a substantial margin. Code is available at https://github.com/aim-uofa/VFN", "bibtex": "@inproceedings{\nmao2024de,\ntitle={De novo Protein Design Using Geometric Vector Field Networks},\nauthor={Weian Mao and Muzhi Zhu and Zheng Sun and Shuaike Shen and Lin Yuanbo Wu and Hao Chen and Chunhua Shen},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9UIGyJJpay}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:54.170647Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Fast Uncovering of Protein Sequence Diversity from Structure", "venue": "ICLR 2025 Spotlight", "year": "2025", "authors": ["luca alessandro silva", "Barthelemy Meynard-Piganeau", "Carlo Lucibello", "Christoph Feinauer"], "affinity_score": 0.5029, "link": "https://openreview.net/pdf/77e7ac1fdcea16201d6f1898d1e501e4a4fac1f0.pdf", "abstract": "We present InvMSAFold, an inverse folding method for generating protein sequences optimized for diversity and speed. For a given structure, InvMSAFold generates the parameters of a pairwise probability distribution over the space of sequences, capturing the amino acid covariances observed in Multiple Sequence Alignments (MSA) of homologous proteins. This allows for the efficient generation of highly diverse protein sequences while preserving structural and functional integrity.\nWe demonstrate that this increased diversity in sampled sequences translates into greater variability in biochemical properties, highlighting the exciting potential of our method for applications such as protein design. The orders of magnitude improvement in sampling speed compared to existing methods unlocks new possibilities for high-throughput in virtual screening.", "bibtex": "@inproceedings{\nsilva2025fast,\ntitle={Fast Uncovering of Protein Sequence Diversity from Structure},\nauthor={luca alessandro silva and Barthelemy Meynard-Piganeau and Carlo Lucibello and Christoph Feinauer},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=1iuaxjssVp}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:54.170653Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization", "venue": "ACL 2024 Findings", "year": "2024", "authors": ["Zhiyu Yang", "Zihan Zhou", "Shuo Wang (王硕)", "Xin Cong", "Xu Han (韩旭)", "Yukun Yan (闫宇坤)", "Zhenghao Liu (刘正皓)", "Zhixing Tan", "Pengyuan Liu (刘鹏远)", "Dong Yu (于东)", "Zhiyuan Liu", "Xiaodong Shi (史晓东)", "Maosong Sun (孙茂松)"], "affinity_score": 0.5029, "link": "https://aclanthology.org/2024.findings-acl.701/", "abstract": "Scientific data visualization plays a crucial role in research by enabling the direct display of complex information and assisting researchers in identifying implicit patterns. Despite its importance, the use of Large Language Models (LLMs) for scientific data visualization remains rather unexplored. In this study, we introduce MatPlotAgent, an efficient model-agnostic LLM agent framework designed to automate scientific data visualization tasks. Leveraging the capabilities of both code LLMs and multi-modal LLMs, MatPlotAgent consists of three core modules: query understanding, code generation with iterative debugging, and a visual feedback mechanism for error correction. To address the lack of benchmarks in this field, we present MatPlotBench, a high-quality benchmark consisting of 100 human-verified test cases. Additionally, we introduce a scoring approach that utilizes GPT-4V for automatic evaluation. Experimental results demonstrate that MatPlotAgent can improve the performance of various LLMs, including both commercial and open-source models. Furthermore, the proposed evaluation method shows a strong correlation with human-annotated scores.", "bibtex": "@inproceedings{yang-etal-2024-matplotagent,\n    title = \"{M}at{P}lot{A}gent: Method and Evaluation for {LLM}-Based Agentic Scientific Data Visualization\",\n    author = \"Yang, Zhiyu  and\n      Zhou, Zihan  and\n      Wang, Shuo  and\n      Cong, Xin  and\n      Han, Xu  and\n      Yan, Yukun  and\n      Liu, Zhenghao  and\n      Tan, Zhixing  and\n      Liu, Pengyuan  and\n      Yu, Dong  and\n      Liu, Zhiyuan  and\n      Shi, Xiaodong  and\n      Sun, Maosong\",\n    editor = \"Ku, Lun-Wei  and\n      Martins, Andre  and\n      Srikumar, Vivek\",\n    booktitle = \"Findings of the Association for Computational Linguistics: ACL 2024\",\n    month = aug,\n    year = \"2024\",\n    address = \"Bangkok, Thailand\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2024.findings-acl.701/\",\n    doi = \"10.18653/v1/2024.findings-acl.701\",\n    pages = \"11789--11804\"\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:54.170657Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "P(all-atom) Is Unlocking New Path For Protein Design", "venue": "ICML 2025 Spotlightposter", "year": "2025", "authors": ["Wei Qu", "Jiawei Guan", "Rui Ma", "kezhai", "Weikun.Wu", "Haobo Wang"], "affinity_score": 0.5027, "link": "https://openreview.net/pdf/5665b4b423ab9ef2c6c00d97d55feffda4dae4ec.pdf", "abstract": "We introduce Pallatom, an innovative protein generation model capable of producing protein structures with all-atom coordinates. Pallatom directly learns and models the joint distribution $P(\\textit{structure}, \\textit{seq})$ by focusing on $P(\\textit{all-atom})$, effectively addressing the interdependence between sequence and structure in protein generation. To achieve this, we propose a novel network architecture specifically designed for all-atom protein generation. Our model employs a dual-track framework that tokenizes proteins into token-level and atomic-level representations, integrating them through a multi-layer decoding process with \"traversing\" representations and recycling mechanism. We also introduce the $\\texttt{atom14}$ representation method, which unifies the description of unknown side-chain coordinates, ensuring high fidelity between the generated all-atom conformation and its physical structure. Experimental results demonstrate that Pallatom excels in key metrics of protein design, including designability, diversity, and novelty, showing significant improvements across the board. Our model not only enhances the accuracy of protein generation but also exhibits excellent sampling efficiency, paving the way for future applications in larger and more complex systems.", "bibtex": "@inproceedings{\nqu2025pallatom,\ntitle={P(all-atom) Is Unlocking New Path For Protein Design},\nauthor={Wei Qu and Jiawei Guan and Rui Ma and kezhai and Weikun.Wu and Haobo Wang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=yXRixu0ONY}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:54.170662Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Protein Structure Tokenization: Benchmarking and New Recipe", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Xinyu Yuan", "Zichen Wang", "Marcus D. Collins", "Huzefa Rangwala"], "affinity_score": 0.5026, "link": "https://openreview.net/pdf/cffcc326e17ab108179a12c6f79dee4dfa69cb92.pdf", "abstract": "Recent years have witnessed a surge in the development of protein structural tokenization methods, which chunk protein 3D structures into discrete or continuous representations. Structure tokenization enables the direct application of powerful techniques like language modeling for protein structures, and large multimodal models to integrate structures with protein sequences and functional texts. Despite the progress, the capabilities and limitations of these methods remain poorly understood due to the lack of a unified evaluation framework. We first introduce\nStructTokenBench\n, a framework that comprehensively evaluates the quality and efficiency of structure tokenizers, focusing on fine-grained local substructures rather than global structures, as typical in existing benchmarks. Our evaluations reveal that no single model dominates all benchmarking perspectives. Observations of codebook under-utilization led us to develop\nAminoAseed\n, a simple yet effective strategy that enhances codebook gradient updates and optimally balances codebook size and dimension for improved tokenizer utilization and quality. Compared to the leading model ESM3, our method achieves an average of 6.31\\% performance improvement across 24 supervised tasks, with sensitivity and utilization rates increased by 12.83\\% and 124.03\\%, respectively. Source code and model weights are available at https://github.com/KatarinaYuan/StructTokenBench.", "bibtex": "@inproceedings{\nyuan2025protein,\ntitle={Protein Structure Tokenization: Benchmarking and New Recipe},\nauthor={Xinyu Yuan and Zichen Wang and Marcus D. Collins and Huzefa Rangwala},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=o4ANDWaomX}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:54.170666Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Structure Language Models for Protein Conformation Generation", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Jiarui Lu", "Xiaoyin Chen", "Stephen Zhewen Lu", "Chence Shi", "Hongyu Guo", "Yoshua Bengio", "Jian Tang"], "affinity_score": 0.5025, "link": "https://openreview.net/pdf/063242f3610e3ab2e08fd2073e307b10d917dffb.pdf", "abstract": "Proteins adopt multiple structural conformations to perform their diverse biological functions, and understanding these conformations is crucial for advancing drug discovery. Traditional physics-based simulation methods often struggle with sampling equilibrium conformations and are computationally expensive. Recently, deep generative models have shown promise in generating protein conformations as a more efficient alternative. However, these methods predominantly rely on the diffusion process within a 3D geometric space, which typically centers around the vicinity of metastable states and is often inefficient in terms of runtime. In this paper, we introduce Structure Language Modeling (SLM) as a novel framework for efficient protein conformation generation. Specifically, the protein structures are first encoded into a compact latent space using a discrete variational auto-encoder, followed by conditional language modeling that effectively captures sequence-specific conformation distributions.  This enables a more efficient and interpretable exploration of diverse ensemble modes compared to existing methods. Based on this general framework, we instantiate SLM with various popular LM architectures as well as proposing the ESMDiff, a novel BERT-like structure language model fine-tuned from ESM3 with masked diffusion. We verify our approach in various scenarios, including the equilibrium dynamics of BPTI, conformational change pairs, and intrinsically disordered proteins. SLM provides a highly efficient solution, offering a 20-100x speedup than existing methods in generating diverse conformations, shedding light on promising avenues for future research.", "bibtex": "@inproceedings{\nlu2025structure,\ntitle={Structure Language Models for Protein Conformation Generation},\nauthor={Jiarui Lu and Xiaoyin Chen and Stephen Zhewen Lu and Chence Shi and Hongyu Guo and Yoshua Bengio and Jian Tang},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=OzUNDnpQyd}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:54.170674Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "AlphaFold Meets Flow Matching for Generating Protein Ensembles", "venue": "ICML 2024 Oral", "year": "2024", "authors": ["Bowen Jing", "Bonnie Berger", "Tommi Jaakkola"], "affinity_score": 0.5023, "link": "https://openreview.net/pdf/29f29a3b22e2038d3f465822db02f5d303a5d273.pdf", "abstract": "The biological functions of proteins often depend on dynamic structural ensembles. In this work, we develop a flow-based generative modeling approach for learning and sampling the conformational landscapes of proteins. We repurpose highly accurate single-state predictors such as AlphaFold and ESMFold and fine-tune them under a custom flow matching framework to obtain sequence-conditioned generative models of protein structure called AlphaFlow and ESMFlow. When trained and evaluated on the PDB, our method provides a superior combination of precision and diversity compared to AlphaFold with MSA subsampling. When further trained on ensembles from all-atom MD, our method accurately captures conformational flexibility, positional distributions, and higher-order ensemble observables for unseen proteins. Moreover, our method can diversify a static PDB structure with faster wall-clock convergence to certain equilibrium properties than replicate MD trajectories, demonstrating its potential as a proxy for expensive physics-based simulations. Code is available at https://github.com/bjing2016/alphaflow.", "bibtex": "@inproceedings{\njing2024alphafold,\ntitle={AlphaFold Meets Flow Matching for Generating Protein Ensembles},\nauthor={Bowen Jing and Bonnie Berger and Tommi Jaakkola},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=rs8Sh2UASt}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:54.170681Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Evaluating Representation Learning on the Protein Structure Universe", "venue": "ICLR 2024 Poster", "year": "2024", "authors": ["Arian Rokkum Jamasb", "Alex Morehead", "Chaitanya K. Joshi", "Zuobai Zhang", "Kieran Didi", "Simon V Mathis", "Charles Harris", "Jian Tang", "Jianlin Cheng", "Pietro Lio", "Tom Leon Blundell"], "affinity_score": 0.502, "link": "https://openreview.net/pdf/69d3702ce7faefe484e8143abfb3242c2e6f99da.pdf", "abstract": "We introduce ProteinWorkshop, a comprehensive benchmark suite for representation learning on protein structures with Geometric Graph Neural Networks. We consider large-scale pre-training and downstream tasks on both experimental and predicted structures to enable the systematic evaluation of the quality of the learned structural representation and their usefulness in capturing functional relationships for downstream tasks. We find that: (1) large-scale pretraining on AlphaFold structures and auxiliary tasks consistently improve the performance of both rotation-invariant and equivariant GNNs, and (2) more expressive equivariant GNNs benefit from pretraining to a greater extent compared to invariant models.\nWe aim to establish a common ground for the machine learning and computational biology communities to rigorously compare and advance protein structure representation learning. Our open-source codebase reduces the barrier to entry for working with large protein structure datasets by providing: (1) storage-efficient dataloaders for large-scale structural databases including AlphaFoldDB and ESM Atlas, as well as (2) utilities for constructing new tasks from the entire PDB. ProteinWorkshop is available at: github.com/a-r-j/ProteinWorkshop.", "bibtex": "@inproceedings{\njamasb2024evaluating,\ntitle={Evaluating Representation Learning on the Protein Structure Universe},\nauthor={Arian Rokkum Jamasb and Alex Morehead and Chaitanya K. Joshi and Zuobai Zhang and Kieran Didi and Simon V Mathis and Charles Harris and Jian Tang and Jianlin Cheng and Pietro Lio and Tom Leon Blundell},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sTYuRVrdK3}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:54.170685Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Diffusion Language Models Are Versatile Protein Learners", "venue": "ICML 2024 Poster", "year": "2024", "authors": ["Xinyou Wang", "Zaixiang Zheng", "Fei YE", "Dongyu Xue", "Shujian Huang", "Quanquan Gu"], "affinity_score": 0.5019, "link": "https://openreview.net/pdf/38c7073abf10f2aa8147ec5cb085074bbbe3e8ed.pdf", "abstract": "This paper introduces diffusion protein language model (DPLM), a versatile protein language model that demonstrates strong generative and predictive capabilities for protein sequences. We first pre-train scalable DPLMs from evolutionary-scale protein sequences within a generative self-supervised discrete diffusion probabilistic framework, which generalizes language modeling for proteins in a principled way. After pre-training, DPLM exhibits the ability to generate structurally plausible, novel and diverse protein sequences for unconditional generation. We further demonstrate the proposed diffusion generative pre-training make DPLM possess a better understanding of proteins, making it a superior representation learner, which can be fine-tuned for various predictive tasks, comparing favorably to ESM2. Moreover, DPLM can be tailored for various needs, which showcases its prowess of conditional generation in several ways: (1) conditioning on partial peptide sequences, e.g., generating scaffolds for functional motifs with high success rate; (2) incorporating other modalities as conditioners, e.g., structure-conditioned generation for inverse folding; and (3) steering sequence generation towards desired properties, e.g., satisfying specified secondary structures, through a plug-and-play classifier guidance.", "bibtex": "@inproceedings{\nwang2024diffusion,\ntitle={Diffusion Language Models Are Versatile Protein Learners},\nauthor={Xinyou Wang and Zaixiang Zheng and Fei YE and Dongyu Xue and Shujian Huang and Quanquan Gu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=NUAbSFqyqb}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:54.170688Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Enhancing Graph Contrastive Learning for Protein Graphs from Perspective of Invariance", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Yusong Wang", "Shiyin Tan", "Jialun Shen", "Yicheng Xu", "Haobo Song", "Qi Xu", "Prayag Tiwari", "Mingkun Xu"], "affinity_score": 0.5018, "link": "https://openreview.net/pdf/38d6e9debaea7eb652b56840f88ba8c90092e09f.pdf", "abstract": "Graph Contrastive Learning (GCL) improves Graph Neural Network (GNN)-based protein representation learning by enhancing its generalization and robustness. Existing GCL approaches for protein representation learning rely on 2D topology, where graph augmentation is solely based on topological features, ignoring the intrinsic biological properties of proteins. Besides, 3D structure-based protein graph augmentation remains unexplored, despite proteins inherently exhibiting 3D structures. To bridge this gap, we propose novel biology-aware graph augmentation strategies from the perspective of invariance and integrate them into the protein GCL framework. Specifically, we introduce Functional Community Invariance (FCI)-based graph augmentation, which employs spectral constraints to preserve topology-driven community structures while incorporating residue-level chemical similarity as edge weights to guide edge sampling and maintain functional communities. Furthermore, we propose 3D Protein Structure Invariance (3-PSI)-based graph augmentation, leveraging dihedral angle perturbations and secondary structure rotations to retain critical 3D structural information of proteins while diversifying graph views.\nExtensive experiments on four different protein-related tasks demonstrate the superiority of our proposed GCL protein representation learning framework.", "bibtex": "@inproceedings{\nwang2025enhancing,\ntitle={Enhancing Graph Contrastive Learning for Protein Graphs from Perspective of Invariance},\nauthor={Yusong Wang and Shiyin Tan and Jialun Shen and Yicheng Xu and Haobo Song and Qi Xu and Prayag Tiwari and Mingkun Xu},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=g2hucDbOJt}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:55.124126Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Integrating Protein Dynamics into Structure-Based Drug Design via Full-Atom Stochastic Flows", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Xiangxin Zhou", "Yi Xiao", "Haowei Lin", "Xinheng He", "Jiaqi Guan", "Yang Wang", "Qiang Liu", "Feng Zhou", "Liang Wang", "Jianzhu Ma"], "affinity_score": 0.5011, "link": "https://openreview.net/pdf/710c067fc722d0beff848449c2a0636ead21a9c6.pdf", "abstract": "The dynamic nature of proteins, influenced by ligand interactions, is essential for comprehending protein-function and progressing drug discovery. Traditional structure-based drug design (SBDD) approaches typically target binding sites with rigid structures, limiting their practical application in drug development. While molecular dynamics simulation can theoretically capture all the biologically relevant conformations, the transition rate is dictated by the intrinsic energy barrier between them, making the sampling process computationally expensive. To overcome the aforementioned challenges, we propose to use generative modeling for SBDD considering conformational changes of protein pockets. We curate a dataset of apo and multiple holo states of protein-ligand complexes, simulated by molecular dynamics, and propose a full-atom flow model (and a stochastic version), named DynamicFlow, that learns to transform apo pockets and noisy ligands into holo pockets and corresponding 3D ligand molecules. Our method uncovers promising ligand molecules and corresponding holo conformations of pockets. Additionally, the resultant holo-like states provide superior inputs for traditional SBDD approaches, playing a significant role in practical drug discovery.", "bibtex": "@inproceedings{\nzhou2025integrating,\ntitle={Integrating Protein Dynamics into Structure-Based Drug Design via Full-Atom Stochastic Flows},\nauthor={Xiangxin Zhou and Yi Xiao and Haowei Lin and Xinheng He and Jiaqi Guan and Yang Wang and Qiang Liu and Feng Zhou and Liang Wang and Jianzhu Ma},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=9qS3HzSDNv}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:55.124148Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "SeedBench: A Multi-task Benchmark for Evaluating Large Language Models in Seed Science", "venue": "ACL 2025 Long", "year": "2025", "authors": ["Jie Ying", "Zihong Chen", "Zhefan Wang", "Wanli Jiang", "Chenyang Wang", "Zhonghang Yuan", "Haoyang Su", "Huanjun Kong", "Fan Yang", "Nanqing Dong"], "affinity_score": 0.4996, "link": "https://aclanthology.org/2025.acl-long.1516/", "abstract": "Seed science is essential for modern agriculture, directly influencing crop yields and global food security. However, challenges such as interdisciplinary complexity and high costs with limited returns hinder progress, leading to a shortage of experts and insufficient technological support. While large language models (LLMs) have shown promise across various fields, their application in seed science remains limited due to the scarcity of digital resources, complex gene-trait relationships, and the lack of standardized benchmarks. To address this gap, we introduce SeedBench—the first multi-task benchmark specifically designed for seed science. Developed in collaboration with domain experts, SeedBench focuses on seed breeding and simulates key aspects of modern breeding processes. We conduct a comprehensive evaluation of 26 leading LLMs, encompassing proprietary, open-source, and domain-specific fine-tuned models. Our findings not only highlight the substantial gaps between the power of LLMs and the real-world seed science problems, but also make a foundational step for research on LLMs for seed design.", "bibtex": "@inproceedings{ying-etal-2025-seedbench,\n    title = \"{S}eed{B}ench: A Multi-task Benchmark for Evaluating Large Language Models in Seed Science\",\n    author = \"Ying, Jie  and\n      Chen, Zihong  and\n      Wang, Zhefan  and\n      Jiang, Wanli  and\n      Wang, Chenyang  and\n      Yuan, Zhonghang  and\n      Su, Haoyang  and\n      Kong, Huanjun  and\n      Yang, Fan  and\n      Dong, Nanqing\",\n    editor = \"Che, Wanxiang  and\n      Nabende, Joyce  and\n      Shutova, Ekaterina  and\n      Pilehvar, Mohammad Taher\",\n    booktitle = \"Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = jul,\n    year = \"2025\",\n    address = \"Vienna, Austria\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.acl-long.1516/\",\n    doi = \"10.18653/v1/2025.acl-long.1516\",\n    pages = \"31395--31449\",\n    ISBN = \"979-8-89176-251-0\"\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:55.124154Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Multi-Scale Representation Learning for Protein Fitness Prediction", "venue": "NeurIPS 2024 Poster", "year": "2024", "authors": ["Zuobai Zhang", "Pascal Notin", "Yining Huang", "Aurelie Lozano", "Vijil Chenthamarakshan", "Debora Susan Marks", "Payel Das", "Jian Tang"], "affinity_score": 0.4984, "link": "https://openreview.net/pdf/42a9efb3a54368d5d17852708b09e753ae1f9ef0.pdf", "abstract": "Designing novel functional proteins crucially depends on accurately modeling their fitness landscape. Given the limited availability of functional annotations from wet-lab experiments, previous methods have primarily relied on self-supervised models trained on vast, unlabeled protein sequence or structure datasets. While initial protein representation learning studies solely focused on either sequence or structural features, recent hybrid architectures have sought to merge these modalities to harness their respective strengths. However, these sequence-structure models have so far achieved only incremental improvements when compared to the leading sequence-only approaches, highlighting unresolved challenges effectively leveraging these modalities together. Moreover, the function of certain proteins is highly dependent on the granular aspects of their surface topology, which have been overlooked by prior models.\nTo address these limitations, we introduce the Sequence-Structure-Surface Fitness (\nS3F\n) model — a novel multimodal representation learning framework that integrates protein features across several scales. Our approach combines sequence representations from a protein language model with Geometric Vector Perceptron networks encoding protein backbone and detailed surface topology. The proposed method achieves state-of-the-art fitness prediction on the ProteinGym benchmark encompassing 217 substitution deep mutational scanning assays, and provides insights into the determinants of protein-function.\nOur code is at https://github.com/DeepGraphLearning/S3F.", "bibtex": "@inproceedings{\nzhang2024multiscale,\ntitle={Multi-Scale Representation Learning for Protein Fitness Prediction},\nauthor={Zuobai Zhang and Pascal Notin and Yining Huang and Aurelie Lozano and Vijil Chenthamarakshan and Debora Susan Marks and Payel Das and Jian Tang},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=kWMVzIdCEn}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:55.124159Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "EvoAgent: Towards Automatic Multi-Agent Generation via Evolutionary Algorithms", "venue": "NAACL 2025 Long", "year": "2025", "authors": ["Siyu Yuan", "Kaitao Song", "Jiangjie Chen", "Xu Tan", "Dongsheng Li", "Deqing Yang"], "affinity_score": 0.4982, "link": "https://aclanthology.org/2025.naacl-long.315/", "abstract": "The rise of powerful large language models (LLMs) has spurred a new trend in building LLM-based autonomous agents for solving complex tasks, especially multi-agent systems. Despite the remarkable progress, we notice that existing works are heavily dependent on human-designed frameworks, which greatly limits the functional scope and scalability of agent systems. How to automatically extend the specialized agent to multi-agent systems to improve task-solving capability still remains a significant challenge. In this paper, we introduce EVOAGENT, a generic method to automatically extend specialized agents to multi-agent systems via the evolutionary algorithm, thereby improving the effectiveness of LLM-based agents in solving tasks. Specifically, we consider the existing agent frameworks as the initial individual and then apply a series of evolutionary operators (e.g., mutation, crossover, selection, etc.) to generate multiple agents with diverse settings. Experimental results across various tasks show that EVOAGENT can significantly enhance the tasksolving capability of LLM-based agents, and can be generalized to any LLM-based agent framework to extend them into multi-agent systems. Resources are available at https://evo-agent.github.io/.", "bibtex": "@inproceedings{yuan-etal-2025-evoagent,\n    title = \"{E}vo{A}gent: Towards Automatic Multi-Agent Generation via Evolutionary Algorithms\",\n    author = \"Yuan, Siyu  and\n      Song, Kaitao  and\n      Chen, Jiangjie  and\n      Tan, Xu  and\n      Li, Dongsheng  and\n      Yang, Deqing\",\n    editor = \"Chiruzzo, Luis  and\n      Ritter, Alan  and\n      Wang, Lu\",\n    booktitle = \"Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)\",\n    month = apr,\n    year = \"2025\",\n    address = \"Albuquerque, New Mexico\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://aclanthology.org/2025.naacl-long.315/\",\n    doi = \"10.18653/v1/2025.naacl-long.315\",\n    pages = \"6192--6217\",\n    ISBN = \"979-8-89176-189-6\"\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:55.124164Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Automated Design of Agentic Systems", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Shengran Hu", "Cong Lu", "Jeff Clune"], "affinity_score": 0.4978, "link": "https://openreview.net/pdf/116ed45ae3d0873b16f5fdcab7f1fa4f12253e6d.pdf", "abstract": "Researchers are investing substantial effort in developing powerful general-purpose agents, wherein Foundation Models are used as modules within agentic systems (e.g. Chain-of-Thought, Self-Reflection, Toolformer). However, the history of machine learning teaches us that hand-designed solutions are eventually replaced by learned solutions. We describe a newly forming research area, Automated Design of Agentic Systems (ADAS), which aims to automatically create powerful agentic system designs, including inventing novel building blocks and/or combining them in new ways. We further demonstrate that there is an unexplored yet promising approach within ADAS where agents can be defined in code and new agents can be automatically discovered by a meta agent programming ever better ones in code. Given that programming languages are Turing Complete, this approach theoretically enables the learning of any possible agentic system: including novel prompts, tool use, workflows, and combinations thereof. We present a simple yet effective algorithm named Meta Agent Search to demonstrate this idea, where a meta agent iteratively programs interesting new agents based on an ever-growing archive of previous discoveries. Through extensive experiments across multiple domains including coding, science, and math, we show that our algorithm can progressively invent agents with novel designs that greatly outperform state-of-the-art hand-designed agents. Importantly, we consistently observe the surprising result that agents invented by Meta Agent Search maintain superior performance even when transferred across domains and models, demonstrating their robustness and generality. Provided we develop it safely, our work illustrates the potential of an exciting new research direction toward automatically designing ever-more powerful agentic systems to benefit humanity.", "bibtex": "@inproceedings{\nhu2025automated,\ntitle={Automated Design of Agentic Systems},\nauthor={Shengran Hu and Cong Lu and Jeff Clune},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=t9U3LW7JVX}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:55.124168Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ProSpero: Active Learning for Robust Protein Design Beyond Wild-Type Neighborhoods", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Michal Kmicikiewicz", "Vincent Fortuin", "Ewa Szczurek"], "affinity_score": 0.4968, "link": "https://openreview.net/pdf/13e696f240061c7d9b88a58ebc610d1d7bfda115.pdf", "abstract": "Designing protein sequences of both high fitness and novelty is a challenging task in data-efficient protein engineering. Exploration beyond wild-type neighborhoods often leads to biologically implausible sequences or relies on surrogate models that lose fidelity in novel regions. Here, we propose ProSpero, an active learning framework in which a frozen pre-trained generative model is guided by a surrogate updated from oracle feedback. By integrating fitness-relevant residue selection with biologically-constrained Sequential Monte Carlo sampling, our approach enables exploration beyond wild-type neighborhoods while preserving biological plausibility. We show that our framework remains effective even when the surrogate is misspecified.\nProSpero consistently outperforms or matches existing methods across diverse protein engineering tasks, retrieving sequences of both high fitness and novelty.", "bibtex": "@inproceedings{\nkmicikiewicz2025prospero,\ntitle={ProSpero: Active Learning for Robust Protein Design Beyond Wild-Type Neighborhoods},\nauthor={Michal Kmicikiewicz and Vincent Fortuin and Ewa Szczurek},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=wSDE3karoF}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:55.124172Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Retrieval Augmented Zero-Shot Enzyme Generation for Specified Substrate", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Jiahe Du", "Kaixiong Zhou", "Xinyu Hong", "Zhaozhuo Xu", "Jinbo Xu", "Xiao Huang"], "affinity_score": 0.4968, "link": "https://openreview.net/pdf/02296ad363ebe920af69a747ba2ac00132c4e706.pdf", "abstract": "Generating novel enzymes for target molecules in zero-shot scenarios is a fundamental challenge in biomaterial synthesis and chemical production. Without known enzymes for a target molecule, training generative models becomes difficult due to the lack of direct supervision. To address this, we propose a retrieval-augmented generation method that uses existing enzyme-substrate data to guide enzyme design. Our method retrieves enzymes with substrates that share structural similarities with the target molecule, leveraging functional similarities in catalytic activity. Since none of the retrieved enzymes directly catalyze the target molecule, we use a conditioned discrete diffusion model to generate new enzymes based on the retrieved examples. An enzyme-substrate relationship classifier guides the generation process to ensure optimal protein sequence distributions. We evaluate our model on enzyme design tasks with diverse real-world substrates and show that it outperforms existing protein generation methods in catalytic capability, foldability, and docking accuracy. Additionally, we define the zero-shot substrate-specified enzyme generation task and introduce a dataset with evaluation benchmarks.", "bibtex": "@inproceedings{\ndu2025retrieval,\ntitle={Retrieval Augmented Zero-Shot Enzyme Generation for Specified Substrate},\nauthor={Jiahe Du and Kaixiong Zhou and Xinyu Hong and Zhaozhuo Xu and Jinbo Xu and Xiao Huang},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=MPhyCn8BcU}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:55.124177Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Enhancing Protein Mutation Effect Prediction through a Retrieval-Augmented Framework", "venue": "NeurIPS 2024 Poster", "year": "2024", "authors": ["Ruihan Guo", "Rui Wang", "Ruidong Wu", "Zhizhou Ren", "Jiahan Li", "Shitong Luo", "Zuofan Wu", "qiang liu", "Jian Peng", "Jianzhu Ma"], "affinity_score": 0.4966, "link": "https://openreview.net/pdf/78cb476b05d22598bd0b0800dced91141a3ce41e.pdf", "abstract": "Predicting the effects of protein mutations is crucial for analyzing protein-functions and understanding genetic diseases. \nHowever, existing models struggle to effectively extract mutation-related local structure motifs from protein databases, which hinders their predictive accuracy and robustness. To tackle this problem, we design a novel retrieval-augmented framework for incorporating similar structure information in known protein structures. We create a vector database consisting of local structure motif embeddings from a pre-trained protein structure encoder, which allows for efficient retrieval of similar local structure motifs during mutation effect prediction. \nOur findings demonstrate that leveraging this method results in the SOTA performance across multiple protein mutation prediction datasets, and offers a scalable solution for studying mutation effects.", "bibtex": "@inproceedings{\nguo2024enhancing,\ntitle={Enhancing Protein Mutation Effect Prediction through a Retrieval-Augmented Framework},\nauthor={Ruihan Guo and Rui Wang and Ruidong Wu and Zhizhou Ren and Jiahan Li and Shitong Luo and Zuofan Wu and qiang liu and Jian Peng and Jianzhu Ma},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=LgeHswiWef}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:55.124181Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Offline Training of Language Model Agents with Functions as Learnable Weights", "venue": "ICML 2024 Poster", "year": "2024", "authors": ["Shaokun Zhang", "Jieyu Zhang", "Jiale Liu", "Linxin Song", "Chi Wang", "Ranjay Krishna", "Qingyun Wu"], "affinity_score": 0.4964, "link": "https://openreview.net/pdf/7fc4174c8876ce9cd87db0e2a33d814d09583fb1.pdf", "abstract": "Researchers and practitioners have recently reframed powerful Large Language Models (LLMs) as\nagents\n, enabling them to automate complex tasks largely via the use of specialized functions. To facilitate the development of LLM agents, we present a novel paradigm of training LLM agents without modifying the LLM weights, which is particularly useful when the LLMs are difficult or inaccessible for modifications. Inspired by how humans continuously forge tools to adapt to real-world tasks, rather than change our biological structure to fit a static set of tools, we propose to progressively forge agent's functions to better solve the downstream tasks instead of modifying the LLM weights. By treating the functions as learnable `agent parameters' and leveraging the fundamental idea of model training in artificial intelligence, we develop AgentOptimizer that employs the LLM to update agents' functions and devise an\nagent training\nalgorithm with two strategies, roll-back, and early-stop, to streamline the training process. With extensive experiments, we showcase that the agent training paradigm could significantly improve the performance of representative LLM agents in various downstream tasks. We also study the behavior of the agent training regarding aspects like the learning curve and domain transferability.", "bibtex": "@inproceedings{\nzhang2024offline,\ntitle={Offline Training of Language Model Agents with Functions as Learnable Weights},\nauthor={Shaokun Zhang and Jieyu Zhang and Jiale Liu and Linxin Song and Chi Wang and Ranjay Krishna and Qingyun Wu},\nbooktitle={Forty-first International Conference on Machine Learning},\nyear={2024},\nurl={https://openreview.net/forum?id=2xbkWiEuR1}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:55.124185Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Fan Liu", "Zhe-Rui Yang", "Cancheng Liu", "Tianrui SONG", "Xiaofeng Gao", "Hao Liu"], "affinity_score": 0.4964, "link": "https://openreview.net/pdf/e01a39be0de98c2f808394f7affa2bfb004c68a5.pdf", "abstract": "Mathematical modeling is a cornerstone of scientific discovery and engineering practice, enabling the translation of real-world problems into formal systems across domains such as physics, biology, and economics. Unlike mathematical reasoning, which assumes a predefined formulation, modeling requires open-ended problem analysis, abstraction, and principled formalization. While Large Language Models (LLMs) have shown strong reasoning capabilities, they fall short in rigorous model construction, limiting their utility in real-world problem-solving. To this end, we formalize the task of LLM-powered real-world mathematical modeling, where agents must analyze problems, construct domain-appropriate formulations, and generate complete end-to-end solutions.We introduce MM-Bench, a curated benchmark of 111 problems from the Mathematical Contest in Modeling (MCM/ICM), spanning the years 2000 to 2025 and across ten diverse domains such as physics, biology, and economics.  To tackle this task, we propose MM-Agent, an expert-inspired framework that decomposes mathematical modeling into four stages: open-ended problem analysis, structured model formulation, computational problem solving, and report generation.Experiments on MM-Bench show that MM-Agent significantly outperforms baseline agents, achieving an 11.88\\% improvement over human expert solutions while requiring only 15 minutes and \\$0.88 per task using GPT-4o. Furthermore, under official MCM/ICM protocols, MM-Agent assisted two undergraduate teams in winning the Finalist Award (\\textbf{top 2.0\\% among 27,456 teams}) in MCM/ICM 2025, demonstrating its practical effectiveness as a modeling copilot.", "bibtex": "@inproceedings{\nliu2025mmagent,\ntitle={{MM}-Agent: {LLM} as Agents for Real-world Mathematical Modeling Problem},\nauthor={Fan Liu and Zhe-Rui Yang and Cancheng Liu and Tianrui SONG and Xiaofeng Gao and Hao Liu},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=o8n5oNDsiq}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:56.080713Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "A Simple yet Effective $\\Delta\\Delta G$ Predictor is An Unsupervised Antibody Optimizer and Explainer", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Lirong Wu", "Yunfan Liu", "Haitao Lin", "Yufei Huang", "Guojiang Zhao", "Zhifeng Gao", "Stan Z. Li"], "affinity_score": 0.4939, "link": "https://openreview.net/pdf/7a25af496939b1b249635d8ac109860880f9c6e4.pdf", "abstract": "The proteins that exist today have been optimized over billions of years of natural evolution, during which nature creates random mutations and selects them. The discovery of functionally promising mutations is challenged by the limited evolutionary accessible regions, i.e., only a small region on the fitness landscape is beneficial. There have been numerous priors used to constrain protein evolution to regions of landscapes with high-fitness variants, among which the change in binding free energy ($\\Delta\\Delta G$) of protein complexes upon mutations is one of the most commonly used priors. However, the huge mutation space poses two challenges: (1) how to improve the efficiency of $\\Delta\\Delta G$ prediction for fast mutation screening; and (2) how to explain mutation preferences and efficiently explore accessible evolutionary regions. To address these challenges, we propose a lightweight $\\Delta\\Delta G$ predictor (Light-DDG), which adopts a structure-aware Transformer as the backbone and enhances it by knowledge distilled from existing powerful but computationally heavy $\\Delta\\Delta G$ predictors. Additionally, we augmented, annotated, and released a large-scale dataset containing millions of mutation data for pre-training Light-DDG. We find that such a simple yet effective Light-DDG can serve as a good unsupervised antibody optimizer and explainer. For the target antibody, we propose a novel Mutation Explainer to learn mutation preferences, which accounts for the marginal benefit of each mutation per residue. To further explore accessible evolutionary regions, we conduct preference-guided antibody optimization and evaluate antibody candidates quickly using Light-DDG to identify desirable mutations. Extensive experiments have demonstrated the effectiveness of Light-DDG in terms of test generalizability, noise robustness, and inference practicality, e.g., 89.7$\\times$ inference acceleration and 15.45\\% performance gains over previous state-of-the-art baselines. A case study of SARS-CoV-2 further demonstrates the crucial role of Light-DDG for mutation explanation and antibody optimization.", "bibtex": "@inproceedings{\nwu2025a,\ntitle={A Simple yet Effective \\${\\textbackslash}Delta{\\textbackslash}Delta G\\$ Predictor is An Unsupervised Antibody Optimizer and Explainer},\nauthor={Lirong Wu and Yunfan Liu and Haitao Lin and Yufei Huang and Guojiang Zhao and Zhifeng Gao and Stan Z. Li},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=IxmWIkcKs5}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:56.080720Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment", "venue": "ICLR 2024 Poster", "year": "2024", "authors": ["Bowen Gao", "Yinjun Jia", "YuanLe Mo", "Yuyan Ni", "Wei-Ying Ma", "Zhi-Ming Ma", "Yanyan Lan"], "affinity_score": 0.4936, "link": "https://openreview.net/pdf/fcb728a7e3b8f50b0b315d0afbd69ca490308c3e.pdf", "abstract": "Pocket representations play a vital role in various biomedical applications, such as druggability estimation, ligand affinity prediction, and de novo drug design. While existing geometric features and pretrained representations have demonstrated promising results, they usually treat pockets independent of ligands, neglecting the fundamental interactions between them. However, the limited pocket-ligand complex structures available in the PDB database (less than 100 thousand non-redundant pairs) hampers large-scale pretraining endeavors for interaction modeling. To address this constraint, we propose a novel pocket pretraining approach that leverages knowledge from high-resolution atomic protein structures, assisted by highly effective pretrained small molecule representations. By segmenting protein structures into drug-like fragments and their corresponding pockets, we obtain a reasonable simulation of ligand-receptor interactions, resulting in the generation of over 5 million complexes. Subsequently, the pocket encoder is trained in a contrastive manner to align with the representation of pseudo-ligand furnished by some pretrained small molecule encoders. Our method, named ProFSA, achieves state-of-the-art performance across various tasks, including pocket druggability prediction, pocket matching, and ligand binding affinity prediction. Notably, ProFSA surpasses other pretraining methods by a substantial margin. Moreover, our work opens up a new avenue for mitigating the scarcity of protein-ligand complex data through the utilization of high-quality and diverse protein structure databases.", "bibtex": "@inproceedings{\ngao2024selfsupervised,\ntitle={Self-supervised Pocket Pretraining via Protein Fragment-Surroundings Alignment},\nauthor={Bowen Gao and Yinjun Jia and YuanLe Mo and Yuyan Ni and Wei-Ying Ma and Zhi-Ming Ma and Yanyan Lan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uMAujpVi9m}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:56.080723Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "ProSST: Protein Language Modeling with Quantized Structure and Disentangled Attention", "venue": "NeurIPS 2024 Poster", "year": "2024", "authors": ["Mingchen Li", "Yang Tan", "Xinzhu Ma", "Bozitao Zhong", "Huiqun Yu", "Ziyi Zhou", "Wanli Ouyang", "Bingxin Zhou", "Pan Tan", "Liang Hong"], "affinity_score": 0.4933, "link": "https://openreview.net/pdf/6c75eed7fafd81f83f87f954b10f95768b59f37b.pdf", "abstract": "Protein language models (PLMs) have shown remarkable capabilities in various protein-function prediction tasks. However, while protein-function is intricately tied to structure, most existing PLMs do not incorporate protein structure information. To address this issue, we introduce ProSST, a Transformer-based protein language model that seamlessly integrates both protein sequences and structures. ProSST incorporates a structure quantization module and a Transformer architecture with disentangled attention. The structure quantization module translates a 3D protein structure into a sequence of discrete tokens by first serializing the protein structure into residue-level local structures and then embeds them into dense vector space. These vectors are then quantized into discrete structure tokens by a pre-trained clustering model. These tokens serve as an effective protein structure representation. Furthermore, ProSST explicitly learns the relationship between protein residue token sequences and structure token sequences through the sequence-structure disentangled attention. We pre-train ProSST on millions of protein structures using a masked language model objective, enabling it to learn comprehensive contextual representations of proteins. To evaluate the proposed ProSST, we conduct extensive experiments on the zero-shot mutation effect prediction and several supervised downstream tasks, where ProSST achieves the state-of-the-art performance among all baselines. Our code and pre-trained models are publicly available.", "bibtex": "@inproceedings{\nli2024prosst,\ntitle={Pro{SST}: Protein Language Modeling with Quantized Structure and Disentangled Attention},\nauthor={Mingchen Li and Yang Tan and Xinzhu Ma and Bozitao Zhong and Huiqun Yu and Ziyi Zhou and Wanli Ouyang and Bingxin Zhou and Pan Tan and Liang Hong},\nbooktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},\nyear={2024},\nurl={https://openreview.net/forum?id=4Z7RZixpJQ}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:56.080726Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "SAGEPhos: Sage Bio-Coupled and Augmented Fusion for Phosphorylation Site Detection", "venue": "ICLR 2025 Poster", "year": "2025", "authors": ["Jingjie Zhang", "Hanqun CAO", "Zijun Gao", "Xiaorui Wang", "Chunbin Gu"], "affinity_score": 0.4926, "link": "https://openreview.net/pdf/21fa61aedb88d308c4b0d33953692bb5dfc01a12.pdf", "abstract": "Phosphorylation site prediction based on kinase-substrate interaction plays a vital role in understanding cellular signaling pathways and disease mechanisms. Computational methods for this task can be categorized into kinase-family-focused and individual kinase-targeted approaches. Individual kinase-targeted methods have gained prominence for their ability to explore a broader protein space and provide more precise target information for kinase inhibitors. However, most existing individual kinase-based approaches focus solely on sequence inputs, neglecting crucial structural information. To address this limitation, we introduce SAGEPhos (Structure-aware kinAse-substrate bio-coupled and bio-auGmented nEtwork for Phosphorylation site prediction), a novel framework that modifies the semantic space of main protein inputs using auxiliary inputs at two distinct modality levels. At the inter-modality level, SAGEPhos introduces a Bio-Coupled Modal Fusion method, distilling essential kinase sequence information to refine task-oriented local substrate feature space, creating a shared semantic space that captures crucial kinase-substrate interaction patterns. Within the substrate's intra-modality domain, it focuses on Bio-Augmented Fusion, emphasizing 2D local sequence information while selectively incorporating 3D spatial information from predicted structures to complement the sequence space. Moreover, to address the lack of structural information in current datasets, we contribute a new, refined phosphorylation site prediction dataset, which incorporates crucial structural elements and will serve as a new benchmark for the field. Experimental results demonstrate that SAGEPhos significantly outperforms baseline methods, notably achieving almost 10\\% and 12\\% improvements in prediction accuracy and AUC-ROC, respectively. We further demonstrate our algorithm's robustness and generalization through stable results across varied data partitions and significant improvements in zero-shot scenarios. These results underscore the effectiveness of constructing a larger and more precise protein space in advancing the state-of-the-art in phosphorylation site prediction. We release the SAGEPhos models and code at https://github.com/ZhangJJ26/SAGEPhos.", "bibtex": "@inproceedings{\nzhang2025sagephos,\ntitle={{SAGEP}hos: Sage Bio-Coupled and Augmented Fusion for Phosphorylation Site Detection},\nauthor={Jingjie Zhang and Hanqun CAO and Zijun Gao and Xiaorui Wang and Chunbin Gu},\nbooktitle={The Thirteenth International Conference on Learning Representations},\nyear={2025},\nurl={https://openreview.net/forum?id=hLwcNSFhC2}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:56.080728Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Dapeng Jiang", "Xiangzhe Kong", "Jiaqi Han", "Mingyu Li", "Rui Jiao", "Wenbing Huang", "Stefano Ermon", "Jianzhu Ma", "Yang Liu"], "affinity_score": 0.4917, "link": "https://openreview.net/pdf/1bf4d742a483ea0ad56242732d9462b995dadce9.pdf", "abstract": "Cyclic peptides, characterized by geometric constraints absent in linear peptides, offer enhanced biochemical properties, presenting new opportunities to address unmet medical needs. However, designing target-specific cyclic peptides remains underexplored due to limited training data. To bridge the gap, we propose CP-Composer, a novel generative framework that enables zero-shot cyclic peptide generation via composable geometric constraints. Our approach decomposes complex cyclization patterns into unit constraints, which are incorporated into a diffusion model through geometric conditioning on nodes and edges. During training, the model learns from unit constraints and their random combinations in linear peptides, while at inference, novel constraint combinations required for cyclization are imposed as input. Experiments show that our model, despite trained with linear peptides, is capable of generating diverse target-binding cyclic peptides, reaching success rates from 38\\% to 84\\% on different cyclization strategies.", "bibtex": "@inproceedings{\njiang2025zeroshot,\ntitle={Zero-Shot Cyclic Peptide Design via Composable Geometric Constraints},\nauthor={Dapeng Jiang and Xiangzhe Kong and Jiaqi Han and Mingyu Li and Rui Jiao and Wenbing Huang and Stefano Ermon and Jianzhu Ma and Yang Liu},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=Q0rJmpLat9}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:56.080729Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "A Physics-Augmented Deep Learning Framework for Classifying Single Molecule Force Spectroscopy Data", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Cailong Hua", "Sivaraman Rajaganapathy", "Rebecca A Slick", "Joseph Vavra", "Joseph M. Muretta", "James M. Ervasti", "Murti Salapaka"], "affinity_score": 0.4911, "link": "https://openreview.net/pdf/490a55ebda1da4934c9bca9b499e5d2b2b459e92.pdf", "abstract": "Deciphering protein folding and unfolding pathways under tension is essential for deepening our understanding of fundamental biological mechanisms. Such insights hold the promise of developing treatments for a range of debilitating and fatal conditions, including muscular disorders like Duchenne Muscular Dystrophy and neurodegenerative diseases such as Parkinson's disease. Single molecule force spectroscopy (SMFS) is a powerful technique for investigating forces involved in protein domains folding and unfolding. However, SMFS trials often involve multiple protein molecules, necessitating filtering to isolate measurements from single-molecule trials. Currently, manual visual inspection is the primary method for classifying single-molecule data; a process that is both time-consuming and requires significant expertise. Here, we both apply state-of-the-art machine learning models and present a novel deep learning model tailored to SMFS data. The proposed model employs a dual-branch fusion strategy; one branch integrates the physics of protein molecules, and the other operates independently of physical constraints. This model automates the isolation of single-molecule measurements, significantly enhancing data processing efficiency. To train and validate our approach, we developed a physics-based Monte Carlo engine to simulate force spectroscopy datasets, including trials involving single molecules, multiple molecules, and no molecules. Our model achieves state-of-the-art performance, outperforming five baseline methods on both simulated and experimental datasets. It attains nearly 100\\% accuracy across all simulated datasets and an average accuracy of $79.6 \\pm 5.2$\\% on experimental datasets, using only $\\sim$30 training samples, surpassing baseline methods by 11.4\\%. Notably, even without expert annotations on experimental data, the model achieves an average accuracy of $72.0 \\pm 5.9$\\% when pre-trained on corresponding simulated datasets. With our deep learning approach, the time required to extract meaningful statistics from single-molecule SMFS trials is reduced from a day to under an hour. This work results in SMFS experimental datasets from four important protein molecules crucial to many biological pathways. To support further research, we have made our datasets publicly available and provided a Python-based toolbox (https://github.com/SalapakaLab-SIMBioSys/SMFS-Identification).", "bibtex": "@inproceedings{\nhua2025a,\ntitle={A Physics-Augmented Deep Learning Framework for Classifying Single Molecule Force Spectroscopy Data},\nauthor={Cailong Hua and Sivaraman Rajaganapathy and Rebecca A Slick and Joseph Vavra and Joseph M. Muretta and James M. Ervasti and Murti Salapaka},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=TamwbDvbdX}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:56.080731Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "DualMPNN: Harnessing Structural Alignments for High-Recovery Inverse Protein Folding", "venue": "NeurIPS 2025 Poster", "year": "2025", "authors": ["Xuhui Liao", "qiyu wang", "Zhiqiang Liang", "Liwei Xiao", "Junjie Chen"], "affinity_score": 0.4908, "link": "https://openreview.net/pdf/faba58f19ead837d5a34f3a9aef572473bfd2447.pdf", "abstract": "Inverse protein folding addresses the challenge of designing amino acid sequences that fold into a predetermined tertiary structure, bridging geometric and evolutionary constraints to advance protein engineering.  Inspired by the pivotal role of multiple sequence alignments (MSAs) in structure prediction models like AlphaFold, we hypothesize that structural alignments can provide an informative prior for inverse folding. In this study, we introduce DualMPNN, a dual-stream message passing neural network that leverages structurally homologous templates to guide amino acid sequence design of predefined query structures. DualMPNN processes the query and template proteins via two interactive branches, coupled through alignment-aware cross-stream attention mechanisms that enable exchange of geometric and co-evolutionary signals. Comprehensive evaluations across on CATH 4.2, TS50 and T500 benchmarks demonstrate DualMPNN achieves state-of-the-art recovery rates of 65.51\\%, 70.99\\%, and 70.37\\%, significantly outperforming base model ProteinMPNN by 15.64\\%, 16.56\\%, 12.29\\%, respectively. Further template quality analysis and structural foldability assessment underscore the value of structural alignment priors for protein design.", "bibtex": "@inproceedings{\nliao2025dualmpnn,\ntitle={Dual{MPNN}: Harnessing Structural Alignments for High-Recovery Inverse Protein Folding},\nauthor={Xuhui Liao and qiyu wang and Zhiqiang Liang and Liwei Xiao and Junjie Chen},\nbooktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},\nyear={2025},\nurl={https://openreview.net/forum?id=R42O6v84cX}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:56.080733Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "A Variational Perspective on Generative Protein Fitness Optimization", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Lea Bogensperger", "Dominik Narnhofer", "Ahmed Allam", "Konrad Schindler", "Michael Krauthammer"], "affinity_score": 0.4901, "link": "https://openreview.net/pdf/c282c82a853adc109e4abab365b8608c2f176daf.pdf", "abstract": "The goal of protein fitness optimization is to discover new protein variants with enhanced fitness for a given use. The vast search space and the sparsely populated fitness landscape, along with the discrete nature of protein sequences, pose significant challenges when trying to determine the gradient towards configurations with higher fitness. We introduce\nVariational Latent Generative Protein Optimization\n(VLGPO), a variational perspective on fitness optimization. Our method embeds protein sequences in a continuous latent space to enable efficient sampling from the fitness distribution and combines a (learned) flow matching prior over sequence mutations with a fitness predictor to guide optimization towards sequences with high fitness. VLGPO achieves state-of-the-art results on two different protein benchmarks of varying complexity. Moreover, the variational design with explicit prior and likelihood functions offers a flexible plug-and-play framework that can be easily customized to suit various protein design tasks.", "bibtex": "@inproceedings{\nbogensperger2025a,\ntitle={A Variational Perspective on Generative Protein Fitness Optimization},\nauthor={Lea Bogensperger and Dominik Narnhofer and Ahmed Allam and Konrad Schindler and Michael Krauthammer},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=fINjgBMnTS}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:56.080736Z"}
{"search_index": 1, "query": "science agent biology protein-function", "title": "Physics Aware Neural Networks for Unsupervised Binding Energy Prediction", "venue": "ICML 2025 Poster", "year": "2025", "authors": ["Ke Liu", "Hao Chen", "Chunhua Shen"], "affinity_score": 0.4896, "link": "https://openreview.net/pdf/980242a987d742e30b1c373f26ad39b58b4754d2.pdf", "abstract": "Developing models for protein-ligand interactions holds substantial significance for drug discovery. Supervised methods often failed due to the lack of labeled data for predicting the protein-ligand binding energy, like antibodies. Therefore, unsupervised approaches are urged to make full use of the unlabeled data. To tackle the problem, we propose an efficient, unsupervised protein-ligand binding energy prediction model via the conservation of energy (CEBind), which follows the physical laws. Specifically, given a protein-ligand complex, we randomly sample forces for each atom in the ligand. Then these forces are applied rigidly to the ligand to perturb its position, following the law of rigid body dynamics. Finally, CEBind predicts the energy of both the unperturbed complex and the perturbed complex. The energy gap between two complexes equals the work of the outer forces, following the law of conservation of energy. Extensive experiments are conducted on the unsupervised protein-ligand binding energy prediction benchmarks, comparing them with previous works. Empirical results and theoretic analysis demonstrate that CEBind is more efficient and outperforms previous unsupervised models on benchmarks.", "bibtex": "@inproceedings{\nliu2025physics,\ntitle={Physics Aware Neural Networks for Unsupervised Binding Energy Prediction},\nauthor={Ke Liu and Hao Chen and Chunhua Shen},\nbooktitle={Forty-second International Conference on Machine Learning},\nyear={2025},\nurl={https://openreview.net/forum?id=ZPqj44Knpd}\n}", "pdf_path": null, "retrieved_at": "2025-11-15T21:00:56.080738Z"}
