# Agentic LLMs & Hierarchical Planning for Protein Function Annotation

## LLM Agents Orchestrating Annotation Pipelines

Recent research has explored using *agentic* large language models (LLMs) as planners in protein/gene function annotation workflows. For example, **GeneWhisperer** (2025) is an AI assistant for genome annotation that embeds an LLM “agent” in a conversational interface. GeneWhisperer’s LLM dynamically calls external bioinformatics tools as needed – e.g. performing sequence homology searches via BLAST – to assist human curators. The system provides access to domain-specific tools within the LLM’s reasoning loop, allowing multi-step curation tasks to be carried out interactively. In one demonstration, GeneWhisperer autonomously invoked an NCBI BLAST search for a query sequence and incorporated the results to answer a functional question. By leveraging such tool-use capabilities, the LLM can retrieve homologous sequences and associated annotations on the fly, then integrate that evidence into its responses. Notably, GeneWhisperer uses a retrieval-augmented generation (RAG) approach – embedding results from BLAST or literature databases into the LLM’s context – which **significantly improves accuracy** of its answers. This agent paradigm *synergizes* AI and human expertise: the LLM handles tedious searches/analysis, while the human provides guidance, yielding a more efficient manual annotation process.

Another example is **GeneAgent** (2024), which tackles gene set enrichment and functional genomics analysis using an autonomous LLM-based agent. GeneAgent connects to multiple biological knowledge bases (e.g. Gene Ontology, pathway databases) as tools. It features a *self-verification* module that prompts the LLM to double-check its own outputs against those databases, reducing hallucinations. This structured agent workflow leads to notable accuracy gains – in benchmarks on 1,106 gene sets, GeneAgent **outperformed a standard GPT-4** baseline by a significant margin. The self-verification step was effective in catching and correcting incorrect gene-function associations, resulting in more trustworthy annotations. These results highlight how deterministic tool integration and feedback can bolster LLM performance on scientific tasks. By having the LLM **“show its work”** through database queries and validation, GeneAgent produces high-confidence functional narratives rather than unsupported guesses.

## Structured Action Plans (“Action IR”)

A key innovation in these systems is the use of **structured intermediate representations** for actions – essentially, explicit plans or scripts that the LLM formulates and then executes step-by-step. In general LLM-agent research, unstructured free-text plans can lead to ambiguity or tool misuse. Recent frameworks address this by introducing a formal **plan-then-act** paradigm with a defined action language. For instance, the *Routine* planning framework (2025) has the LLM output a well-formatted “Routine script” encoding each subtask and tool call, which an execution engine then follows deterministically. This **plan script IR** acts as a transparent bridge between the LLM’s high-level reasoning and the actual tool APIs. Such hierarchical *macro-to-micro* planning (high-level task ➔ concrete tool commands) greatly improves reliability. In evaluations, forcing GPT-4 to produce a structured plan before acting boosted correct tool use from \~41% to over 96%. It prevents the model from skipping essential steps or mis-formatting API calls, issues noted with ad-hoc planning. The idea of **hierarchical decomposition** is that the LLM first outlines a macro-plan (e.g. *“1. Find similar sequences; 2. Retrieve their GO terms; 3. Compile enriched functions”*), then proceeds through each micro-action with appropriate tools. This approach has begun to influence bioinformatics pipelines – for example, GeneWhisperer implements **tool-specific prompts** (wrappers) for BLAST, literature search, GO term mapping, etc., ensuring the LLM’s instructions to each tool are precisely structured. The agent’s internal plan can thus be represented in a formalized manner (an “Action IR”) that the system executes deterministically, bringing much-needed traceability and consistency to complex annotation workflows.

## Multi-Step Workflows in CAFA5 and Protein Annotation

The **CAFA5** challenge (2023) exemplified the power of multi-step, integrated pipelines for protein function prediction. While not all top methods explicitly used LLM agents, their designs foreshadow the value of orchestrating diverse knowledge sources – a role that LLM planners can fill. Notably, the winning system (**GoCurator**) and other top teams went beyond sequence-only prediction by incorporating *literature mining* and ontology knowledge into their models. For example, GoCurator encoded textual information from research papers mentioning a given protein (e.g. functional descriptions in UniProt or PMIDs) into feature vectors that complemented sequence-based features. This “text-in-the-loop” approach is akin to an LLM agent retrieving relevant literature as context. In fact, it proved very effective: new functional insights often appear in literature before being formalized as database annotations, so text mining gave these models a preview of forthcoming annotations. We can envision an LLM agent replicating this by automatically querying papers or summaries about a protein and extracting likely functions.

Top CAFA5 methods also integrated *other modalities* in a structured pipeline. One leading team combined **structure predictions, protein–protein interactions, and domain family (Pfam) data** to enrich their function predictions. For instance, they used AlphaFold2 to generate 3D structure models and perform structural alignments, leveraged known interaction networks to propagate functions through protein–protein links, and checked Pfam domains for motif-based annotations. Each of these steps provides a piece of evidence toward a protein’s role. A future agentic LLM could coordinate such steps: e.g. *“If sequence homology is weak, try a structural comparison; if a known domain is detected, suggest functions from that domain’s ontology; if the protein is in an interaction network, see if neighbors have known GO terms,”* and so on. By planning conditionally like this, the LLM would implement a **macro-to-micro strategy**, ensuring all relevant angles (sequence, structure, network, text) are explored. Indeed, researchers are beginning to use LLMs as *orchestrators* that call specialized models/services for each aspect of the annotation task, then synthesize the results. The **ProtGPT** and **ProteinChat** initiatives, for example, have developed multi-modal LLM systems that take protein sequences and generate functional insights in dialogue form. These systems combine a protein encoder (for sequence/structure input) with a language model, effectively letting the LLM “see” the protein and reason about its function in natural language. This is another form of integration – marrying hard biophysical data with the soft reasoning of an LLM. While such models are trained end-to-end rather than performing explicit tool calls, they underscore the trend of **structured multi-step reasoning** for protein function. In summary, the state-of-the-art is moving toward *holistic pipelines* where an LLM (explicitly or implicitly) coordinates various analytic steps – from sequence alignment and GO term mapping to literature review – to produce accurate and richly justified protein annotations.

## Notable Innovations and Impact

Across these efforts, several innovations stand out as particularly relevant to protein function annotation:

* **Structured Action Planning:** Formulating intermediate action plans (an *“Action IR”*) for the annotation process has improved reproducibility and correctness. By constraining an LLM to output plans in a formal schema (as with Routine or tool-specific prompts), researchers achieved far higher success rates in complex multi-tool sequences. This approach is directly applicable to bioinformatics pipelines, where the cost of an error (e.g. mis-parsing a BLAST output) can be high. A structured plan ensures each step (search, alignment, mapping, etc.) happens in the right order with the right parameters.

* **Deterministic Tool Integration:** Agentic LLM systems now routinely integrate deterministic engines like BLAST, HMMER, or GO enrichment tools as part of the workflow. GeneWhisperer’s ability to run BLAST on demand and feed the alignments into its context is a prime example. This guarantees that the LLM’s reasoning is grounded in actual sequence similarity data rather than free-form guesswork. The *combination* of neural and symbolic methods – LLM for reasoning plus conventional bioinformatics tools for scoring alignments or retrieving ontology terms – leverages the strength of each. It mitigates the LLM’s tendency to hallucinate by tethering its decisions to database results.

* **Self-Verification and Accuracy Checks:** Borrowing from ideas in software agents, bioinformatics LLMs have started to include verification steps to improve reliability. GeneAgent’s self-verification module, which cross-checks the LLM’s proposed gene functions against curated databases, is one such innovation. Another emerging idea is to have the LLM reason about confidence: e.g. *“Do the retrieved homologs actually support this GO term prediction?”* and if not, adjust its plan. By explicitly modeling uncertainty and verification, these systems are achieving higher precision in function prediction – a critical need in the face of vast, noisy sequence data.

* **Multi-Modal and Hierarchical Reasoning:** The integration of sequence, structure, network, and textual evidence in CAFA5 methods demonstrates the value of multi-modal reasoning. Hierarchical planning allows an LLM to decide **which modality to invoke next**. For instance, an agent might start with a quick sequence scan (fast, low info), then escalate to a more complex structural analysis if needed (slower but potentially more informative) – a macro-to-micro decision process. This kind of hierarchical tool use was manually encoded in some CAFA5 pipelines; going forward, LLMs can be tasked with making these choices dynamically. Early frameworks like *Manus* already split the workflow into Planner, Executor, and Verifier stages for accuracy and traceability. In protein annotation, this could translate to a Planner suggesting a series of analyses (homology search → motif scan → network query), an Executor running them, and a Verifier (which could be another LLM or rule-based checker) ensuring the results make sense before finalizing the annotation.

In conclusion, the landscape of protein function prediction is being enriched by these agentic LLM approaches. By structuring the *thinking process* of an LLM into discrete, tool-grounded actions, researchers are achieving more accurate and explainable annotations. The CAFA5 challenge affirmed that no single model or modality suffices; rather, a *coordinated workflow* is needed. LLMs, when used as intelligent orchestrators, offer a flexible way to implement such workflows – planning at a high level and drilling down to micro-tasks as required. This fusion of **AI reasoning with bioinformatics domain tools** is yielding state-of-the-art results and holds promise for tackling the ever-growing deluge of unannotated proteins in genomic databases. By adopting structured action representations and hierarchical planning, future annotation systems can become more **agentic**, accurate, and integrative, ultimately accelerating discoveries in functional genomics.
